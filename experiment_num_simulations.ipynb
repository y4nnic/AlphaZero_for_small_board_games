{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: TicTacToe - Number of simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from pipeline import Pipeline, agent_vs_player, agent_vs_agent\n",
    "import memory\n",
    "import model\n",
    "import agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCTS = {\n",
    "    'c_puct': 5,\n",
    "    'dir_alpha': 0.6,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 10,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 10\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 1,\n",
    "    'temperature': 0,\n",
    "    'show_games': False\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 1,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.002,\n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 512,\n",
    "    'num_filters_value': 512,\n",
    "    'num_filters_tower': 512,\n",
    "    'num_residual_blocks': 3,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 512\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"tictactoe_num_sim_1\", \"TicTacToe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 4s 989us/step - loss: 6.6843 - value_loss: 0.9239 - policy_loss: 2.3581 - val_loss: 6.5520 - val_value_loss: 0.8064 - val_policy_loss: 2.2115\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.4751 - value_loss: 0.7455 - policy_loss: 2.1189 - val_loss: 6.4954 - val_value_loss: 0.8230 - val_policy_loss: 2.0823\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.3850 - value_loss: 0.6970 - policy_loss: 1.9877 - val_loss: 6.4347 - val_value_loss: 0.7815 - val_policy_loss: 2.0031\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.3257 - value_loss: 0.6680 - policy_loss: 1.8989 - val_loss: 6.4435 - val_value_loss: 0.8511 - val_policy_loss: 1.9516\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.2631 - value_loss: 0.6135 - policy_loss: 1.8288 - val_loss: 6.3638 - val_value_loss: 0.7402 - val_policy_loss: 1.9038\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2392 - value_loss: 0.6185 - policy_loss: 1.7766 - val_loss: 6.3547 - val_value_loss: 0.7561 - val_policy_loss: 1.8703\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1776 - value_loss: 0.5405 - policy_loss: 1.7320 - val_loss: 6.3139 - val_value_loss: 0.7062 - val_policy_loss: 1.8393\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1391 - value_loss: 0.5029 - policy_loss: 1.6932 - val_loss: 6.3175 - val_value_loss: 0.7350 - val_policy_loss: 1.8183\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1378 - value_loss: 0.5313 - policy_loss: 1.6628 - val_loss: 6.3033 - val_value_loss: 0.7286 - val_policy_loss: 1.7969\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1135 - value_loss: 0.5076 - policy_loss: 1.6385 - val_loss: 6.2864 - val_value_loss: 0.7120 - val_policy_loss: 1.7805\n",
      "Saved model  tictactoe_num_sim_1_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.54 - draw ratio 0.23\n",
      "Number of seen trajectories: 100\n",
      "Number of unique trajectories: 100\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.2614 - value_loss: 0.6666 - policy_loss: 1.7761 - val_loss: 6.2144 - val_value_loss: 0.6266 - val_policy_loss: 1.7223\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.2113 - value_loss: 0.6272 - policy_loss: 1.7160 - val_loss: 6.1944 - val_value_loss: 0.6094 - val_policy_loss: 1.7002\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1581 - value_loss: 0.5658 - policy_loss: 1.6714 - val_loss: 6.1756 - val_value_loss: 0.5936 - val_policy_loss: 1.6792\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1396 - value_loss: 0.5637 - policy_loss: 1.6373 - val_loss: 6.1717 - val_value_loss: 0.5967 - val_policy_loss: 1.6688\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0976 - value_loss: 0.5092 - policy_loss: 1.6084 - val_loss: 6.2015 - val_value_loss: 0.6694 - val_policy_loss: 1.6563\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0809 - value_loss: 0.5009 - policy_loss: 1.5839 - val_loss: 6.1722 - val_value_loss: 0.6293 - val_policy_loss: 1.6385\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0798 - value_loss: 0.5200 - policy_loss: 1.5634 - val_loss: 6.1503 - val_value_loss: 0.5929 - val_policy_loss: 1.6317\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0644 - value_loss: 0.5071 - policy_loss: 1.5459 - val_loss: 6.1512 - val_value_loss: 0.6064 - val_policy_loss: 1.6207\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0342 - value_loss: 0.4648 - policy_loss: 1.5285 - val_loss: 6.1595 - val_value_loss: 0.6337 - val_policy_loss: 1.6106\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0406 - value_loss: 0.4933 - policy_loss: 1.5134 - val_loss: 6.1872 - val_value_loss: 0.6955 - val_policy_loss: 1.6049\n",
      "Saved model  tictactoe_num_sim_1_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.48 - draw ratio 0.16\n",
      "Number of seen trajectories: 200\n",
      "Number of unique trajectories: 199\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 180us/step - loss: 6.1629 - value_loss: 0.6574 - policy_loss: 1.5946 - val_loss: 6.1361 - val_value_loss: 0.6258 - val_policy_loss: 1.5729\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1016 - value_loss: 0.5850 - policy_loss: 1.5451 - val_loss: 6.1193 - val_value_loss: 0.6130 - val_policy_loss: 1.5529\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0729 - value_loss: 0.5579 - policy_loss: 1.5155 - val_loss: 6.0898 - val_value_loss: 0.5703 - val_policy_loss: 1.5371\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0508 - value_loss: 0.5390 - policy_loss: 1.4908 - val_loss: 6.0887 - val_value_loss: 0.5794 - val_policy_loss: 1.5265\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0374 - value_loss: 0.5275 - policy_loss: 1.4760 - val_loss: 6.0755 - val_value_loss: 0.5638 - val_policy_loss: 1.5163\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0185 - value_loss: 0.5067 - policy_loss: 1.4597 - val_loss: 6.0739 - val_value_loss: 0.5644 - val_policy_loss: 1.5132\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0047 - value_loss: 0.4959 - policy_loss: 1.4434 - val_loss: 6.0708 - val_value_loss: 0.5652 - val_policy_loss: 1.5068\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.9921 - value_loss: 0.4849 - policy_loss: 1.4299 - val_loss: 6.0611 - val_value_loss: 0.5580 - val_policy_loss: 1.4952\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9877 - value_loss: 0.4870 - policy_loss: 1.4198 - val_loss: 6.0648 - val_value_loss: 0.5690 - val_policy_loss: 1.4923\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9783 - value_loss: 0.4796 - policy_loss: 1.4090 - val_loss: 6.0640 - val_value_loss: 0.5696 - val_policy_loss: 1.4906\n",
      "Saved model  tictactoe_num_sim_1_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.56 - draw ratio 0.04\n",
      "Number of seen trajectories: 300\n",
      "Number of unique trajectories: 292\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 6.0790 - value_loss: 0.6735 - policy_loss: 1.4171 - val_loss: 6.0444 - val_value_loss: 0.6516 - val_policy_loss: 1.3702\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0256 - value_loss: 0.6062 - policy_loss: 1.3783 - val_loss: 6.0164 - val_value_loss: 0.6228 - val_policy_loss: 1.3437\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9960 - value_loss: 0.5688 - policy_loss: 1.3571 - val_loss: 6.0019 - val_value_loss: 0.6001 - val_policy_loss: 1.3378\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9710 - value_loss: 0.5368 - policy_loss: 1.3397 - val_loss: 5.9948 - val_value_loss: 0.5976 - val_policy_loss: 1.3269\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9617 - value_loss: 0.5340 - policy_loss: 1.3244 - val_loss: 5.9869 - val_value_loss: 0.5888 - val_policy_loss: 1.3204\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.9428 - value_loss: 0.5082 - policy_loss: 1.3131 - val_loss: 5.9808 - val_value_loss: 0.5798 - val_policy_loss: 1.3179\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9363 - value_loss: 0.5048 - policy_loss: 1.3043 - val_loss: 5.9807 - val_value_loss: 0.5909 - val_policy_loss: 1.3073\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.9252 - value_loss: 0.4919 - policy_loss: 1.2955 - val_loss: 5.9822 - val_value_loss: 0.5892 - val_policy_loss: 1.3125\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.9282 - value_loss: 0.5073 - policy_loss: 1.2869 - val_loss: 5.9746 - val_value_loss: 0.5840 - val_policy_loss: 1.3032\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.9140 - value_loss: 0.4835 - policy_loss: 1.2827 - val_loss: 5.9680 - val_value_loss: 0.5715 - val_policy_loss: 1.3032\n",
      "Saved model  tictactoe_num_sim_1_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.57 - draw ratio 0.1\n",
      "Number of seen trajectories: 400\n",
      "Number of unique trajectories: 379\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.9712 - value_loss: 0.6010 - policy_loss: 1.2803 - val_loss: 5.9532 - val_value_loss: 0.5550 - val_policy_loss: 1.2907\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9361 - value_loss: 0.5624 - policy_loss: 1.2493 - val_loss: 5.9427 - val_value_loss: 0.5472 - val_policy_loss: 1.2780\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9101 - value_loss: 0.5315 - policy_loss: 1.2289 - val_loss: 5.9390 - val_value_loss: 0.5401 - val_policy_loss: 1.2785\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.8953 - value_loss: 0.5120 - policy_loss: 1.2195 - val_loss: 5.9314 - val_value_loss: 0.5363 - val_policy_loss: 1.2676\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.8840 - value_loss: 0.5015 - policy_loss: 1.2080 - val_loss: 5.9299 - val_value_loss: 0.5408 - val_policy_loss: 1.2608\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.8745 - value_loss: 0.4927 - policy_loss: 1.1984 - val_loss: 5.9357 - val_value_loss: 0.5479 - val_policy_loss: 1.2659\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.8718 - value_loss: 0.4931 - policy_loss: 1.1933 - val_loss: 5.9288 - val_value_loss: 0.5394 - val_policy_loss: 1.2613\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.8631 - value_loss: 0.4833 - policy_loss: 1.1862 - val_loss: 5.9259 - val_value_loss: 0.5418 - val_policy_loss: 1.2537\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.8637 - value_loss: 0.4889 - policy_loss: 1.1825 - val_loss: 5.9277 - val_value_loss: 0.5471 - val_policy_loss: 1.2526\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.8557 - value_loss: 0.4819 - policy_loss: 1.1742 - val_loss: 5.9336 - val_value_loss: 0.5551 - val_policy_loss: 1.2573\n",
      "Saved model  tictactoe_num_sim_1_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.57 - draw ratio 0.09\n",
      "Number of seen trajectories: 500\n",
      "Number of unique trajectories: 449\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 181us/step - loss: 5.8728 - value_loss: 0.5326 - policy_loss: 1.1582 - val_loss: 5.8936 - val_value_loss: 0.5491 - val_policy_loss: 1.1834\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.8540 - value_loss: 0.5072 - policy_loss: 1.1463 - val_loss: 5.8859 - val_value_loss: 0.5393 - val_policy_loss: 1.1783\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.8431 - value_loss: 0.4942 - policy_loss: 1.1378 - val_loss: 5.8816 - val_value_loss: 0.5380 - val_policy_loss: 1.1712\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.8332 - value_loss: 0.4807 - policy_loss: 1.1318 - val_loss: 5.8787 - val_value_loss: 0.5358 - val_policy_loss: 1.1680\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.8278 - value_loss: 0.4759 - policy_loss: 1.1262 - val_loss: 5.8775 - val_value_loss: 0.5347 - val_policy_loss: 1.1669\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.8227 - value_loss: 0.4692 - policy_loss: 1.1231 - val_loss: 5.8766 - val_value_loss: 0.5368 - val_policy_loss: 1.1634\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.8180 - value_loss: 0.4660 - policy_loss: 1.1170 - val_loss: 5.8750 - val_value_loss: 0.5364 - val_policy_loss: 1.1609\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.8148 - value_loss: 0.4623 - policy_loss: 1.1147 - val_loss: 5.8727 - val_value_loss: 0.5336 - val_policy_loss: 1.1593\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.8122 - value_loss: 0.4605 - policy_loss: 1.1116 - val_loss: 5.8712 - val_value_loss: 0.5322 - val_policy_loss: 1.1581\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.8086 - value_loss: 0.4549 - policy_loss: 1.1102 - val_loss: 5.8708 - val_value_loss: 0.5341 - val_policy_loss: 1.1556\n",
      "Saved model  tictactoe_num_sim_1_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.58 - draw ratio 0.05\n",
      "Number of seen trajectories: 600\n",
      "Number of unique trajectories: 508\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 5.8447 - value_loss: 0.5225 - policy_loss: 1.1154 - val_loss: 5.8702 - val_value_loss: 0.5412 - val_policy_loss: 1.1477\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.8265 - value_loss: 0.4982 - policy_loss: 1.1035 - val_loss: 5.8630 - val_value_loss: 0.5284 - val_policy_loss: 1.1465\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.8174 - value_loss: 0.4856 - policy_loss: 1.0982 - val_loss: 5.8590 - val_value_loss: 0.5240 - val_policy_loss: 1.1433\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.8112 - value_loss: 0.4788 - policy_loss: 1.0929 - val_loss: 5.8542 - val_value_loss: 0.5210 - val_policy_loss: 1.1369\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.8075 - value_loss: 0.4739 - policy_loss: 1.0907 - val_loss: 5.8545 - val_value_loss: 0.5190 - val_policy_loss: 1.1399\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.8036 - value_loss: 0.4710 - policy_loss: 1.0862 - val_loss: 5.8565 - val_value_loss: 0.5225 - val_policy_loss: 1.1405\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.8012 - value_loss: 0.4681 - policy_loss: 1.0845 - val_loss: 5.8523 - val_value_loss: 0.5181 - val_policy_loss: 1.1371\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7971 - value_loss: 0.4640 - policy_loss: 1.0807 - val_loss: 5.8474 - val_value_loss: 0.5131 - val_policy_loss: 1.1325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7954 - value_loss: 0.4631 - policy_loss: 1.0786 - val_loss: 5.8470 - val_value_loss: 0.5125 - val_policy_loss: 1.1326\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7924 - value_loss: 0.4581 - policy_loss: 1.0778 - val_loss: 5.8485 - val_value_loss: 0.5148 - val_policy_loss: 1.1337\n",
      "Saved model  tictactoe_num_sim_1_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.67 - draw ratio 0.07\n",
      "Number of seen trajectories: 700\n",
      "Number of unique trajectories: 568\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 5.8382 - value_loss: 0.5335 - policy_loss: 1.0945 - val_loss: 5.8730 - val_value_loss: 0.5572 - val_policy_loss: 1.1407\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.8245 - value_loss: 0.5131 - policy_loss: 1.0878 - val_loss: 5.8700 - val_value_loss: 0.5540 - val_policy_loss: 1.1380\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.8195 - value_loss: 0.5050 - policy_loss: 1.0862 - val_loss: 5.8693 - val_value_loss: 0.5517 - val_policy_loss: 1.1392\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.8110 - value_loss: 0.4951 - policy_loss: 1.0795 - val_loss: 5.8659 - val_value_loss: 0.5490 - val_policy_loss: 1.1356\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.8081 - value_loss: 0.4910 - policy_loss: 1.0780 - val_loss: 5.8640 - val_value_loss: 0.5456 - val_policy_loss: 1.1354\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.8049 - value_loss: 0.4872 - policy_loss: 1.0758 - val_loss: 5.8625 - val_value_loss: 0.5453 - val_policy_loss: 1.1331\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.8033 - value_loss: 0.4869 - policy_loss: 1.0732 - val_loss: 5.8611 - val_value_loss: 0.5439 - val_policy_loss: 1.1319\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.8008 - value_loss: 0.4835 - policy_loss: 1.0718 - val_loss: 5.8604 - val_value_loss: 0.5439 - val_policy_loss: 1.1308\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7983 - value_loss: 0.4807 - policy_loss: 1.0699 - val_loss: 5.8601 - val_value_loss: 0.5435 - val_policy_loss: 1.1310\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7977 - value_loss: 0.4814 - policy_loss: 1.0685 - val_loss: 5.8584 - val_value_loss: 0.5429 - val_policy_loss: 1.1285\n",
      "Saved model  tictactoe_num_sim_1_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.6 - draw ratio 0.06\n",
      "Number of seen trajectories: 800\n",
      "Number of unique trajectories: 624\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 5.8010 - value_loss: 0.4744 - policy_loss: 1.0824 - val_loss: 5.8152 - val_value_loss: 0.4623 - val_policy_loss: 1.1229\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.7891 - value_loss: 0.4548 - policy_loss: 1.0785 - val_loss: 5.8113 - val_value_loss: 0.4601 - val_policy_loss: 1.1178\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.7801 - value_loss: 0.4400 - policy_loss: 1.0756 - val_loss: 5.8096 - val_value_loss: 0.4589 - val_policy_loss: 1.1160\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.7748 - value_loss: 0.4326 - policy_loss: 1.0728 - val_loss: 5.8109 - val_value_loss: 0.4614 - val_policy_loss: 1.1164\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.7716 - value_loss: 0.4272 - policy_loss: 1.0720 - val_loss: 5.8109 - val_value_loss: 0.4631 - val_policy_loss: 1.1149\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7691 - value_loss: 0.4236 - policy_loss: 1.0709 - val_loss: 5.8110 - val_value_loss: 0.4650 - val_policy_loss: 1.1134\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.7653 - value_loss: 0.4198 - policy_loss: 1.0675 - val_loss: 5.8121 - val_value_loss: 0.4675 - val_policy_loss: 1.1134\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.7644 - value_loss: 0.4189 - policy_loss: 1.0669 - val_loss: 5.8105 - val_value_loss: 0.4685 - val_policy_loss: 1.1097\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7620 - value_loss: 0.4167 - policy_loss: 1.0646 - val_loss: 5.8100 - val_value_loss: 0.4687 - val_policy_loss: 1.1088\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.7601 - value_loss: 0.4137 - policy_loss: 1.0642 - val_loss: 5.8093 - val_value_loss: 0.4688 - val_policy_loss: 1.1076\n",
      "Saved model  tictactoe_num_sim_1_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.61 - draw ratio 0.09\n",
      "Number of seen trajectories: 900\n",
      "Number of unique trajectories: 660\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.8128 - value_loss: 0.4944 - policy_loss: 1.0890 - val_loss: 5.7918 - val_value_loss: 0.4783 - val_policy_loss: 1.0633\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7979 - value_loss: 0.4696 - policy_loss: 1.0846 - val_loss: 5.7832 - val_value_loss: 0.4659 - val_policy_loss: 1.0588\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7892 - value_loss: 0.4557 - policy_loss: 1.0813 - val_loss: 5.7828 - val_value_loss: 0.4664 - val_policy_loss: 1.0580\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7828 - value_loss: 0.4462 - policy_loss: 1.0782 - val_loss: 5.7765 - val_value_loss: 0.4546 - val_policy_loss: 1.0576\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7776 - value_loss: 0.4371 - policy_loss: 1.0774 - val_loss: 5.7758 - val_value_loss: 0.4544 - val_policy_loss: 1.0567\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7740 - value_loss: 0.4308 - policy_loss: 1.0768 - val_loss: 5.7731 - val_value_loss: 0.4516 - val_policy_loss: 1.0544\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7707 - value_loss: 0.4278 - policy_loss: 1.0734 - val_loss: 5.7782 - val_value_loss: 0.4584 - val_policy_loss: 1.0581\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7703 - value_loss: 0.4259 - policy_loss: 1.0749 - val_loss: 5.7756 - val_value_loss: 0.4566 - val_policy_loss: 1.0549\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.7684 - value_loss: 0.4242 - policy_loss: 1.0732 - val_loss: 5.7682 - val_value_loss: 0.4454 - val_policy_loss: 1.0516\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7656 - value_loss: 0.4198 - policy_loss: 1.0723 - val_loss: 5.7703 - val_value_loss: 0.4486 - val_policy_loss: 1.0531\n",
      "Saved model  tictactoe_num_sim_1_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.57 - draw ratio 0.07\n",
      "Number of seen trajectories: 1000\n",
      "Number of unique trajectories: 709\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 5.8240 - value_loss: 0.5401 - policy_loss: 1.0688 - val_loss: 5.7836 - val_value_loss: 0.5006 - val_policy_loss: 1.0277\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.8135 - value_loss: 0.5208 - policy_loss: 1.0675 - val_loss: 5.7822 - val_value_loss: 0.4973 - val_policy_loss: 1.0284\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.8065 - value_loss: 0.5091 - policy_loss: 1.0652 - val_loss: 5.7805 - val_value_loss: 0.4960 - val_policy_loss: 1.0264\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.8021 - value_loss: 0.5012 - policy_loss: 1.0646 - val_loss: 5.7792 - val_value_loss: 0.4950 - val_policy_loss: 1.0251\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7982 - value_loss: 0.4956 - policy_loss: 1.0624 - val_loss: 5.7801 - val_value_loss: 0.4963 - val_policy_loss: 1.0257\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7959 - value_loss: 0.4915 - policy_loss: 1.0621 - val_loss: 5.7796 - val_value_loss: 0.4967 - val_policy_loss: 1.0246\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7935 - value_loss: 0.4881 - policy_loss: 1.0609 - val_loss: 5.7799 - val_value_loss: 0.4983 - val_policy_loss: 1.0235\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7930 - value_loss: 0.4871 - policy_loss: 1.0612 - val_loss: 5.7793 - val_value_loss: 0.4978 - val_policy_loss: 1.0231\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7899 - value_loss: 0.4821 - policy_loss: 1.0600 - val_loss: 5.7789 - val_value_loss: 0.4978 - val_policy_loss: 1.0224\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7875 - value_loss: 0.4797 - policy_loss: 1.0578 - val_loss: 5.7792 - val_value_loss: 0.4986 - val_policy_loss: 1.0223\n",
      "Saved model  tictactoe_num_sim_1_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.66 - draw ratio 0.02\n",
      "Number of seen trajectories: 1100\n",
      "Number of unique trajectories: 748\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 180us/step - loss: 5.8037 - value_loss: 0.5010 - policy_loss: 1.0690 - val_loss: 5.8347 - val_value_loss: 0.5538 - val_policy_loss: 1.0783\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7927 - value_loss: 0.4814 - policy_loss: 1.0668 - val_loss: 5.8305 - val_value_loss: 0.5455 - val_policy_loss: 1.0783\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7844 - value_loss: 0.4666 - policy_loss: 1.0653 - val_loss: 5.8262 - val_value_loss: 0.5387 - val_policy_loss: 1.0768\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7787 - value_loss: 0.4576 - policy_loss: 1.0630 - val_loss: 5.8254 - val_value_loss: 0.5367 - val_policy_loss: 1.0772\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7738 - value_loss: 0.4491 - policy_loss: 1.0618 - val_loss: 5.8227 - val_value_loss: 0.5321 - val_policy_loss: 1.0767\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7708 - value_loss: 0.4446 - policy_loss: 1.0605 - val_loss: 5.8195 - val_value_loss: 0.5274 - val_policy_loss: 1.0751\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7680 - value_loss: 0.4396 - policy_loss: 1.0600 - val_loss: 5.8191 - val_value_loss: 0.5273 - val_policy_loss: 1.0746\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7654 - value_loss: 0.4355 - policy_loss: 1.0591 - val_loss: 5.8186 - val_value_loss: 0.5261 - val_policy_loss: 1.0748\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7644 - value_loss: 0.4342 - policy_loss: 1.0584 - val_loss: 5.8182 - val_value_loss: 0.5261 - val_policy_loss: 1.0744\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7621 - value_loss: 0.4313 - policy_loss: 1.0569 - val_loss: 5.8177 - val_value_loss: 0.5261 - val_policy_loss: 1.0735\n",
      "Saved model  tictactoe_num_sim_1_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.62 - draw ratio 0.06\n",
      "Number of seen trajectories: 1200\n",
      "Number of unique trajectories: 788\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7556 - value_loss: 0.4345 - policy_loss: 1.0409 - val_loss: 5.8025 - val_value_loss: 0.4711 - val_policy_loss: 1.0981\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7470 - value_loss: 0.4189 - policy_loss: 1.0396 - val_loss: 5.7988 - val_value_loss: 0.4661 - val_policy_loss: 1.0961\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7427 - value_loss: 0.4111 - policy_loss: 1.0390 - val_loss: 5.7966 - val_value_loss: 0.4631 - val_policy_loss: 1.0947\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7394 - value_loss: 0.4066 - policy_loss: 1.0368 - val_loss: 5.7949 - val_value_loss: 0.4607 - val_policy_loss: 1.0939\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7372 - value_loss: 0.4030 - policy_loss: 1.0363 - val_loss: 5.7941 - val_value_loss: 0.4597 - val_policy_loss: 1.0934\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7353 - value_loss: 0.4008 - policy_loss: 1.0348 - val_loss: 5.7930 - val_value_loss: 0.4587 - val_policy_loss: 1.0924\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7333 - value_loss: 0.3974 - policy_loss: 1.0344 - val_loss: 5.7916 - val_value_loss: 0.4573 - val_policy_loss: 1.0912\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7324 - value_loss: 0.3957 - policy_loss: 1.0344 - val_loss: 5.7911 - val_value_loss: 0.4568 - val_policy_loss: 1.0908\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7305 - value_loss: 0.3945 - policy_loss: 1.0321 - val_loss: 5.7907 - val_value_loss: 0.4565 - val_policy_loss: 1.0905\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7295 - value_loss: 0.3925 - policy_loss: 1.0322 - val_loss: 5.7899 - val_value_loss: 0.4557 - val_policy_loss: 1.0899\n",
      "Saved model  tictactoe_num_sim_1_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.62 - draw ratio 0.04\n",
      "Number of seen trajectories: 1300\n",
      "Number of unique trajectories: 813\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7940 - value_loss: 0.5035 - policy_loss: 1.0504 - val_loss: 5.7430 - val_value_loss: 0.4132 - val_policy_loss: 1.0387\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7846 - value_loss: 0.4872 - policy_loss: 1.0480 - val_loss: 5.7382 - val_value_loss: 0.4060 - val_policy_loss: 1.0365\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7791 - value_loss: 0.4774 - policy_loss: 1.0470 - val_loss: 5.7388 - val_value_loss: 0.4059 - val_policy_loss: 1.0379\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7747 - value_loss: 0.4699 - policy_loss: 1.0458 - val_loss: 5.7381 - val_value_loss: 0.4043 - val_policy_loss: 1.0383\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7707 - value_loss: 0.4635 - policy_loss: 1.0444 - val_loss: 5.7354 - val_value_loss: 0.4000 - val_policy_loss: 1.0373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7685 - value_loss: 0.4595 - policy_loss: 1.0442 - val_loss: 5.7357 - val_value_loss: 0.4016 - val_policy_loss: 1.0364\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7654 - value_loss: 0.4549 - policy_loss: 1.0427 - val_loss: 5.7352 - val_value_loss: 0.4009 - val_policy_loss: 1.0363\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7640 - value_loss: 0.4519 - policy_loss: 1.0431 - val_loss: 5.7361 - val_value_loss: 0.4027 - val_policy_loss: 1.0366\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7627 - value_loss: 0.4505 - policy_loss: 1.0421 - val_loss: 5.7322 - val_value_loss: 0.3973 - val_policy_loss: 1.0344\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7614 - value_loss: 0.4490 - policy_loss: 1.0410 - val_loss: 5.7346 - val_value_loss: 0.4002 - val_policy_loss: 1.0364\n",
      "Saved model  tictactoe_num_sim_1_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.66 - draw ratio 0.06\n",
      "Number of seen trajectories: 1400\n",
      "Number of unique trajectories: 843\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.7906 - value_loss: 0.4954 - policy_loss: 1.0534 - val_loss: 5.7542 - val_value_loss: 0.4473 - val_policy_loss: 1.0286\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7813 - value_loss: 0.4784 - policy_loss: 1.0518 - val_loss: 5.7533 - val_value_loss: 0.4443 - val_policy_loss: 1.0300\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7754 - value_loss: 0.4672 - policy_loss: 1.0512 - val_loss: 5.7525 - val_value_loss: 0.4449 - val_policy_loss: 1.0280\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7707 - value_loss: 0.4602 - policy_loss: 1.0492 - val_loss: 5.7533 - val_value_loss: 0.4461 - val_policy_loss: 1.0284\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7676 - value_loss: 0.4554 - policy_loss: 1.0479 - val_loss: 5.7519 - val_value_loss: 0.4454 - val_policy_loss: 1.0266\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7656 - value_loss: 0.4509 - policy_loss: 1.0486 - val_loss: 5.7520 - val_value_loss: 0.4457 - val_policy_loss: 1.0268\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7631 - value_loss: 0.4470 - policy_loss: 1.0477 - val_loss: 5.7526 - val_value_loss: 0.4453 - val_policy_loss: 1.0284\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7614 - value_loss: 0.4449 - policy_loss: 1.0466 - val_loss: 5.7527 - val_value_loss: 0.4459 - val_policy_loss: 1.0282\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7607 - value_loss: 0.4433 - policy_loss: 1.0468 - val_loss: 5.7524 - val_value_loss: 0.4461 - val_policy_loss: 1.0275\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7598 - value_loss: 0.4414 - policy_loss: 1.0470 - val_loss: 5.7557 - val_value_loss: 0.4530 - val_policy_loss: 1.0275\n",
      "Saved model  tictactoe_num_sim_1_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.55 - draw ratio 0.02\n",
      "Number of seen trajectories: 1500\n",
      "Number of unique trajectories: 874\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.7422 - value_loss: 0.4105 - policy_loss: 1.0430 - val_loss: 5.7572 - val_value_loss: 0.4168 - val_policy_loss: 1.0667\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7338 - value_loss: 0.3948 - policy_loss: 1.0419 - val_loss: 5.7547 - val_value_loss: 0.4119 - val_policy_loss: 1.0667\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7296 - value_loss: 0.3868 - policy_loss: 1.0415 - val_loss: 5.7530 - val_value_loss: 0.4087 - val_policy_loss: 1.0666\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7263 - value_loss: 0.3806 - policy_loss: 1.0412 - val_loss: 5.7514 - val_value_loss: 0.4059 - val_policy_loss: 1.0663\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7235 - value_loss: 0.3759 - policy_loss: 1.0405 - val_loss: 5.7509 - val_value_loss: 0.4052 - val_policy_loss: 1.0660\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7215 - value_loss: 0.3717 - policy_loss: 1.0408 - val_loss: 5.7505 - val_value_loss: 0.4040 - val_policy_loss: 1.0666\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7191 - value_loss: 0.3686 - policy_loss: 1.0390 - val_loss: 5.7496 - val_value_loss: 0.4025 - val_policy_loss: 1.0661\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7185 - value_loss: 0.3668 - policy_loss: 1.0397 - val_loss: 5.7488 - val_value_loss: 0.4018 - val_policy_loss: 1.0655\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.7170 - value_loss: 0.3651 - policy_loss: 1.0386 - val_loss: 5.7492 - val_value_loss: 0.4021 - val_policy_loss: 1.0661\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7156 - value_loss: 0.3624 - policy_loss: 1.0386 - val_loss: 5.7488 - val_value_loss: 0.4014 - val_policy_loss: 1.0660\n",
      "Saved model  tictactoe_num_sim_1_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.57 - draw ratio 0.03\n",
      "Number of seen trajectories: 1600\n",
      "Number of unique trajectories: 899\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 5.7789 - value_loss: 0.4521 - policy_loss: 1.0755 - val_loss: 5.7413 - val_value_loss: 0.4226 - val_policy_loss: 1.0298\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7744 - value_loss: 0.4445 - policy_loss: 1.0741 - val_loss: 5.7409 - val_value_loss: 0.4214 - val_policy_loss: 1.0302\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7702 - value_loss: 0.4382 - policy_loss: 1.0721 - val_loss: 5.7411 - val_value_loss: 0.4206 - val_policy_loss: 1.0316\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7668 - value_loss: 0.4322 - policy_loss: 1.0714 - val_loss: 5.7407 - val_value_loss: 0.4205 - val_policy_loss: 1.0310\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7640 - value_loss: 0.4277 - policy_loss: 1.0703 - val_loss: 5.7401 - val_value_loss: 0.4202 - val_policy_loss: 1.0302\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7619 - value_loss: 0.4240 - policy_loss: 1.0700 - val_loss: 5.7406 - val_value_loss: 0.4202 - val_policy_loss: 1.0313\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7599 - value_loss: 0.4204 - policy_loss: 1.0697 - val_loss: 5.7404 - val_value_loss: 0.4204 - val_policy_loss: 1.0307\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7585 - value_loss: 0.4179 - policy_loss: 1.0693 - val_loss: 5.7408 - val_value_loss: 0.4208 - val_policy_loss: 1.0312\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7573 - value_loss: 0.4156 - policy_loss: 1.0694 - val_loss: 5.7404 - val_value_loss: 0.4210 - val_policy_loss: 1.0303\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7552 - value_loss: 0.4125 - policy_loss: 1.0684 - val_loss: 5.7407 - val_value_loss: 0.4211 - val_policy_loss: 1.0308\n",
      "Saved model  tictactoe_num_sim_1_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.52 - draw ratio 0.07\n",
      "Number of seen trajectories: 1700\n",
      "Number of unique trajectories: 924\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 5.7818 - value_loss: 0.4792 - policy_loss: 1.0550 - val_loss: 5.7836 - val_value_loss: 0.4788 - val_policy_loss: 1.0591\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7774 - value_loss: 0.4735 - policy_loss: 1.0520 - val_loss: 5.7824 - val_value_loss: 0.4772 - val_policy_loss: 1.0582\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7745 - value_loss: 0.4681 - policy_loss: 1.0518 - val_loss: 5.7817 - val_value_loss: 0.4765 - val_policy_loss: 1.0576\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7707 - value_loss: 0.4620 - policy_loss: 1.0503 - val_loss: 5.7814 - val_value_loss: 0.4759 - val_policy_loss: 1.0578\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7684 - value_loss: 0.4583 - policy_loss: 1.0494 - val_loss: 5.7811 - val_value_loss: 0.4754 - val_policy_loss: 1.0577\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7663 - value_loss: 0.4549 - policy_loss: 1.0487 - val_loss: 5.7812 - val_value_loss: 0.4756 - val_policy_loss: 1.0579\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7655 - value_loss: 0.4532 - policy_loss: 1.0489 - val_loss: 5.7809 - val_value_loss: 0.4751 - val_policy_loss: 1.0578\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7633 - value_loss: 0.4496 - policy_loss: 1.0483 - val_loss: 5.7806 - val_value_loss: 0.4745 - val_policy_loss: 1.0580\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7622 - value_loss: 0.4478 - policy_loss: 1.0478 - val_loss: 5.7811 - val_value_loss: 0.4751 - val_policy_loss: 1.0583\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7617 - value_loss: 0.4464 - policy_loss: 1.0484 - val_loss: 5.7812 - val_value_loss: 0.4754 - val_policy_loss: 1.0584\n",
      "Saved model  tictactoe_num_sim_1_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.59 - draw ratio 0.07\n",
      "Number of seen trajectories: 1800\n",
      "Number of unique trajectories: 943\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 5.7173 - value_loss: 0.3713 - policy_loss: 1.0347 - val_loss: 5.6923 - val_value_loss: 0.3522 - val_policy_loss: 1.0038\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7096 - value_loss: 0.3567 - policy_loss: 1.0340 - val_loss: 5.6895 - val_value_loss: 0.3469 - val_policy_loss: 1.0037\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7056 - value_loss: 0.3497 - policy_loss: 1.0331 - val_loss: 5.6878 - val_value_loss: 0.3438 - val_policy_loss: 1.0034\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7037 - value_loss: 0.3460 - policy_loss: 1.0331 - val_loss: 5.6867 - val_value_loss: 0.3416 - val_policy_loss: 1.0035\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7010 - value_loss: 0.3414 - policy_loss: 1.0324 - val_loss: 5.6859 - val_value_loss: 0.3397 - val_policy_loss: 1.0039\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.6995 - value_loss: 0.3380 - policy_loss: 1.0327 - val_loss: 5.6848 - val_value_loss: 0.3382 - val_policy_loss: 1.0032\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.6983 - value_loss: 0.3366 - policy_loss: 1.0320 - val_loss: 5.6846 - val_value_loss: 0.3373 - val_policy_loss: 1.0038\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.6964 - value_loss: 0.3336 - policy_loss: 1.0312 - val_loss: 5.6841 - val_value_loss: 0.3363 - val_policy_loss: 1.0038\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.6953 - value_loss: 0.3312 - policy_loss: 1.0315 - val_loss: 5.6836 - val_value_loss: 0.3355 - val_policy_loss: 1.0037\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6946 - value_loss: 0.3299 - policy_loss: 1.0314 - val_loss: 5.6836 - val_value_loss: 0.3350 - val_policy_loss: 1.0044\n",
      "Saved model  tictactoe_num_sim_1_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.55 - draw ratio 0.12\n",
      "Number of seen trajectories: 1900\n",
      "Number of unique trajectories: 966\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 5.7254 - value_loss: 0.3963 - policy_loss: 1.0266 - val_loss: 5.7378 - val_value_loss: 0.4195 - val_policy_loss: 1.0283\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7210 - value_loss: 0.3881 - policy_loss: 1.0261 - val_loss: 5.7362 - val_value_loss: 0.4171 - val_policy_loss: 1.0275\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7175 - value_loss: 0.3818 - policy_loss: 1.0255 - val_loss: 5.7353 - val_value_loss: 0.4156 - val_policy_loss: 1.0275\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7144 - value_loss: 0.3768 - policy_loss: 1.0244 - val_loss: 5.7349 - val_value_loss: 0.4143 - val_policy_loss: 1.0279\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7120 - value_loss: 0.3725 - policy_loss: 1.0240 - val_loss: 5.7343 - val_value_loss: 0.4134 - val_policy_loss: 1.0277\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7099 - value_loss: 0.3693 - policy_loss: 1.0230 - val_loss: 5.7338 - val_value_loss: 0.4126 - val_policy_loss: 1.0276\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7084 - value_loss: 0.3661 - policy_loss: 1.0233 - val_loss: 5.7333 - val_value_loss: 0.4120 - val_policy_loss: 1.0274\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7069 - value_loss: 0.3638 - policy_loss: 1.0229 - val_loss: 5.7330 - val_value_loss: 0.4113 - val_policy_loss: 1.0276\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7059 - value_loss: 0.3623 - policy_loss: 1.0223 - val_loss: 5.7328 - val_value_loss: 0.4108 - val_policy_loss: 1.0276\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7046 - value_loss: 0.3595 - policy_loss: 1.0226 - val_loss: 5.7324 - val_value_loss: 0.4101 - val_policy_loss: 1.0277\n",
      "Saved model  tictactoe_num_sim_1_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.65 - draw ratio 0.11\n",
      "Number of seen trajectories: 2000\n",
      "Number of unique trajectories: 978\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.7708 - value_loss: 0.4592 - policy_loss: 1.0553 - val_loss: 5.7615 - val_value_loss: 0.4540 - val_policy_loss: 1.0420\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7670 - value_loss: 0.4538 - policy_loss: 1.0532 - val_loss: 5.7601 - val_value_loss: 0.4525 - val_policy_loss: 1.0407\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7649 - value_loss: 0.4509 - policy_loss: 1.0520 - val_loss: 5.7588 - val_value_loss: 0.4510 - val_policy_loss: 1.0397\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7637 - value_loss: 0.4487 - policy_loss: 1.0519 - val_loss: 5.7579 - val_value_loss: 0.4498 - val_policy_loss: 1.0391\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7623 - value_loss: 0.4455 - policy_loss: 1.0522 - val_loss: 5.7570 - val_value_loss: 0.4485 - val_policy_loss: 1.0386\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7599 - value_loss: 0.4423 - policy_loss: 1.0508 - val_loss: 5.7562 - val_value_loss: 0.4474 - val_policy_loss: 1.0381\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7586 - value_loss: 0.4397 - policy_loss: 1.0507 - val_loss: 5.7556 - val_value_loss: 0.4466 - val_policy_loss: 1.0379\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7576 - value_loss: 0.4382 - policy_loss: 1.0503 - val_loss: 5.7551 - val_value_loss: 0.4459 - val_policy_loss: 1.0376\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7575 - value_loss: 0.4371 - policy_loss: 1.0513 - val_loss: 5.7545 - val_value_loss: 0.4452 - val_policy_loss: 1.0372\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7556 - value_loss: 0.4342 - policy_loss: 1.0502 - val_loss: 5.7540 - val_value_loss: 0.4446 - val_policy_loss: 1.0369\n",
      "Saved model  tictactoe_num_sim_1_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.68 - draw ratio 0.1\n",
      "Number of seen trajectories: 2100\n",
      "Number of unique trajectories: 990\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.7672 - value_loss: 0.4664 - policy_loss: 1.0413 - val_loss: 5.8175 - val_value_loss: 0.5440 - val_policy_loss: 1.0643\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7647 - value_loss: 0.4619 - policy_loss: 1.0409 - val_loss: 5.8159 - val_value_loss: 0.5409 - val_policy_loss: 1.0642\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7625 - value_loss: 0.4581 - policy_loss: 1.0404 - val_loss: 5.8149 - val_value_loss: 0.5391 - val_policy_loss: 1.0642\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7616 - value_loss: 0.4553 - policy_loss: 1.0414 - val_loss: 5.8138 - val_value_loss: 0.5369 - val_policy_loss: 1.0642\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7592 - value_loss: 0.4517 - policy_loss: 1.0402 - val_loss: 5.8131 - val_value_loss: 0.5356 - val_policy_loss: 1.0641\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7573 - value_loss: 0.4482 - policy_loss: 1.0400 - val_loss: 5.8126 - val_value_loss: 0.5346 - val_policy_loss: 1.0641\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7567 - value_loss: 0.4473 - policy_loss: 1.0397 - val_loss: 5.8117 - val_value_loss: 0.5330 - val_policy_loss: 1.0641\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7550 - value_loss: 0.4444 - policy_loss: 1.0393 - val_loss: 5.8112 - val_value_loss: 0.5320 - val_policy_loss: 1.0641\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7532 - value_loss: 0.4411 - policy_loss: 1.0390 - val_loss: 5.8109 - val_value_loss: 0.5315 - val_policy_loss: 1.0641\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7526 - value_loss: 0.4398 - policy_loss: 1.0393 - val_loss: 5.8104 - val_value_loss: 0.5306 - val_policy_loss: 1.0641\n",
      "Saved model  tictactoe_num_sim_1_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.56 - draw ratio 0.11\n",
      "Number of seen trajectories: 2200\n",
      "Number of unique trajectories: 1007\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 5.7669 - value_loss: 0.4519 - policy_loss: 1.0557 - val_loss: 5.7685 - val_value_loss: 0.4597 - val_policy_loss: 1.0511\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7660 - value_loss: 0.4501 - policy_loss: 1.0556 - val_loss: 5.7675 - val_value_loss: 0.4583 - val_policy_loss: 1.0505\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7628 - value_loss: 0.4449 - policy_loss: 1.0545 - val_loss: 5.7666 - val_value_loss: 0.4573 - val_policy_loss: 1.0498\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7619 - value_loss: 0.4432 - policy_loss: 1.0546 - val_loss: 5.7659 - val_value_loss: 0.4563 - val_policy_loss: 1.0494\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7606 - value_loss: 0.4409 - policy_loss: 1.0542 - val_loss: 5.7655 - val_value_loss: 0.4556 - val_policy_loss: 1.0493\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7596 - value_loss: 0.4393 - policy_loss: 1.0539 - val_loss: 5.7650 - val_value_loss: 0.4548 - val_policy_loss: 1.0491\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7581 - value_loss: 0.4368 - policy_loss: 1.0535 - val_loss: 5.7646 - val_value_loss: 0.4542 - val_policy_loss: 1.0490\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7572 - value_loss: 0.4355 - policy_loss: 1.0529 - val_loss: 5.7643 - val_value_loss: 0.4538 - val_policy_loss: 1.0488\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7566 - value_loss: 0.4340 - policy_loss: 1.0533 - val_loss: 5.7640 - val_value_loss: 0.4535 - val_policy_loss: 1.0487\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7554 - value_loss: 0.4309 - policy_loss: 1.0540 - val_loss: 5.7636 - val_value_loss: 0.4531 - val_policy_loss: 1.0483\n",
      "Saved model  tictactoe_num_sim_1_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.03\n",
      "Number of seen trajectories: 2300\n",
      "Number of unique trajectories: 1021\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 5.7647 - value_loss: 0.4521 - policy_loss: 1.0514 - val_loss: 5.7572 - val_value_loss: 0.4300 - val_policy_loss: 1.0586\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7613 - value_loss: 0.4453 - policy_loss: 1.0516 - val_loss: 5.7563 - val_value_loss: 0.4282 - val_policy_loss: 1.0585\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7579 - value_loss: 0.4399 - policy_loss: 1.0503 - val_loss: 5.7556 - val_value_loss: 0.4271 - val_policy_loss: 1.0584\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7562 - value_loss: 0.4365 - policy_loss: 1.0502 - val_loss: 5.7551 - val_value_loss: 0.4263 - val_policy_loss: 1.0583\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7536 - value_loss: 0.4320 - policy_loss: 1.0496 - val_loss: 5.7547 - val_value_loss: 0.4255 - val_policy_loss: 1.0582\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7524 - value_loss: 0.4295 - policy_loss: 1.0497 - val_loss: 5.7544 - val_value_loss: 0.4250 - val_policy_loss: 1.0582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7510 - value_loss: 0.4267 - policy_loss: 1.0496 - val_loss: 5.7542 - val_value_loss: 0.4247 - val_policy_loss: 1.0581\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7502 - value_loss: 0.4246 - policy_loss: 1.0502 - val_loss: 5.7541 - val_value_loss: 0.4245 - val_policy_loss: 1.0581\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7481 - value_loss: 0.4211 - policy_loss: 1.0495 - val_loss: 5.7539 - val_value_loss: 0.4243 - val_policy_loss: 1.0581\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7471 - value_loss: 0.4201 - policy_loss: 1.0487 - val_loss: 5.7538 - val_value_loss: 0.4241 - val_policy_loss: 1.0581\n",
      "Saved model  tictactoe_num_sim_1_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.57 - draw ratio 0.07\n",
      "Number of seen trajectories: 2400\n",
      "Number of unique trajectories: 1037\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7375 - value_loss: 0.4253 - policy_loss: 1.0242 - val_loss: 5.7691 - val_value_loss: 0.4639 - val_policy_loss: 1.0489\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7353 - value_loss: 0.4212 - policy_loss: 1.0239 - val_loss: 5.7690 - val_value_loss: 0.4639 - val_policy_loss: 1.0488\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7337 - value_loss: 0.4185 - policy_loss: 1.0236 - val_loss: 5.7689 - val_value_loss: 0.4639 - val_policy_loss: 1.0487\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7322 - value_loss: 0.4154 - policy_loss: 1.0238 - val_loss: 5.7691 - val_value_loss: 0.4641 - val_policy_loss: 1.0488\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7305 - value_loss: 0.4128 - policy_loss: 1.0229 - val_loss: 5.7689 - val_value_loss: 0.4637 - val_policy_loss: 1.0489\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7298 - value_loss: 0.4109 - policy_loss: 1.0234 - val_loss: 5.7689 - val_value_loss: 0.4636 - val_policy_loss: 1.0490\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7284 - value_loss: 0.4089 - policy_loss: 1.0227 - val_loss: 5.7689 - val_value_loss: 0.4637 - val_policy_loss: 1.0490\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7267 - value_loss: 0.4062 - policy_loss: 1.0222 - val_loss: 5.7688 - val_value_loss: 0.4636 - val_policy_loss: 1.0489\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7265 - value_loss: 0.4053 - policy_loss: 1.0226 - val_loss: 5.7687 - val_value_loss: 0.4634 - val_policy_loss: 1.0490\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7257 - value_loss: 0.4034 - policy_loss: 1.0230 - val_loss: 5.7686 - val_value_loss: 0.4632 - val_policy_loss: 1.0490\n",
      "Saved model  tictactoe_num_sim_1_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.54 - draw ratio 0.11\n",
      "Number of seen trajectories: 2500\n",
      "Number of unique trajectories: 1047\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 5.7267 - value_loss: 0.4097 - policy_loss: 1.0188 - val_loss: 5.7032 - val_value_loss: 0.3679 - val_policy_loss: 1.0135\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7246 - value_loss: 0.4069 - policy_loss: 1.0174 - val_loss: 5.7024 - val_value_loss: 0.3661 - val_policy_loss: 1.0136\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7243 - value_loss: 0.4053 - policy_loss: 1.0182 - val_loss: 5.7017 - val_value_loss: 0.3647 - val_policy_loss: 1.0137\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7223 - value_loss: 0.4022 - policy_loss: 1.0173 - val_loss: 5.7010 - val_value_loss: 0.3633 - val_policy_loss: 1.0138\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7213 - value_loss: 0.3997 - policy_loss: 1.0179 - val_loss: 5.7005 - val_value_loss: 0.3622 - val_policy_loss: 1.0138\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7197 - value_loss: 0.3977 - policy_loss: 1.0168 - val_loss: 5.6999 - val_value_loss: 0.3611 - val_policy_loss: 1.0138\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7188 - value_loss: 0.3960 - policy_loss: 1.0168 - val_loss: 5.6994 - val_value_loss: 0.3602 - val_policy_loss: 1.0138\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7178 - value_loss: 0.3937 - policy_loss: 1.0169 - val_loss: 5.6990 - val_value_loss: 0.3594 - val_policy_loss: 1.0138\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7170 - value_loss: 0.3926 - policy_loss: 1.0167 - val_loss: 5.6987 - val_value_loss: 0.3586 - val_policy_loss: 1.0138\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7157 - value_loss: 0.3901 - policy_loss: 1.0165 - val_loss: 5.6983 - val_value_loss: 0.3580 - val_policy_loss: 1.0138\n",
      "Saved model  tictactoe_num_sim_1_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.6 - draw ratio 0.08\n",
      "Number of seen trajectories: 2600\n",
      "Number of unique trajectories: 1060\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 5.7531 - value_loss: 0.4333 - policy_loss: 1.0480 - val_loss: 5.7475 - val_value_loss: 0.4138 - val_policy_loss: 1.0563\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7526 - value_loss: 0.4319 - policy_loss: 1.0484 - val_loss: 5.7471 - val_value_loss: 0.4131 - val_policy_loss: 1.0563\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7510 - value_loss: 0.4306 - policy_loss: 1.0465 - val_loss: 5.7469 - val_value_loss: 0.4126 - val_policy_loss: 1.0564\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7502 - value_loss: 0.4291 - policy_loss: 1.0466 - val_loss: 5.7467 - val_value_loss: 0.4121 - val_policy_loss: 1.0564\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7490 - value_loss: 0.4272 - policy_loss: 1.0460 - val_loss: 5.7465 - val_value_loss: 0.4117 - val_policy_loss: 1.0565\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7485 - value_loss: 0.4262 - policy_loss: 1.0461 - val_loss: 5.7463 - val_value_loss: 0.4113 - val_policy_loss: 1.0566\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7484 - value_loss: 0.4260 - policy_loss: 1.0461 - val_loss: 5.7462 - val_value_loss: 0.4110 - val_policy_loss: 1.0566\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7476 - value_loss: 0.4247 - policy_loss: 1.0458 - val_loss: 5.7460 - val_value_loss: 0.4107 - val_policy_loss: 1.0567\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7465 - value_loss: 0.4231 - policy_loss: 1.0453 - val_loss: 5.7459 - val_value_loss: 0.4104 - val_policy_loss: 1.0567\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7460 - value_loss: 0.4220 - policy_loss: 1.0453 - val_loss: 5.7458 - val_value_loss: 0.4102 - val_policy_loss: 1.0567\n",
      "Saved model  tictactoe_num_sim_1_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.58 - draw ratio 0.02\n",
      "Number of seen trajectories: 2700\n",
      "Number of unique trajectories: 1070\n",
      "iteration 27 | self-play\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving memory position_memory_tictactoe_num_sim_1_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 5.7239 - value_loss: 0.3947 - policy_loss: 1.0286 - val_loss: 5.7437 - val_value_loss: 0.4288 - val_policy_loss: 1.0340\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7229 - value_loss: 0.3922 - policy_loss: 1.0290 - val_loss: 5.7435 - val_value_loss: 0.4287 - val_policy_loss: 1.0337\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7217 - value_loss: 0.3909 - policy_loss: 1.0279 - val_loss: 5.7434 - val_value_loss: 0.4286 - val_policy_loss: 1.0336\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7207 - value_loss: 0.3894 - policy_loss: 1.0274 - val_loss: 5.7433 - val_value_loss: 0.4285 - val_policy_loss: 1.0334\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7199 - value_loss: 0.3876 - policy_loss: 1.0277 - val_loss: 5.7432 - val_value_loss: 0.4285 - val_policy_loss: 1.0333\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7196 - value_loss: 0.3871 - policy_loss: 1.0276 - val_loss: 5.7431 - val_value_loss: 0.4286 - val_policy_loss: 1.0332\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7189 - value_loss: 0.3860 - policy_loss: 1.0273 - val_loss: 5.7431 - val_value_loss: 0.4286 - val_policy_loss: 1.0331\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7180 - value_loss: 0.3845 - policy_loss: 1.0270 - val_loss: 5.7431 - val_value_loss: 0.4287 - val_policy_loss: 1.0330\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7172 - value_loss: 0.3829 - policy_loss: 1.0270 - val_loss: 5.7431 - val_value_loss: 0.4289 - val_policy_loss: 1.0329\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7169 - value_loss: 0.3823 - policy_loss: 1.0270 - val_loss: 5.7431 - val_value_loss: 0.4290 - val_policy_loss: 1.0328\n",
      "Saved model  tictactoe_num_sim_1_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.72 - draw ratio 0.09\n",
      "Number of seen trajectories: 2800\n",
      "Number of unique trajectories: 1077\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 5.7349 - value_loss: 0.4092 - policy_loss: 1.0361 - val_loss: 5.7346 - val_value_loss: 0.4094 - val_policy_loss: 1.0355\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7346 - value_loss: 0.4085 - policy_loss: 1.0364 - val_loss: 5.7344 - val_value_loss: 0.4090 - val_policy_loss: 1.0354\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7331 - value_loss: 0.4051 - policy_loss: 1.0366 - val_loss: 5.7342 - val_value_loss: 0.4088 - val_policy_loss: 1.0354\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7322 - value_loss: 0.4046 - policy_loss: 1.0355 - val_loss: 5.7341 - val_value_loss: 0.4085 - val_policy_loss: 1.0354\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7316 - value_loss: 0.4031 - policy_loss: 1.0358 - val_loss: 5.7341 - val_value_loss: 0.4085 - val_policy_loss: 1.0354\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7303 - value_loss: 0.4013 - policy_loss: 1.0349 - val_loss: 5.7341 - val_value_loss: 0.4085 - val_policy_loss: 1.0355\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7304 - value_loss: 0.4011 - policy_loss: 1.0353 - val_loss: 5.7341 - val_value_loss: 0.4085 - val_policy_loss: 1.0355\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7292 - value_loss: 0.3988 - policy_loss: 1.0353 - val_loss: 5.7342 - val_value_loss: 0.4086 - val_policy_loss: 1.0355\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7284 - value_loss: 0.3980 - policy_loss: 1.0346 - val_loss: 5.7343 - val_value_loss: 0.4088 - val_policy_loss: 1.0355\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7282 - value_loss: 0.3972 - policy_loss: 1.0350 - val_loss: 5.7343 - val_value_loss: 0.4088 - val_policy_loss: 1.0355\n",
      "Saved model  tictactoe_num_sim_1_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.67 - draw ratio 0.04\n",
      "Number of seen trajectories: 2900\n",
      "Number of unique trajectories: 1090\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_1_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.7298 - value_loss: 0.4102 - policy_loss: 1.0252 - val_loss: 5.7411 - val_value_loss: 0.4256 - val_policy_loss: 1.0325\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7288 - value_loss: 0.4083 - policy_loss: 1.0252 - val_loss: 5.7405 - val_value_loss: 0.4243 - val_policy_loss: 1.0325\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7270 - value_loss: 0.4056 - policy_loss: 1.0242 - val_loss: 5.7400 - val_value_loss: 0.4231 - val_policy_loss: 1.0327\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7254 - value_loss: 0.4035 - policy_loss: 1.0232 - val_loss: 5.7394 - val_value_loss: 0.4218 - val_policy_loss: 1.0329\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7246 - value_loss: 0.4011 - policy_loss: 1.0240 - val_loss: 5.7389 - val_value_loss: 0.4207 - val_policy_loss: 1.0330\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7231 - value_loss: 0.3991 - policy_loss: 1.0230 - val_loss: 5.7384 - val_value_loss: 0.4196 - val_policy_loss: 1.0331\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7223 - value_loss: 0.3970 - policy_loss: 1.0235 - val_loss: 5.7379 - val_value_loss: 0.4185 - val_policy_loss: 1.0332\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7212 - value_loss: 0.3952 - policy_loss: 1.0232 - val_loss: 5.7373 - val_value_loss: 0.4174 - val_policy_loss: 1.0332\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7199 - value_loss: 0.3934 - policy_loss: 1.0223 - val_loss: 5.7369 - val_value_loss: 0.4164 - val_policy_loss: 1.0333\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7196 - value_loss: 0.3920 - policy_loss: 1.0230 - val_loss: 5.7364 - val_value_loss: 0.4154 - val_policy_loss: 1.0333\n",
      "Saved model  tictactoe_num_sim_1_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.59 - draw ratio 0.08\n",
      "Number of seen trajectories: 3000\n",
      "Number of unique trajectories: 1104\n"
     ]
    }
   ],
   "source": [
    "wins_1, draws_1, seen_trajectories_1, unique_trajectories_1 = test_pipeline.run(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzsnXdYVEfXwH9DB6WDYEcUbIiIvWusKZrkNcbERGOayZsY02N6TI+pr4mmaFSsUb9YosZo7IoRFeyoSFEUFASUInXZne+PBYJKWWCXBZ3f89yH3Tvt7N3lnjvnnDkjpJQoFAqFQgFgYW4BFAqFQlF3UEpBoVAoFCUopaBQKBSKEpRSUCgUCkUJSikoFAqFogSlFBQKhUJRglIKCrMhhNgphHjKRH2/LYT41RR91wZCiP5CiCgT9T1dCLGkBu0jhRCDjCiSog6hlIKiUoQQ54QQuUKIa6WOWeaWqxghxCAhRELpc1LKz6SUJlE4BsgzRwgRJYTQCSEmVacPKeUeKWVbI4tWZYQQIUKIT0qfk1J2lFLuNJNIChNjZW4BFPWGUVLKreYWop5wFFgBzDC3IApFVVEzBUW1EULYCiHShRABpc55Fs0qGgkhXIUQG4QQKUKIq0Wvm5XT13UmDSGEjxBCCiGsit4/LoQ4JYTIEkLECSGeKTrfAPgLaFJqFtOkjP5GF5k90ovMVu1LlZ0TQrwmhDgmhMgQQqwQQthV97pIKWdLKbcBeZXVFULcJYQ4WfS5EoUQrxWdv272UyTj60UyZgsh5gkhvIQQfxW13SqEcC2rban2Q8uR4f+EEElFn323EKJj0fnJwCPAG0XXdf2NfRX9Bv4nhLhYdPxPCGFbWg4hxKtCiMtCiEtCiMercUkVtYhSCopqI6XMB1YDD5c6/SCwS0p5Gf3vawHQEmgB5ALVNTtdBu4BnIDHge+EEMFSymzgTuCilLJh0XGxdEMhhD/wG/AS4AlsBNYLIWxukHsk0AoIBCZVU86qMg94RkrpCAQA2yuoOwYYBvgDo9Arw7cBD/TXemo1ZfgL8AMaAYeApQBSyjlFr78suq6jymj7DtALCAI6Az2Ad0uVewPOQFPgSWB2sfJS1E2UUlAYytqip+zi4+mi88u4XimMLzqHlDJNSrlKSpkjpcwCPgUGVmdwKeWfUspYqWcX8DfQ38Dm44A/pZRbpJQa4GvAHuhTqs73UsqLUsorwHr0N7naQAN0EEI4SSmvSikPVVD3ByllspQyEdgD7JdSHi5SzmuALtURQEo5X0qZVdTPdKCzEMLZwOaPAB9JKS9LKVOAD4EJpco1ReUaKeVG4Bpgdl+JonyUUlAYyn1SSpdSx9yi89sBeyFETyFES/Q30zUAQggHIcQvQoh4IUQmsBtwEUJYVnVwIcSdQogwIcQVIUQ6cBf6J2RDaALEF7+RUuqAC+ifXotJKvU6B2hYjhyRpcxUhiqlihiD/rPECyF2CSF6V1A3udTr3DLelylzRQghLIUQXwghYou+o3NFRdW6tkWvm5R6nyalLCz1vtxrq6gbKKWgqBFFN9iV6GcL44ENRbMCgFfRPxX2lFI6AQOKzosyusoGHEq99y5+UWSjXoX+Cd9LSumC3gRU3E9lqX4vojdhFfcngOZAYmWf70aKIm+KzVR7qtq+jP4OSinvRW+6WYv+WtaU665lkRL2LKfueOBeYCh6M49PcbNiESsZ67pri95MeLGcuop6gFIKCmOwDL2J5pGi18U4on+CTRdCuAEfVNDHEWCAEKJFkenirVJlNoAtkAIUCiHuBIaXKk8G3CsweawE7hZCDBFCWKNXVvnAP4Z+wKoghLApclQLwFoIYSeEuOl/rajeI0II5yKzViagNYIIZwA7IcTdRZ/3XfTXrywc0V+LNPSK5LMbypMB3wrG+g14V+gDDDyA94Fqr4FQmB+lFBSGsl5cv05hTXGBlHI/+qfTJuidlsX8D73tPhUIAzaV17mUcgv6MM5jQASwoVRZFnon6krgKvqn23Wlyk+jvznFFfk7SpsvkFJGAY8CPxTJMgp9iG1BVS+CgfyNXhn2AeYUvR5QTt0JwLki082zRXLWCCllBvAc8Cv62VA2kFBO9UXoTT6JwEn031Np5qH3eaQLIdaW0f4TIBz993YcvaP6kzLqKeoJQm2yo1AoFIpi1ExBoVAoFCUopaBQKBSKEpRSUCgUCkUJSikoFAqFooR6lxDPw8ND+vj4mFsMhUKhqFdERESkSinLW69SQr1TCj4+PoSHh5tbDIVCoahXCCHiK6+lzEcKhUKhKIVSCgqFQqEoQSkFhUKhUJRQ73wKZaHRaEhISCAvr9I9TRRVwM7OjmbNmmFtbW1uURQKRS1xSyiFhIQEHB0d8fHxQZ8AU1FTpJSkpaWRkJBAq1atzC2OQqGoJW4J81FeXh7u7u5KIRgRIQTu7u5q9qVQ3GbcEkoBUArBBKhrqlDcftwySkGhUCjqAlJKVoZf4HJW/ZxlK6VQS9x1112kp6cbvd8jR46wcePGkvfr1q3jiy++MPo4CoXCME4nZfHG78d4dnEEGq3O3OJUGaUUaomNGzfi4uJSrbaFhYXllt2oFEaPHs2bb75ZrXEUCkXN2RuTCsCh8+l8/XeUmaWpOkopGIEvv/yS77//HoCXX36ZO+64A4Bt27bx6KP6jbR8fHxITU3l3LlztG/fnqeffpqOHTsyfPhwcnNzb+pz0qRJvPLKKwwePJhp06Zx4MAB+vTpQ5cuXejTpw9RUVEUFBTw/vvvs2LFCoKCglixYgUhISFMmTIFgPj4eIYMGUJgYCBDhgzh/PnztXRFFIrbl9CYVFp7NmB8zxb8siuOHVGXzS1SlTBpSKoQYiQwE7AEfpVSfnFD+XfA4KK3DkCjok3Zq82H6yM5eTGzJl3cRIcmTnwwqmO55QMGDOCbb75h6tSphIeHk5+fj0ajITQ0lP79+99UPzo6mt9++425c+fy4IMPsmrVqhLlUZozZ86wdetWLC0tyczMZPfu3VhZWbF161befvttVq1axUcffUR4eDizZs0CICQkpKT9lClTmDhxIo899hjz589n6tSprF1b1o6KCoXCGBQU6tgfd4UHuzXjrbvacyj+Kq+uPMrGqf3xdrYzt3gGYbKZghDCEpgN3Al0AB4WQnQoXUdK+bKUMkhKGYR+/9zVppLHlHTt2pWIiAiysrKwtbWld+/ehIeHs2fPnjKVQqtWrQgKCippe+7cuTL7HTt2LJaWlgBkZGQwduxYAgICePnll4mMjKxUrn379jF+/HgAJkyYQGhoaDU/oUKhMITD56+Sq9HSt40HdtaWzBofTJ5Gy9TlhymsJ/4FU84UegAxUso4ACHEcuBe9JuDl8XDwAc1HbSiJ3pTYW1tjY+PDwsWLKBPnz4EBgayY8cOYmNjad++/U31bW1tS15bWlqWaT4CaNCgQcnr9957j8GDB7NmzRrOnTvHoEGDqiynCjFV1EU2HLvI1pPJ/O+hLuYWpcbsjUnFQkCv1u4AtGnUkE/uC+CVlUf5fls0rwxva2YJK8eUPoWmwIVS7xOKzt2EEKIl0ArYXk75ZCFEuBAiPCUlxeiCGoMBAwbw9ddfM2DAAPr378/PP/9MUFCQ0W7EGRkZNG2qv3ylTUSOjo5kZWWV2aZPnz4sX74cgKVLl9KvXz+jyKJQGJPF++JZe+QiZ1OzzS1KjQmNSaVzcxec7P5NDfOf4GaM7dqMH3bElDih6zKmVApl3Q1lOXUfAn6XUmrLKpRSzpFSdpNSdvP0rHSPCLPQv39/Ll26RO/evfHy8sLOzq5M01F1eeONN3jrrbfo27cvWu2/l2nw4MGcPHmyxNFcmu+//54FCxYQGBjI4sWLmTlzptHkUSiMQU5BIYfOXwVgZz1zyN5IZp6GowkZ9GvjcVPZh/d2pLVnQ15cfoSUrHwzSGc4Qsry7tM17FiI3sB0KeWIovdvAUgpPy+j7mHgeSnlP5X1261bN3njJjunTp0q00yjqDnq2ipMyc6oy0xacBArC0HfNh4sfKKHuUWqNltOJvP0onCWT+5FL1/3m8qjkrIYPSuU7j5uLHyiB5YWtWvOFUJESCm7VVbPlDOFg4CfEKKVEMIG/Wxg3Y2VhBBtAVdgnwllUSgUdZC9ManYWFkwtltzwuLSyNOUaSyoF+yNScXe2pIuLcoOoGzr7ciHozsSGpPKTztjalk6wzGZUpBSFgJTgM3AKWCllDJSCPGREGJ0qaoPA8ulqaYsCoXCaBQU6riaXWC0/kJj0ujW0pWRAd7kF+rYF5dmtL5rm9CYVLq3csPWyrLcOuO6N+feoCZ8u+UMB85eqUXpDMeki9eklBullP5SytZSyk+Lzr0vpVxXqs50KaVagqtQ1HHOp+UwelYoQ7/dRX5hzZ/oU6/lc+pSJn3beNCzlRt21hbsPF0//QrJmXnEXL5GvzY3m41KI4Tg0/s70cLNgam/HeaKERWssVArmhUKRaWERqcyenYosSnXSMsuYF9szZ/o/ynqo19RTH9vX3d2nqmb0YWVURxV1LcMJ/ONNLS1Ytb4YK5kF/DqyiPodHXLSKKUwm1AoVbHtfzy8ycpFOUhpeTXPXFMnL8fL0c7/pzaHwcbS7acTK5x33ujU3GysyKgqTMAg9o2Ij4tp16GpobGpOLWwIb23k4G1Q9o6sx797RnR1QKv4bGmVi6qqGUwm1AUmYecSnXyC1QikFhOHkaLa+sPMonf55ieAdvVj/XB38vRwb6e7L1VHKNnnCllITGpNKntUdJFM7gto2A+heaKqVkb0wqfVq7Y1GFiKJHe7VkREcvvvn7DKnX6k6YqlIKJmD69Ol8/fXX5hYDgE8+/ZT0HA0ASZn59OnTx8wSKeoDF9NzGfvzPtYcTuTVYf78+EgwDWz1CRCGdfAiOTOfY4kZ1e4/Pi2HxPRc+vr9a25p4e6Ar0cDdkbVLxNSbMo1kjPzy1yfUBFCCKaNbEeBVkfI3nOmEa4aKKVQi1SUAru6lF7IVhaff/45OilxdbAhK0/D39t3G10GY3HhSg5L98ebxcaq00mWhMVzMb3slCO3EwfOXmH0rFDOpmbz68RuvDDE77on4DvaNcLSQrDlZFK1x9gbq7fB33gjHdjWk7C4NHIL6k9oami04f6EG/H1bMiIDt4s2neuzph4lVIwEp9++ilt27Zl6NChREX9m0N90KBBvP322wwcOJCZM2eyfv16evbsSZcuXRg6dCjJyXrbbKdOnUhPT0dKibu7O4sWLQL0iey2bt163Vg7d+5k8ODBjB8/nk6dOgFw33330bVrVzp27MicOXMAmDZtGnm5uYwbOYBpU57G2tICL3cXpJRIKXn99dcJCAigU6dON62GNgcfro/knTUn+PjPk9RmhLKUkvfXneDdtSfqZf57Y7IkLJ7xc8NwtLNm7fN9GNrB66Y6Lg42dPdxrZFfYW9MKk1d7PFxd7ju/KC2jcgv1BFWj0JTQ2PSaOnuQHM3h8orl8Gzg1qTmVfI8gN1I7W9SVNnm4W/3oSk48bt07sT3Fn+bmYREREsX76cw4cPU1hYSHBwMF27di0pT09PZ9euXQBcvXqVsLAwhBD8+uuvfPnll3zzzTf07duXvXv30rJlS3x9fdmzZw8TJ04kLCyMn3766aYxDxw4wIkTJ2jVqhUA8+fPx83NjdzcXLp3786YMWN478NP+GHWbP7ZH45rAxuuZOcjgcy8QrZuXMeRI0c4evQoqampdO/enQEDBtC4cWPjXjsDSbiaw7bTl2nuZs+CvedwdbBh6hC/Whn72y1nWBJ2Ho+GNmyJTCa/UFthrPmtSEGhjg/WRfLbgfMMbuvJ/x7qgrO9dbn1h3fw5qMNJzmXmo2PR4Ny65WFVif5JzaN4R28bsoNVhKaGnWZwe0aVeuz1CaFWr0CGx3UpNp9BDV3oZevG7/uOcvE3j7YWJn3WV3NFIzAnj17uP/++3FwcMDJyYnRo0dfVz5u3LiS1wkJCYwYMYJOnTrx1VdflaTA7t+/P7t372b37t3897//5fjx4yQmJuLm5kbDhg1vGrNHjx4lCgH0eY46d+5Mr169uHDhAtHR0aQVxUAX/3O7OtgggOSMPPbs2cPDDz+MpaUlXl5eDBw4kIMHDxr70hjMbwfOI4Dfnu7Ff4Kb8u2WMyz855zJx/11Txw/bI/hoe7N+WpsZ7LyC9l9pu4nLTMmWp1kwrz9/HbgPM8Nas2vj3WvUCGA3q8AVGu2cPJiJuk5mjLNLXbWlvRp7VFvQlOPJmRwLb+wyv6EG3l2YGuSMvP440iikSSrPrfeTKGCJ3pTUlE21NIpsF944QVeeeUVRo8ezc6dO5k+fTqgz7I6e/Zszp8/z6effsqaNWv4/fffy02qV7rPnTt3snXrVvbt24eDgwODBg3iWnYOmbmFCEGJPVgIgRCQV6itU+kE8gu1rDh4gSHtvWjm6sCXYwLJzC3kg3WRONtbc1+XMpPr1piV4Rf45M9T3N2pMZ/e3wmdlLg4WPPnsYslN73bgT3RKew/e4WP7u3IxN4+BrVp7uZAO29Hfb6fAb5VGi+0KKa/T+uyb6SD2nqy/fRlzqZm06qKs5DaZm9MKkJA7zJyHVWFgf6etG/sxJzdcYwJblalKCZjo2YKRmDAgAGsWbOG3NxcsrKyWL9+fbl1S6fAXrhwYcn55s2bk5qaSnR0NL6+vvTr14+vv/7aoEyrGRkZuLq64uDgwOnTpwkLCyMzrxCJxMbaGo1Gc119extLOgT3ZPmKFWi1WlJSUti9ezc9epgnGdmmE0mkXitgQq+WAFhZWjBrfBd6+7rz6v8dZasRYuLLGvPNVcfo7+fBt+M6Y2khsLa0YGRHb7acTK5TStPUrDqUiIuDNeO6N69Su+EdvQmPv0JaFcMp98ak0s7bEU9H2zLLB/nXn9DU0JhUApo449rApkb9CCF4dqAv0Zevsd3Mq7qVUjACwcHBjBs3jqCgIMaMGVPhjXz69OmMHTuW/v374+Fx/ZNSz5498ff3B/TmpMTERIP2QBg5ciSFhYUEBgby3nvv0atXL7LyNDjaWTN58mQCAwN55JFHSup7O9kxcPjd+LfrSOfOnbnjjjv48ssv8fb2ruYVqBlLwuJp6e5w3RTcztqSuY91o2MTJ55fdsiojse9MalM/e0wQc1d+GVC1+v8B/cENiG7QFvvwiKrS0auhs2RSYzu3KTKfpThHbzQSdhWhZtYnkbLgXNXKozUKQ5N3VHHv4Ps/EIOn79araijsri7U2Oaudrz865Yo/RXbYojUerL0bVrV3kjJ0+evOnc7Ux6dr48euGqzMgpKLdO7OUsGZmYIQu1ugr7MvW1PXUpQ7actkHO2RVbZnnatXx5x9c7ZMf3N8njCek1Hu/w+auy/Xt/yRHf7ZLp2TdfH02hVgZ/9Ld8fmlEjceqDywNi5ctp22QR85frXJbnU4ne3+2VT618KDBbUKjU2TLaRvk9lPJFdb7cF2k9Htno8zJL6yyXLXF9tPJsuW0DXLPmRSj9Rmy96xsOW2DPHg2zWh9FgOESwPusWqmcAuSll2AjaUFjnblu4y8ne0o1OnMvpJySVg8tlYWPNC1WZnlbg1sWPJUT5ztrXls/gFiU65Ve6zo5CwmLTiAR0NbFj3RA2eHm52pVpYWjAzwZtupy/UqVr66rDqUQJtGDQls5lzltkIIhnbwYk90isHXKjQmFSsLQY9WbhXWG9TWk4I6Hpq6N1qf9rubj6vR+nywW3NcHazNOltQSuEWI0+j5Vp+IW4NbCp0fjvYWOFsb01qVr7ZNhTPytOw5lAiozo3qdAm29jZnsVP9kAImPDr/motMLtwJYdH5+3HxtKCJU/2pJGTXbl17w5sTK5Ga3bbrqk5m5pNRPxVxgQ3q/a2scM7eJOn0bEn2jBTz96YVIJbuJasji6PHq3csLe2rNN+hdCYVLr7uGJnbbzwZXsbSx7r48PWU5c5k1z2NrumRimFW4wr2QUIIQxyfHk52aGTkstm2h5w7eFEsgu0PFrkYK4IX8+GLHyiB1l5hTw6b3+VnJuXs/KYMG8/eRodi5/sSQv3ihcZ9WzljkdDW/48ftHgMeojqw8lYCHg/hpEd/X0dcPRzsqg0NT0nAKOJ2YYZIO3s7akd+u6mzU1JSuf00lZRvMnlOax3j7YW1vyyy7zJMq79UJSb2O0OsnVnAKc7ayxtqxc39tZW+LqYENadgEeDW1rddGMlJIlYefp1NSZzgaaLjo2cWbepO5MmLefxxYcYNrIdogytwL/F52UfP7XaZIz81n6dE/aejtWOo6lheCuTt6sDL9Adn5hpU+19RGdTrL6UCL9/Dzxdi5/1lQZ1pYWDG7biG2nL6PVyQq3mNwXm4aU0M/PsPDNuhya+k85aTqMgWsDG8Z1b86SsHheHe5PExd7o49REbfer/02JiO3AK1O4t7Q8PC4Rk52XM3VkJyZV+1l+tXh4LmrRCVn8eWYwCqZLnq0cuPnR7vy9KJwJsw7YFAba0vB/EndCW5huO33nsAmLNoXz7bTlxndufqrVesqYWfTSEzP5Y2RbWvc1/COXqw7epGI+KsV+gpCY1JpaGtFYLOyt6u8EX1oaiQ7Tl+mVb9WldavTfbGpOJsb03HJlX3xRjCU/1bsTgsnnmhZ3nvng4mGaM8lFK4RZBSknatADtrSxxsDLdx2lhZ4NHAhtRr+Xg62hrVPloRi8PicbKzYlQ1briD2zVix2uDSMrMM6h+Y2c7mrlWTeF1a+mKl5MtG45evCWVwu8RCTjaWjGiY83DkAf6e2JtqU+QV5FS2BuTSi9fN4NmsVAUmurZgJ1nUniiDikFKSWh0fpU2RXNjGpCM1cHRnduwm8HzvPCHW1wcajZOoiqoHwKRqKsVBS1SVh4BH9v/gv3IgfzunXr+OILw1Z3ezraYiEEyQbeZPM0WvZEp7DpxKVqyZqSlc+mE5d4oGtz7KugwErT3M2B7j5uBh1VVQigXwV+V6fG7DyTQlaepvIG9Yjs/EI2nUji7sDGRnkIcLSzpndrD/4+mVxuIsMLV3I4l5ZTZRv8IP9GdS5r6rm0HC5m5JnEn1CaZwb6klOgZfG+eJOOcyMmVQpCiJFCiCghRIwQosx9mIUQDwohTgohIoUQy0wpT32notTb+/ZHELp9a8kTxejRo3nzTcO2vraytMDD0ZaMXA05ZaTv1ekkJxIz+GlnLI/8Gkbgh38zYd4Bnl1yqFqhcyvDL6DRSh7p1aLKbWuTewIbU1CoY+sp46+oNid/nUgip0DLmHLCgKvDsA5exKflEH257JDh6trg62JoavHWm6bwJ5SmnbcTg9t6EvLPuVpdYW8ypSCEsARmA3cCHYCHhRAdbqjjB7wF9JVSdgReMpU8tYUsJyX1pUuXGDBgAEFBQQQEBLBnzx60Wi2TJk0qqfvdd9/d1N+kSZN45ZVXGDx4MNOmTePAgQP06dOHLl260KdPH6KiosjJzeOrzz/h7w1r6BrchRUrVhASEsKUKVMAiI+PZ8iQIQQGBjJkyBDOn785Ra9HQ1usLCy4lJmHlJKCQh1XsvO5kl1At0+3cs8PoczYdJrULH06igWPd2dU5yZ88ddpfqtCyl+tTrI0LJ6+bdxp7Wne2VVldGnuShNnO/48Vr0ZUV1lVUQCLd0d6NbSePH1w9pXnCAvNCaNRo62tGlUte+8LoamFqf9bllJFJsxeHZga9KyC/i/8AsmH6sYU/oUegAxUso4ACHEcuBe4GSpOk8Ds6WUVwGklDX+5mccmMHpK6dr2s11tHNrx7Qe0wyqu3r16jJTUi9btowRI0bwzjvvoNVqycnJ4ciRIyQmJnLixAlAn2K7LM6cOcPWrVuxtLQkMzOT3bt3Y2VlxdatW3n77bf5OWQpz736Fokxkfz842wAQkJCStpPmTKFiRMn8thjjzF//nymTp3K2rVrrxvD0kLQyMmWi+m5RCVlUVC0diG/UMcgf0/6+XnQr43HdfH9fVt7kJWn4Z01x3G2t+auTpWn3d5++jIXM/J4f1TtOs+qQ7EJaeG+c2TkairNHFofSLiaw764NF4Z5l/ttQll4e1sR+dmzvx9MpnnB7e5rkynk/wTk8pAf88qj6nPmurOjqgUpktpVJlBn/p69o5YOjd3Nki+4rTfIzt6G12WsujRyo0uLVyYsyeOh3u0wMpAf0xNMOUITYHS6i2h6Fxp/AF/IcReIUSYEGJkWR0JISYLIcKFEOEpKXUzbrmY0NDQMlNSd+/enQULFjB9+nSOHz+Oo6Mjvr6+xMXF8cILL7Bp0yacnMre9Hvs2LFYWuptvxkZGYwdO5aAgABefvllIiMjScsuwNbKAqtynF779u1j/PjxgH7TntDQ0DLruTWwoaGtFbbWljR2tsffy5HGznZ8Oy6I/wQ3u2nBl42VBT890pXgFq68uPywQQuYloTF4+Vky9D29SML6T2dm6DRSqNsVF8XWHNIn5q5JmsTymNYBy+OXki/yTd1OimLtOyCatvgB7X15PyVHM6mZhtDzOtYuC+e77aeYdKCg4yfu5+jF8p+MCsm8mIGGbma67YRNSX6RHmtuXAll40nqr/TXVUw5UyhrDvUjV4oK8APGAQ0A/YIIQKklNd9M1LKOcAcgG7dulW4JZehT/SmojxH24ABA9i9ezd//vknEyZM4PXXX2fixIkcPXqUzZs3M3v2bFauXMn8+fNvals6TfZ7773H4MGDWbNmDefOnWPgwEEUFOpoWIVY+vKecCyEwLeKJh17G0vmTerOQ3PCmLwogiVP9aRrOWaJ+LRsdp1J4eWh/rXyxGMMOjdzpqmLPRuOXSw3FUd9QUrJ6sOJ9PJ1M0n48fCO3nz99xm2nEy+bkFisQ2++kpBH5q6Myqlyr/PiriUkcu3f0cx0N+TwW09+WF7DPfO3svdnRrz2oi2Za6N+Dftd81SZVeFYe29aO3ZgF92xTIqsLHJZyim/M9MAErn4m0G3LhENAH4Q0qpkVKeBaLQK4l6y4ABA1hRRkrq+Ph4GjVqxNNPP82TTz7JoUOHSE1NRafTMWbMGD7++GMOHTpUaf+lU2+HhISglRIrCws83V3Iyip7WXyfPn1KaCR3AAAgAElEQVRYvnw5AEuXLjUo82pVcLa3ZtETPfBysuWJkIOcTsoss97S/eextBA81KNqKZrNiRCCewIbExqdSnpOgbnFIb9QyysrjlQrnfih81c5m5rNmGDTKDe/Rg1p6e5w06xqb2wqbRo1rPYiueZu/4amGpMP151EKyWf3BfApL6t2PXGYF4c4seOqMsM/XYX76w5zuUbZj17Y1Jp39gJj4Zlp/02BRYWgmcGtCbyYmaJUjLpeCbs+yDgJ4RoJYSwAR4C1t1QZy0wGEAI4YHenGSetd1G4v777ycwMPCmlNQ7d+4kKCiILl26sGrVKl588UUSExMZNGgQQUFBTJo0ic8//7zS/t944w3eeust+vbtS4GmECklbg2sGXLHHZw8eZKgoKCb9lv+/vvvWbBgAYGBgSxevJiZM2ca/XN7Otqy+Mme2FlbMGHeAc6n5VxXnqfRsjL8AiM6euFVQd6husg9gU0o1Ek2R9bO9L0ilu0/z+rDiTy39JDB+YaK+T0iAXtrS+40wPdTHYQQDGvvxT+xqSVhvAWFOvbHXalxpI6xQ1O3nUpmU2QSU4f4lcyaGtpa8fIwf3a9PphHerZgxcELDPxqJ9/8HUVWnoY8jZaD567Sr03tzRKKubdLE3r7ulOoq4W9yw1JpVrdA7gLOAPEAu8UnfsIGF30WgDfonc+HwceqqxPlTr7Xy6l58pjF67KfI3p0gtX9dqeScqUnT/cLPvN2CaTMnJLzv8efkG2nLZB7o0xXprh2kKn08n+M7bLR38NM6scWXkaGfzR33LMj3vlyP/tlu3f+0tGxF8xqG1uQaEMeH+TfHn5YZPKGBabKltO2yDXH0287v3fkUk16nf3mcsGpdw2hOx8jezz+TY59JudMl+jLbfe2ZRrcsqyQ7LltA0y6MPN8o3/OypbTtsgd5yuuQzmgLqQOltKuVFK6S+lbC2l/LTo3PtSynVFr6WU8hUpZQcpZScp5XJTynMrUFCoJS07n/i0bFKv5eNoZ41NHdpk3s/LkZDHe3DlWgET5x0oMbksDountWeDGm9baA6KTUj/xKZVeZcxYzI/9Cxp2QW8c3d7Fj3Rg0aOtjy+4CBRSZVn0/z7ZDJZ+YUm94t0bemKWwObEhPS3phULC0EPX0rTpVdGcWhqTuMEJo6c1s0iem5fPafThXm+/LxaMAPD3dh/ZR+dGzizIrwC1hbVp72u75TP7x9tzGFOh0ZuRoSr+YQlZTJ6aQsEq/mklOgxdnemiYudc8UE9TchbkTu3E2NZvHQw6yPy6NIxfSebRXy1oJ4zMFdwc2RquTbI40TxTSlewC5uyOY0RHL7q0cL3BXLf/JnPdjayKSKCpiz29TKyUrSwtuKNdI7afvoxGqyM0JpXOzZxxsqtZOK+tlT40dWdUSrnBHIZwOimTeXvOMq5bc7r7GHZz79TMmSVP9WTpUz2ZPT4YB5tbOzvQLaMUavJDqQ00Wh35Gq1Bx7X8QpIy8oi5fI1TFzOJT8vmao4GW6t/Q0XbeTvS3M3BpLOEmlzTPm08+GF8F45eSGfi/APYW1vyHxM5OGuDDo2d8PVowIZjVUunnZGrMcpv88cdMeQUFPLa8H8T2DV3c2Dxkz0p0Op4dN7+m5yixSRn5rEnOoX7uzStlQ3hh3XwIiuvkG2nkjmakGG0lb81DU3V6STvrDmBk701b97Zrsrt+7bxYLgRckXVdW4JpWBnZ0daWlqdUgxanSQzV8PF9FzOJGVx6lImUclZBh1xKddIydL/g3s62uHr2ZAOTZzw8WhQkrTO1E/cUkrS0tKws6v+TGRER29mjAkkv1DHfV2a1OvFX0II7g5sTFhcGikG7D9xOTOPt9ccJ/jjLXy4/mSl9SsiMT2XRWHxjAluhp/X9am//YvMdanX8plQylxXmrWHE9FJ+E+w8dcmlMUAP0/srC344q/TaHXSaDmC9KGp8NGGk2RWIx/VivALRMRf5e272hu038jtyi0xD2rWrBkJCQmYc2GblBKNVpJXqCVfo6OgUIcEhABbKwtsrSwMzqhoIQQ2lhZoLARXgasmlbx87OzsaNasZk/3Y7s1p31jpzqf0sIQ7glswg/bY9gUmcSEcjYGyszT8MuuWOaFnkWrkwQ0dSbkn3P0bOVW7aifmVvPgISXhvmXWV5srnt8wUEeDznI0qd6lpg4pJSsOpRAcAsXo8b4V4S9jSX92niy9VQy9taWdKlCyvKKaO7mwMf3BfDhukjun72XORO7Gfy7Sr2Wzxd/naZnKzfG1JJyrK/cEkrB2tqaVq1qP7VunkbL7xEJ7IlO4Z/YNLLyChECApo408/Pg/5tPAhuadzt+uojAU1Nk3O+tvH3akibRg3ZcPTiTUohT6NlSVg8s3bEkJ6jYXTnJrw63J/GzvaM/WUfb6w6RscmzpXu+nYjMZez+D0igcf7tqJpBZut9G3jwfcPd+G5pRE8sziCXx/rhq2VJccTMziTfI1P7w+o1meuLsM7eLH1VDI9fd2MunnThF4t8WvUkOeWHuK+WXuZ+XAQd7SrfHX8Z3+eIqegkE/v71Rv/Vq1xS1hPjIXn288xbtrT3AiMZO7OzVm1vguRLw7jPUv9GPayHb0aeNx2yuEW4niKKQD566U2O+1OsmqiASGfLOLT/48Raemzmx4oR/fP9yFlu4NsLGyYNbDXQB44bdDFBRWbT/srzefwcHGiucGta607sgAb74YE8ie6FReXnGkRDYbKwvuCazdPSGGtG+Eg40lQ0yQzqSXrzvrX+hHC3cHnlwYzuwdMRWajv+JSWX14USeHdi6ygn5bkduiZmCOUi7ls+K8AuM7dqMLx+o2u5hivrLPYGN+d/WaDYev0QLdwdm/BVFVHIWnZo6M2NMIP3KyInT3M2Brx4I5Nklh5ix6bTBO2kduZDOpsgkXh7qj7uBK2gf7NaczFwNn/x5ioa2x9hyMpnhHbxq3Z/j3tCWvdPuMNm4TV3s+f3ZPkxbdYyvNkcReTGDrx7ofNPWqfmFWt5de4KW7g43JepTlI1SCtVk4T/nyC/U8czA1koh3Ea0aaSP/Pps42kKtDpaujswa3wX7gpoXGFkz8iAxjzWuyXzQs/Sy9edYR0qfoKWUjLjr9O4N7Dhyf5VM40+1d+X9BwNs3bEABh134SqYGpnrr2NJTMfCiKgqRNf/HWauJRs5k7sdl1ep593xhGXms3CJ3qoWbuBKPNRNcjOL2ThvniGtfdS09HbkAm9W+LpaMvH93Zky8sDuSewiUGhnm/f3Z6Apk689n9HSUzPrbBuaEwq++LSmHJHmyolOyzm1eH+PN2/FUHNXehv4s1gzIkQgskDWhPyeA8uZeQxalZoSQK+s6nZzN4Zwz2BjRno72lmSesPoi6FcRpCt27dZHh4uFllmBd6lo83nGT1c32qtBm8QnEuNZt7fgilrbcjyyf3KnO/Yiklo2ft5Up2AdtfG4htHVqxXpeJT8vm6UXhxKZk8/Zd7dlx+jJHL6Sz7dWBN6V9vx0RQkRIKbtVVu+2mSnsOH2ZpxYepFBbNUffjWi0OubtiaNHKzelEBRVxsejAZ/9pxMR8Vf5dsuZMuv8dSKJ44kZvDLMXymEKtDSvQGrn+vL0PaN+HjDSUJjUnljZFulEKrIbaMUcjVatp66zMIaboK97shFLmbk8d+BlUeDKBRlMbpzEx7u0YKfdsay64Z00IVaHV9vjsLfqyH3mWAjnFudhrZW/PRIV6aNbMeY4GaM71n2ehJF+dw2SuHOAG8Gt/Xk27+juJRRsT23PHQ6yS+7Y2nn7cigtspGqag+H4zqQFsvR15ZceS6ncp+j0ggLjWb10e0M3ixo+J6LCwE/x3Umm8e7KyuYTW4bZSCEIKP7g1AKyUfrqte2oEdUZc5k3yNZwb6qogjRY2ws7Zk9iNdyCnQMvW3w2h1kjyNlv9tjSa4hQtD2zcyt4iK25TbRimAPl586hA/NkUmse1U1bNd/rwrlqYu9rW+EEhxa9KmkSOf3BfA/rNXmLktmkX7zpGUmccbI9uphw6F2bjt1ik83d+XtYcTef+PSHq3djc4DW5E/BUOnrvKB6M6lBkxolBUhzFdm/FPbBo/bI/GwdqSgf6eJk9vrVBUxG13d7O2tODT+zuRmJ7LzG3RBrf7aWccrg7WjOtef/YXVtQPPrq3I74eDcgu0PL6iLaVN1AoTMhtpxQAuvu4Ma5bc+btOVvuJvOliU7OYuupZCb29rnlN9hQ1D4NbK1Y8lRPFj7R45ZJHqiov9yWSgHgzTvb4WRvzTtrTqCrZDPsObvjsLO24LE+PrUjnOK2o7GzvVp1q6gTmFQpCCFGCiGihBAxQog3yyifJIRIEUIcKTqeMqU8pXFtYMPbd7UnIv4qK8IvlFvvUkYua48k8lD3FripjTkUCsUtjsmUghDCEpgN3Al0AB4WQpSVHnKFlDKo6PjVVPKUxZjgpvRs5cYXf50mtZwN2eeHnkUn4cl+tb9fg0KhUNQ2ppwp9ABipJRxUsoCYDlwrwnHqzJCCD69vxM5BYV89uepm8ozcjQs23+eewIbX5d5UaFQKG5VTKkUmgKl7TIJReduZIwQ4pgQ4nchRJmhPUKIyUKIcCFEuLG33GzTqCHPDmzN6sOJ/FOUXbGYJfvjyS7Q8swAldJCoVDcHphSKZS1+uZGj+56wEdKGQhsBRaW1ZGUco6UspuUspunp/Gdcc8PbkNLdwfeXXuC/EItoN9eccHeswz096RDEyejj6lQKBR1EVMqhQSg9JN/M+Bi6QpSyjQpZbExfy7Q1YTylIudtSUf3xtAXGo2P++MA/Q5aFKvFfCsSnynUChuI0ypFA4CfkKIVkIIG+AhYF3pCkKIxqXejgZuNuzXEgP8PRnVuQmzd8YQc/kac/fE0bm5C7183cwlkkKhUNQ6JlMKUspCYAqwGf3NfqWUMlII8ZEQYnRRtalCiEghxFFgKjDJVPIYwnt3t8fW0oJHfg0jPi2H/6rEdwqF4jZD7bx2A4v3neO9PyLx9WjAllcGqtS7CoXilsDQnddUzoYbGN+zJXGp2Qxr76UUgkKhuO1QSuEGLC0EH4zqaG4xFAqFwizctrmPFAqFQnEzSikoFAqFogSlFBQKhUJRglIKCoVCoShBKQWFQqFQlKCUgkKhUChKUEpBoVAoFCUopaBQKBSKEpRSUCgUCkUJSikoFAqFogSlFBQKhUJRglIKCkUViUuPY8GJBRRoC8wtikJhdJRSUCiqyNzjc/k24lue2PwEKTnG3TNcoTA3SikoFFVASsnBpIO0dm7NmatnGLdhHMdSjplbLIXCaCiloFBUgYRrCSTnJPNQu4dYfOdibCxtmLRpEmui15hbNIXCKCiloFBUgfAk/a5/3b2709atLcvvXk6wVzDv//M+n+//HI1OY2YJFYqaoZSCQlEFwpPDcbNzw9fZFwAXOxd+HvozEztMZNnpZUz+ezJX8q6YWUqFovqYVCkIIUYKIaKEEDFCiDcrqPeAEEIKISrdP1ShMCfhSeF09eqKEP9u1WplYcXr3V/ns36fcSzlGA9teIhTaacq7Stfm8++i/v4NuJbHlz/IA+uf5B8bb4pxVcoKsVkSkEIYQnMBu4EOgAPCyE6lFHPEZgK7DeVLAqFMUi8lsjF7It08yr72WVU61EsunMROqlj4l8T2Ri38bpyndRx+sppFpxYwOS/J9P3t75M3jKZxScXY2Vhxakrp1hxekVtfBSFolxMuUdzDyBGShkHIIRYDtwLnLyh3sfAl8BrJpTFZOQW5mJvZW9uMRS1QLE/oZt3+RPajh4dWX7Pcl7d+SrT9kzj1JVT+Dr7su/SPvZf2l9iWmrj0oax/mPp3aQ33by64WDtwDNbnmHu8bn8x+8/NLRpWCufSWE4hbpCNDrNLf//brBSEEJ0BvoXvd0jpTxaSZOmwIVS7xOAnjf02QVoLqXcIISoV0pBJ3W8t/c9dpzfwep7V+PdwNvcIilMzMGkg7jYutDGpU2F9TzsPfh1+K/MODiDkMiQknN9mvShd5Pe9Grci0YOjW5qNzV4Kg9teIiFJxfyfNDzpvgIihow48AM9l7cy8b/bKy8cj3GIKUghHgReBpYXXRqiRBijpTyh4qalXFOlurTAvgOmGTA+JOByQAtWrQwRGSTIqVkxoEZrItdh0Dw89Gfmd5nurnFUpiY8GS9P8FCVG51tba05t1e73KP7z04WDvg5+J3nR+iLDq6d2SEzwgWRi7kobYP4W7vbizRFTXkcs5lVkWvQqPTkJqbioe9h7lFMhmG+hSeBHpKKd+XUr4P9EKvJCoiAWhe6n0z4GKp945AALBTCHGuqM91ZTmbpZRzpJTdpJTdPD09DRTZdPx09CeWnV7GxA4TGd9+PGtj1nI246y5xVKYkEvXLpF4LZHu3t2r1C6oURD+rv6VKoRipgRNoUBbwNzjc6sjpsJELDm5pCTc+MzVM2aWxrQYqhQEoC31XkvZM4HSHAT8hBCthBA2wEPAuuJCKWWGlNJDSukjpfQBwoDRUspwg6U3A0tOLuGnoz9xX5v7eK3bazzd6WlsLW2ZdXiWuUVTmJDw5CJ/QjlOZmPh4+zD/X73syJqBYnXEk06lsIwMgsyWXlmJT0b663f0VejzSyRaTFUKSwA9gshpgshpqO/gc+rqIGUshCYAmwGTgErpZSRQoiPhBCjayCz2VgXu44ZB2cwpMUQPuj9AUII3O3deazjY/wd/zeRqZHmFlFhIsKTw3GyccLP1c/kYz0b+CyWwpIfj/xo8rEUlbMyaiXZmmxe7foq7nbuSikASCm/BR4HrgBXgcellP8zoN1GKaW/lLK1lPLTonPvSynXlVF3UF2eJew4v4P3975Pz8Y9mTFgBlYW/7pjJnaYiKutKzMPzTSjhApTcjDpoMH+hJri1cCL8e3Hsz52/S1/A6rr5GvzWXpqKb0b96a9e3v8Xf2JTr+1v5MKf+FCCKeiv27AOWAJsBiILzp3W3Aw6SCv7XqNDu4dmDl4JraWtteVN7RpyNOBT7Pv0j7CLoWZSUqFqUjKTuJC1gWTm45K82TAkzS0bsj3h7+vtTEVN7M+dj2puak80ekJAPxc/YhNj0Wr01bSsv5S2WPPsqK/EUB4qaP4/S1PZGokL2x/geaOzflxyI80sG5QZr0H2z5I4waNmRkxEyllmXUU9ZNif0JVncw1wdnWmSc6PcHOCzs5cvlIrY2r+BetTktIZAgd3DvQ01vvT/Bz9SNfm8/5rPNmls50VKgUpJT3FP1tJaX0LXW0klL61o6I5iMuPY5ntz6Li60Lvwz7BRc7l3Lr2lra8lzQc5xIO8G289tMLluOJofvD33PybQb1wIqjE14UjiO1o74u/rX6rjj243H3c6d7yK+Uw8aZmD7he3EZ8bzRMATJdFjxT6lW9msZ5CBVAhx012urHO3EhevXWTylslYCkvmDJuDVwOvStuM8h1Fa+fWfH/4ewp1hSaT7ULWBR7961HmHp/L7COzTTaOQk9EcgTBXsFYWljW6rgO1g482/lZDl0+RGhiaK2OfbsjpWT+8fm0cGzB0BZDS863dm6NhbC4pcNSK/Mp2BX5DjyEEK5CCLeiwwdoUhsCmoO03DQmb5lMTmEOvwz7hRZOhi2Ys7Sw5IXgFzibcZb1setNItu+i/t4+M+HSc5Opnfj3vxz8R8y8jNMMpYCUnJSOJd5rlZNR6UZ4zeGZg2bMfPQTHRSZxYZbkcOJh3kRNoJHuv42HUPA3ZWdrRwbHFbzxSeQe8/aFf0t/j4A32yu1sOKSVTt08lOTuZH4f8SFu3tlVqf0fzOwj0CGT2kdlGzXgppWRh5EKe3fosnvaeLL97OVODp1KoK2T7+e1GG8fY5GvzeXnHy/wR84e5RakWtbU+oTysLa2Z0mUKUVej2HR2k1lkqCvkFebxzJZneH3X66yOXs2la5dMNtb8E/Nxt3Pn3jb33lTm5+p3S0cgVeZTmCmlbAW8VsqX0EpK2VlKeUuu1opNj+VY6jFe6voSQY2CqtxeCMGLwS+SnJPM8tPLjSJTXmEeb4e+zdfhXzO4+WCW3LWE5k7N6ejekaYNm7I5frNRxjEFvx7/la3nt/Le3vfq5U3tYNJBGlo3rPLDgTG5s9Wd+Lv6M+vIrNt6E59N5zbxz8V/2H9pPx/88wHDVw1n1JpRfBr2KdvObyOrIMso45y+cpq9F/fyaIdHb4o0BPB39edC1gVyNDlGGa+uYVDuIynlD0KIAPQpsO1KnV9kKsHMRbHtdkiLIdXuo0fjHvRp0odfj//KGL8xNcp4mZSdxIs7XuRk2kmeD3qeyYGTS2LlhRCM8BnBoshFpOelV+gINwdnM84y7/g8hrccTlpeGm+FvkVDm4b0a9rP3KIZTHhyOF0adbluXUptYyEseDH4RZ7f9jxrotfwYNsHzSaLOVlxegWtnVuz+t7VxKbHEnYpjH0X9/FH7B8sj1qOpbAkwCOA3k1607txbzp5dsLawrrK48w/MZ8G1g3Kvc7FzuaY9BgCPQNr9JnqIoY6mj8Afig6BqNPdV0vVyVXRmhiKG1c2tQ46+nU4Kmk56ez8OTCavcRkRzBuA3jiM+M5/vB3/Ns52dvWjw1wmcEhbKwViKeqoKUkk/CPsHOyo63er7FD3f8gJ+LHy/veJnDlw+bWzyDSM1N5WzGWbP5E0rTv2l/ghsF89PRn8gtzDW3OLVOZGokJ9JO8GDbB7EQFvi5+jGhwwR+HPojex/ay/wR83ki4Al0UsecY3N4bNNj3LX6Lk6knqjSOAlZCWw+t5mx/mNxsnEqs46/iz4K7Vb1Kxi6PPMBYAiQJKV8HOgM3Dyvqudka7KJuBxB/6b9K69cCaUzXqblplW5/cqolTy1+SkcbRxZdtcyBrcYXGa99m7taeHYgk3n6pZpZkPcBg4kHeCl4JfwsPfA0caRn4b+hHcDb57f+jxRV6LMLWKlmNufUBohBC91fYnU3FSWnlpqbnFqnRVRK7C3smdU61E3lVlbWtPduztTg6ey7O5l7B63m28GfoMFFjz212Osi70pgUK5LIxciIWw4NH2j5Zbp6ljU+yt7G/ZCCRDlUKelFIHFBatcr4M3HLrFPZf2k+hrtBo5o3qZLzM0eTw4b4P+TjsY3o16cWyu5fh61L+pS42IR1IOmCUvYEz8jNqHOWSkZ/B1+FfE+gZyAP+D5Scd7d355dhv5RsKHM+0/QLgAq0BdVSyqBfn+Bg5UB79/ZGlqp6dGnUhUHNBjH/+Pzbah/ojPwMNp7dyN2+d+No41hpfWdbZ4b7DGf5PcsJahTEO6HvMOPAjErDxK/kXWFtzFpG+Y6qMATdQljg53LrOpsrVQpCv2rjmBDCBZiLPvroEHDAxLLVOqGJoThYOdClURej9GdIxkutTsuxlGP8cvQXJm2aRN/lffn9zO88GfAks+6YVe4UtjQjfEagkzq2xm+tkbxpuWncuepOnt/2PBpt9R2a30V8R0Z+Bu/3ev8mc1eThk2YM3wOOqlj8pbJJGcn10jm8tDqtKyLXcc9a+7hztV3kpCVUOU+wpPC6eJlXn/CjbwQ/ALZhdkM/b+hPLH5CeYem8uJ1BO3dNqFP2L+IF+bz7i246rUztXOlZ+H/cyj7R9lyaklPLvlWdLz0sutv+zUMvK0eUwKmFRp336ufkRfjb4lFxVWqhSk/lMHSSnTpZQ/A8OAx4rMSLcMUkr2JO6hV+NeWFtW3TlVHmVlvLyQeYGVUSt5ecfL9F/Rn0c2PsKsI7PI0eQwof0EFt25iJe6vmTwYil/V398nHzYfK5mUUjLTi8jS5NFaGIob4e+Xa0bzZHLR1gVvYpH2z9absSOr7MvPw39iat5V3lmyzMV/qNWFSkluxN288D6B3gn9B1cbF0QCD7b/1mV/oHTctOIzYitE6aj0vi7+rP4zsU80v4Rsgqy+P7w9zz858MMWDGAV3a+wsqolVzIulB5R/UEndSx8sxKgjyDaOfWrsrtrS2smdZjGh/3/ZjDlw/z0J8PlWm6zNHk8Nvp3xjcfDC+zpUbQfxc/UjPTyclN6XKMtV1DH0EChNCdJdSHpRSnjOlQOYiNj2WpOwkJgdONmq/xRkvQ06EAHrncfGswbuBN0NbDKV3k970bNwTN7vq5RgUQjCy1UjmHJtT7V2hcjQ5LD+9nCEthtDZszPfRnyLk40T7/Z61+ANYjQ6DR/u+xDvBt48F/RchXU7enTkhzt+4L9b/8tz255j7vC55eaVMpSjKUf5LuI7IpIjaO7YnK8GfsXwlsNZcnIJX4V/xdbzWxnWcphBfUUkRwC1m+/IUAI9A0uiXtJy09h/aT/7Lu1j38V9bInfAkCzhs3o3aQ3o1qPMtrMt6ocTDpIB/cONfpe91/aT3xmPM/0e6ZGstzX5j5aO7fmpR0vMeGvCXzc92NG+IwoKV8VvYrMgkyeCHjCoP6KU55EX40uc2tVYyOlZEXUCoNNaDUerLIDOAkUArHAMeA4cMyQtsY+unbtKk3BguMLZEBIgLx07ZLR+07PS5f9f+svey7tKadsmyKXnlwq49LjpE6nM9oY0VeiZUBIgFx2alm12i+KXCQDQgLk0ctHpZRSfhf+nQwICZAzI2Ya3Mf84/NlQEiA3Ba/zeA22+K3yc4LO8snNz0p8wrzqiy3lFLGpsfKF7e/KANCAuTA5QPlb6d+kwXagpJyjVYjH1j3gLxjxR0yKz/LoD4/DftUdl/S/bp+6jo6nU7GpsfKJSeXyCnbpsieS3vKoEVBMiUnpdZlic+IlwEhAfL1na/XqJ8Xt78o+//Wv9q/jRu5nH1ZPvLnIzIgJED+L+J/slBbKAu0BXLo/w2VEzdONLifq7lXZUBIgFxwfIFR5KqMn4/8LANCAmTIiZBq9wGES0Pu9wZVgpZlHYa0NfZhKqXw5KYn5X1r7zNJ31JKmYf6Ap8AACAASURBVF2QbfIbzH1r76vSD7uY4n+KSX9NKjmn0+nk9H+mG/zDT8xKlN2XdJcvbHuhyuP/EfOHDAgJkFO3TZUarcbgdknXkuQHez+QgQsDZY8lPeRPR36S2QXZZdY9dvmY7BTSSX6+/3OD+r5v7X1y8t+TDZalLnIu45wMCAmQPx/5udbH/uXoLzIgJEAGhATIvQl7q9XHpWuXZOeFneW34d8aVbb8wnz5wd4PZEBIgPzvlv/KJSeXyICQALnrwq4q9TN4xWD59p63jSpbWSw7tUwGhATIt/e8LbU6bbX7MVQpGLp4Ld7YM5S6RHEo6oT2E0w2hoO1g8n6Lma4z3B+OvITydnJBiXwK+avs3+RlJ3E+73eLzknhODdnu+SVZDFNxHf4GTrxH/8/lNmeykln+3/DIC3erxVZblHtx5NZn4mMw7OYMq2KbR2aV1pm2uaa/wZ9ydaqWV8u/E8Hfh0hea3Tp6deLDtg/x2+jdGtR5FR/eO5da9mneVmPQY7mp1V5U/S12ipVNLejfuze/Rv/Nkpydr1WG++dxmAtwDuKa5xif7P2H16NXYWdlV3rAUq6JXoZM6xvqPNapsNpY2TO8znQ7uHfh8/+fsSdxDG5c2VQ5F93f1N3lY6oa4DXy2/zMGNR/Eh30+rJVNnupOWIUZMXYoqrkY4TOCH4/8yJb4LTzaofw469LopI4FJxbg5+p30+e3tLDk836fc01zjQ/3fYijjWOZNvnt57ezK2EXr3V7jcYNG1dL9kc7PEqeNo/5x+cbtLjNQlgwtOVQpgRNoZljM4PGmBo8lW3nt/Hxvo9ZetfSch35h5IPAdDNu245mavDuLbjeGnnS+xO2M0dLe6olTHjMuI4c/UMb/Z4kzYubXjq76eYe3wuL3R5weA+NDoNv5/5nX5N+xn8/VaVB9s+SGuX1nwS9gkvBb9ksO+sGD9XPw6eOkihrtAkCnd3wm7eDX2XHt49+Hrg17Wm1JVSAPYk7jFqKKq58HX2xd/Vn83nNhusFPYk7CEmPYbP+n1W5j+FtaU13w78lme2PMO03dNoMKQBfZr0KSnP1mTz2YHP8Hf1Z3z78TWS/6lOT/FUp6dq1EdFONk48Ub3N3hj9xus+P/2zjysqmpt4L+XUcEJFRVHFBFztlAzTU3TTEuzNC1tsG5mZXO38dbtNnzZvXVv480srW5laZZJOZCWllYOaGpOmCgqJIiiCA6M6/tjHRTxAOfA2ZxzOOv3PDxwzt577Xexh3etd71D4twy5V2fvp5a/rXo0qiLZbJUFwNbDaRJSBPmJs6tNqUQnxyPIAxtM5QmIU24qt1VzN46m5HtRjrk2QN6oHH41GEmdJxgqawXNb2IBaMXVOrY6LBo8ory2H98f7mxRJVhQ/oGHlr5EDENY+xWe7QS6+ciHo5SitWpq+nbvK9LXVHdxfDI4WzK2ETaiTSH9p+9dTYRoREMbzu8zH1CAkN4a8hbRNaP5IEVD7A5Y/OZbW9vepuMkxk80/eZSuWZqW6GRw7nkuaX8MZvb3Do5CG7+ySkJdC9SfcacT8E+AUwrsM4fvnzl2oJFgSI3xvPhU0vPOOV83Dsw9QOqM3zvz7vsFvwvMR5tKjTgn7N+1kpapUo9kBytQlpx5EdTPt+Gs3rNOedy9+pUu60ymCpUhCR4SKSKCK7ReRxO9unisjvIrJJRFaLSCcr5bFHsSuqt5uOiil2s3MkZmHToU1sPLSRWzrfUuELvX5wfd69/F0a127M3cvv5o+jf7DjyA4+3fEpYzuMpXt4d5fIbzUiwlN9niK/MJ+X17183vas3Cx2Hd1Fr6ae54paWa6Lvo4ACWBe4jzLz7X76G6SspIYHnl2kNG4dmMevOhBEtIT+GZPxXVG9hzbw7q0dYztMLbaCxs5Q7v67fAXf5cqheSsZKYun0rdoLrMHDqz0m7qVcEypSAi/uiaC1eis6veYOelP0cp1VUp1QOdZO/fVslTFsVZUWuKUmhdrzUXNLzAIaUwa+ssGgQ3YEz7MQ61HR4SzsyhMwn2D+bOZXfy9M9P0yC4AfdfeH9Vxa5WWtdrzZRuU/hu33esSll1zrYN6RtQqBqxnlBMeEg4g1sPZsHuBZwuOG3puZYmLz2z3lOS66Kvo3t4d15Z/0qFwYpzE+cS6Bfo8H3pLoL8g2hTr43L0l2knUhjyjIdJzVz6MwqJ+WsLFbOFHoDu5VSe5RSecDnwDkVK5RSx0t8DAWqPWbcVVlRPYkrIq/g98O/l5laA/QMaeWBldzQ8QanPKNa1m3JzKEzySvKI/FoIo/2epT6wfVdIXa1MrnLZCLrRfLi2hfPyTq6Pm09wf7BdG3c1Y3SuZ4JHSdwPO+4pYkTlVLEJ8fTq2mv8wIo/cSPpy9+muN5x3lt42tltnEy/yRxSXEMixxGo9qNLJPVVRSnu6gqmaczmbJsCtl52cy4fAaR9SOrLlwlsVIptABKxtun2L47BxG5R0SS0DOF++w1JCJTRCRBRBIyMlwXVu7KrKiehCMmpA+2fkAt/1rc0PEGp9tvH9aeWcNm8Xjvx73WbTPIP4hn+j5Dak4q7205m7BwQ/oGuod3J8g/yI3SuZ7YprG0q9/OUhPSrqO7SD6ezLDIYXa3xzSM4eZON/PlH1+e8fAqzeK9i8nJz2FCjLULzK6iQ1gHUnNSOZF/otJt5OTlcNfyu/gz50/eGvKW2xMwWqkU7Pl3nTcTUEq9rZSKAh4D/mavIaXUTKVUrFIqNjw83GUCrjm4pka4opamZd2WdGnUpUylkHYijUV7F3Ft9LWE1Qqr1DliGsYw8YKJTrvxeRK9mvViVNQoPtj2AUnHkjied5ydmTs9Lt+RKxARro+5nt8P/862w9ssOUd8cjz+4n+e6agkU7tPJSI0gufXPH9e0kVlS+XQIayD16xRRTfQBXcqO1vILczlvhX3sStzF/8e9G8uanqRK8WrFFYqhRSgVYnPLYE/y9n/c+AaC+U5j9WpqwkNDPV6V1R7DG87nO1Httv1OPl4+8copbi5881ukMyzeDj2YUICQnju1+fYkFbz1hNKMipqFLUDajM3ca7L21ZKsTR5Kb2b9S53cTQkMIQn+zzJ7mO7+d/2cws3bs7YzM7MnYyPGe81g43iKmyVXWx+fePrJKQl8EL/FxjQcoArRas0ViqF9UC0iLQVkSBgAnBOtQsRiS7xcSRQbQnKi11RXZ0V1VMY1kZP4b/b990532flZjF/13yGtx1OizrnWfN8joa1GvLQRQ+x8dBGXt3wKkF+QTWyxCJA3aC6jGw3kiV7l5CVm+XStndk7uBA9oFyXZuLGdRqEINbDWbG5hnnpDSflziP0MBQrmp3lUtls5LmdZoTGhhaqZlCXmEeC3cv5IrIKxjZbqQF0lUOy5SCUqoAmAbEAzuAeUqpbSLynIgUl/KcJiLbRGQT8BBwi1XylKamuaKWJqJOBN3Du7N077kLi3MT53Ky4CSTO9eozOdVYkz0GHo26cm+4/voFt6tWgOFqpvxMeM5XXjaqWpkjrA0eSkBEsDgVo4FyD3R5wlEzqY0P3r6KEuTl3J1u6urJSWMq/ATP9o3aF8pD6QfU37keN5xRrcfXfHO1YilcQpKqcVKqQ5KqSil1Iu2755RSsXZ/r5fKdVZKdVDKXWZUsoaY6cdaporqj2uiLyCxKOJ7M3aC8DpgtN8uuNT+rfoX2atA1+k2DMmwC+Avs37ulscS+nYsCPdw7szL3GeywrEKKX4Lvk7+jTvQ4NaDRw6plloM+7pcQ+rUlexfP9yFuxeQH5RvtOFdDyB6LBodh3d5fT/M253HOG1w+kb4Vn3nM9GNBcnwapJrqilKTYhFS84L9y9kMzTmQ7njPclosOiWTRmEbd2vtXdoljO+JjxJB9PZm3aWpe0t/XwVlJzUs8JWHOEiRdMpGPDjkxfO515ifOIbRpL+7D2LpGpOukQ1oHsvGzSTzpeRfDIqSOsTl3NVe2u8rgAPZ9UCifyT7Dx0EYubVmzXFFL0zS0KRc2uZD45HgKigr4cNuHdG3ctUZ617iC5nWa1zhXVHsMixxGWHAYc3e6ZsE5PjmeAL8ALmt1mVPHBfgF8PTFT5NxKoPUnFSvnCVA5TyQFu9dTIEqYFTUqIp3rmZ8UikUu6LWtPgEe1wReQW7j+3m3S3vkpKTwm1dbvMazw6DNQT7B3NN9DWsOLCiyjWyi1QR8fvi6de8X6WCGLuFd2PiBRNpUacFQ1oPqZIs7qLYA8mZdYW4pDg6NerkkTMjn1QKxa6oPZr0cLcoljO0zVAEYcbmGUTWi3R6NGeomYzrMI4iVcSXf3xZpXa2ZGwh7UTaOaUtneXRXo+yaMwir/UCrB9cnyYhTRx2S03MTGRn5k6PnCWADyqFc1xRvSCrZ1UJDwk/43d/a+dbPc5+aXAPreq2on+L/szfNZ/8ovyKDyiD+OR4gvyCqjTYEBGvvy87hHVw2HwUlxRHgF+Ax2YD8DmlUNNdUe0x6YJJ9Inow9VRV7tbFIMHMaHjBDJOZbBi/4pKHV+kivgu+Tv6tehX7emdPY3osGj2ZO2pUMHmF+Xz7Z5vGdhyYKWzCViNzymFVak6K6YvKYXBrQfz/rD3fWIR1eA4/Zr3o3lo80rnQ/rt0G8cOnXIaa+jmkh0g2gKigpIzkoud79fUn8h83Smx5qOwAeVwurU1USHRddoV1SDwRH8/fwZFzOOtWlr2XNsj9PHxyfHE+wfzMBWAy2QzrsoLrhTkQlpYdJCwoLDPNrJxaeUQrErqi/NEgyG8hjTfgyBfoHM2+XcbKGwqJBl+5YxoOUAQgNDLZLOe2hXvx0BElCuB1JWbhYrD6xkRLsRHr2o7lNKwZdcUQ0GR2hUuxHDIoexcPdCTuafdPi4jYc2cvjU4TLTZPsagf6BRNaPLNcDaenepeQX5Xu06Qh8TCn4kiuqweAo42PGk5Ofw99+/lu5hZlKsnTvUmoH1GZAC8/I7OkJVFRwJy4pjvYN2nNBQ/fWS6gIn1EKSilWpazyGVdUg8FReoT34O7ud/NTyk9cveBqXl73MkdPHy1z/4KiApbvX86AlgO8Knmd1XQI68DBEwfJzss+b9verL1sObyF0VGjPT541GeUwu7MXaSfTDemI4OhFCLCXT3u4tsx3zIqahRzds5hxFcjmLllpl2T0vq09WSezjReR6UoL91FXFIc/uLvUSmyy8JnlMLqVc8D0K9uOzdLYjB4Js1Cm/HsJc+yYNQCejfrzZu/vcnIBSOZlzjvHP/7+OR4QgJCjMNGKc6kuyilFAqLCvkm6RsuaX4J4SGuqxxpFT6jFC7vdS//OJJFs3Xvu1sUg8GjadegHa8Pfp2Pr/yY1nVb8/ya5xmzcAzxyfHkF+azfP9yBrUaRK2AWu4W1aOICI2gTmCd8zyQ1qatJf1kOqPae/YCczE+oxRatejDtZ0mwqY5kFG50nkGgy/Ro0kPPhz+IW8NfotAv0Ae+fERRn09iqzcrCrlOqqpiIjdxea4pDjqBtX1mrxjPqMUALj0YQgMgR+ed7ckBoNXICIMbDWQ+VfP5/l+z1OgCmhYqyH9WvRzt2geSXQDrRSKC+7k5OXw/b7vGR453Gsq+vmWUghtDJfcCzviIHWDu6UxGLwGfz9/rml/DYvGLCLumjivecFVNx3COpCdn03aiTQAlu1bxunC0x4fm1AS31IKAH3vgZBGsPwf7pbEYPA6gvyDKlU3wVcoXVthYdJC2tRrQ/fw7u4UyyksVQoiMlxEEkVkt4g8bmf7QyKyXUS2iMj3ItLGSnkACK4LA/4Ke3+EpMplhzQYDAZ7FBfN2XV0FynZKWxI38CoqFEeH5tQEsuUgoj4A28DVwKdgBtEpFOp3X4DYpVS3YD5wD+tkuccYm+D+q1g+bPgouLlBoPBUC+oHhGhEew6uotvkr5BEK5u510p662cKfQGdiul9iil8oDPgdEld1BKrVBKFUfHrAFaWijPWQKC4bIn4eAm2L6wWk5pMBh8g+iwaHZl7mJh0kJ6R/Qmok6Eu0VyCiuVQgvgQInPKbbvyuJ2YIm9DSIyRUQSRCQhIyPDNdJ1Gw/hHeGHF6CwwDVtGgwGnye6QTRJWUmk5qQyOmp0xQd4GFYqBXtGNLu2GhGZBMQC/7K3XSk1UykVq5SKDQ93UUSgnz8MeQaO/AGb57imTYPB4PMULzaHBIQwpPUQN0vjPFYqhRSgVYnPLYE/S+8kIpcDTwGjlFK5FspzPjEjoGUvWDkd8k9V66kNBkPNpLjgztA2Q70yYaCVSmE9EC0ibUUkCJgAxJXcQUR6Au+iFcIhC2WxjwgM+TscT4X1Jv2FwWCoOlENorij6x3c2e1Od4tSKSxTCkqpAmAaEA/sAOYppbaJyHMiUhzJ8S+gDvCFiGwSkbgymrOOtpdC1BBY9Sqczqr20xsMhpqFn/hx34X30apeq4p39kBEeZlLZmxsrEpISHBto39ugpkDdfzC4L+5tm2DwWDwAERkg1IqtqL9fC+i2R7Ne0Dna+HXtyGn+q1YBoPB4CkYpVDM4L9BQS78ZNcBymAwGHwCoxSKaRQFF94MCR/A0WR3S2MwGAxuwSiFkgx8TMcvrHjJ3ZIYDAaDWzBKoST1IqDPVNgyF9K3uVsag8FgqHaMUihN/wcgqA6secfdkhgMBkO1Y5RCaWqHQYdhsGspFBW6WxqDwWCoVoxSsEfMCDiRASkujocwGAwGD8coBXtEDwW/QNj5rbslMRgMhmrFKAV71Kqv018kLna3JAaDwVCtGKVQFjEj4MhuyNjlbkkMBoOh2jBKoSxiRujfxoRkMBh8CKMUyqJ+C4joYUxIBoPBpzBKoTw6XqU9kLLT3S2JwWAwVAtGKZRHxxGAgl12S0cbDAZDjcMohfJo0gkatIGdi9wticHgPEpBQZ67pTB4GQHuFsCjEdEmpPXvQ24OBNdxt0QGg+MsfgQ2fAStekO7y6DdIGjeE/zNY28oGzNTqIiOI6AwF5K+d7ckBoPj/D5fD2baXgp5ObDiBZh1OfyzHXw+UW87kqRnEwZDCcyQoSJaXazzIe1cBJ1Gu1sag6FijiTBNw9Ay95w4zzwD4QTR2DvSkhaAXtWnnW1btBazyKiLoO2AyGkoWtkKCyAjJ0QHqPPX93knYSTh3X/DE5hqVIQkeHA64A/8L5Sanqp7QOA14BuwASl1Hwr5akU/gHQYTgkLoHCfPfc4AaDoxTkwvzJui7I2Nln79fQRtDlOv2jlFYce1ZoJbFtAWz8CBCI6K4VRLvLoPXFEBDs2HmV0sGeSSt0u8mrIfc4XPoIDHnasu7aJTcbProa0rbCiH9C7G3Ve34vxzKlICL+wNvAUCAFWC8icUqp7SV22w/cCjxilRwuoeNI2PwZ7P8V2g5wtzQGQ9l89zQc3AwTPoMGrezvIwKN2+uf3nfoUX3qBj2D2LMCfnkTVv8HAmpDm0tsSmIQNO2ijy3mxOGzxySthOMp+vsGraHzGK0k1r2n09EH17W022fIPw2f3QBpv0PzC+HbB+HgFrjynxAQVD0yeDlWzhR6A7uVUnsARORzYDRwRikopZJt24oslKPqRA2GgFqwc3HllcLu7/XordXFEFjLtfIZDAA7voF178LFd9vcqR3EPwBa99E/gx6D08dh389nR/3f/U3vFxqulUOdprD3R/3iBVuusAFw6UNagYS11cojdQO8Nxg2fAiX3OviztqhsADm36ZnKde+B12uhe+fg59f06as6/8HdZpYL4eXY6VSaAEcKPE5BehTmYZEZAowBaB1azfYCINC9cOwcxEMf+nc0ZIj7F8Ln1yr/w6oDW36nrXjNukMfma931BFju6Dhfdo76LL/1G1tmrVg5gr9Q9AVupZU1PSCjidpT2aLvubvoeb99QDntK0uAgiL4Vf/wu977R2pF5UBHH3QuIiGPEKdBunvx/6D4joBl/fA+8OhAmfQosLrZOjBmClUrD35qyUq4NSaiYwEyA2NtY97hIxI3ThnfSt0Kyr48cV5uspbL0WegqbvEo/WMuehmWcHX0VK4l6zS3qgKHGUpCn1xGUgrEfuP7lW78F9Jykf4qKoCjf8bWG/g/AJ9fB7/P08VagFMQ/CZvnwGVPaZNYSbpcB42itdfV7OEw6g3oPsEaWWoAViqFFKCkUbMl8KeF57OWmCvhG9EmJGeUwpp34NA2GP8pXHCV/gE9+tr741lvkN+/0N83joELroZBT3i2P/mBddok1usvUCfc3dL4Nj88p0014z6Ehm2tPZefH/g5qBAAoobo5+Xn16H7jdbMin/6F6x9R5vNBvzV/j4R3WDKCvjiVlhwp15nGPqcNc9YUaF+7juOtP56WICVdov1QLSItBWRIGACEGfh+aylThM9ZXYma+qx/bDyJT3LKFYGxdRvAT1uhOveg0d2wdSfYdgLeqaw6hX45j49KvNEEmbDByPgx+nwRg9YOV17fBiqn13xemE49na9uOtpiEC/B+DwLmvSxaydCSte1Apn2Ivlm3ZDG8NNC6DPVFjztjbpnsx0vUxb5sJ3T8HnN2rXWC/DMqWglCoApgHxwA5gnlJqm4g8JyKjAESkl4ikAOOAd0Vkm1XyuISYEZC2BY4dqHhfpWDxo/rvK18uf18RaNZFL8bd/LWeJWz6VN9YnhRcVJCn/d+/fRDaDYS//KAX4Ve+BG/01J4mJq1C9ZGVCgumQtOucMX/uVuasul0jfZIWv2aa+/nLfNgyV8hZiSMetOxWYh/oH4eR7+tvQlnDtKuq66iIBdW/B/UbwWHtsPSx1zXdjUNEi1d4VRKLVZKdVBKRSmlXrR994xSKs7293qlVEulVKhSqpFSqrOV8lSZjiP170QHRjw7F+mR0aAnnA+gGfiYbTTzX/jpFefltILsdO37veEDPfK7cR60vAjGfwx/+V6bvRY/Am/31tG0njrLqSkUFsCXt+uX0LgPPdujzT8A+t4LKev0i9gVJC7RCjHyUls8hpNmoJ6TYPISKMyDWUMh+WfXyJUwG7IOaCXV/yHY+D/Y8kXV283JgJkD4I9lVW+rAozbizM0jobGHbSHQ3nkZsOSR7Vn0cV3OX8eEbjiJeg2XqcnWPde5eR1Fakb9Ijq4Gb9AA79x7neJi1j4dZvYeJ87an15e3w3iC9XmKwhpUv6Rfs1a/peANPp+ckCGmkZwtVJXm1XhuI6AY3fFZ5hdgyFqashLrNtOdS/umqyZWbrdc32g7QTiOXPaVd0L99QAcLVpbTWdrUdXh3tcR7GKXgLDEj9E156ljZ+6ycDsdT9QNb2QhoPz89xe1wJSz+q2tGG5Vh02cw+0rwC4C/LNOeHPYQgeihcOcqGDMTTh6Fj6+B/10Df26qXplrOkk/wKpX9Yu22/XulsYxgkK0W+of8ZC+veL9y+LPTTBngp59T/yy6i/Jus1g5L8hMwlW/7tqbf36Npw8AkOe1Z/9A2DsLP0O+OKWyimd/FO6v4d2wPhPdJS5xYjyJJu1A8TGxqqEhAT3CXBgnZ5uXvv+WV/okhzcokfVF94EV79e9fPln4JPxsKBNTBhDnS4wrnjM/fqhbj9a6BVH+3+GnUZ1G9Z/nGFBdptds1/9RR93Ec6VYKjFOTC+ll65HQqU9u8+97jnOy+xIqX9EtFOWB2KzitZ613/KBnZt7CyUz4T2edQ2zMDOePP/yHdikNrA23xWtnDVfx5V9g+0K46xf9v3WWE4fhdVuKkPGfnLstcQl8NgF63QEjnTAHF+bD3EnamWDsrLIHZA4iIhuUUrEV7meUgpMUFcGrMRDZT9tyz9lWqBXG0X1wb4JOpOcKTh+Hj66CjETtPdHmkoqPycnQL+SE2XqUHzUYUhMgx1ZFrlH02Rw3kf11wFIxJ47A/Fth70/Q5y4Y9nzlZzyns2DBXTrGY/ISHTVrOJfV/4Hlz+ocW40cMAX5B8JFkyGsjeWiuZwlj8P69+C+TWWn4bDHsQNaIRTmwuSlrjeZ5RyCN2OheXe4Oc75ANWlT8DaGXD3Gp0EsDTxT8Gvb+moakcSaxYVadfZ3+fBVf9xSf4moxSsJO4+2PolPLrn3CCe9e/Dooe1+aT7eNee88Rh/VDkpGv7fUR3+/vlZusR5y9v6lnGhTfrhet6Edrz49B2HReRtEKnMsg/CeIPLXvZ8tt01l5P2en6Zuw5seqyn86Cdwfo2cfUVa7JxJmbA4EhrvV7z82GoDrOvxCqwoYP4Zv7octYnZqhpke3Hzug3Zh7T9HZARzhnHt/kV5LsIL1s2DRQ84/v8f2w5sXaVPe6Lft71OQBx8M1+sCU3+CsMiy21NKr0mumwlD/q7Th7gAR5VCDb8DLaLjSJ2jfu+qs99lp8Py53T6YSvsvKGNtbtqcD342LboVJKCPL0g/UZPvQgZNRjuWavXNepF6H1E9Eu/7z0waT48lgy3fKujTgvz4MeXYd5N+uU9eYlrFALo3DhjP9AP9cJ7qu6WeGCdnq29e6n2xqhqezkZ2n345bbao6W6PKe2fqVdfKOHaXNKTVcIoGcHXcbq4j+OxAicPq4XWbNStMebVQoB9OyrZS8dHe1M/MLK6YDAwMfL3icgSDtpAHwxuXzX7ZUvaYVwyb3Q/0HH5XARPnAXWkDbgRAYeq4XUvyTUHBKL1pZNdKs31IrBpRexM1K0S+w3+drV9DFj2jX0NuXa1fRimyjAcG6CMuQZ3S056N79OLd1NXa3dSVtLhQm6ESF+toz8qSvg0+Hac9WfJy4NOx8OFVkFKJ2WNutn6g3+ihZ3mtL4Ytn8PSx62PD9m9HL6aos857iPfSsne7z7IP6H/5+WRf0pnPE3fps0ubfpaK5efn54dnzqqzXmOcGinzqDc+46KzWFhkTD6TfhzI3xfRn6qX/+rB2c9b4Khz1fvrNWGUQqVIbAWtB+iF5CKinS6h63ztV+y1e6BjaNhMYKozgAADElJREFU0lfa++l/o7Xr55e3a1PKxPnatNSqV+XaDmkI0Zc7t6DsDH2m6kCjZc9oN1dnydwLH4/RC423fAP3rNfJzw4nwvtDYO5NejGyIsqaVd3yDfSdpjONrpxecTuVZf9aLWuTjnDD59ozx5do2lnPjtbOKDvitzBfj6j3/Qxj3oUOw6pHtmZdtRv5xo/0daqIH57XA8T+Dpp4Oo3WC86/vnV+vNOmORD/BFwwSjupuEEhgFEKlafjSMg+qH3FFz0MDaOqb6rXvAfcOFfPFE5m6odm6irtEuqmG8khRGD0W9oN8IvJeq3BUY4f1EqwMA9u+lovsgYE6RHafb/pIMGkH+DtPtokk512fhtFRXotqOSs6i/fn51ViehUIz0n6RQeVZnRlEXaVpgzTv8PJn0FtRu4/hzeQL8HtPvmpk/P31ZUpM2Mu5Zob52uY6tXtkFPQL2WOr6gML/s/VISdNqbfvc5N5Aa9gI06wZf36WfYdDBrgun6XW96963n3W2mjALzZXlZCb8q73OcpqTpl9UUZdVrww5h7S93tGMlZ7CgXV64fCCq7TppCJFdjITPhypF/RujivbtFXa46rv3dDvfv0/SloBy/+uA/CadNYBeO0vt3/uwgLtfbXjG7hmBvS4ocpdBiBzj+63+MNtS73Te8hVKKU99XLS4d7fzkYkKwVLHtOztcFPwwA31d/auUjnLhr6nL6HSqOUjvA/tAPu3wzBdZxr/0iSdr5o2hkGPa5jEZp1hZsXOt+Wg5iFZqsJaahdQ3PSoOv11a8QQCfp8zaFADqx4JBntF94wqzy983NgTnX6ypeE+aUv9ZRJ1yXX5y2Ts/kVr2qfcdnX6nXYBydVfkHwHWz9NrRwnv0C6KqHD+oA/kK87VbsS8rBDibKO/Yftj+9dnvV07XCqHvNLj0YffJ13GkNnWunK5lLE3SDzoN/sBHK/cSbxSlTUQH1mrHkUZRMPELyxSCMxilUBV6ToL6reGKF90tifdxyX3QfigsfVIH/NmjIFcH76Ru0N5L7QY61nbDdjrYZ8qPugDMsX06eG5ags6j78jUPCBYK6HmPbWpq6SnmbOczNRrISePaK+vJh0r31ZNImaEThvzsy1R3poZ2mzXY5I2sbjbFHrly4DojAIlLSpFRXqhuEFruOjWyrffdaxO9x3eUZsSXeGq7QKM+cjgPk4chhn9dVTulJXnpiwoKtSFY7Yv1L7fVhVoqYiTmTpNeFYK3BLnfNWu3Bw9Szm4RSsEU+P7XDZ+DHHT9Mt1w4fQ0WZS9JRaIr+8qcuRjv9E1zkB7Uo8f7KedbqiWI9S1aIAjfnI4PmENtZmmsw98O1DZ0djSulFvu0L9QjfXQoB9OjtpgUQEqYriGUkOnZcdrpO7fzJtbaZzmyjEOzR7XqoG6EVQtuB+n7wFIUAOqK/aVcdx5Kbrc1/P7wATTpBVztpbiqDu2dEpTBKweBeIvvBoCd1OP9vtpwxy/+uUw4P+Ktn5EuqF6EdCfwCtBnIno057wT8sVynM/jvJfBqB/jqDu0iO+bd84ssGTQBwTqyufO1un6yp6UA9w/QsQvZB3V+qt8+0cnzhjzjVg8hKzHmI4P7KSrUL9sD6/SsYP17uszniFc8axSVthU+HAEhjWHyYp0Jt7ic6oG12l3WP1gHpBXnlWrWzTcilWs63z6oZzO1Gmj35dviPevedACT+8jgXWSnw4x+cCLDs/MA7V9ri5fIPZvRtGlXiBqklUDrvr4XjOYLnDoKb/XS9+fkJY4lpfQwHFUKHmS8M/g0dZvq6N5dS3UCP09UCKCzvE6cp4Pg2vTXHlF1mrhbKoPV1A6D6z+GP3/zSoXgDGamYDAYDD6AR3gfichwEUkUkd0icl4KQREJFpG5tu1rRSTSSnkMBoPBUD6WKQUR8QfeBq4EOgE3iEinUrvdDhxVSrUH/gO8bJU8BoPBYKgYK2cKvYHdSqk9Sqk84HOgdMmh0cBHtr/nA0NEvGxJ32AwGGoQViqFFsCBEp9TbN/Z3UcpVQBkARblbTYYDAZDRVipFOyN+EuvajuyDyIyRUQSRCQhIyPDJcIZDAaD4XysVAopQMlSRC2BP8vaR0QCgPrAeXXwlFIzlVKxSqnY8PBwi8Q1GAwGg5VKYT0QLSJtRSQImADEldonDrjF9vdY4AflbT6yBoPBUIOwLHhNKVUgItOAeMAfmK2U2iYizwEJSqk4YBbwsYjsRs8QXJBy0GAwGAyVxeuC10QkA9hXycMbA4ddKI4nUNP6VNP6AzWvTzWtP1Dz+mSvP22UUhXa371OKVQFEUlwJKLPm6hpfapp/YGa16ea1h+oeX2qSn88NMGMwWAwGNyBUQoGg8FgOIOvKYWZ7hbAAmpan2paf6Dm9amm9QdqXp8q3R+fWlMwGAwGQ/n42kzBYDAYDOVglILBYDAYzuAzSqGi2g7ehogki8jvIrJJRLyy6pCIzBaRQyKytcR3DUVkmYj8Yfsd5k4ZnaGM/jwrIqm267RJREa4U0ZnEZFWIrJCRHaIyDYRud/2vVdep3L647XXSURqicg6Edls69M/bN+3tdWp+cNWtybIofZ8YU3BVtthFzAUnW9pPXCDUmq7WwWrAiKSDMQqpbw24EZEBgA5wP+UUl1s3/0TyFRKTbcp7zCl1GPulNNRyujPs0COUuoVd8pWWUQkAohQSm0UkbrABuAa4Fa88DqV05/r8dLrZCs3EKqUyhGRQGA1cD/wEPCVUupzEZkBbFZKvVNRe74yU3CktoOhmlFK/cT5CRBL1tj4CP3AegVl9MerUUodVEpttP2dDexAp7z3yutUTn+8FqXJsX0MtP0oYDC6Tg04cY18RSk4UtvB21DAdyKyQUSmuFsYF9JUKXUQ9AMMNHGzPK5gmohssZmXvMLMYg9budyewFpqwHUq1R/w4uskIv4isgk4BCwDkoBjtjo14MQ7z1eUgkN1G7yMfkqpC9HlTu+xmS4Mnsc7QBTQAzgIvOpecSqHiNQBvgQeUEodd7c8VcVOf7z6OimlCpVSPdAlCnoDF9jbzZG2fEUpOFLbwatQSv1p+30IWIC+EWoC6Ta7b7H995Cb5akSSql02wNbBLyHF14nm536S+BTpdRXtq+99jrZ609NuE4ASqljwErgYqCBrU4NOPHO8xWl4EhtB69BREJti2SISCgwDNha/lFeQ8kaG7cAC90oS5UpfnHaGIOXXSfbIuYsYIdS6t8lNnnldSqrP958nUQkXEQa2P6uDVyOXitZga5TA05cI5/wPgKwuZi9xtnaDi+6WaRKIyLt0LMD0DUx5nhjf0TkM2AQOs1vOvB34GtgHtAa2A+MU0p5xeJtGf0ZhDZJKCAZuLPYFu8NiEh/YBXwO1Bk+/pJtB3e665TOf25AS+9TiLSDb2Q7I8e6M9TSj1ne098DjQEfgMmKaVyK2zPV5SCwWAwGCrGV8xHBoPBYHAAoxQMBoPBcAajFAwGg8FwBqMUDAaDwXAGoxQMBoPBcAajFAw+i4j8YvsdKSI3urjtJ+2dy2DwdIxLqsHnEZFBwCNKqaucOMZfKVVYzvYcpVQdV8hnMFQnZqZg8FlEpDiz5HTgUlse/QdtycX+JSLrbQnS7rTtP8iWi38OOvgJEfnalpRwW3FiQhGZDtS2tfdpyXOJ5l8islV0PYzxJdpeKSLzRWSniHxqi741GKqVgIp3MRhqPI9TYqZge7lnKaV6iUgw8LOIfGfbtzfQRSm11/b5NqVUpi29wHoR+VIp9biITLMlKCvNtejI2e7oyOf1IvKTbVtPoDM6R83PQD90bnyDodowMwWD4XyGATfbUhGvBRoB0bZt60ooBID7RGQzsAaddDGa8ukPfGZLvpYO/Aj0KtF2ii0p2yYg0iW9MRicwMwUDIbzEeBepVT8OV/qtYcTpT5fDvRVSp0UkZVALQfaLouSeWkKMc+nwQ2YmYLBANlA3RKf44G7bCmWEZEOtmy0pakPHLUphI7odMXF5BcfX4qfgPG2dYtwYACwziW9MBhcgBmJGAywBSiwmYE+BF5Hm2422hZ7M7BfynApMFVEtgCJaBNSMTOBLSKyUSk1scT3C4C+wGZ0Rs5HlVJpNqViMLgd45JqMBgMhjMY85HBYDAYzmCUgsFgMBjOYJSCwWAwGM5glILBYDAYzmCUgsFgMBjOYJSCwWAwGM5glILBYDAYzvD/oXCKNwNI+kMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - 1 simulation\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "losses_1 = np.ones(30) - wins_1 - draws_1\n",
    "\n",
    "plt.plot(x, wins_1, label=\"win ratio\")\n",
    "plt.plot(x, draws_1, label=\"draw ratio\")\n",
    "plt.plot(x, losses_1, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "exploration_rate_1 = unique_trajectories_1/seen_trajectories_1\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - 1 simulation\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "\n",
    "plt.plot(x, exploration_rate_1, label=\"unique/seen\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins_1 = [0.54, 0.48, 0.56, 0.57, 0.57, 0.58, 0.67, 0.6, 0.61, 0.57, 0.66, 0.62, 0.62, 0.66, 0.55, 0.57, 0.52, 0.59, 0.55, 0.65, 0.68, 0.56, 0.7, 0.57, 0.54, 0.6, 0.58, 0.72, 0.67, 0.59]\n",
      "draws_1 = [0.23, 0.16, 0.04, 0.1, 0.09, 0.05, 0.07, 0.06, 0.09, 0.07, 0.02, 0.06, 0.04, 0.06, 0.02, 0.03, 0.07, 0.07, 0.12, 0.11, 0.1, 0.11, 0.03, 0.07, 0.11, 0.08, 0.02, 0.09, 0.04, 0.08]\n",
      "seen_trajectories_1 = [ 100.  200.  300.  400.  500.  600.  700.  800.  900. 1000. 1100. 1200.\n",
      " 1300. 1400. 1500. 1600. 1700. 1800. 1900. 2000. 2100. 2200. 2300. 2400.\n",
      " 2500. 2600. 2700. 2800. 2900. 3000.]\n",
      "unique_trajectories_1 = [ 100.  199.  292.  379.  449.  508.  568.  624.  660.  709.  748.  788.\n",
      "  813.  843.  874.  899.  924.  943.  966.  978.  990. 1007. 1021. 1037.\n",
      " 1047. 1060. 1070. 1077. 1090. 1104.]\n"
     ]
    }
   ],
   "source": [
    "print(\"wins_1 =\",wins_1)\n",
    "print(\"draws_1 =\",draws_1)\n",
    "print(\"seen_trajectories_1 =\", seen_trajectories_1)\n",
    "print(\"unique_trajectories_1 =\", unique_trajectories_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCTS = {\n",
    "    'c_puct': 5,\n",
    "    'dir_alpha': 0.6,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 10,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 10\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 5,\n",
    "    'temperature': 0,\n",
    "    'show_games': False\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 5,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.002,\n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 512,\n",
    "    'num_filters_value': 512,\n",
    "    'num_filters_tower': 512,\n",
    "    'num_residual_blocks': 3,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 512\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"tictactoe_num_sim_5\", \"TicTacToe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 4s 989us/step - loss: 6.8359 - value_loss: 1.1770 - policy_loss: 2.4084 - val_loss: 6.6491 - val_value_loss: 0.9648 - val_policy_loss: 2.2474\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.5783 - value_loss: 0.8887 - policy_loss: 2.1823 - val_loss: 6.5860 - val_value_loss: 0.9480 - val_policy_loss: 2.1387\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.4982 - value_loss: 0.8309 - policy_loss: 2.0806 - val_loss: 6.5578 - val_value_loss: 0.9605 - val_policy_loss: 2.0704\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.4196 - value_loss: 0.7429 - policy_loss: 2.0119 - val_loss: 6.4831 - val_value_loss: 0.8613 - val_policy_loss: 2.0210\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.3620 - value_loss: 0.6781 - policy_loss: 1.9623 - val_loss: 6.5177 - val_value_loss: 0.9693 - val_policy_loss: 1.9827\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.3583 - value_loss: 0.7088 - policy_loss: 1.9247 - val_loss: 6.4560 - val_value_loss: 0.8749 - val_policy_loss: 1.9544\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.3206 - value_loss: 0.6658 - policy_loss: 1.8930 - val_loss: 6.3975 - val_value_loss: 0.7842 - val_policy_loss: 1.9287\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2929 - value_loss: 0.6370 - policy_loss: 1.8670 - val_loss: 6.4050 - val_value_loss: 0.8201 - val_policy_loss: 1.9085\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2529 - value_loss: 0.5776 - policy_loss: 1.8472 - val_loss: 6.3811 - val_value_loss: 0.7913 - val_policy_loss: 1.8901\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2477 - value_loss: 0.5880 - policy_loss: 1.8269 - val_loss: 6.4145 - val_value_loss: 0.8745 - val_policy_loss: 1.8744\n",
      "Saved model  tictactoe_num_sim_5_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.67 - draw ratio 0.07\n",
      "Number of seen trajectories: 100\n",
      "Number of unique trajectories: 100\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 183us/step - loss: 6.3857 - value_loss: 0.8301 - policy_loss: 1.8616 - val_loss: 6.3419 - val_value_loss: 0.7389 - val_policy_loss: 1.8654\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.3364 - value_loss: 0.7622 - policy_loss: 1.8314 - val_loss: 6.3449 - val_value_loss: 0.7617 - val_policy_loss: 1.8493\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2956 - value_loss: 0.7046 - policy_loss: 1.8080 - val_loss: 6.3490 - val_value_loss: 0.7830 - val_policy_loss: 1.8367\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2767 - value_loss: 0.6860 - policy_loss: 1.7895 - val_loss: 6.4209 - val_value_loss: 0.9373 - val_policy_loss: 1.8270\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2635 - value_loss: 0.6759 - policy_loss: 1.7737 - val_loss: 6.3074 - val_value_loss: 0.7210 - val_policy_loss: 1.8168\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2303 - value_loss: 0.6221 - policy_loss: 1.7619 - val_loss: 6.3927 - val_value_loss: 0.9004 - val_policy_loss: 1.8086\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.2358 - value_loss: 0.6460 - policy_loss: 1.7496 - val_loss: 6.3095 - val_value_loss: 0.7410 - val_policy_loss: 1.8023\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.2151 - value_loss: 0.6153 - policy_loss: 1.7394 - val_loss: 6.2960 - val_value_loss: 0.7224 - val_policy_loss: 1.7946\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1994 - value_loss: 0.5942 - policy_loss: 1.7298 - val_loss: 6.2807 - val_value_loss: 0.6975 - val_policy_loss: 1.7895\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1936 - value_loss: 0.5920 - policy_loss: 1.7210 - val_loss: 6.2830 - val_value_loss: 0.7086 - val_policy_loss: 1.7836\n",
      "Saved model  tictactoe_num_sim_5_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.66 - draw ratio 0.05\n",
      "Number of seen trajectories: 200\n",
      "Number of unique trajectories: 200\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 6.3147 - value_loss: 0.7970 - policy_loss: 1.7588 - val_loss: 6.3268 - val_value_loss: 0.8201 - val_policy_loss: 1.7603\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2848 - value_loss: 0.7591 - policy_loss: 1.7376 - val_loss: 6.3243 - val_value_loss: 0.8233 - val_policy_loss: 1.7529\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2389 - value_loss: 0.6848 - policy_loss: 1.7208 - val_loss: 6.2910 - val_value_loss: 0.7661 - val_policy_loss: 1.7440\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.2179 - value_loss: 0.6560 - policy_loss: 1.7082 - val_loss: 6.3160 - val_value_loss: 0.8216 - val_policy_loss: 1.7391\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1974 - value_loss: 0.6267 - policy_loss: 1.6972 - val_loss: 6.2653 - val_value_loss: 0.7256 - val_policy_loss: 1.7344\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1742 - value_loss: 0.5925 - policy_loss: 1.6857 - val_loss: 6.2733 - val_value_loss: 0.7464 - val_policy_loss: 1.7302\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1587 - value_loss: 0.5716 - policy_loss: 1.6761 - val_loss: 6.2684 - val_value_loss: 0.7428 - val_policy_loss: 1.7248\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1433 - value_loss: 0.5493 - policy_loss: 1.6682 - val_loss: 6.2638 - val_value_loss: 0.7372 - val_policy_loss: 1.7218\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1667 - value_loss: 0.6037 - policy_loss: 1.6613 - val_loss: 6.2855 - val_value_loss: 0.7849 - val_policy_loss: 1.7182\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1345 - value_loss: 0.5461 - policy_loss: 1.6551 - val_loss: 6.2523 - val_value_loss: 0.7224 - val_policy_loss: 1.7148\n",
      "Saved model  tictactoe_num_sim_5_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.77 - draw ratio 0.01\n",
      "Number of seen trajectories: 300\n",
      "Number of unique trajectories: 298\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 180us/step - loss: 6.2801 - value_loss: 0.7785 - policy_loss: 1.7145 - val_loss: 6.2630 - val_value_loss: 0.7498 - val_policy_loss: 1.7094\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2326 - value_loss: 0.6989 - policy_loss: 1.6999 - val_loss: 6.2506 - val_value_loss: 0.7305 - val_policy_loss: 1.7046\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.2011 - value_loss: 0.6498 - policy_loss: 1.6865 - val_loss: 6.2288 - val_value_loss: 0.6936 - val_policy_loss: 1.6985\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1833 - value_loss: 0.6234 - policy_loss: 1.6781 - val_loss: 6.2649 - val_value_loss: 0.7721 - val_policy_loss: 1.6929\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1823 - value_loss: 0.6315 - policy_loss: 1.6685 - val_loss: 6.2699 - val_value_loss: 0.7868 - val_policy_loss: 1.6888\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1568 - value_loss: 0.5889 - policy_loss: 1.6607 - val_loss: 6.2124 - val_value_loss: 0.6746 - val_policy_loss: 1.6866\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1486 - value_loss: 0.5789 - policy_loss: 1.6551 - val_loss: 6.2153 - val_value_loss: 0.6829 - val_policy_loss: 1.6848\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1297 - value_loss: 0.5487 - policy_loss: 1.6482 - val_loss: 6.2142 - val_value_loss: 0.6864 - val_policy_loss: 1.6797\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1348 - value_loss: 0.5649 - policy_loss: 1.6428 - val_loss: 6.2156 - val_value_loss: 0.6933 - val_policy_loss: 1.6763\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1230 - value_loss: 0.5464 - policy_loss: 1.6382 - val_loss: 6.2034 - val_value_loss: 0.6714 - val_policy_loss: 1.6744\n",
      "Saved model  tictactoe_num_sim_5_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.0\n",
      "Number of seen trajectories: 400\n",
      "Number of unique trajectories: 394\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 183us/step - loss: 6.1977 - value_loss: 0.6674 - policy_loss: 1.6673 - val_loss: 6.2375 - val_value_loss: 0.7290 - val_policy_loss: 1.6856\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1602 - value_loss: 0.6093 - policy_loss: 1.6509 - val_loss: 6.2271 - val_value_loss: 0.7161 - val_policy_loss: 1.6783\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1376 - value_loss: 0.5760 - policy_loss: 1.6397 - val_loss: 6.2133 - val_value_loss: 0.6944 - val_policy_loss: 1.6731\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1266 - value_loss: 0.5623 - policy_loss: 1.6321 - val_loss: 6.2136 - val_value_loss: 0.6974 - val_policy_loss: 1.6714\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1118 - value_loss: 0.5395 - policy_loss: 1.6260 - val_loss: 6.2055 - val_value_loss: 0.6848 - val_policy_loss: 1.6684\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1027 - value_loss: 0.5286 - policy_loss: 1.6193 - val_loss: 6.2128 - val_value_loss: 0.7029 - val_policy_loss: 1.6656\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0938 - value_loss: 0.5172 - policy_loss: 1.6134 - val_loss: 6.2142 - val_value_loss: 0.7081 - val_policy_loss: 1.6637\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0925 - value_loss: 0.5193 - policy_loss: 1.6094 - val_loss: 6.2070 - val_value_loss: 0.6964 - val_policy_loss: 1.6617\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0858 - value_loss: 0.5118 - policy_loss: 1.6042 - val_loss: 6.1936 - val_value_loss: 0.6716 - val_policy_loss: 1.6603\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.0786 - value_loss: 0.5018 - policy_loss: 1.6005 - val_loss: 6.1904 - val_value_loss: 0.6682 - val_policy_loss: 1.6580\n",
      "Saved model  tictactoe_num_sim_5_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.01\n",
      "Number of seen trajectories: 500\n",
      "Number of unique trajectories: 487\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 181us/step - loss: 6.1816 - value_loss: 0.7146 - policy_loss: 1.5941 - val_loss: 6.1606 - val_value_loss: 0.6701 - val_policy_loss: 1.5969\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1556 - value_loss: 0.6711 - policy_loss: 1.5860 - val_loss: 6.1543 - val_value_loss: 0.6623 - val_policy_loss: 1.5922\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1357 - value_loss: 0.6391 - policy_loss: 1.5785 - val_loss: 6.1489 - val_value_loss: 0.6555 - val_policy_loss: 1.5886\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1232 - value_loss: 0.6195 - policy_loss: 1.5735 - val_loss: 6.1439 - val_value_loss: 0.6487 - val_policy_loss: 1.5857\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1129 - value_loss: 0.6034 - policy_loss: 1.5693 - val_loss: 6.1404 - val_value_loss: 0.6449 - val_policy_loss: 1.5829\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1046 - value_loss: 0.5915 - policy_loss: 1.5649 - val_loss: 6.1376 - val_value_loss: 0.6416 - val_policy_loss: 1.5810\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0970 - value_loss: 0.5799 - policy_loss: 1.5616 - val_loss: 6.1350 - val_value_loss: 0.6385 - val_policy_loss: 1.5792\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.0915 - value_loss: 0.5723 - policy_loss: 1.5585 - val_loss: 6.1340 - val_value_loss: 0.6387 - val_policy_loss: 1.5773\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0849 - value_loss: 0.5624 - policy_loss: 1.5556 - val_loss: 6.1312 - val_value_loss: 0.6353 - val_policy_loss: 1.5755\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0806 - value_loss: 0.5575 - policy_loss: 1.5520 - val_loss: 6.1317 - val_value_loss: 0.6373 - val_policy_loss: 1.5748\n",
      "Saved model  tictactoe_num_sim_5_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.02\n",
      "Number of seen trajectories: 600\n",
      "Number of unique trajectories: 580\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 180us/step - loss: 6.1357 - value_loss: 0.6574 - policy_loss: 1.5628 - val_loss: 6.1224 - val_value_loss: 0.6194 - val_policy_loss: 1.5744\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1135 - value_loss: 0.6208 - policy_loss: 1.5552 - val_loss: 6.1148 - val_value_loss: 0.6081 - val_policy_loss: 1.5709\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.0996 - value_loss: 0.6004 - policy_loss: 1.5481 - val_loss: 6.1112 - val_value_loss: 0.6040 - val_policy_loss: 1.5680\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0886 - value_loss: 0.5834 - policy_loss: 1.5435 - val_loss: 6.1057 - val_value_loss: 0.5959 - val_policy_loss: 1.5654\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.0786 - value_loss: 0.5695 - policy_loss: 1.5378 - val_loss: 6.1004 - val_value_loss: 0.5873 - val_policy_loss: 1.5637\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0716 - value_loss: 0.5604 - policy_loss: 1.5332 - val_loss: 6.0973 - val_value_loss: 0.5835 - val_policy_loss: 1.5616\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.0639 - value_loss: 0.5480 - policy_loss: 1.5305 - val_loss: 6.0960 - val_value_loss: 0.5825 - val_policy_loss: 1.5603\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0590 - value_loss: 0.5429 - policy_loss: 1.5262 - val_loss: 6.0939 - val_value_loss: 0.5806 - val_policy_loss: 1.5584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.0537 - value_loss: 0.5356 - policy_loss: 1.5231 - val_loss: 6.0931 - val_value_loss: 0.5803 - val_policy_loss: 1.5574\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.0511 - value_loss: 0.5329 - policy_loss: 1.5210 - val_loss: 6.0915 - val_value_loss: 0.5789 - val_policy_loss: 1.5559\n",
      "Saved model  tictactoe_num_sim_5_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.0\n",
      "Number of seen trajectories: 700\n",
      "Number of unique trajectories: 657\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 182us/step - loss: 6.0784 - value_loss: 0.6104 - policy_loss: 1.4983 - val_loss: 6.0688 - val_value_loss: 0.5846 - val_policy_loss: 1.5052\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0579 - value_loss: 0.5759 - policy_loss: 1.4921 - val_loss: 6.0633 - val_value_loss: 0.5780 - val_policy_loss: 1.5010\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0449 - value_loss: 0.5566 - policy_loss: 1.4858 - val_loss: 6.0623 - val_value_loss: 0.5787 - val_policy_loss: 1.4988\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.0361 - value_loss: 0.5428 - policy_loss: 1.4823 - val_loss: 6.0626 - val_value_loss: 0.5819 - val_policy_loss: 1.4965\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0268 - value_loss: 0.5297 - policy_loss: 1.4772 - val_loss: 6.0599 - val_value_loss: 0.5784 - val_policy_loss: 1.4948\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0209 - value_loss: 0.5210 - policy_loss: 1.4743 - val_loss: 6.0603 - val_value_loss: 0.5806 - val_policy_loss: 1.4937\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.0153 - value_loss: 0.5139 - policy_loss: 1.4705 - val_loss: 6.0636 - val_value_loss: 0.5899 - val_policy_loss: 1.4912\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0120 - value_loss: 0.5108 - policy_loss: 1.4674 - val_loss: 6.0583 - val_value_loss: 0.5805 - val_policy_loss: 1.4906\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0078 - value_loss: 0.5050 - policy_loss: 1.4652 - val_loss: 6.0588 - val_value_loss: 0.5826 - val_policy_loss: 1.4897\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0060 - value_loss: 0.5039 - policy_loss: 1.4628 - val_loss: 6.0570 - val_value_loss: 0.5810 - val_policy_loss: 1.4881\n",
      "Saved model  tictactoe_num_sim_5_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.0\n",
      "Number of seen trajectories: 800\n",
      "Number of unique trajectories: 730\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 182us/step - loss: 6.0014 - value_loss: 0.5197 - policy_loss: 1.4382 - val_loss: 6.0097 - val_value_loss: 0.5023 - val_policy_loss: 1.4724\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.9842 - value_loss: 0.4925 - policy_loss: 1.4314 - val_loss: 6.0047 - val_value_loss: 0.4962 - val_policy_loss: 1.4688\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.9742 - value_loss: 0.4779 - policy_loss: 1.4263 - val_loss: 6.0025 - val_value_loss: 0.4947 - val_policy_loss: 1.4663\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.9664 - value_loss: 0.4671 - policy_loss: 1.4217 - val_loss: 6.0011 - val_value_loss: 0.4945 - val_policy_loss: 1.4641\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9617 - value_loss: 0.4611 - policy_loss: 1.4188 - val_loss: 5.9997 - val_value_loss: 0.4938 - val_policy_loss: 1.4623\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9577 - value_loss: 0.4565 - policy_loss: 1.4157 - val_loss: 6.0007 - val_value_loss: 0.4972 - val_policy_loss: 1.4611\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.9553 - value_loss: 0.4530 - policy_loss: 1.4146 - val_loss: 6.0010 - val_value_loss: 0.4994 - val_policy_loss: 1.4598\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.9525 - value_loss: 0.4514 - policy_loss: 1.4109 - val_loss: 5.9993 - val_value_loss: 0.4981 - val_policy_loss: 1.4580\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.9507 - value_loss: 0.4500 - policy_loss: 1.4091 - val_loss: 5.9960 - val_value_loss: 0.4930 - val_policy_loss: 1.4568\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.9457 - value_loss: 0.4430 - policy_loss: 1.4063 - val_loss: 5.9975 - val_value_loss: 0.4981 - val_policy_loss: 1.4550\n",
      "Saved model  tictactoe_num_sim_5_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.0\n",
      "Number of seen trajectories: 900\n",
      "Number of unique trajectories: 798\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 180us/step - loss: 6.0166 - value_loss: 0.6007 - policy_loss: 1.3908 - val_loss: 5.9871 - val_value_loss: 0.5287 - val_policy_loss: 1.4040\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0000 - value_loss: 0.5746 - policy_loss: 1.3840 - val_loss: 5.9837 - val_value_loss: 0.5254 - val_policy_loss: 1.4009\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.9893 - value_loss: 0.5580 - policy_loss: 1.3796 - val_loss: 5.9848 - val_value_loss: 0.5301 - val_policy_loss: 1.3986\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.9822 - value_loss: 0.5482 - policy_loss: 1.3755 - val_loss: 5.9836 - val_value_loss: 0.5303 - val_policy_loss: 1.3964\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.9803 - value_loss: 0.5476 - policy_loss: 1.3726 - val_loss: 5.9841 - val_value_loss: 0.5332 - val_policy_loss: 1.3947\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.9744 - value_loss: 0.5393 - policy_loss: 1.3694 - val_loss: 5.9814 - val_value_loss: 0.5295 - val_policy_loss: 1.3934\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9703 - value_loss: 0.5321 - policy_loss: 1.3686 - val_loss: 5.9819 - val_value_loss: 0.5321 - val_policy_loss: 1.3921\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9695 - value_loss: 0.5338 - policy_loss: 1.3658 - val_loss: 5.9808 - val_value_loss: 0.5312 - val_policy_loss: 1.3912\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9670 - value_loss: 0.5302 - policy_loss: 1.3647 - val_loss: 5.9809 - val_value_loss: 0.5329 - val_policy_loss: 1.3900\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9652 - value_loss: 0.5296 - policy_loss: 1.3619 - val_loss: 5.9770 - val_value_loss: 0.5265 - val_policy_loss: 1.3888\n",
      "Saved model  tictactoe_num_sim_5_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.01\n",
      "Number of seen trajectories: 1000\n",
      "Number of unique trajectories: 869\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.0008 - value_loss: 0.6359 - policy_loss: 1.3271 - val_loss: 6.0288 - val_value_loss: 0.6889 - val_policy_loss: 1.3303\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.9877 - value_loss: 0.6153 - policy_loss: 1.3216 - val_loss: 6.0238 - val_value_loss: 0.6812 - val_policy_loss: 1.3280\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9815 - value_loss: 0.6052 - policy_loss: 1.3195 - val_loss: 6.0212 - val_value_loss: 0.6780 - val_policy_loss: 1.3261\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.9741 - value_loss: 0.5940 - policy_loss: 1.3161 - val_loss: 6.0158 - val_value_loss: 0.6688 - val_policy_loss: 1.3247\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.9711 - value_loss: 0.5894 - policy_loss: 1.3148 - val_loss: 6.0143 - val_value_loss: 0.6675 - val_policy_loss: 1.3232\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9677 - value_loss: 0.5850 - policy_loss: 1.3127 - val_loss: 6.0128 - val_value_loss: 0.6661 - val_policy_loss: 1.3219\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9626 - value_loss: 0.5774 - policy_loss: 1.3102 - val_loss: 6.0119 - val_value_loss: 0.6655 - val_policy_loss: 1.3207\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.9621 - value_loss: 0.5780 - policy_loss: 1.3087 - val_loss: 6.0086 - val_value_loss: 0.6603 - val_policy_loss: 1.3196\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.9612 - value_loss: 0.5770 - policy_loss: 1.3082 - val_loss: 6.0076 - val_value_loss: 0.6593 - val_policy_loss: 1.3186\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.9584 - value_loss: 0.5732 - policy_loss: 1.3065 - val_loss: 6.0091 - val_value_loss: 0.6633 - val_policy_loss: 1.3179\n",
      "Saved model  tictactoe_num_sim_5_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.0\n",
      "Number of seen trajectories: 1100\n",
      "Number of unique trajectories: 919\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 5.9215 - value_loss: 0.5609 - policy_loss: 1.2451 - val_loss: 5.9149 - val_value_loss: 0.5542 - val_policy_loss: 1.2387\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9131 - value_loss: 0.5489 - policy_loss: 1.2406 - val_loss: 5.9132 - val_value_loss: 0.5535 - val_policy_loss: 1.2361\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9075 - value_loss: 0.5417 - policy_loss: 1.2367 - val_loss: 5.9117 - val_value_loss: 0.5524 - val_policy_loss: 1.2345\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.9054 - value_loss: 0.5397 - policy_loss: 1.2345 - val_loss: 5.9110 - val_value_loss: 0.5531 - val_policy_loss: 1.2324\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9016 - value_loss: 0.5346 - policy_loss: 1.2323 - val_loss: 5.9112 - val_value_loss: 0.5549 - val_policy_loss: 1.2313\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.8996 - value_loss: 0.5328 - policy_loss: 1.2301 - val_loss: 5.9096 - val_value_loss: 0.5530 - val_policy_loss: 1.2300\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.8978 - value_loss: 0.5308 - policy_loss: 1.2287 - val_loss: 5.9092 - val_value_loss: 0.5533 - val_policy_loss: 1.2291\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.8965 - value_loss: 0.5290 - policy_loss: 1.2282 - val_loss: 5.9096 - val_value_loss: 0.5551 - val_policy_loss: 1.2283\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.8942 - value_loss: 0.5271 - policy_loss: 1.2257 - val_loss: 5.9089 - val_value_loss: 0.5550 - val_policy_loss: 1.2273\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.8921 - value_loss: 0.5247 - policy_loss: 1.2239 - val_loss: 5.9086 - val_value_loss: 0.5555 - val_policy_loss: 1.2263\n",
      "Saved model  tictactoe_num_sim_5_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.0\n",
      "Number of seen trajectories: 1200\n",
      "Number of unique trajectories: 957\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 5.8503 - value_loss: 0.5121 - policy_loss: 1.1531 - val_loss: 5.8758 - val_value_loss: 0.5288 - val_policy_loss: 1.1875\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.8404 - value_loss: 0.4967 - policy_loss: 1.1488 - val_loss: 5.8753 - val_value_loss: 0.5306 - val_policy_loss: 1.1848\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.8358 - value_loss: 0.4906 - policy_loss: 1.1459 - val_loss: 5.8736 - val_value_loss: 0.5297 - val_policy_loss: 1.1825\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.8327 - value_loss: 0.4873 - policy_loss: 1.1433 - val_loss: 5.8737 - val_value_loss: 0.5318 - val_policy_loss: 1.1808\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.8306 - value_loss: 0.4850 - policy_loss: 1.1414 - val_loss: 5.8730 - val_value_loss: 0.5323 - val_policy_loss: 1.1790\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.8300 - value_loss: 0.4850 - policy_loss: 1.1404 - val_loss: 5.8739 - val_value_loss: 0.5356 - val_policy_loss: 1.1777\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.8261 - value_loss: 0.4809 - policy_loss: 1.1368 - val_loss: 5.8724 - val_value_loss: 0.5340 - val_policy_loss: 1.1765\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.8248 - value_loss: 0.4804 - policy_loss: 1.1348 - val_loss: 5.8712 - val_value_loss: 0.5331 - val_policy_loss: 1.1752\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.8229 - value_loss: 0.4780 - policy_loss: 1.1337 - val_loss: 5.8718 - val_value_loss: 0.5355 - val_policy_loss: 1.1741\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.8220 - value_loss: 0.4773 - policy_loss: 1.1328 - val_loss: 5.8696 - val_value_loss: 0.5324 - val_policy_loss: 1.1729\n",
      "Saved model  tictactoe_num_sim_5_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.0\n",
      "Number of seen trajectories: 1300\n",
      "Number of unique trajectories: 981\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 180us/step - loss: 5.8139 - value_loss: 0.5133 - policy_loss: 1.0806 - val_loss: 5.7891 - val_value_loss: 0.5003 - val_policy_loss: 1.0443\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.8070 - value_loss: 0.5043 - policy_loss: 1.0762 - val_loss: 5.7871 - val_value_loss: 0.4996 - val_policy_loss: 1.0411\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.8039 - value_loss: 0.5008 - policy_loss: 1.0736 - val_loss: 5.7870 - val_value_loss: 0.5018 - val_policy_loss: 1.0387\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.8002 - value_loss: 0.4962 - policy_loss: 1.0708 - val_loss: 5.7843 - val_value_loss: 0.4987 - val_policy_loss: 1.0367\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7992 - value_loss: 0.4954 - policy_loss: 1.0698 - val_loss: 5.7841 - val_value_loss: 0.4999 - val_policy_loss: 1.0351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7964 - value_loss: 0.4924 - policy_loss: 1.0674 - val_loss: 5.7831 - val_value_loss: 0.4996 - val_policy_loss: 1.0337\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7944 - value_loss: 0.4917 - policy_loss: 1.0643 - val_loss: 5.7830 - val_value_loss: 0.5008 - val_policy_loss: 1.0325\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7926 - value_loss: 0.4899 - policy_loss: 1.0626 - val_loss: 5.7826 - val_value_loss: 0.5013 - val_policy_loss: 1.0313\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7916 - value_loss: 0.4889 - policy_loss: 1.0618 - val_loss: 5.7839 - val_value_loss: 0.5049 - val_policy_loss: 1.0304\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7906 - value_loss: 0.4870 - policy_loss: 1.0619 - val_loss: 5.7817 - val_value_loss: 0.5017 - val_policy_loss: 1.0295\n",
      "Saved model  tictactoe_num_sim_5_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.0\n",
      "Number of seen trajectories: 1400\n",
      "Number of unique trajectories: 1006\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.7926 - value_loss: 0.5422 - policy_loss: 1.0108 - val_loss: 5.8019 - val_value_loss: 0.5434 - val_policy_loss: 1.0283\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7853 - value_loss: 0.5306 - policy_loss: 1.0078 - val_loss: 5.8022 - val_value_loss: 0.5460 - val_policy_loss: 1.0264\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7819 - value_loss: 0.5259 - policy_loss: 1.0060 - val_loss: 5.7994 - val_value_loss: 0.5423 - val_policy_loss: 1.0248\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7787 - value_loss: 0.5231 - policy_loss: 1.0025 - val_loss: 5.7998 - val_value_loss: 0.5447 - val_policy_loss: 1.0232\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7789 - value_loss: 0.5236 - policy_loss: 1.0025 - val_loss: 5.7996 - val_value_loss: 0.5458 - val_policy_loss: 1.0219\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7768 - value_loss: 0.5216 - policy_loss: 1.0005 - val_loss: 5.7974 - val_value_loss: 0.5429 - val_policy_loss: 1.0206\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7747 - value_loss: 0.5196 - policy_loss: 0.9985 - val_loss: 5.7972 - val_value_loss: 0.5437 - val_policy_loss: 1.0195\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7739 - value_loss: 0.5193 - policy_loss: 0.9974 - val_loss: 5.7967 - val_value_loss: 0.5439 - val_policy_loss: 1.0185\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7725 - value_loss: 0.5180 - policy_loss: 0.9960 - val_loss: 5.7953 - val_value_loss: 0.5421 - val_policy_loss: 1.0176\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7732 - value_loss: 0.5205 - policy_loss: 0.9950 - val_loss: 5.7966 - val_value_loss: 0.5458 - val_policy_loss: 1.0167\n",
      "Saved model  tictactoe_num_sim_5_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.0\n",
      "Number of seen trajectories: 1500\n",
      "Number of unique trajectories: 1013\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.7665 - value_loss: 0.5563 - policy_loss: 0.9460 - val_loss: 5.7641 - val_value_loss: 0.5650 - val_policy_loss: 0.9325\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7633 - value_loss: 0.5511 - policy_loss: 0.9449 - val_loss: 5.7631 - val_value_loss: 0.5642 - val_policy_loss: 0.9315\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7607 - value_loss: 0.5474 - policy_loss: 0.9436 - val_loss: 5.7612 - val_value_loss: 0.5616 - val_policy_loss: 0.9304\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7586 - value_loss: 0.5446 - policy_loss: 0.9421 - val_loss: 5.7606 - val_value_loss: 0.5613 - val_policy_loss: 0.9296\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7591 - value_loss: 0.5457 - policy_loss: 0.9421 - val_loss: 5.7603 - val_value_loss: 0.5616 - val_policy_loss: 0.9287\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7571 - value_loss: 0.5431 - policy_loss: 0.9407 - val_loss: 5.7591 - val_value_loss: 0.5601 - val_policy_loss: 0.9279\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7570 - value_loss: 0.5438 - policy_loss: 0.9399 - val_loss: 5.7589 - val_value_loss: 0.5606 - val_policy_loss: 0.9271\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7562 - value_loss: 0.5432 - policy_loss: 0.9392 - val_loss: 5.7588 - val_value_loss: 0.5610 - val_policy_loss: 0.9265\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7549 - value_loss: 0.5414 - policy_loss: 0.9384 - val_loss: 5.7584 - val_value_loss: 0.5611 - val_policy_loss: 0.9258\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7543 - value_loss: 0.5409 - policy_loss: 0.9378 - val_loss: 5.7588 - val_value_loss: 0.5626 - val_policy_loss: 0.9252\n",
      "Saved model  tictactoe_num_sim_5_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.0\n",
      "Number of seen trajectories: 1600\n",
      "Number of unique trajectories: 1027\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 5.7662 - value_loss: 0.5756 - policy_loss: 0.9269 - val_loss: 5.7417 - val_value_loss: 0.5332 - val_policy_loss: 0.9204\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7563 - value_loss: 0.5572 - policy_loss: 0.9256 - val_loss: 5.7418 - val_value_loss: 0.5345 - val_policy_loss: 0.9193\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7536 - value_loss: 0.5531 - policy_loss: 0.9245 - val_loss: 5.7409 - val_value_loss: 0.5339 - val_policy_loss: 0.9183\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7524 - value_loss: 0.5504 - policy_loss: 0.9247 - val_loss: 5.7375 - val_value_loss: 0.5280 - val_policy_loss: 0.9174\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7508 - value_loss: 0.5486 - policy_loss: 0.9235 - val_loss: 5.7380 - val_value_loss: 0.5298 - val_policy_loss: 0.9166\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7486 - value_loss: 0.5457 - policy_loss: 0.9220 - val_loss: 5.7371 - val_value_loss: 0.5290 - val_policy_loss: 0.9158\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7476 - value_loss: 0.5448 - policy_loss: 0.9210 - val_loss: 5.7378 - val_value_loss: 0.5312 - val_policy_loss: 0.9151\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7471 - value_loss: 0.5445 - policy_loss: 0.9205 - val_loss: 5.7373 - val_value_loss: 0.5309 - val_policy_loss: 0.9144\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7467 - value_loss: 0.5442 - policy_loss: 0.9200 - val_loss: 5.7369 - val_value_loss: 0.5308 - val_policy_loss: 0.9138\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7462 - value_loss: 0.5432 - policy_loss: 0.9200 - val_loss: 5.7363 - val_value_loss: 0.5303 - val_policy_loss: 0.9131\n",
      "Saved model  tictactoe_num_sim_5_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.0\n",
      "Number of seen trajectories: 1700\n",
      "Number of unique trajectories: 1032\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.7385 - value_loss: 0.5551 - policy_loss: 0.8928 - val_loss: 5.7129 - val_value_loss: 0.5345 - val_policy_loss: 0.8622\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.7358 - value_loss: 0.5512 - policy_loss: 0.8915 - val_loss: 5.7132 - val_value_loss: 0.5361 - val_policy_loss: 0.8614\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.7332 - value_loss: 0.5470 - policy_loss: 0.8906 - val_loss: 5.7135 - val_value_loss: 0.5374 - val_policy_loss: 0.8606\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.7317 - value_loss: 0.5453 - policy_loss: 0.8892 - val_loss: 5.7121 - val_value_loss: 0.5355 - val_policy_loss: 0.8599\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7307 - value_loss: 0.5438 - policy_loss: 0.8888 - val_loss: 5.7124 - val_value_loss: 0.5370 - val_policy_loss: 0.8592\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7290 - value_loss: 0.5411 - policy_loss: 0.8882 - val_loss: 5.7127 - val_value_loss: 0.5381 - val_policy_loss: 0.8586\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7276 - value_loss: 0.5395 - policy_loss: 0.8871 - val_loss: 5.7115 - val_value_loss: 0.5364 - val_policy_loss: 0.8580\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7275 - value_loss: 0.5399 - policy_loss: 0.8865 - val_loss: 5.7110 - val_value_loss: 0.5361 - val_policy_loss: 0.8574\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7273 - value_loss: 0.5399 - policy_loss: 0.8863 - val_loss: 5.7124 - val_value_loss: 0.5394 - val_policy_loss: 0.8569\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7269 - value_loss: 0.5398 - policy_loss: 0.8857 - val_loss: 5.7101 - val_value_loss: 0.5355 - val_policy_loss: 0.8563\n",
      "Saved model  tictactoe_num_sim_5_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.0\n",
      "Number of seen trajectories: 1800\n",
      "Number of unique trajectories: 1037\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.7078 - value_loss: 0.5384 - policy_loss: 0.8489 - val_loss: 5.7120 - val_value_loss: 0.5398 - val_policy_loss: 0.8561\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7031 - value_loss: 0.5310 - policy_loss: 0.8470 - val_loss: 5.7113 - val_value_loss: 0.5391 - val_policy_loss: 0.8555\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7012 - value_loss: 0.5280 - policy_loss: 0.8463 - val_loss: 5.7105 - val_value_loss: 0.5380 - val_policy_loss: 0.8550\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6994 - value_loss: 0.5256 - policy_loss: 0.8451 - val_loss: 5.7124 - val_value_loss: 0.5422 - val_policy_loss: 0.8545\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6994 - value_loss: 0.5257 - policy_loss: 0.8450 - val_loss: 5.7119 - val_value_loss: 0.5419 - val_policy_loss: 0.8541\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6993 - value_loss: 0.5265 - policy_loss: 0.8443 - val_loss: 5.7110 - val_value_loss: 0.5405 - val_policy_loss: 0.8536\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6980 - value_loss: 0.5246 - policy_loss: 0.8435 - val_loss: 5.7109 - val_value_loss: 0.5409 - val_policy_loss: 0.8532\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.6979 - value_loss: 0.5253 - policy_loss: 0.8428 - val_loss: 5.7107 - val_value_loss: 0.5409 - val_policy_loss: 0.8528\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.6985 - value_loss: 0.5264 - policy_loss: 0.8429 - val_loss: 5.7111 - val_value_loss: 0.5423 - val_policy_loss: 0.8524\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6977 - value_loss: 0.5262 - policy_loss: 0.8416 - val_loss: 5.7107 - val_value_loss: 0.5419 - val_policy_loss: 0.8520\n",
      "Saved model  tictactoe_num_sim_5_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.0\n",
      "Number of seen trajectories: 1900\n",
      "Number of unique trajectories: 1039\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.7023 - value_loss: 0.5487 - policy_loss: 0.8285 - val_loss: 5.6900 - val_value_loss: 0.5230 - val_policy_loss: 0.8295\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.6989 - value_loss: 0.5426 - policy_loss: 0.8278 - val_loss: 5.6892 - val_value_loss: 0.5221 - val_policy_loss: 0.8289\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6978 - value_loss: 0.5408 - policy_loss: 0.8274 - val_loss: 5.6886 - val_value_loss: 0.5216 - val_policy_loss: 0.8284\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6963 - value_loss: 0.5389 - policy_loss: 0.8265 - val_loss: 5.6877 - val_value_loss: 0.5203 - val_policy_loss: 0.8278\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6954 - value_loss: 0.5377 - policy_loss: 0.8260 - val_loss: 5.6878 - val_value_loss: 0.5210 - val_policy_loss: 0.8274\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6952 - value_loss: 0.5369 - policy_loss: 0.8265 - val_loss: 5.6861 - val_value_loss: 0.5184 - val_policy_loss: 0.8269\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6943 - value_loss: 0.5361 - policy_loss: 0.8254 - val_loss: 5.6871 - val_value_loss: 0.5208 - val_policy_loss: 0.8265\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6942 - value_loss: 0.5371 - policy_loss: 0.8244 - val_loss: 5.6864 - val_value_loss: 0.5199 - val_policy_loss: 0.8260\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6939 - value_loss: 0.5362 - policy_loss: 0.8248 - val_loss: 5.6856 - val_value_loss: 0.5188 - val_policy_loss: 0.8256\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.6941 - value_loss: 0.5367 - policy_loss: 0.8247 - val_loss: 5.6860 - val_value_loss: 0.5201 - val_policy_loss: 0.8253\n",
      "Saved model  tictactoe_num_sim_5_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.67 - draw ratio 0.0\n",
      "Number of seen trajectories: 2000\n",
      "Number of unique trajectories: 1042\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.7047 - value_loss: 0.5606 - policy_loss: 0.8221 - val_loss: 5.7041 - val_value_loss: 0.5508 - val_policy_loss: 0.8307\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7017 - value_loss: 0.5564 - policy_loss: 0.8203 - val_loss: 5.7039 - val_value_loss: 0.5507 - val_policy_loss: 0.8305\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7000 - value_loss: 0.5532 - policy_loss: 0.8202 - val_loss: 5.7039 - val_value_loss: 0.5509 - val_policy_loss: 0.8302\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7009 - value_loss: 0.5538 - policy_loss: 0.8216 - val_loss: 5.7041 - val_value_loss: 0.5516 - val_policy_loss: 0.8300\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6997 - value_loss: 0.5529 - policy_loss: 0.8199 - val_loss: 5.7043 - val_value_loss: 0.5523 - val_policy_loss: 0.8298\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.6991 - value_loss: 0.5520 - policy_loss: 0.8198 - val_loss: 5.7042 - val_value_loss: 0.5524 - val_policy_loss: 0.8296\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7002 - value_loss: 0.5525 - policy_loss: 0.8216 - val_loss: 5.7043 - val_value_loss: 0.5528 - val_policy_loss: 0.8294\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6982 - value_loss: 0.5509 - policy_loss: 0.8191 - val_loss: 5.7042 - val_value_loss: 0.5529 - val_policy_loss: 0.8292\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6987 - value_loss: 0.5518 - policy_loss: 0.8193 - val_loss: 5.7045 - val_value_loss: 0.5537 - val_policy_loss: 0.8290\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6979 - value_loss: 0.5508 - policy_loss: 0.8187 - val_loss: 5.7044 - val_value_loss: 0.5537 - val_policy_loss: 0.8288\n",
      "Saved model  tictactoe_num_sim_5_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.0\n",
      "Number of seen trajectories: 2100\n",
      "Number of unique trajectories: 1042\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 5.7374 - value_loss: 0.6202 - policy_loss: 0.8283 - val_loss: 5.7186 - val_value_loss: 0.5943 - val_policy_loss: 0.8166\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7329 - value_loss: 0.6122 - policy_loss: 0.8274 - val_loss: 5.7184 - val_value_loss: 0.5942 - val_policy_loss: 0.8164\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7309 - value_loss: 0.6089 - policy_loss: 0.8267 - val_loss: 5.7178 - val_value_loss: 0.5932 - val_policy_loss: 0.8162\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7302 - value_loss: 0.6072 - policy_loss: 0.8270 - val_loss: 5.7174 - val_value_loss: 0.5927 - val_policy_loss: 0.8160\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7290 - value_loss: 0.6051 - policy_loss: 0.8268 - val_loss: 5.7176 - val_value_loss: 0.5934 - val_policy_loss: 0.8158\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7290 - value_loss: 0.6048 - policy_loss: 0.8270 - val_loss: 5.7173 - val_value_loss: 0.5928 - val_policy_loss: 0.8156\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7287 - value_loss: 0.6040 - policy_loss: 0.8274 - val_loss: 5.7182 - val_value_loss: 0.5948 - val_policy_loss: 0.8155\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7281 - value_loss: 0.6035 - policy_loss: 0.8267 - val_loss: 5.7180 - val_value_loss: 0.5948 - val_policy_loss: 0.8153\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7286 - value_loss: 0.6047 - policy_loss: 0.8266 - val_loss: 5.7174 - val_value_loss: 0.5938 - val_policy_loss: 0.8152\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7281 - value_loss: 0.6041 - policy_loss: 0.8263 - val_loss: 5.7177 - val_value_loss: 0.5944 - val_policy_loss: 0.8150\n",
      "Saved model  tictactoe_num_sim_5_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.72 - draw ratio 0.0\n",
      "Number of seen trajectories: 2200\n",
      "Number of unique trajectories: 1042\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.7222 - value_loss: 0.6024 - policy_loss: 0.8161 - val_loss: 5.6669 - val_value_loss: 0.5237 - val_policy_loss: 0.7843\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7179 - value_loss: 0.5949 - policy_loss: 0.8150 - val_loss: 5.6662 - val_value_loss: 0.5224 - val_policy_loss: 0.7842\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7164 - value_loss: 0.5917 - policy_loss: 0.8152 - val_loss: 5.6665 - val_value_loss: 0.5232 - val_policy_loss: 0.7840\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7152 - value_loss: 0.5900 - policy_loss: 0.8147 - val_loss: 5.6669 - val_value_loss: 0.5241 - val_policy_loss: 0.7838\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7147 - value_loss: 0.5893 - policy_loss: 0.8145 - val_loss: 5.6671 - val_value_loss: 0.5248 - val_policy_loss: 0.7837\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7146 - value_loss: 0.5891 - policy_loss: 0.8144 - val_loss: 5.6674 - val_value_loss: 0.5256 - val_policy_loss: 0.7835\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7139 - value_loss: 0.5879 - policy_loss: 0.8143 - val_loss: 5.6669 - val_value_loss: 0.5249 - val_policy_loss: 0.7833\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7138 - value_loss: 0.5885 - policy_loss: 0.8136 - val_loss: 5.6669 - val_value_loss: 0.5250 - val_policy_loss: 0.7832\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7135 - value_loss: 0.5872 - policy_loss: 0.8142 - val_loss: 5.6668 - val_value_loss: 0.5251 - val_policy_loss: 0.7830\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7130 - value_loss: 0.5868 - policy_loss: 0.8136 - val_loss: 5.6671 - val_value_loss: 0.5259 - val_policy_loss: 0.7829\n",
      "Saved model  tictactoe_num_sim_5_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.0\n",
      "Number of seen trajectories: 2300\n",
      "Number of unique trajectories: 1044\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 5.7037 - value_loss: 0.5653 - policy_loss: 0.8166 - val_loss: 5.6920 - val_value_loss: 0.5598 - val_policy_loss: 0.7987\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7012 - value_loss: 0.5609 - policy_loss: 0.8160 - val_loss: 5.6924 - val_value_loss: 0.5609 - val_policy_loss: 0.7985\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6995 - value_loss: 0.5583 - policy_loss: 0.8152 - val_loss: 5.6925 - val_value_loss: 0.5613 - val_policy_loss: 0.7984\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6976 - value_loss: 0.5545 - policy_loss: 0.8153 - val_loss: 5.6929 - val_value_loss: 0.5621 - val_policy_loss: 0.7983\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6973 - value_loss: 0.5538 - policy_loss: 0.8156 - val_loss: 5.6935 - val_value_loss: 0.5634 - val_policy_loss: 0.7982\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6963 - value_loss: 0.5530 - policy_loss: 0.8144 - val_loss: 5.6934 - val_value_loss: 0.5634 - val_policy_loss: 0.7981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6965 - value_loss: 0.5527 - policy_loss: 0.8150 - val_loss: 5.6934 - val_value_loss: 0.5637 - val_policy_loss: 0.7979\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6968 - value_loss: 0.5522 - policy_loss: 0.8162 - val_loss: 5.6938 - val_value_loss: 0.5646 - val_policy_loss: 0.7978\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6953 - value_loss: 0.5509 - policy_loss: 0.8147 - val_loss: 5.6943 - val_value_loss: 0.5657 - val_policy_loss: 0.7977\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6948 - value_loss: 0.5504 - policy_loss: 0.8141 - val_loss: 5.6939 - val_value_loss: 0.5651 - val_policy_loss: 0.7976\n",
      "Saved model  tictactoe_num_sim_5_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.0\n",
      "Number of seen trajectories: 2400\n",
      "Number of unique trajectories: 1046\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 5.6950 - value_loss: 0.5500 - policy_loss: 0.8149 - val_loss: 5.6861 - val_value_loss: 0.5285 - val_policy_loss: 0.8187\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6930 - value_loss: 0.5459 - policy_loss: 0.8150 - val_loss: 5.6852 - val_value_loss: 0.5268 - val_policy_loss: 0.8186\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6911 - value_loss: 0.5429 - policy_loss: 0.8143 - val_loss: 5.6848 - val_value_loss: 0.5261 - val_policy_loss: 0.8185\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6899 - value_loss: 0.5408 - policy_loss: 0.8141 - val_loss: 5.6845 - val_value_loss: 0.5256 - val_policy_loss: 0.8184\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6902 - value_loss: 0.5411 - policy_loss: 0.8144 - val_loss: 5.6841 - val_value_loss: 0.5250 - val_policy_loss: 0.8183\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6891 - value_loss: 0.5391 - policy_loss: 0.8141 - val_loss: 5.6840 - val_value_loss: 0.5248 - val_policy_loss: 0.8182\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6888 - value_loss: 0.5395 - policy_loss: 0.8132 - val_loss: 5.6837 - val_value_loss: 0.5244 - val_policy_loss: 0.8181\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6887 - value_loss: 0.5392 - policy_loss: 0.8133 - val_loss: 5.6834 - val_value_loss: 0.5240 - val_policy_loss: 0.8180\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6888 - value_loss: 0.5399 - policy_loss: 0.8130 - val_loss: 5.6832 - val_value_loss: 0.5237 - val_policy_loss: 0.8179\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6881 - value_loss: 0.5385 - policy_loss: 0.8130 - val_loss: 5.6835 - val_value_loss: 0.5245 - val_policy_loss: 0.8178\n",
      "Saved model  tictactoe_num_sim_5_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.0\n",
      "Number of seen trajectories: 2500\n",
      "Number of unique trajectories: 1047\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 5.7130 - value_loss: 0.5721 - policy_loss: 0.8292 - val_loss: 5.7071 - val_value_loss: 0.5648 - val_policy_loss: 0.8247\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7113 - value_loss: 0.5689 - policy_loss: 0.8289 - val_loss: 5.7065 - val_value_loss: 0.5638 - val_policy_loss: 0.8246\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7095 - value_loss: 0.5658 - policy_loss: 0.8286 - val_loss: 5.7062 - val_value_loss: 0.5631 - val_policy_loss: 0.8245\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.7094 - value_loss: 0.5652 - policy_loss: 0.8290 - val_loss: 5.7058 - val_value_loss: 0.5625 - val_policy_loss: 0.8245\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7078 - value_loss: 0.5626 - policy_loss: 0.8284 - val_loss: 5.7056 - val_value_loss: 0.5622 - val_policy_loss: 0.8244\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7075 - value_loss: 0.5618 - policy_loss: 0.8286 - val_loss: 5.7054 - val_value_loss: 0.5619 - val_policy_loss: 0.8243\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7068 - value_loss: 0.5605 - policy_loss: 0.8284 - val_loss: 5.7054 - val_value_loss: 0.5620 - val_policy_loss: 0.8242\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7062 - value_loss: 0.5596 - policy_loss: 0.8283 - val_loss: 5.7054 - val_value_loss: 0.5620 - val_policy_loss: 0.8241\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7058 - value_loss: 0.5593 - policy_loss: 0.8279 - val_loss: 5.7053 - val_value_loss: 0.5619 - val_policy_loss: 0.8241\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7056 - value_loss: 0.5575 - policy_loss: 0.8291 - val_loss: 5.7053 - val_value_loss: 0.5620 - val_policy_loss: 0.8240\n",
      "Saved model  tictactoe_num_sim_5_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.0\n",
      "Number of seen trajectories: 2600\n",
      "Number of unique trajectories: 1051\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.7044 - value_loss: 0.5537 - policy_loss: 0.8307 - val_loss: 5.7123 - val_value_loss: 0.5813 - val_policy_loss: 0.8188\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.7017 - value_loss: 0.5480 - policy_loss: 0.8309 - val_loss: 5.7116 - val_value_loss: 0.5799 - val_policy_loss: 0.8188\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.7002 - value_loss: 0.5452 - policy_loss: 0.8308 - val_loss: 5.7110 - val_value_loss: 0.5789 - val_policy_loss: 0.8187\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6983 - value_loss: 0.5422 - policy_loss: 0.8300 - val_loss: 5.7107 - val_value_loss: 0.5782 - val_policy_loss: 0.8186\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6976 - value_loss: 0.5405 - policy_loss: 0.8302 - val_loss: 5.7105 - val_value_loss: 0.5780 - val_policy_loss: 0.8186\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6972 - value_loss: 0.5398 - policy_loss: 0.8303 - val_loss: 5.7102 - val_value_loss: 0.5775 - val_policy_loss: 0.8185\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6964 - value_loss: 0.5382 - policy_loss: 0.8301 - val_loss: 5.7101 - val_value_loss: 0.5774 - val_policy_loss: 0.8184\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6960 - value_loss: 0.5378 - policy_loss: 0.8299 - val_loss: 5.7099 - val_value_loss: 0.5771 - val_policy_loss: 0.8184\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.6964 - value_loss: 0.5378 - policy_loss: 0.8307 - val_loss: 5.7098 - val_value_loss: 0.5769 - val_policy_loss: 0.8183\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6955 - value_loss: 0.5367 - policy_loss: 0.8298 - val_loss: 5.7096 - val_value_loss: 0.5767 - val_policy_loss: 0.8182\n",
      "Saved model  tictactoe_num_sim_5_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.0\n",
      "Number of seen trajectories: 2700\n",
      "Number of unique trajectories: 1052\n",
      "iteration 27 | self-play\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving memory position_memory_tictactoe_num_sim_5_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 5.6782 - value_loss: 0.5353 - policy_loss: 0.7967 - val_loss: 5.6745 - val_value_loss: 0.5233 - val_policy_loss: 0.8013\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6760 - value_loss: 0.5311 - policy_loss: 0.7966 - val_loss: 5.6739 - val_value_loss: 0.5221 - val_policy_loss: 0.8013\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6750 - value_loss: 0.5292 - policy_loss: 0.7966 - val_loss: 5.6736 - val_value_loss: 0.5216 - val_policy_loss: 0.8013\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6747 - value_loss: 0.5283 - policy_loss: 0.7970 - val_loss: 5.6734 - val_value_loss: 0.5214 - val_policy_loss: 0.8013\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6733 - value_loss: 0.5261 - policy_loss: 0.7963 - val_loss: 5.6735 - val_value_loss: 0.5215 - val_policy_loss: 0.8012\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6728 - value_loss: 0.5259 - policy_loss: 0.7955 - val_loss: 5.6734 - val_value_loss: 0.5215 - val_policy_loss: 0.8012\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6725 - value_loss: 0.5250 - policy_loss: 0.7959 - val_loss: 5.6736 - val_value_loss: 0.5218 - val_policy_loss: 0.8012\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6719 - value_loss: 0.5238 - policy_loss: 0.7957 - val_loss: 5.6735 - val_value_loss: 0.5216 - val_policy_loss: 0.8012\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6717 - value_loss: 0.5233 - policy_loss: 0.7960 - val_loss: 5.6736 - val_value_loss: 0.5220 - val_policy_loss: 0.8011\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6715 - value_loss: 0.5232 - policy_loss: 0.7958 - val_loss: 5.6737 - val_value_loss: 0.5222 - val_policy_loss: 0.8011\n",
      "Saved model  tictactoe_num_sim_5_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.69 - draw ratio 0.0\n",
      "Number of seen trajectories: 2800\n",
      "Number of unique trajectories: 1055\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.7031 - value_loss: 0.5786 - policy_loss: 0.8035 - val_loss: 5.6941 - val_value_loss: 0.5611 - val_policy_loss: 0.8030\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6999 - value_loss: 0.5732 - policy_loss: 0.8026 - val_loss: 5.6931 - val_value_loss: 0.5591 - val_policy_loss: 0.8029\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6979 - value_loss: 0.5693 - policy_loss: 0.8025 - val_loss: 5.6925 - val_value_loss: 0.5583 - val_policy_loss: 0.8027\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6975 - value_loss: 0.5681 - policy_loss: 0.8029 - val_loss: 5.6923 - val_value_loss: 0.5581 - val_policy_loss: 0.8026\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6957 - value_loss: 0.5656 - policy_loss: 0.8019 - val_loss: 5.6921 - val_value_loss: 0.5578 - val_policy_loss: 0.8024\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6954 - value_loss: 0.5647 - policy_loss: 0.8022 - val_loss: 5.6922 - val_value_loss: 0.5580 - val_policy_loss: 0.8023\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6954 - value_loss: 0.5642 - policy_loss: 0.8027 - val_loss: 5.6921 - val_value_loss: 0.5580 - val_policy_loss: 0.8022\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6949 - value_loss: 0.5640 - policy_loss: 0.8018 - val_loss: 5.6920 - val_value_loss: 0.5579 - val_policy_loss: 0.8021\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6953 - value_loss: 0.5640 - policy_loss: 0.8025 - val_loss: 5.6922 - val_value_loss: 0.5585 - val_policy_loss: 0.8020\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6952 - value_loss: 0.5642 - policy_loss: 0.8023 - val_loss: 5.6923 - val_value_loss: 0.5589 - val_policy_loss: 0.8019\n",
      "Saved model  tictactoe_num_sim_5_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.0\n",
      "Number of seen trajectories: 2900\n",
      "Number of unique trajectories: 1055\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_5_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 5.6707 - value_loss: 0.5274 - policy_loss: 0.7902 - val_loss: 5.6944 - val_value_loss: 0.5620 - val_policy_loss: 0.8030\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6696 - value_loss: 0.5256 - policy_loss: 0.7898 - val_loss: 5.6945 - val_value_loss: 0.5622 - val_policy_loss: 0.8029\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6691 - value_loss: 0.5246 - policy_loss: 0.7898 - val_loss: 5.6944 - val_value_loss: 0.5621 - val_policy_loss: 0.8029\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6686 - value_loss: 0.5236 - policy_loss: 0.7897 - val_loss: 5.6940 - val_value_loss: 0.5613 - val_policy_loss: 0.8028\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6678 - value_loss: 0.5223 - policy_loss: 0.7895 - val_loss: 5.6937 - val_value_loss: 0.5608 - val_policy_loss: 0.8027\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6681 - value_loss: 0.5222 - policy_loss: 0.7901 - val_loss: 5.6937 - val_value_loss: 0.5608 - val_policy_loss: 0.8027\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6676 - value_loss: 0.5216 - policy_loss: 0.7898 - val_loss: 5.6936 - val_value_loss: 0.5608 - val_policy_loss: 0.8026\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6677 - value_loss: 0.5214 - policy_loss: 0.7902 - val_loss: 5.6933 - val_value_loss: 0.5603 - val_policy_loss: 0.8025\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6669 - value_loss: 0.5203 - policy_loss: 0.7897 - val_loss: 5.6930 - val_value_loss: 0.5599 - val_policy_loss: 0.8024\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.6667 - value_loss: 0.5201 - policy_loss: 0.7896 - val_loss: 5.6929 - val_value_loss: 0.5597 - val_policy_loss: 0.8023\n",
      "Saved model  tictactoe_num_sim_5_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.73 - draw ratio 0.0\n",
      "Number of seen trajectories: 3000\n",
      "Number of unique trajectories: 1057\n"
     ]
    }
   ],
   "source": [
    "wins_2, draws_2, seen_trajectories_2, unique_trajectories_2 = test_pipeline.run(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - 5 simulations\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "losses_2 = np.ones(30) - wins_2 - draws_2\n",
    "\n",
    "plt.plot(x, wins_2, label=\"win ratio\")\n",
    "plt.plot(x, draws_2, label=\"draw ratio\")\n",
    "plt.plot(x, losses_2, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3XecVPX1//HXma3A0ll6WxSUIlKWJmCJMYC9RyzYIkbFksR8ozFRY8wvMbaoMSqW2AuxRxSxISpFFqQ3FwRZ6tI7287vj5ndrLjAAjvcnZn38/HYB3PvfObuuXPZec/93Hs/19wdERERgFDQBYiISPWhUBARkTIKBRERKaNQEBGRMgoFEREpo1AQEZEyCgU5pMxsnJn9IkrL/r2ZPRWNZR8KZnaRmY2N0rKfNbO7D+L1W82sXVXWJNWTQkEqZGZLzGxH5MOg9OefQddVysyON7O88vPc/f+5e1QCpxL1uJltK/de7Xc4uftL7v6zaNS3PyoKbnfPcPfFQdUkh05y0AVItXaau38cdBEx5Gh3zw26CJGDoT0F2S9mlmZmG82sS7l5mZG9isZmVt/M3jOzfDPbEHnccg/LutPMXiw33TbyjTs5Mn25mc0zsy1mttjMro7MrwV8ADQv9828eQXLO93M5kTqHWdmHcs9t8TMbjazmWa2ycxeM7P0qn/HKlzvyyLrs8XMvjOzi8rN/7JcOzeza83s20jbP5vZYWY20cw2m9koM0ut6LXlXn94Bb9/j9vIzP4CDAT+WX7vsPyyzKyumT0fef1SM/uDmYXK12Fm90WW/Z2ZDdnXukv1oVCQ/eLuu4A3gaHlZp8PfO7uawj/n/o30AZoDewADrTbaQ1wKlAHuBx40Mx6uPs2YAiwItKtkeHuK8q/0Mw6AK8ANwGZwPvAf0s/RMvVPRjIAroClx1gnaXGm9kqM3vTzNpW1CASaA8DQ9y9NnAMMH0vyxwM9AT6Av8HjAQuAloBXfjhdqisPW4jd78N+AIYEXlfR1Tw+keAukA74DhgGOHtU6oPsABoBPwdeNrC9nfdJQAKBdmbtyPfskt/rorMf5kffhhdGJmHu69z9zfcfbu7bwH+QviDY7+5+2h3X+RhnwNjCX+LrYyfA6Pd/SN3LwTuA2oQ/iAq9bC7r3D39cB/gW4HUmfEcUBb4EhgBfBe6R5PBUqALmZWw91XuvucvSz3HnffHGkzGxjr7ovdfRPhvaXu+1vowWwjM0si/N7e6u5b3H0JcD9wSblmS939SXcvBp4DmgFNIs/tz7pLABQKsjdnunu9cj9PRuZ/CtQwsz5m1obwh+lbAGZW08yeiHQrbAbGA/UiHyb7xcyGmNkkM1tvZhuBkwl/+6yM5sDS0gl3LwGWAS3KtVlV7vF2IGMPdcwp101VYSi5+3h3L3D3jcCNhPc+OlbQbhvhD9VfAivNbLSZHbmX9Vhd7vGOCqYrrHlvDnIbNQJSKffeRh5X+L66+/bIw4wDWHcJgEJB9lvkA3YU4b2FC4H3It84AX4DHAH0cfc6wLGR+VbBorYBNctNNy19YGZpwBuEv+E3cfd6hLuASpezr+F9VxDuHildnhHuclm+r/Xbnbt3LtdN9UVlX0bF64y7f+juJxH+Bj0feLKidvvpB++lmTXdS9t9baO9vbdrgULKvbeEu6Aq9b5Gad2lCikU5EC9TPhb30WRx6VqE/4Gu9HMGgB37GUZ04Fjzay1mdUFbi33XCqQBuQDRZGDleVP11wNNIy8riKjgFPM7EQzSyH8QbgLmFDZFawsM+tsZt3MLMnMMgh3pywH5lXQtknkAHitSD1bgeIqKGMGUFpHOnDnXtruaxutJny84EciXUKjgL+YWe3InuKvgRcral9eFNddqpBCQfbmv/bD6xTeKn3C3ScT/nbanHDfdql/EO67XwtMAsbsaeHu/hHwGjATmAq8V+65LcANhD+ANhDeI3m33PPzCR9IXhw53tF8t2UvAC4mfFB0LXAa4VNsC/b3TaiEJpH12AwsJnxs4dTIsYzdhQgH1ApgPeG+/GsPtgB3XwjcBXwMfAt8uZfm+9pGDwHnRs4eeriC119PeNsvjvyel4FnKlFmVNZdqpbpJjsiIlJKewoiIlJGoSAiImUUCiIiUkahICIiZWJuQLxGjRp527Ztgy5DRCSmTJ06da27Z+6rXcyFQtu2bcnJyQm6DBGRmGJmS/fdSt1HIiJSjkJBRETKKBRERKRMzB1TqEhhYSF5eXns3Lkz6FISVnp6Oi1btiQlJSXoUkTkIMRFKOTl5VG7dm3atm1LeDBMOZTcnXXr1pGXl0dWVlbQ5YjIQYha95GZPWNma8xs9h6eNzN72MxyLXxLxB4H+rt27txJw4YNFQgBMTMaNmyoPTWROBDNYwrPEr6V4J4MAdpHfoYDjx3ML1MgBEvvv0h8iFr3kbuP39N9aiPOAJ738DCtk8ysnpk1c/eV0ahn264ituwsqnT71OQQNVJCpKUkEdIHnogkiCCPKbQgfHvEUnmReT8KBTMbTnhvgtatWx/QL9teUMSaLfvfvWFmpCeHqJGSRI3UJNJTkqiRkkQodHBBkZOTw/PPP8/DD1c0XP3BWblyJZdeeiljx46t8mWLSHwLMhQq+lSt8OYO7j4SGAmQnZ19QDeAyKydTmbt9Eq1dXcKikrYUVgc/ikoZvPOQtZvLygrPC05ifTUcEDUSgv/uz9dKNnZ2WRnZx/IquzTmDFjGDRoUFSWLSLxLcjrFPII3zO3VEvCd2QKnJmRlpJEvZqpNKtbg3aZGXRsVocjm9ahTcNaNK6TTmpyiG27ili5aQe5a7by0eRZHNGxE2s272TbriLuvfde7rzzTo4//nh+97vf0bt3bzp06MAXX4Rv8Ttu3DhOPfVUANatW8fPfvYzunfvztVXX02bNm1Yu3YtS5YsoUuXLmV13Xfffdx5550ALFq0iMGDB9OzZ08GDhzI/Pnzy9qNGTOGIUOGsHLlSo499li6detGly5dyn732LFj6devHz169OC8885j69atAEydOpXjjjuOnj17MmjQIFauDO+07WkdRCT+BLmn8C4wwsxeBfoAm6rieMKf/juHuSs2H3Rx5XVqXoc7TutMarKRmhyibo3/nYtfWFTCtoIitq9LwR1WbQ53Ua3evIuCnQUUFJewfWcBEydN5sMxH/CnP/2Jjz/++Ic1/+lPDBgwgNtvv53Ro0czcuTIfdY0fPhwHn/8cdq3b8/kyZO59tpr+fTTTykuLmbBggV06tSJ+++/n0GDBnHbbbdRXFzM9u3bWbt2LXfffTcff/wxtWrV4p577uGBBx7g1ltv5frrr+edd94hMzOT1157jdtuu41nngnfZbGoqIivv/6a999/v8J1EJH4ELVQMLNXgOOBRmaWR/jm4CkA7v448D5wMpALbAcuj1Yt0ZSSHKJecipN69YgNTlEp2Z12FZQTM3UJHbtcAqLSsg+fhBzV2ymUZsjWfTddxQWlfxgGePHj+fNN98E4JRTTqF+/fp7/Z1bt25lwoQJnHfeeWXzdu3aBcDkyZPp06cPAL169eKKK66gsLCQM888k27duvH5558zd+5c+vfvD0BBQQH9+vVjwYIFzJ49m5NOOgmA4uJimjVrVrb8s88+G4CePXuyZMmSg3jHRKQ6i+bZR0P38bwD11X1773jtM5VvchKSU5OpqSkhOSkEHVrhEi1YhpmpFEzLZm2jevRqHYqSzeFKCgoZN6qzSzfsIOCohJ2FRYDFZ/SWbrMUqXXAZSUlFCvXj2mT5/+o9d88MEHDB4cPhP42GOPZfz48YwePZpLLrmE3/72t9SvX5+TTjqJV1555QevmzVrFp07d2bixIkVrl9aWhoASUlJFBVV/iwuEYktGvuoijRp0oQ1a9awbt06du3axXvvvQeED0rXSkumWd0aHN4kg+SkEE3rpOPu7CwqZsHqLXTN7ssTzzzHjoJi3n//fTZs2LDXZdapU4esrCz+85//AOED4zNmzADgk08+4cQTTwRg6dKlNG7cmKuuuoorr7ySadOm0bdvX7766ityc3MB2L59OwsXLuSII44gPz+/LBQKCwuZM2fOIXv/RKR6iIthLqqDlJQUbr/9dvr06UNWVhZHHnlkhe0MaFwnnZYNapIRCYsbbr6V64dfTo+3e9C73wBatGzF5u0F1KmXxB//+McKl/nSSy9xzTXXcPfdd1NYWMgFF1xA8+bNSU9Pp06dOkD4YPa9995LSkoKGRkZPP/882RmZvLss88ydOjQsi6nu+++mw4dOvD6669zww03sGnTJoqKirjpppvo3DmYPS8RCYaFe3FiR3Z2tu9+k5158+bRsWPHgCqqGoXFJWzeUcjmnUUM6N6Rl0d/Rv0GDUlOClEzJYmaqeGfGqlJJIUq3sF78cUXycvL45ZbbjnE1YfFw3YQiVdmNtXd93kevPYUqomUpBANM9JomJFGSlKIrEa1qFmnBjsKitkeuU6iVFry/0Kibo0UkpPCIXHxxRcHVb6IxAmFQjVU0dk9RcXhi+m2F4Qvptuys4gN2wvI37KLNg1rUSM16dAXKiJxJ25Cwd3jelC25KQQtZNC1E4PXyPh7mwvKOb79dtZlL+VVvVrULdmamD1xVo3pIhULC7OPkpPT2fdunUJ9cFkZtRKS+bwxhmkpySxdP12Vm3aGch7UHo/hfT0yg0jIiLVV1zsKbRs2ZK8vDzy8/ODLiUQ7s7W7YWs/r6Y3JQQ9WulHvKRXUvvvCYisS0uQiElJSXh7/jl7vz7qyXc/eZc2jeuzZPDsmndsGbQZYlIjImL7iMJdyddMSCL567ozarNOzn90S+ZkLs26LJEJMYoFOLMwPaZvHNdfxplpHHJM1/z3IQlCXWsRUQOjkIhDrVtVIu3rj2GE47I5I5353Drm7Mo2G0QPhGRiigU4lTt9BRGXpLNdSccxqtTlnHhk5NYtWn/7zwnIolFoRDHQiHjt4OO5JGh3Zm7cjOnPPwFX3ybmGdoiUjlKBQSwGlHN+fdEf1pUCuVYc98zYMfLaS4RMcZROTHFAoJ4vDGtXlnRH/O6taChz75lkuf+Zq1W3cFXZaIVDMKhQRSMzWZ+88/mnvOOYopS9Zz8kNf8PV364MuS0SqEYVCgjEzft6rNW9d259aackMfXISj41bRIm6k0QEhULC6tS8Du+O6M/gzk25Z8x8rno+h43bC4IuS0QCplBIYLXTU/jnhd2564zOjP82n1Me/pJvvt8QdFkiEiCFQoIzM4b1a8vrvzwGMzj/iYk88+V3ugpaJEEpFASAo1vVY/T1AzmuQ2Puem8uv3xxKpt2FO77hSISV6IaCmY22MwWmFmumf3oxsFm1sbMPjGzmWY2zsw09nKA6tZM4clhPfnDKR35ZN4aTn3kC2Ys2xh0WSJyCEUtFMwsCXgUGAJ0AoaaWafdmt0HPO/uXYG7gL9Gqx6pHDPjFwPbMeqX/SgpgXMfn8CzX6k7SSRRRHNPoTeQ6+6L3b0AeBU4Y7c2nYBPIo8/q+B5CUiP1vUZfcMAjuuQyZ3/ncs1L05Td5JIAohmKLQAlpWbzovMK28GcE7k8VlAbTNruPuCzGy4meWYWU6i3l0tCPVqpvLksGz+cEpHPp63mlMf+YKZeepOEoln0QyFiu4HuXsfxM3AcWb2DXAcsBwo+tGL3Ee6e7a7Z2dmZlZ9pbJHpd1Jr13dj+Ji55zH1J0kEs+iGQp5QKty0y2BFeUbuPsKdz/b3bsDt0XmbYpiTXKAerapz+gbBjKwfbg76dqXprF5p7qTROJNNENhCtDezLLMLBW4AHi3fAMza2RmpTXcCjwTxXrkINWvlcpTw7L5/clHMnbuaob84wten5pHUbFu4CMSL6IWCu5eBIwAPgTmAaPcfY6Z3WVmp0eaHQ8sMLOFQBPgL9GqR6pGKGQMP/YwRl3dj/q1Urj5PzP42YPjeWf6co2fJBIHLNb6hrOzsz0nJyfoMgRwd8bOXc0DYxeyYPUWjmhSm1+d1IFBnZtgVtEhJREJiplNdffsfbXTFc1ywMyMQZ2b8sGNA3l4aHcKS0r45YtTOe2fX/LZ/DU6GC0SgxQKctBCIeP0o5sz9qZjue+8o9m0o5DLn53C2Y9N4KvctQoHkRiiUJAqk5wU4tyeLfn0N8fz17OPYtWmnVz01GQuGDmJb1dvCbo8EakEhYJUuZSkEEN7t+azm4/nztM6kbtmK+c/MZE5K3S2sUh1p1CQqElPSeKy/lm8ee0x1ExN5sInJ+uKaJFqTqEgUdemYS1eHd6X2unJXPTkZKbpRj4i1ZZCQQ6JVg1qMurqfjTMSOWSpyYzZcn6oEsSkQooFOSQaV6vBq9d3Y8mddMZ9vTXTFy0LuiSRGQ3CgU5pJrUSee14f1o1aAGlz/7NV98q1FvRaoThYIccpm103jlqr5kNcrgyudy+Gz+mqBLEpEIhYIEomFGGq9c1YcjmtRm+As5jJ2zKuiSRASFggSoXs1UXvxFHzo3r8u1L03j/Vkrgy5JJOEpFCRQdWuk8MKVvenWqh7Xv/IN70xfHnRJIglNoSCBq52ewnNX9KZX2/r86rXpfDR3ddAliSQshYJUC7XSknn60l4c1bIeI16eRo6uYxAJhEJBqo1aacn8+7JetKhfgyuencJCDaIncsgpFKRaaVArleev6E2N1CSGPf01yzfuCLokkYSiUJBqp2X9mjx3RW+2FRQx7OnJbNhWEHRJIglDoSDV0pFN6/D0pb1YtmEHlz87he0FRUGXJJIQFApSbfXOasAjQ7szM28j1700jcLikqBLEol7CgWp1gZ1bspfzjqKzxbk87s3ZurWniJRFtVQMLPBZrbAzHLN7JYKnm9tZp+Z2TdmNtPMTo5mPRKbhvZuzW9O6sCb05bztzHzgy5HJK4lR2vBZpYEPAqcBOQBU8zsXXefW67ZH4BR7v6YmXUC3gfaRqsmiV0jfnI4+Vt38cTni8nMSOMXA9sFXZJIXIpaKAC9gVx3XwxgZq8CZwDlQ8GBOpHHdYEVUaxHYpiZccdpnVm7dRd3j55Ho4w0zuzeIuiyROJONLuPWgDLyk3nReaVdydwsZnlEd5LuL6iBZnZcDPLMbOc/HyNv5+okkLGgz/vRr92Dbn5PzN0LwaRKIhmKFgF83Y/SjgUeNbdWwInAy+Y2Y9qcveR7p7t7tmZmZlRKFViRVpyEiOH9eTwxhmMePkblq7bFnRJInElmqGQB7QqN92SH3cPXQmMAnD3iUA60CiKNUkcqJ2ewshLsgEY/vxUtu3SNQwiVSWaoTAFaG9mWWaWClwAvLtbm++BEwHMrCPhUFCfgOxT64Y1+eeF3fl2zRZ++/oMnaoqUkWiFgruXgSMAD4E5hE+y2iOmd1lZqdHmv0GuMrMZgCvAJe5/rqlkga2z+SWIUfy/qxVPPb5oqDLEYkL0Tz7CHd/n/AB5PLzbi/3eC7QP5o1SHy7amA7Zi/fzL0fLqBjszqccETjoEsSiWm6ollimplxzzldObJpHW585RuWrNWBZ5GDoVCQmFcjNYmRl/QkFDKGv5DDVh14FjlgCgWJC60a1OSfQ3uQu2YrN4/SgWeRA6VQkLgxoH0jfn9yR8bMWcWjn+UGXY5ITFIoSFy5ckAWZ3Zrzv0fLeTT+auDLkck5igUJK6YGX89uysdm9bhxlenszh/a9AlicQUhYLEnRqpSTxxSU+SQ8bwF6ayZWdh0CWJxAyFgsSlVg1q8uiFPfhu7TZ+PWoGxSU68CxSGQoFiVvHHN6IP57SkY/mruaWN2ZSomAQ2aeoXtEsErTL+mexfnshD3/yLTVTk7jz9M6YVTSAr4iAQkESwK9+2p7tu4p46svvqJGazO8GH6FgENkDhYLEPTPjtlM6sqOwmMc/X0RGWhIjftI+6LJEqiWFgiQEM+PPZ3RhR0Ex941dSI3UZK4ckBV0WSLVjkJBEkYoZPz93K7sKCzmz+/NpWZqEkN7tw66LJFqRWcfSUJJTgrx0AXdOf6ITH7/1izemb486JJEqhWFgiSc1OQQj1/ckz5ZDfj1qBmMmb0q6JJEqg2FgiSk9JQknrq0F11b1uX6V6YxbsGaoEsSqRYUCpKwMtKSefby3rRvXJurX5jKpMXrgi5JJHAKBUlodWuk8MKVvWnVoCZXPjuFmXkbgy5JJFAKBUl4DTPSeOkXfahfK5Xhz08lf8uuoEsSCYxCQQRoUiedJy7pycYdBVz30jQKi0uCLkkkEAoFkYjOzetyzzld+XrJev4yel7Q5YgEIqqhYGaDzWyBmeWa2S0VPP+gmU2P/Cw0M3XoSqDO6NaCKwdk8eyEJbwxNS/ockQOuUpf0WxmRwMDI5NfuPuMfbRPAh4FTgLygClm9q67zy1t4+6/Ktf+eqD7ftQuEhW3DjmSOSs28fu3ZnFE09p0aVE36JJEDplK7SmY2Y3AS0DjyM+LkQ/xvekN5Lr7YncvAF4FzthL+6HAK5WpRySakpNCPHphDxrWSuXqF6ayfltB0CWJHDKV7T66Eujj7re7++1AX+CqfbymBbCs3HReZN6PmFkbIAv4dA/PDzezHDPLyc/Pr2TJIgeuYUYaj1/Sk/ytuxjx8jSKdOBZEkRlQ8GA4nLTxZF5+3rN7vZ066sLgNfdvbiiJ919pLtnu3t2ZmbmPosVqQpdW9bjL2d2YcKidfz9wwVBlyNySFT2mMK/gclm9lZk+kzg6X28Jg9oVW66JbBiD20vAK6rZC0ih8x52a2YtXwTI8cvpkuLupx+dPOgSxKJqkrtKbj7A8DlwHpgA3C5u/9jHy+bArQ3sywzSyX8wf/u7o3M7AigPjBxfwoXOVT+cEonerWtz+9en8m8lZuDLkckqvYaCmZWJ/JvA2AJ8CLwArA0Mm+P3L0IGAF8CMwDRrn7HDO7y8xOL9d0KPCqu+uu6lItpSaHePSiHtSpkczVL0xl43YdeJb4ZXv7LDaz99z9VDP7jh8eDzDA3b1dtAvcXXZ2tufk5BzqXyvCtO838PMnJtLvsEb8+7JeJIV0n2eJHWY21d2z99Vur3sK7n5q5N8sd29X7icriEAQCVKP1vX50+ldGL8wn/vH6sCzxKfKXqfwSWXmicS7C/u0Zmjv1vxr3CIe/Sw36HJEqtxezz4ys3SgJtDIzOrzv9NM6wA6DUMS0p/P6MyOgiLu/XABBUUl3PTT9pipK0niw75OSb0auIlwAEzlf6GwmfAQFiIJJzkpxP3ndyMlKcRDn3xLQXEJ/zfoCAWDxIW9hoK7PwQ8ZGbXu/sjh6gmkWovKWTcc05XUpNDPDZuEQVFJfzhlI4KBol5lbp4zd0fMbMuQCcgvdz856NVmEh1FwoZd5/ZhZSkEE9/+R2FxSXceVpnQjorSWJYpULBzO4AjiccCu8DQ4AvAYWCJDQz447TOpGWHOKJ8YspKCrh/511lIJBYlZlh7k4Fzga+MbdLzezJsBT0StLJHaYGbcMOZLU5BCPfJpLYbHz93O76joGiUmVDYWd7l5iZkWRq5zXALpOQSTCzPjNz44gJSnEAx8tpLC4hAfOP5rkJN3cUGLLPkPBwkfOZppZPeBJwmchbQW+jnJtIjHnhhPbk5oc4m8fzKewuISHLuhOarKCQWLHPkPB3d3Murn7RuBxMxsD1HH3mdEvTyT2/PK4w0hNCnHXe3MpfGkqj17Ug7TkpKDLEqmUyn6FmWRmvQDcfYkCQWTvrhiQxd1nduHjeWu45sVp7Cqq8FYhItVOZUPhBGCimS0ys5lmNsvMFAwie3Fx3zb89eyj+HT+Gq57aRoFRbp7m1R/lT3QPCSqVYjEqaG9W1Nc4vzh7dmMeHkaj17UgxQdfJZqrLIXry2NdiEi8erivm0ocef2d+Zw/cvf8MiF3RUMUm3pf6bIITCsX1vuOK0TY+as4qZXp1NUrK4kqZ4q230kIgfp8v5ZFJc4d4+ehxn84+fddB2DVDsKBZFD6BcD21Hizv97fz5JIeOB87vpymepVhQKIofY8GMPo7gE7hkzn5AZ9513tIJBqg2FgkgArjn+MIpLSrhv7EJCZhorSaoNhYJIQEb8pD3FJfDgxwtJCsHfzu6q0VUlcFE9ymVmg81sgZnlmtkte2hzvpnNNbM5ZvZyNOsRqW5u/Gl7bjixPaNy8vj9W7MoLvGgS5IEF7U9BTNLInzLzpOAPGCKmb3r7nPLtWkP3Ar0d/cNZtY4WvWIVFe/+ml73J1HPs1l045CHvx5N9JTNFaSBCOaewq9gVx3X+zuBcCrwBm7tbkKeNTdNwC4+5oo1iNSLZUOu/3HUzvxwexVDHvmazbtKAy6LElQ0QyFFsCyctN5kXnldQA6mNlXZjbJzAZXtCAzG25mOWaWk5+fH6VyRYJ15YAsHh7anW++38DPn5jIqk07gy5JElA0Q6GiI2a7d5gmA+0J3+pzKPBU5L4NP3yR+0h3z3b37MzMzCovVKS6OP3o5vz7st4sW7+dcx6bQO6aLUGXJAkmmqGQB7QqN90SWFFBm3fcvdDdvwMWEA4JkYQ1oH0jXru6H7uKSjj38YlMXboh6JIkgUQzFKYA7c0sy8xSgQuAd3dr8zbhYbkxs0aEu5MWR7EmkZjQpUVd3rzmGOrVSOGipybxybzVQZckCSJqoeDuRcAI4ENgHjDK3eeY2V1mdnqk2YfAOjObC3wG/Nbd10WrJpFY0rphTV6/5hg6NKnN8Bem8tqU74MuSRKAucfWedHZ2dmek5MTdBkih8y2XUVc89I0xi/M5zcndWDETw4nfOt0kcozs6nunr2vdhqiUaSaq5WWzFPDsjmrewvu/2ght78zRxe5SdRomAuRGJCaHOL+846mce00nhi/mJWbdvLQBd2olaY/Yala2lMQiRGhkHHryR350+md+XT+as7XtQwSBQoFkRhz6TFtefrSXixZu40zHv2S2cs3BV2SxBGFgkgMOuHIxrx+zTEkmXH+ExP5eK5OWZWqoVAQiVEdm9Xh7ev6c3jjDK56IYenvlhMrJ1NKNWPQkEkhjWuk85rw/sxqFNT7h49jz+8PZvC4pKgy5IYplAQiXE1UpP410U9+OVxh/HS5O+54tkpbN6pUVblwCgUROJAKGTcMuQKz7EQAAAQAklEQVRI/n5OVyYuWsc5/5rAsvXbgy5LYpBCQSSOnN+rFc9f2ZvVm3dy1r++Ytr3GkxP9o9CQSTOHHNYI966rj+10pK54IlJvDBxiQ5AS6UpFETi0GGZGbx9bX/6H96QP74zhxEvf6PjDFIpCgWROFW/VipPX9qLW4YcyZg5qzjtEV3oJvumUBCJY6GQ8cvjDuO14X3ZVVjC2f+awAuTlqo7SfZIoSCSALLbNuD9GwfS77CG/PHt2Yx45Ru2qDtJKqBQEEkQDWql8u/LevF/g49gzOxwd9KcFepOkh9SKIgkkFDIuPb4w3nlqr7sLCzhrH9N4KXJ6k6S/1EoiCSg3lkNGH3DAPq2a8htb83mhlenqztJAIWCSMJqmJHGs5f14reDjmD0zBWc8vCXTF+2MeiyJGAKBZEEFgoZ151wOK9d3Y/iEufcxybw6Ge5ut1nAlMoiAi92jbg/RsGMqhzU+79cAEXPzVZd3VLUAoFEQGgbs0U/nlhd/5+TlemL9vI4IfGM3bOqqDLkkMsqqFgZoPNbIGZ5ZrZLRU8f5mZ5ZvZ9MjPL6JZj4jsnZlxfq9WvHfDAFrWr8HwF6byh7dnsbOwOOjS5BCJWiiYWRLwKDAE6AQMNbNOFTR9zd27RX6eilY9IlJ5h2Vm8MY1x3DVwCxenPQ9pz3yJfNXbQ66LDkEormn0BvIdffF7l4AvAqcEcXfJyJVKC05idtO6cRzV/Rmw/ZCTv/nVzw3QSOuxrtohkILYFm56bzIvN2dY2Yzzex1M2tV0YLMbLiZ5ZhZTn5+fjRqFZE9OK5DJmNuGsgxhzXkjnfncOVzOazerIPQ8SqaoWAVzNv9K8Z/gbbu3hX4GHiuogW5+0h3z3b37MzMzCouU0T2pVFGGv++rBe3n9qJr3LX8tMHPmdUzjLtNcShaIZCHlD+m39LYEX5Bu6+zt13RSafBHpGsR4ROQhmxhUDshhz07F0bFqH/3t9JsOe+Zq8DbrtZzyJZihMAdqbWZaZpQIXAO+Wb2BmzcpNng7Mi2I9IlIFshrV4tXhfbnrjM5MXbqBQQ+O54WJSyjRBW9xIWqh4O5FwAjgQ8If9qPcfY6Z3WVmp0ea3WBmc8xsBnADcFm06hGRqhMKGcP6teXDm46lR5v6/PGdOQx9chJL1m4LujQ5SBZrfYLZ2dmek5MTdBkiEuHu/Ccnjz+PnkthcQk3/+wILu+fRVKoosOKEhQzm+ru2ftqpyuaReSglF7w9tGvjmPA4Y24e/Q8zn18ArlrtgRdmhwAhYKIVImmddN5clg2D13QjSVrt3HyQ19y/9gFbC8oCro02Q8KBRGpMmbGGd1a8NGvj+Pko5ryyKe5nHDfON6clqcD0TFCoSAiVa5RRhr/uKA7b1xzDE3rpPPrUTM467EJTPt+Q9ClyT4oFEQkanq2qc9b1/bn/vOOZuXGHZz9rwnc+Oo3rNy0I+jSZA8UCiISVaGQcU7Plnx28/GMOOFwPpi9ihPuG8c/Pl7IjgKNvlrdKBRE5JColZbMzYOO4JNfH8eJHZvwj4+/5cT7x/HO9OUaLqMaUSiIyCHVqkFNHr2wB6Ou7keDjFRufHU65zw2gUmL1wVdmqBQEJGA9M5qwDvXDeDv53RlxcadXDByEsOe+ZpZeZuCLi2h6YpmEQnczsJiXpi4lH+Ny2XD9kJOPqopvz6pA4c3rh10aXGjslc0KxREpNrYsrOQp774jqe+WMyOwmLO6dGSG3/anpb1awZdWsxTKIhIzFq3dRePjVvE85OWgsOFfVpz3QmHk1k7LejSYpZCQURi3oqNO3jk028ZlZNHWnKIK/pncdXAdtStmRJ0aTFHoSAicWNx/lYe/Phb/jtjBbXTkrmsf1uuHJBFvZqpQZcWMxQKIhJ35q3czMOffMsHs1eRkZbMpce04RcD2lG/lsJhXxQKIhK35q/azCOf5PL+7JXUTEli2DFtuWpgOxooHPZIoSAicW/h6i088mku781cQY2UJC7p14bhA9vRMEMHpHenUBCRhJG7JhwO/52xgrTkJC7u25rhxx6ms5XKUSiISMJZlL+Vf36ayzvTl5OcFOK0rs259Jg2dG1ZL+jSAqdQEJGE9d3abfz7q+94Y2oe2wqK6daqHpcd05YhRzUlLTkp6PICoVAQkYS3eWchb07N4/mJS1m8dhuNMtK4sHcrLuzThqZ104Mu75CqFqFgZoOBh4Ak4Cl3/9se2p0L/Afo5e57/cRXKIjI/iopcb7MXctzE5bw6YI1JJkxqEtTLu3Xll5t62NmQZcYdZUNheQoFpAEPAqcBOQBU8zsXXefu1u72sANwORo1SIiiS0UMo7tkMmxHTL5ft12Xpy8lNemLGP0zJV0bFaHS/u14YxuLaiRmphdS+VFc+js3kCuuy929wLgVeCMCtr9Gfg7sDOKtYiIANC6YU1+f3JHJt16In87+yjcnVvenEXfv37CX9+fx7L124MuMVDRDIUWwLJy03mReWXMrDvQyt3f29uCzGy4meWYWU5+fn7VVyoiCadGahIX9G7NBzcO5LXhfRlweCOe+vI7jr33M37xXA5ffrs2Ie8IF7XuI6CiTrqyd9jMQsCDwGX7WpC7jwRGQviYQhXVJyKCmdGnXUP6tGvIyk07eGnS97zy9fd8PG81h2XW4tJj2nJ2j5ZkpEXz47L6iNqBZjPrB9zp7oMi07cCuPtfI9N1gUXA1shLmgLrgdP3drBZB5pFJNp2Fhbz/qyVPDdhCTPyNpGRlsy5PVtycd82HN44I+jyDkjgZx+ZWTKwEDgRWA5MAS509zl7aD8OuFlnH4lIdfLN9xt4fuJS3pu5gsJip0frepzbsxWndG1G3RqxM4R34KEQKeJk4B+ET0l9xt3/YmZ3ATnu/u5ubcehUBCRaip/yy7enJbH61Pz+HbNVlKTQwzq3JRzerRgYPtMkkLV+7TWahEK0aBQEJEguTuzlm/i9al5vDtjBRu3F9KkThpndW/JuT1bVNv7SisURESibFdRMZ/OW8PrU/MYtzCf4hLn6Fb1OLdHC047unm1ugmQQkFE5BDK37KLd6Yv5/WpecxftYXUpBAndW7CeT1bVovuJYWCiEgA3J05Kzbz+tQ83p6+vKx76eweLTmvZ0vaZQZz9pJCQUQkYLuKivmktHtpwRpKHHq2qc+5PVtyatdm1E4/dGcvKRRERKqRNZt38uY3y/lPzjIW5W8jPSXEkC7NOKdHS/q2a0ByUjQHmFAoiIhUS+7O9GUb+c/UPP47YwVbdhbRoFYqgzo35dSuzeiTFZ2AUCiIiFRzOwuLGbdgDe/NXMmn89ewvaA4agGhUBARiSE7Cor5fOEaRs9axSfzVld5QCgURERiVOkexO4BccdpnTijW4t9L6ACgd9kR0REDkx6ShKDuzRjcJdmPwiIZnVrRP13KxRERKqx8gFxKET3HCgREYkpCgURESmjUBARkTIKBRERKaNQEBGRMgoFEREpo1AQEZEyCgURESkTc8NcmFk+sPQAX94IWFuF5VQH8bZO8bY+EH/rFG/rA/G3ThWtTxt3z9zXC2MuFA6GmeVUZuyPWBJv6xRv6wPxt07xtj4Qf+t0MOuj7iMRESmjUBARkTKJFgojgy4gCuJtneJtfSD+1ine1gfib50OeH0S6piCiIjsXaLtKYiIyF4oFEREpEzChIKZDTazBWaWa2a3BF3PwTKzJWY2y8ymm1lM3p/UzJ4xszVmNrvcvAZm9pGZfRv5t36QNe6PPazPnWa2PLKdppvZyUHWuL/MrJWZfWZm88xsjpndGJkfk9tpL+sTs9vJzNLN7GszmxFZpz9F5meZ2eTINnrNzFIrtbxEOKZgZknAQuAkIA+YAgx197mBFnYQzGwJkO3uMXvBjZkdC2wFnnf3LpF5fwfWu/vfIuFd391/F2SdlbWH9bkT2Oru9wVZ24Eys2ZAM3efZma1ganAmcBlxOB22sv6nE+MbiczM6CWu281sxTgS+BG4NfAm+7+qpk9Dsxw98f2tbxE2VPoDeS6+2J3LwBeBc4IuKaE5+7jgfW7zT4DeC7y+DnCf7AxYQ/rE9PcfaW7T4s83gLMA1oQo9tpL+sTszxsa2QyJfLjwE+A1yPzK72NEiUUWgDLyk3nEeP/EQhv9LFmNtXMhgddTBVq4u4rIfwHDDQOuJ6qMMLMZka6l2Kim6UiZtYW6A5MJg62027rAzG8ncwsycymA2uAj4BFwEZ3L4o0qfRnXqKEglUwL9b7zfq7ew9gCHBdpOtCqp/HgMOAbsBK4P5gyzkwZpYBvAHc5O6bg67nYFWwPjG9ndy92N27AS0J94x0rKhZZZaVKKGQB7QqN90SWBFQLVXC3VdE/l0DvEX4P0I8WB3p9y3t/10TcD0Hxd1XR/5gS4AnicHtFOmnfgN4yd3fjMyO2e1U0frEw3YCcPeNwDigL1DPzJIjT1X6My9RQmEK0D5yND4VuAB4N+CaDpiZ1YocJMPMagE/A2bv/VUx413g0sjjS4F3AqzloJV+cEacRYxtp8hBzKeBee7+QLmnYnI77Wl9Ynk7mVmmmdWLPK4B/JTwsZLPgHMjzSq9jRLi7COAyClm/wCSgGfc/S8Bl3TAzKwd4b0DgGTg5VhcHzN7BTie8DC/q4E7gLeBUUBr4HvgPHePiYO3e1if4wl3STiwBLi6tC8+FpjZAOALYBZQEpn9e8L98DG3nfayPkOJ0e1kZl0JH0hOIvxFf5S73xX5nHgVaAB8A1zs7rv2ubxECQUREdm3ROk+EhGRSlAoiIhIGYWCiIiUUSiIiEgZhYKIiJRRKEjCMrMJkX/bmtmFVbzs31f0u0SqO52SKgnPzI4Hbnb3U/fjNUnuXryX57e6e0ZV1CdyKGlPQRKWmZWOLPk3YGBkHP1fRQYXu9fMpkQGSLs60v74yFj8LxO++AkzezsyKOGc0oEJzexvQI3I8l4q/7ss7F4zm23h+2H8vNyyx5nZ62Y238xeilx9K3JIJe+7iUjcu4VyewqRD/dN7t7LzNKAr8xsbKRtb6CLu38Xmb7C3ddHhheYYmZvuPstZjYiMkDZ7s4mfOXs0YSvfJ5iZuMjz3UHOhMeo+YroD/hsfFFDhntKYj82M+AYZGhiCcDDYH2kee+LhcIADeY2QxgEuFBF9uzdwOAVyKDr60GPgd6lVt2XmRQtulA2ypZG5H9oD0FkR8z4Hp3//AHM8PHHrbtNv1ToJ+7bzezcUB6JZa9J+XHpSlGf58SAO0piMAWoHa56Q+BayJDLGNmHSKj0e6uLrAhEghHEh6uuFRh6et3Mx74eeS4RSZwLPB1layFSBXQNxERmAkURbqBngUeItx1My1ysDefim9lOAb4pZnNBBYQ7kIqNRKYaWbT3P2icvPfAvoBMwiPyPl/7r4qEioigdMpqSIiUkbdRyIiUkahICIiZRQKIiJSRqEgIiJlFAoiIlJGoSAiImUUCiIiUub/A2ubefANn2EwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "exploration_rate_2 = unique_trajectories_2/seen_trajectories_2\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - 5 simulations\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "plt.plot(x, exploration_rate_2, label=\"unique/seen\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins_2 = [0.67, 0.66, 0.77, 0.78, 0.74, 0.76, 0.83, 0.83, 0.8, 0.78, 0.87, 0.74, 0.87, 0.79, 0.78, 0.79, 0.79, 0.88, 0.82, 0.67, 0.82, 0.72, 0.83, 0.79, 0.84, 0.8, 0.8, 0.69, 0.79, 0.73]\n",
      "draws_2 = [0.07, 0.05, 0.01, 0.0, 0.01, 0.02, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "seen_trajectories_2 = [ 100.  200.  300.  400.  500.  600.  700.  800.  900. 1000. 1100. 1200.\n",
      " 1300. 1400. 1500. 1600. 1700. 1800. 1900. 2000. 2100. 2200. 2300. 2400.\n",
      " 2500. 2600. 2700. 2800. 2900. 3000.]\n",
      "unique_trajectories_2 = [ 100.  200.  298.  394.  487.  580.  657.  730.  798.  869.  919.  957.\n",
      "  981. 1006. 1013. 1027. 1032. 1037. 1039. 1042. 1042. 1042. 1044. 1046.\n",
      " 1047. 1051. 1052. 1055. 1055. 1057.]\n"
     ]
    }
   ],
   "source": [
    "print(\"wins_2 =\",wins_2)\n",
    "print(\"draws_2 =\",draws_2)\n",
    "print(\"seen_trajectories_2 =\", seen_trajectories_2)\n",
    "print(\"unique_trajectories_2 =\", unique_trajectories_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCTS = {\n",
    "    'c_puct': 5,\n",
    "    'dir_alpha': 0.6,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 10,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 10\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 10,\n",
    "    'temperature': 0,\n",
    "    'show_games': False\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 10,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.002,\n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 512,\n",
    "    'num_filters_value': 512,\n",
    "    'num_filters_tower': 512,\n",
    "    'num_residual_blocks': 3,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 512\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"tictactoe_num_sim_10\", \"TicTacToe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 4s 934us/step - loss: 6.6719 - value_loss: 0.8623 - policy_loss: 2.3899 - val_loss: 6.5342 - val_value_loss: 0.7486 - val_policy_loss: 2.2286\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.4910 - value_loss: 0.7189 - policy_loss: 2.1722 - val_loss: 6.4678 - val_value_loss: 0.7188 - val_policy_loss: 2.1263\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.3915 - value_loss: 0.6158 - policy_loss: 2.0769 - val_loss: 6.4590 - val_value_loss: 0.7693 - val_policy_loss: 2.0588\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.3555 - value_loss: 0.6103 - policy_loss: 2.0110 - val_loss: 6.3737 - val_value_loss: 0.6462 - val_policy_loss: 2.0119\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.3027 - value_loss: 0.5534 - policy_loss: 1.9631 - val_loss: 6.3568 - val_value_loss: 0.6504 - val_policy_loss: 1.9746\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2780 - value_loss: 0.5411 - policy_loss: 1.9266 - val_loss: 6.3761 - val_value_loss: 0.7184 - val_policy_loss: 1.9458\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2595 - value_loss: 0.5330 - policy_loss: 1.8983 - val_loss: 6.3459 - val_value_loss: 0.6817 - val_policy_loss: 1.9227\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2434 - value_loss: 0.5256 - policy_loss: 1.8740 - val_loss: 6.3364 - val_value_loss: 0.6829 - val_policy_loss: 1.9032\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2246 - value_loss: 0.5079 - policy_loss: 1.8549 - val_loss: 6.3202 - val_value_loss: 0.6680 - val_policy_loss: 1.8863\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2077 - value_loss: 0.4917 - policy_loss: 1.8379 - val_loss: 6.3119 - val_value_loss: 0.6660 - val_policy_loss: 1.8723\n",
      "Saved model  tictactoe_num_sim_10_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.02\n",
      "Number of seen trajectories: 100\n",
      "Number of unique trajectories: 99\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.3381 - value_loss: 0.7232 - policy_loss: 1.8680 - val_loss: 6.2966 - val_value_loss: 0.6508 - val_policy_loss: 1.8576\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2851 - value_loss: 0.6390 - policy_loss: 1.8467 - val_loss: 6.2863 - val_value_loss: 0.6458 - val_policy_loss: 1.8426\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2511 - value_loss: 0.5891 - policy_loss: 1.8293 - val_loss: 6.2709 - val_value_loss: 0.6276 - val_policy_loss: 1.8306\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2431 - value_loss: 0.5881 - policy_loss: 1.8148 - val_loss: 6.2912 - val_value_loss: 0.6779 - val_policy_loss: 1.8216\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2204 - value_loss: 0.5563 - policy_loss: 1.8020 - val_loss: 6.2679 - val_value_loss: 0.6408 - val_policy_loss: 1.8127\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2007 - value_loss: 0.5269 - policy_loss: 1.7925 - val_loss: 6.2787 - val_value_loss: 0.6711 - val_policy_loss: 1.8046\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1878 - value_loss: 0.5114 - policy_loss: 1.7828 - val_loss: 6.2681 - val_value_loss: 0.6573 - val_policy_loss: 1.7980\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1965 - value_loss: 0.5370 - policy_loss: 1.7753 - val_loss: 6.2562 - val_value_loss: 0.6397 - val_policy_loss: 1.7924\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1797 - value_loss: 0.5113 - policy_loss: 1.7682 - val_loss: 6.2824 - val_value_loss: 0.6985 - val_policy_loss: 1.7866\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1666 - value_loss: 0.4922 - policy_loss: 1.7616 - val_loss: 6.2382 - val_value_loss: 0.6155 - val_policy_loss: 1.7819\n",
      "Saved model  tictactoe_num_sim_10_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.06\n",
      "Number of seen trajectories: 200\n",
      "Number of unique trajectories: 198\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2920 - value_loss: 0.7229 - policy_loss: 1.7823 - val_loss: 6.3216 - val_value_loss: 0.7737 - val_policy_loss: 1.7911\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2379 - value_loss: 0.6279 - policy_loss: 1.7699 - val_loss: 6.2997 - val_value_loss: 0.7391 - val_policy_loss: 1.7826\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.2255 - value_loss: 0.6129 - policy_loss: 1.7607 - val_loss: 6.2900 - val_value_loss: 0.7260 - val_policy_loss: 1.7770\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2078 - value_loss: 0.5868 - policy_loss: 1.7520 - val_loss: 6.3015 - val_value_loss: 0.7555 - val_policy_loss: 1.7710\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1927 - value_loss: 0.5642 - policy_loss: 1.7449 - val_loss: 6.3062 - val_value_loss: 0.7699 - val_policy_loss: 1.7668\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1727 - value_loss: 0.5309 - policy_loss: 1.7389 - val_loss: 6.2952 - val_value_loss: 0.7533 - val_policy_loss: 1.7620\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1575 - value_loss: 0.5068 - policy_loss: 1.7333 - val_loss: 6.2742 - val_value_loss: 0.7151 - val_policy_loss: 1.7587\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1572 - value_loss: 0.5123 - policy_loss: 1.7279 - val_loss: 6.2709 - val_value_loss: 0.7124 - val_policy_loss: 1.7556\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1452 - value_loss: 0.4925 - policy_loss: 1.7242 - val_loss: 6.2720 - val_value_loss: 0.7180 - val_policy_loss: 1.7527\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1349 - value_loss: 0.4772 - policy_loss: 1.7196 - val_loss: 6.2690 - val_value_loss: 0.7165 - val_policy_loss: 1.7490\n",
      "Saved model  tictactoe_num_sim_10_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.75 - draw ratio 0.03\n",
      "Number of seen trajectories: 300\n",
      "Number of unique trajectories: 298\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2947 - value_loss: 0.7849 - policy_loss: 1.7321 - val_loss: 6.2912 - val_value_loss: 0.7836 - val_policy_loss: 1.7269\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2305 - value_loss: 0.6663 - policy_loss: 1.7230 - val_loss: 6.2894 - val_value_loss: 0.7852 - val_policy_loss: 1.7223\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2015 - value_loss: 0.6158 - policy_loss: 1.7161 - val_loss: 6.2529 - val_value_loss: 0.7162 - val_policy_loss: 1.7189\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2113 - value_loss: 0.6409 - policy_loss: 1.7111 - val_loss: 6.3234 - val_value_loss: 0.8604 - val_policy_loss: 1.7162\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2223 - value_loss: 0.6681 - policy_loss: 1.7066 - val_loss: 6.2734 - val_value_loss: 0.7644 - val_policy_loss: 1.7130\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1606 - value_loss: 0.5496 - policy_loss: 1.7024 - val_loss: 6.2347 - val_value_loss: 0.6895 - val_policy_loss: 1.7111\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1536 - value_loss: 0.5410 - policy_loss: 1.6977 - val_loss: 6.2658 - val_value_loss: 0.7536 - val_policy_loss: 1.7098\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1626 - value_loss: 0.5629 - policy_loss: 1.6943 - val_loss: 6.2438 - val_value_loss: 0.7144 - val_policy_loss: 1.7057\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1357 - value_loss: 0.5142 - policy_loss: 1.6900 - val_loss: 6.2258 - val_value_loss: 0.6808 - val_policy_loss: 1.7038\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1309 - value_loss: 0.5079 - policy_loss: 1.6873 - val_loss: 6.2249 - val_value_loss: 0.6821 - val_policy_loss: 1.7015\n",
      "Saved model  tictactoe_num_sim_10_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.03\n",
      "Number of seen trajectories: 400\n",
      "Number of unique trajectories: 396\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2642 - value_loss: 0.7298 - policy_loss: 1.7326 - val_loss: 6.2718 - val_value_loss: 0.7539 - val_policy_loss: 1.7241\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.2275 - value_loss: 0.6630 - policy_loss: 1.7267 - val_loss: 6.2480 - val_value_loss: 0.7102 - val_policy_loss: 1.7209\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2077 - value_loss: 0.6296 - policy_loss: 1.7212 - val_loss: 6.2491 - val_value_loss: 0.7150 - val_policy_loss: 1.7189\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1909 - value_loss: 0.6003 - policy_loss: 1.7175 - val_loss: 6.2618 - val_value_loss: 0.7421 - val_policy_loss: 1.7178\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1756 - value_loss: 0.5740 - policy_loss: 1.7138 - val_loss: 6.2417 - val_value_loss: 0.7047 - val_policy_loss: 1.7157\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1752 - value_loss: 0.5764 - policy_loss: 1.7112 - val_loss: 6.2353 - val_value_loss: 0.6946 - val_policy_loss: 1.7137\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1716 - value_loss: 0.5729 - policy_loss: 1.7082 - val_loss: 6.2315 - val_value_loss: 0.6887 - val_policy_loss: 1.7126\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1587 - value_loss: 0.5511 - policy_loss: 1.7049 - val_loss: 6.2345 - val_value_loss: 0.6971 - val_policy_loss: 1.7107\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1466 - value_loss: 0.5295 - policy_loss: 1.7028 - val_loss: 6.2387 - val_value_loss: 0.7067 - val_policy_loss: 1.7102\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1552 - value_loss: 0.5493 - policy_loss: 1.7008 - val_loss: 6.2331 - val_value_loss: 0.6982 - val_policy_loss: 1.7082\n",
      "Saved model  tictactoe_num_sim_10_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.81 - draw ratio 0.01\n",
      "Number of seen trajectories: 500\n",
      "Number of unique trajectories: 490\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2393 - value_loss: 0.7183 - policy_loss: 1.7007 - val_loss: 6.2206 - val_value_loss: 0.6761 - val_policy_loss: 1.7056\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.2096 - value_loss: 0.6636 - policy_loss: 1.6962 - val_loss: 6.2082 - val_value_loss: 0.6533 - val_policy_loss: 1.7041\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1872 - value_loss: 0.6224 - policy_loss: 1.6929 - val_loss: 6.1988 - val_value_loss: 0.6357 - val_policy_loss: 1.7030\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1735 - value_loss: 0.5977 - policy_loss: 1.6905 - val_loss: 6.1990 - val_value_loss: 0.6376 - val_policy_loss: 1.7018\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1617 - value_loss: 0.5761 - policy_loss: 1.6888 - val_loss: 6.1917 - val_value_loss: 0.6240 - val_policy_loss: 1.7012\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1540 - value_loss: 0.5634 - policy_loss: 1.6866 - val_loss: 6.1911 - val_value_loss: 0.6241 - val_policy_loss: 1.7002\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1440 - value_loss: 0.5457 - policy_loss: 1.6846 - val_loss: 6.1852 - val_value_loss: 0.6133 - val_policy_loss: 1.6995\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1376 - value_loss: 0.5347 - policy_loss: 1.6830 - val_loss: 6.1813 - val_value_loss: 0.6066 - val_policy_loss: 1.6987\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1318 - value_loss: 0.5251 - policy_loss: 1.6814 - val_loss: 6.1809 - val_value_loss: 0.6067 - val_policy_loss: 1.6981\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1254 - value_loss: 0.5142 - policy_loss: 1.6798 - val_loss: 6.1786 - val_value_loss: 0.6033 - val_policy_loss: 1.6972\n",
      "Saved model  tictactoe_num_sim_10_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.01\n",
      "Number of seen trajectories: 600\n",
      "Number of unique trajectories: 585\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2233 - value_loss: 0.7067 - policy_loss: 1.6835 - val_loss: 6.1945 - val_value_loss: 0.6400 - val_policy_loss: 1.6927\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1917 - value_loss: 0.6471 - policy_loss: 1.6802 - val_loss: 6.1875 - val_value_loss: 0.6276 - val_policy_loss: 1.6914\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1731 - value_loss: 0.6128 - policy_loss: 1.6775 - val_loss: 6.1828 - val_value_loss: 0.6193 - val_policy_loss: 1.6907\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1587 - value_loss: 0.5869 - policy_loss: 1.6749 - val_loss: 6.1794 - val_value_loss: 0.6139 - val_policy_loss: 1.6896\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1486 - value_loss: 0.5682 - policy_loss: 1.6738 - val_loss: 6.1766 - val_value_loss: 0.6095 - val_policy_loss: 1.6887\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1419 - value_loss: 0.5569 - policy_loss: 1.6720 - val_loss: 6.1770 - val_value_loss: 0.6114 - val_policy_loss: 1.6880\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1335 - value_loss: 0.5427 - policy_loss: 1.6696 - val_loss: 6.1762 - val_value_loss: 0.6108 - val_policy_loss: 1.6872\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1276 - value_loss: 0.5320 - policy_loss: 1.6690 - val_loss: 6.1734 - val_value_loss: 0.6062 - val_policy_loss: 1.6866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1228 - value_loss: 0.5243 - policy_loss: 1.6672 - val_loss: 6.1713 - val_value_loss: 0.6030 - val_policy_loss: 1.6858\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1179 - value_loss: 0.5167 - policy_loss: 1.6655 - val_loss: 6.1715 - val_value_loss: 0.6045 - val_policy_loss: 1.6852\n",
      "Saved model  tictactoe_num_sim_10_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.71 - draw ratio 0.03\n",
      "Number of seen trajectories: 700\n",
      "Number of unique trajectories: 680\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1866 - value_loss: 0.6304 - policy_loss: 1.6896 - val_loss: 6.1975 - val_value_loss: 0.6449 - val_policy_loss: 1.6970\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1627 - value_loss: 0.5851 - policy_loss: 1.6873 - val_loss: 6.1940 - val_value_loss: 0.6395 - val_policy_loss: 1.6957\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1474 - value_loss: 0.5572 - policy_loss: 1.6850 - val_loss: 6.1852 - val_value_loss: 0.6232 - val_policy_loss: 1.6946\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1362 - value_loss: 0.5380 - policy_loss: 1.6821 - val_loss: 6.1755 - val_value_loss: 0.6052 - val_policy_loss: 1.6937\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1295 - value_loss: 0.5269 - policy_loss: 1.6800 - val_loss: 6.1747 - val_value_loss: 0.6046 - val_policy_loss: 1.6929\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1213 - value_loss: 0.5119 - policy_loss: 1.6789 - val_loss: 6.1737 - val_value_loss: 0.6039 - val_policy_loss: 1.6920\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1143 - value_loss: 0.5006 - policy_loss: 1.6765 - val_loss: 6.1707 - val_value_loss: 0.5992 - val_policy_loss: 1.6911\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1108 - value_loss: 0.4948 - policy_loss: 1.6757 - val_loss: 6.1687 - val_value_loss: 0.5962 - val_policy_loss: 1.6903\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1076 - value_loss: 0.4900 - policy_loss: 1.6744 - val_loss: 6.1691 - val_value_loss: 0.5980 - val_policy_loss: 1.6896\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1027 - value_loss: 0.4828 - policy_loss: 1.6723 - val_loss: 6.1690 - val_value_loss: 0.5987 - val_policy_loss: 1.6891\n",
      "Saved model  tictactoe_num_sim_10_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.75 - draw ratio 0.02\n",
      "Number of seen trajectories: 800\n",
      "Number of unique trajectories: 778\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1920 - value_loss: 0.6610 - policy_loss: 1.6729 - val_loss: 6.1632 - val_value_loss: 0.6148 - val_policy_loss: 1.6617\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1694 - value_loss: 0.6177 - policy_loss: 1.6713 - val_loss: 6.1624 - val_value_loss: 0.6144 - val_policy_loss: 1.6608\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1544 - value_loss: 0.5911 - policy_loss: 1.6682 - val_loss: 6.1534 - val_value_loss: 0.5975 - val_policy_loss: 1.6600\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1412 - value_loss: 0.5672 - policy_loss: 1.6660 - val_loss: 6.1505 - val_value_loss: 0.5931 - val_policy_loss: 1.6590\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1303 - value_loss: 0.5481 - policy_loss: 1.6637 - val_loss: 6.1520 - val_value_loss: 0.5967 - val_policy_loss: 1.6586\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1239 - value_loss: 0.5373 - policy_loss: 1.6621 - val_loss: 6.1468 - val_value_loss: 0.5870 - val_policy_loss: 1.6583\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1165 - value_loss: 0.5241 - policy_loss: 1.6607 - val_loss: 6.1453 - val_value_loss: 0.5849 - val_policy_loss: 1.6577\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1111 - value_loss: 0.5148 - policy_loss: 1.6596 - val_loss: 6.1464 - val_value_loss: 0.5879 - val_policy_loss: 1.6573\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1071 - value_loss: 0.5082 - policy_loss: 1.6584 - val_loss: 6.1438 - val_value_loss: 0.5833 - val_policy_loss: 1.6569\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1022 - value_loss: 0.5001 - policy_loss: 1.6571 - val_loss: 6.1412 - val_value_loss: 0.5790 - val_policy_loss: 1.6564\n",
      "Saved model  tictactoe_num_sim_10_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.72 - draw ratio 0.02\n",
      "Number of seen trajectories: 900\n",
      "Number of unique trajectories: 866\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.2441 - value_loss: 0.7549 - policy_loss: 1.6865 - val_loss: 6.2452 - val_value_loss: 0.7506 - val_policy_loss: 1.6931\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2191 - value_loss: 0.7083 - policy_loss: 1.6834 - val_loss: 6.2424 - val_value_loss: 0.7462 - val_policy_loss: 1.6921\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2026 - value_loss: 0.6773 - policy_loss: 1.6816 - val_loss: 6.2324 - val_value_loss: 0.7271 - val_policy_loss: 1.6916\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1875 - value_loss: 0.6495 - policy_loss: 1.6797 - val_loss: 6.2370 - val_value_loss: 0.7375 - val_policy_loss: 1.6907\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1778 - value_loss: 0.6314 - policy_loss: 1.6785 - val_loss: 6.2261 - val_value_loss: 0.7166 - val_policy_loss: 1.6901\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1685 - value_loss: 0.6144 - policy_loss: 1.6772 - val_loss: 6.2254 - val_value_loss: 0.7162 - val_policy_loss: 1.6894\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1626 - value_loss: 0.6045 - policy_loss: 1.6757 - val_loss: 6.2342 - val_value_loss: 0.7347 - val_policy_loss: 1.6888\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1561 - value_loss: 0.5928 - policy_loss: 1.6747 - val_loss: 6.2258 - val_value_loss: 0.7188 - val_policy_loss: 1.6882\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1510 - value_loss: 0.5843 - policy_loss: 1.6733 - val_loss: 6.2211 - val_value_loss: 0.7104 - val_policy_loss: 1.6877\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1457 - value_loss: 0.5748 - policy_loss: 1.6725 - val_loss: 6.2265 - val_value_loss: 0.7220 - val_policy_loss: 1.6871\n",
      "Saved model  tictactoe_num_sim_10_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.03\n",
      "Number of seen trajectories: 1000\n",
      "Number of unique trajectories: 956\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.2697 - value_loss: 0.8077 - policy_loss: 1.6878 - val_loss: 6.2661 - val_value_loss: 0.7925 - val_policy_loss: 1.6960\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.2462 - value_loss: 0.7620 - policy_loss: 1.6867 - val_loss: 6.2614 - val_value_loss: 0.7839 - val_policy_loss: 1.6954\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2312 - value_loss: 0.7339 - policy_loss: 1.6850 - val_loss: 6.2598 - val_value_loss: 0.7814 - val_policy_loss: 1.6948\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2204 - value_loss: 0.7133 - policy_loss: 1.6842 - val_loss: 6.2549 - val_value_loss: 0.7725 - val_policy_loss: 1.6942\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2120 - value_loss: 0.6976 - policy_loss: 1.6834 - val_loss: 6.2552 - val_value_loss: 0.7737 - val_policy_loss: 1.6936\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2039 - value_loss: 0.6819 - policy_loss: 1.6829 - val_loss: 6.2525 - val_value_loss: 0.7690 - val_policy_loss: 1.6931\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1986 - value_loss: 0.6724 - policy_loss: 1.6820 - val_loss: 6.2506 - val_value_loss: 0.7659 - val_policy_loss: 1.6926\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1920 - value_loss: 0.6603 - policy_loss: 1.6810 - val_loss: 6.2535 - val_value_loss: 0.7722 - val_policy_loss: 1.6921\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1875 - value_loss: 0.6518 - policy_loss: 1.6808 - val_loss: 6.2495 - val_value_loss: 0.7649 - val_policy_loss: 1.6918\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1843 - value_loss: 0.6461 - policy_loss: 1.6802 - val_loss: 6.2494 - val_value_loss: 0.7652 - val_policy_loss: 1.6913\n",
      "Saved model  tictactoe_num_sim_10_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.0\n",
      "Number of seen trajectories: 1100\n",
      "Number of unique trajectories: 1051\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2475 - value_loss: 0.7736 - policy_loss: 1.6792 - val_loss: 6.2238 - val_value_loss: 0.7351 - val_policy_loss: 1.6704\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2286 - value_loss: 0.7369 - policy_loss: 1.6783 - val_loss: 6.2224 - val_value_loss: 0.7332 - val_policy_loss: 1.6698\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2148 - value_loss: 0.7111 - policy_loss: 1.6767 - val_loss: 6.2176 - val_value_loss: 0.7241 - val_policy_loss: 1.6692\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2051 - value_loss: 0.6935 - policy_loss: 1.6750 - val_loss: 6.2143 - val_value_loss: 0.7184 - val_policy_loss: 1.6687\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1955 - value_loss: 0.6748 - policy_loss: 1.6747 - val_loss: 6.2156 - val_value_loss: 0.7215 - val_policy_loss: 1.6682\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1888 - value_loss: 0.6624 - policy_loss: 1.6738 - val_loss: 6.2108 - val_value_loss: 0.7126 - val_policy_loss: 1.6678\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1819 - value_loss: 0.6497 - policy_loss: 1.6728 - val_loss: 6.2095 - val_value_loss: 0.7106 - val_policy_loss: 1.6672\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1753 - value_loss: 0.6385 - policy_loss: 1.6711 - val_loss: 6.2113 - val_value_loss: 0.7148 - val_policy_loss: 1.6668\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1725 - value_loss: 0.6327 - policy_loss: 1.6714 - val_loss: 6.2073 - val_value_loss: 0.7074 - val_policy_loss: 1.6664\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1675 - value_loss: 0.6243 - policy_loss: 1.6699 - val_loss: 6.2074 - val_value_loss: 0.7081 - val_policy_loss: 1.6660\n",
      "Saved model  tictactoe_num_sim_10_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.89 - draw ratio 0.01\n",
      "Number of seen trajectories: 1200\n",
      "Number of unique trajectories: 1138\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1926 - value_loss: 0.6915 - policy_loss: 1.6531 - val_loss: 6.1959 - val_value_loss: 0.6772 - val_policy_loss: 1.6741\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1759 - value_loss: 0.6599 - policy_loss: 1.6516 - val_loss: 6.1915 - val_value_loss: 0.6693 - val_policy_loss: 1.6734\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1651 - value_loss: 0.6399 - policy_loss: 1.6500 - val_loss: 6.1880 - val_value_loss: 0.6629 - val_policy_loss: 1.6729\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1571 - value_loss: 0.6248 - policy_loss: 1.6493 - val_loss: 6.1851 - val_value_loss: 0.6578 - val_policy_loss: 1.6723\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1504 - value_loss: 0.6126 - policy_loss: 1.6482 - val_loss: 6.1829 - val_value_loss: 0.6542 - val_policy_loss: 1.6719\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1435 - value_loss: 0.5999 - policy_loss: 1.6474 - val_loss: 6.1818 - val_value_loss: 0.6525 - val_policy_loss: 1.6715\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1385 - value_loss: 0.5910 - policy_loss: 1.6464 - val_loss: 6.1788 - val_value_loss: 0.6469 - val_policy_loss: 1.6712\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1342 - value_loss: 0.5836 - policy_loss: 1.6453 - val_loss: 6.1772 - val_value_loss: 0.6441 - val_policy_loss: 1.6709\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1286 - value_loss: 0.5738 - policy_loss: 1.6441 - val_loss: 6.1764 - val_value_loss: 0.6430 - val_policy_loss: 1.6705\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1263 - value_loss: 0.5696 - policy_loss: 1.6439 - val_loss: 6.1753 - val_value_loss: 0.6413 - val_policy_loss: 1.6703\n",
      "Saved model  tictactoe_num_sim_10_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.0\n",
      "Number of seen trajectories: 1300\n",
      "Number of unique trajectories: 1216\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1658 - value_loss: 0.6219 - policy_loss: 1.6707 - val_loss: 6.1749 - val_value_loss: 0.6241 - val_policy_loss: 1.6869\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1500 - value_loss: 0.5917 - policy_loss: 1.6695 - val_loss: 6.1717 - val_value_loss: 0.6188 - val_policy_loss: 1.6860\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1400 - value_loss: 0.5740 - policy_loss: 1.6673 - val_loss: 6.1711 - val_value_loss: 0.6184 - val_policy_loss: 1.6853\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1324 - value_loss: 0.5601 - policy_loss: 1.6662 - val_loss: 6.1706 - val_value_loss: 0.6181 - val_policy_loss: 1.6847\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1253 - value_loss: 0.5468 - policy_loss: 1.6655 - val_loss: 6.1656 - val_value_loss: 0.6089 - val_policy_loss: 1.6841\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1221 - value_loss: 0.5416 - policy_loss: 1.6645 - val_loss: 6.1675 - val_value_loss: 0.6134 - val_policy_loss: 1.6835\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1167 - value_loss: 0.5315 - policy_loss: 1.6638 - val_loss: 6.1657 - val_value_loss: 0.6105 - val_policy_loss: 1.6831\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1122 - value_loss: 0.5234 - policy_loss: 1.6631 - val_loss: 6.1651 - val_value_loss: 0.6098 - val_policy_loss: 1.6826\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1084 - value_loss: 0.5168 - policy_loss: 1.6624 - val_loss: 6.1648 - val_value_loss: 0.6099 - val_policy_loss: 1.6822\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1051 - value_loss: 0.5110 - policy_loss: 1.6616 - val_loss: 6.1639 - val_value_loss: 0.6085 - val_policy_loss: 1.6818\n",
      "Saved model  tictactoe_num_sim_10_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.0\n",
      "Number of seen trajectories: 1400\n",
      "Number of unique trajectories: 1292\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1546 - value_loss: 0.6264 - policy_loss: 1.6454 - val_loss: 6.1654 - val_value_loss: 0.6515 - val_policy_loss: 1.6421\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1383 - value_loss: 0.5958 - policy_loss: 1.6436 - val_loss: 6.1617 - val_value_loss: 0.6446 - val_policy_loss: 1.6417\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1279 - value_loss: 0.5762 - policy_loss: 1.6425 - val_loss: 6.1587 - val_value_loss: 0.6391 - val_policy_loss: 1.6413\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1195 - value_loss: 0.5604 - policy_loss: 1.6417 - val_loss: 6.1563 - val_value_loss: 0.6348 - val_policy_loss: 1.6409\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1126 - value_loss: 0.5474 - policy_loss: 1.6410 - val_loss: 6.1547 - val_value_loss: 0.6322 - val_policy_loss: 1.6406\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1065 - value_loss: 0.5364 - policy_loss: 1.6399 - val_loss: 6.1535 - val_value_loss: 0.6303 - val_policy_loss: 1.6403\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1020 - value_loss: 0.5288 - policy_loss: 1.6389 - val_loss: 6.1522 - val_value_loss: 0.6280 - val_policy_loss: 1.6399\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0980 - value_loss: 0.5212 - policy_loss: 1.6385 - val_loss: 6.1513 - val_value_loss: 0.6268 - val_policy_loss: 1.6397\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0933 - value_loss: 0.5131 - policy_loss: 1.6374 - val_loss: 6.1491 - val_value_loss: 0.6228 - val_policy_loss: 1.6394\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0892 - value_loss: 0.5061 - policy_loss: 1.6365 - val_loss: 6.1481 - val_value_loss: 0.6212 - val_policy_loss: 1.6392\n",
      "Saved model  tictactoe_num_sim_10_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.02\n",
      "Number of seen trajectories: 1500\n",
      "Number of unique trajectories: 1377\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1303 - value_loss: 0.5848 - policy_loss: 1.6401 - val_loss: 6.1523 - val_value_loss: 0.6341 - val_policy_loss: 1.6346\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1227 - value_loss: 0.5706 - policy_loss: 1.6391 - val_loss: 6.1504 - val_value_loss: 0.6306 - val_policy_loss: 1.6344\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1171 - value_loss: 0.5597 - policy_loss: 1.6389 - val_loss: 6.1487 - val_value_loss: 0.6274 - val_policy_loss: 1.6343\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1120 - value_loss: 0.5502 - policy_loss: 1.6382 - val_loss: 6.1474 - val_value_loss: 0.6252 - val_policy_loss: 1.6341\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1078 - value_loss: 0.5420 - policy_loss: 1.6380 - val_loss: 6.1461 - val_value_loss: 0.6228 - val_policy_loss: 1.6339\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1042 - value_loss: 0.5361 - policy_loss: 1.6369 - val_loss: 6.1451 - val_value_loss: 0.6211 - val_policy_loss: 1.6338\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1006 - value_loss: 0.5293 - policy_loss: 1.6365 - val_loss: 6.1440 - val_value_loss: 0.6191 - val_policy_loss: 1.6336\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0973 - value_loss: 0.5233 - policy_loss: 1.6362 - val_loss: 6.1434 - val_value_loss: 0.6180 - val_policy_loss: 1.6335\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0939 - value_loss: 0.5169 - policy_loss: 1.6357 - val_loss: 6.1425 - val_value_loss: 0.6165 - val_policy_loss: 1.6333\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0926 - value_loss: 0.5142 - policy_loss: 1.6359 - val_loss: 6.1416 - val_value_loss: 0.6149 - val_policy_loss: 1.6332\n",
      "Saved model  tictactoe_num_sim_10_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.0\n",
      "Number of seen trajectories: 1600\n",
      "Number of unique trajectories: 1455\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1165 - value_loss: 0.5615 - policy_loss: 1.6364 - val_loss: 6.1474 - val_value_loss: 0.5978 - val_policy_loss: 1.6621\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1104 - value_loss: 0.5507 - policy_loss: 1.6352 - val_loss: 6.1453 - val_value_loss: 0.5938 - val_policy_loss: 1.6618\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1058 - value_loss: 0.5420 - policy_loss: 1.6348 - val_loss: 6.1430 - val_value_loss: 0.5897 - val_policy_loss: 1.6616\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1025 - value_loss: 0.5363 - policy_loss: 1.6339 - val_loss: 6.1414 - val_value_loss: 0.5867 - val_policy_loss: 1.6613\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0978 - value_loss: 0.5276 - policy_loss: 1.6333 - val_loss: 6.1397 - val_value_loss: 0.5837 - val_policy_loss: 1.6611\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0951 - value_loss: 0.5225 - policy_loss: 1.6330 - val_loss: 6.1384 - val_value_loss: 0.5813 - val_policy_loss: 1.6609\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0921 - value_loss: 0.5175 - policy_loss: 1.6323 - val_loss: 6.1373 - val_value_loss: 0.5794 - val_policy_loss: 1.6607\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0887 - value_loss: 0.5112 - policy_loss: 1.6318 - val_loss: 6.1361 - val_value_loss: 0.5772 - val_policy_loss: 1.6605\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.0864 - value_loss: 0.5070 - policy_loss: 1.6314 - val_loss: 6.1353 - val_value_loss: 0.5760 - val_policy_loss: 1.6603\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0844 - value_loss: 0.5029 - policy_loss: 1.6315 - val_loss: 6.1344 - val_value_loss: 0.5744 - val_policy_loss: 1.6601\n",
      "Saved model  tictactoe_num_sim_10_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.81 - draw ratio 0.01\n",
      "Number of seen trajectories: 1700\n",
      "Number of unique trajectories: 1539\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1492 - value_loss: 0.6337 - policy_loss: 1.6305 - val_loss: 6.1720 - val_value_loss: 0.6558 - val_policy_loss: 1.6542\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1426 - value_loss: 0.6209 - policy_loss: 1.6302 - val_loss: 6.1669 - val_value_loss: 0.6458 - val_policy_loss: 1.6540\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1361 - value_loss: 0.6085 - policy_loss: 1.6296 - val_loss: 6.1649 - val_value_loss: 0.6420 - val_policy_loss: 1.6539\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1312 - value_loss: 0.5995 - policy_loss: 1.6290 - val_loss: 6.1594 - val_value_loss: 0.6310 - val_policy_loss: 1.6538\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1264 - value_loss: 0.5908 - policy_loss: 1.6282 - val_loss: 6.1574 - val_value_loss: 0.6272 - val_policy_loss: 1.6537\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1221 - value_loss: 0.5827 - policy_loss: 1.6278 - val_loss: 6.1552 - val_value_loss: 0.6230 - val_policy_loss: 1.6536\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1191 - value_loss: 0.5766 - policy_loss: 1.6279 - val_loss: 6.1531 - val_value_loss: 0.6190 - val_policy_loss: 1.6535\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1155 - value_loss: 0.5699 - policy_loss: 1.6274 - val_loss: 6.1517 - val_value_loss: 0.6164 - val_policy_loss: 1.6534\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1124 - value_loss: 0.5642 - policy_loss: 1.6271 - val_loss: 6.1502 - val_value_loss: 0.6134 - val_policy_loss: 1.6533\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1099 - value_loss: 0.5598 - policy_loss: 1.6266 - val_loss: 6.1484 - val_value_loss: 0.6100 - val_policy_loss: 1.6533\n",
      "Saved model  tictactoe_num_sim_10_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.0\n",
      "Number of seen trajectories: 1800\n",
      "Number of unique trajectories: 1628\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1391 - value_loss: 0.5981 - policy_loss: 1.6467 - val_loss: 6.1104 - val_value_loss: 0.5411 - val_policy_loss: 1.6463\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1314 - value_loss: 0.5833 - policy_loss: 1.6461 - val_loss: 6.1078 - val_value_loss: 0.5364 - val_policy_loss: 1.6459\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1257 - value_loss: 0.5731 - policy_loss: 1.6450 - val_loss: 6.1058 - val_value_loss: 0.5327 - val_policy_loss: 1.6457\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1214 - value_loss: 0.5645 - policy_loss: 1.6452 - val_loss: 6.1040 - val_value_loss: 0.5296 - val_policy_loss: 1.6454\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1165 - value_loss: 0.5557 - policy_loss: 1.6442 - val_loss: 6.1027 - val_value_loss: 0.5271 - val_policy_loss: 1.6451\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1134 - value_loss: 0.5496 - policy_loss: 1.6442 - val_loss: 6.1013 - val_value_loss: 0.5246 - val_policy_loss: 1.6449\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1087 - value_loss: 0.5410 - policy_loss: 1.6434 - val_loss: 6.1004 - val_value_loss: 0.5233 - val_policy_loss: 1.6447\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1061 - value_loss: 0.5364 - policy_loss: 1.6430 - val_loss: 6.1001 - val_value_loss: 0.5228 - val_policy_loss: 1.6446\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1029 - value_loss: 0.5310 - policy_loss: 1.6420 - val_loss: 6.0990 - val_value_loss: 0.5210 - val_policy_loss: 1.6444\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1011 - value_loss: 0.5274 - policy_loss: 1.6422 - val_loss: 6.0987 - val_value_loss: 0.5205 - val_policy_loss: 1.6442\n",
      "Saved model  tictactoe_num_sim_10_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.02\n",
      "Number of seen trajectories: 1900\n",
      "Number of unique trajectories: 1705\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1086 - value_loss: 0.5406 - policy_loss: 1.6439 - val_loss: 6.1109 - val_value_loss: 0.5524 - val_policy_loss: 1.6368\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1026 - value_loss: 0.5293 - policy_loss: 1.6434 - val_loss: 6.1082 - val_value_loss: 0.5474 - val_policy_loss: 1.6365\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0981 - value_loss: 0.5203 - policy_loss: 1.6435 - val_loss: 6.1065 - val_value_loss: 0.5443 - val_policy_loss: 1.6363\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0945 - value_loss: 0.5138 - policy_loss: 1.6428 - val_loss: 6.1049 - val_value_loss: 0.5415 - val_policy_loss: 1.6361\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0903 - value_loss: 0.5068 - policy_loss: 1.6416 - val_loss: 6.1038 - val_value_loss: 0.5395 - val_policy_loss: 1.6359\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0870 - value_loss: 0.5005 - policy_loss: 1.6412 - val_loss: 6.1029 - val_value_loss: 0.5379 - val_policy_loss: 1.6357\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0842 - value_loss: 0.4950 - policy_loss: 1.6413 - val_loss: 6.1019 - val_value_loss: 0.5360 - val_policy_loss: 1.6356\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0827 - value_loss: 0.4912 - policy_loss: 1.6422 - val_loss: 6.1014 - val_value_loss: 0.5353 - val_policy_loss: 1.6355\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0792 - value_loss: 0.4866 - policy_loss: 1.6399 - val_loss: 6.1004 - val_value_loss: 0.5336 - val_policy_loss: 1.6354\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0767 - value_loss: 0.4810 - policy_loss: 1.6405 - val_loss: 6.0999 - val_value_loss: 0.5327 - val_policy_loss: 1.6353\n",
      "Saved model  tictactoe_num_sim_10_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.02\n",
      "Number of seen trajectories: 2000\n",
      "Number of unique trajectories: 1779\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1578 - value_loss: 0.6342 - policy_loss: 1.6496 - val_loss: 6.1232 - val_value_loss: 0.5675 - val_policy_loss: 1.6470\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1515 - value_loss: 0.6217 - policy_loss: 1.6495 - val_loss: 6.1185 - val_value_loss: 0.5583 - val_policy_loss: 1.6468\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1472 - value_loss: 0.6136 - policy_loss: 1.6491 - val_loss: 6.1154 - val_value_loss: 0.5524 - val_policy_loss: 1.6467\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1431 - value_loss: 0.6058 - policy_loss: 1.6486 - val_loss: 6.1131 - val_value_loss: 0.5479 - val_policy_loss: 1.6465\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1409 - value_loss: 0.6013 - policy_loss: 1.6488 - val_loss: 6.1111 - val_value_loss: 0.5442 - val_policy_loss: 1.6464\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1376 - value_loss: 0.5956 - policy_loss: 1.6480 - val_loss: 6.1095 - val_value_loss: 0.5412 - val_policy_loss: 1.6463\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1358 - value_loss: 0.5920 - policy_loss: 1.6480 - val_loss: 6.1081 - val_value_loss: 0.5385 - val_policy_loss: 1.6461\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1340 - value_loss: 0.5886 - policy_loss: 1.6479 - val_loss: 6.1070 - val_value_loss: 0.5365 - val_policy_loss: 1.6460\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1310 - value_loss: 0.5833 - policy_loss: 1.6472 - val_loss: 6.1058 - val_value_loss: 0.5343 - val_policy_loss: 1.6459\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1291 - value_loss: 0.5799 - policy_loss: 1.6469 - val_loss: 6.1050 - val_value_loss: 0.5327 - val_policy_loss: 1.6458\n",
      "Saved model  tictactoe_num_sim_10_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.02\n",
      "Number of seen trajectories: 2100\n",
      "Number of unique trajectories: 1860\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1446 - value_loss: 0.6004 - policy_loss: 1.6575 - val_loss: 6.1171 - val_value_loss: 0.5839 - val_policy_loss: 1.6189\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1398 - value_loss: 0.5914 - policy_loss: 1.6569 - val_loss: 6.1165 - val_value_loss: 0.5829 - val_policy_loss: 1.6187\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1367 - value_loss: 0.5851 - policy_loss: 1.6569 - val_loss: 6.1158 - val_value_loss: 0.5818 - val_policy_loss: 1.6185\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1345 - value_loss: 0.5812 - policy_loss: 1.6564 - val_loss: 6.1149 - val_value_loss: 0.5801 - val_policy_loss: 1.6184\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1310 - value_loss: 0.5748 - policy_loss: 1.6559 - val_loss: 6.1141 - val_value_loss: 0.5788 - val_policy_loss: 1.6182\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1299 - value_loss: 0.5730 - policy_loss: 1.6555 - val_loss: 6.1133 - val_value_loss: 0.5774 - val_policy_loss: 1.6181\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1278 - value_loss: 0.5688 - policy_loss: 1.6556 - val_loss: 6.1125 - val_value_loss: 0.5759 - val_policy_loss: 1.6180\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1259 - value_loss: 0.5654 - policy_loss: 1.6553 - val_loss: 6.1120 - val_value_loss: 0.5750 - val_policy_loss: 1.6178\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1239 - value_loss: 0.5616 - policy_loss: 1.6551 - val_loss: 6.1113 - val_value_loss: 0.5738 - val_policy_loss: 1.6177\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1225 - value_loss: 0.5591 - policy_loss: 1.6549 - val_loss: 6.1108 - val_value_loss: 0.5729 - val_policy_loss: 1.6176\n",
      "Saved model  tictactoe_num_sim_10_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.04\n",
      "Number of seen trajectories: 2200\n",
      "Number of unique trajectories: 1929\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1116 - value_loss: 0.5384 - policy_loss: 1.6537 - val_loss: 6.1073 - val_value_loss: 0.5252 - val_policy_loss: 1.6584\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1089 - value_loss: 0.5336 - policy_loss: 1.6531 - val_loss: 6.1060 - val_value_loss: 0.5229 - val_policy_loss: 1.6582\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1063 - value_loss: 0.5285 - policy_loss: 1.6532 - val_loss: 6.1049 - val_value_loss: 0.5209 - val_policy_loss: 1.6580\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1047 - value_loss: 0.5256 - policy_loss: 1.6530 - val_loss: 6.1040 - val_value_loss: 0.5193 - val_policy_loss: 1.6579\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1020 - value_loss: 0.5205 - policy_loss: 1.6528 - val_loss: 6.1032 - val_value_loss: 0.5179 - val_policy_loss: 1.6577\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1003 - value_loss: 0.5178 - policy_loss: 1.6521 - val_loss: 6.1023 - val_value_loss: 0.5163 - val_policy_loss: 1.6576\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0988 - value_loss: 0.5149 - policy_loss: 1.6518 - val_loss: 6.1015 - val_value_loss: 0.5149 - val_policy_loss: 1.6575\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0964 - value_loss: 0.5104 - policy_loss: 1.6518 - val_loss: 6.1011 - val_value_loss: 0.5141 - val_policy_loss: 1.6573\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0957 - value_loss: 0.5088 - policy_loss: 1.6518 - val_loss: 6.1004 - val_value_loss: 0.5130 - val_policy_loss: 1.6572\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0942 - value_loss: 0.5062 - policy_loss: 1.6515 - val_loss: 6.1000 - val_value_loss: 0.5123 - val_policy_loss: 1.6571\n",
      "Saved model  tictactoe_num_sim_10_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.01\n",
      "Number of seen trajectories: 2300\n",
      "Number of unique trajectories: 2004\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1613 - value_loss: 0.6647 - policy_loss: 1.6273 - val_loss: 6.1578 - val_value_loss: 0.6423 - val_policy_loss: 1.6427\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1555 - value_loss: 0.6535 - policy_loss: 1.6270 - val_loss: 6.1553 - val_value_loss: 0.6374 - val_policy_loss: 1.6426\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1510 - value_loss: 0.6450 - policy_loss: 1.6264 - val_loss: 6.1531 - val_value_loss: 0.6331 - val_policy_loss: 1.6425\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1467 - value_loss: 0.6367 - policy_loss: 1.6262 - val_loss: 6.1510 - val_value_loss: 0.6291 - val_policy_loss: 1.6425\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1432 - value_loss: 0.6298 - policy_loss: 1.6262 - val_loss: 6.1495 - val_value_loss: 0.6262 - val_policy_loss: 1.6424\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1404 - value_loss: 0.6241 - policy_loss: 1.6263 - val_loss: 6.1481 - val_value_loss: 0.6234 - val_policy_loss: 1.6423\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1377 - value_loss: 0.6192 - policy_loss: 1.6257 - val_loss: 6.1469 - val_value_loss: 0.6213 - val_policy_loss: 1.6422\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1339 - value_loss: 0.6117 - policy_loss: 1.6258 - val_loss: 6.1457 - val_value_loss: 0.6189 - val_policy_loss: 1.6422\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1306 - value_loss: 0.6060 - policy_loss: 1.6250 - val_loss: 6.1446 - val_value_loss: 0.6168 - val_policy_loss: 1.6422\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1286 - value_loss: 0.6020 - policy_loss: 1.6250 - val_loss: 6.1437 - val_value_loss: 0.6150 - val_policy_loss: 1.6421\n",
      "Saved model  tictactoe_num_sim_10_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.02\n",
      "Number of seen trajectories: 2400\n",
      "Number of unique trajectories: 2080\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1521 - value_loss: 0.6490 - policy_loss: 1.6250 - val_loss: 6.1577 - val_value_loss: 0.6625 - val_policy_loss: 1.6226\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1485 - value_loss: 0.6427 - policy_loss: 1.6241 - val_loss: 6.1553 - val_value_loss: 0.6580 - val_policy_loss: 1.6226\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1443 - value_loss: 0.6347 - policy_loss: 1.6237 - val_loss: 6.1536 - val_value_loss: 0.6546 - val_policy_loss: 1.6225\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1421 - value_loss: 0.6303 - policy_loss: 1.6238 - val_loss: 6.1519 - val_value_loss: 0.6513 - val_policy_loss: 1.6225\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1385 - value_loss: 0.6241 - policy_loss: 1.6228 - val_loss: 6.1503 - val_value_loss: 0.6482 - val_policy_loss: 1.6224\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1363 - value_loss: 0.6200 - policy_loss: 1.6225 - val_loss: 6.1491 - val_value_loss: 0.6457 - val_policy_loss: 1.6224\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1332 - value_loss: 0.6137 - policy_loss: 1.6228 - val_loss: 6.1479 - val_value_loss: 0.6434 - val_policy_loss: 1.6224\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1310 - value_loss: 0.6096 - policy_loss: 1.6225 - val_loss: 6.1466 - val_value_loss: 0.6409 - val_policy_loss: 1.6224\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1296 - value_loss: 0.6064 - policy_loss: 1.6229 - val_loss: 6.1457 - val_value_loss: 0.6392 - val_policy_loss: 1.6223\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1264 - value_loss: 0.6011 - policy_loss: 1.6219 - val_loss: 6.1448 - val_value_loss: 0.6375 - val_policy_loss: 1.6223\n",
      "Saved model  tictactoe_num_sim_10_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.9 - draw ratio 0.0\n",
      "Number of seen trajectories: 2500\n",
      "Number of unique trajectories: 2145\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1421 - value_loss: 0.6289 - policy_loss: 1.6255 - val_loss: 6.1623 - val_value_loss: 0.6557 - val_policy_loss: 1.6391\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1395 - value_loss: 0.6241 - policy_loss: 1.6250 - val_loss: 6.1614 - val_value_loss: 0.6541 - val_policy_loss: 1.6390\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1379 - value_loss: 0.6210 - policy_loss: 1.6251 - val_loss: 6.1606 - val_value_loss: 0.6527 - val_policy_loss: 1.6388\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1363 - value_loss: 0.6180 - policy_loss: 1.6248 - val_loss: 6.1599 - val_value_loss: 0.6514 - val_policy_loss: 1.6387\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1345 - value_loss: 0.6146 - policy_loss: 1.6247 - val_loss: 6.1593 - val_value_loss: 0.6503 - val_policy_loss: 1.6386\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1327 - value_loss: 0.6110 - policy_loss: 1.6247 - val_loss: 6.1587 - val_value_loss: 0.6492 - val_policy_loss: 1.6385\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1315 - value_loss: 0.6088 - policy_loss: 1.6245 - val_loss: 6.1581 - val_value_loss: 0.6480 - val_policy_loss: 1.6384\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1304 - value_loss: 0.6068 - policy_loss: 1.6243 - val_loss: 6.1575 - val_value_loss: 0.6469 - val_policy_loss: 1.6384\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1288 - value_loss: 0.6039 - policy_loss: 1.6240 - val_loss: 6.1570 - val_value_loss: 0.6460 - val_policy_loss: 1.6383\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1271 - value_loss: 0.6006 - policy_loss: 1.6241 - val_loss: 6.1565 - val_value_loss: 0.6452 - val_policy_loss: 1.6382\n",
      "Saved model  tictactoe_num_sim_10_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.0\n",
      "Number of seen trajectories: 2600\n",
      "Number of unique trajectories: 2216\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1405 - value_loss: 0.6249 - policy_loss: 1.6265 - val_loss: 6.1427 - val_value_loss: 0.6353 - val_policy_loss: 1.6205\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1380 - value_loss: 0.6207 - policy_loss: 1.6257 - val_loss: 6.1413 - val_value_loss: 0.6325 - val_policy_loss: 1.6205\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1361 - value_loss: 0.6170 - policy_loss: 1.6256 - val_loss: 6.1402 - val_value_loss: 0.6304 - val_policy_loss: 1.6205\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1338 - value_loss: 0.6128 - policy_loss: 1.6253 - val_loss: 6.1394 - val_value_loss: 0.6289 - val_policy_loss: 1.6204\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1323 - value_loss: 0.6096 - policy_loss: 1.6254 - val_loss: 6.1388 - val_value_loss: 0.6277 - val_policy_loss: 1.6204\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1300 - value_loss: 0.6046 - policy_loss: 1.6259 - val_loss: 6.1383 - val_value_loss: 0.6267 - val_policy_loss: 1.6204\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1298 - value_loss: 0.6046 - policy_loss: 1.6254 - val_loss: 6.1379 - val_value_loss: 0.6258 - val_policy_loss: 1.6204\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1287 - value_loss: 0.6026 - policy_loss: 1.6254 - val_loss: 6.1375 - val_value_loss: 0.6252 - val_policy_loss: 1.6204\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1268 - value_loss: 0.5990 - policy_loss: 1.6252 - val_loss: 6.1372 - val_value_loss: 0.6245 - val_policy_loss: 1.6203\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1256 - value_loss: 0.5972 - policy_loss: 1.6246 - val_loss: 6.1369 - val_value_loss: 0.6240 - val_policy_loss: 1.6203\n",
      "Saved model  tictactoe_num_sim_10_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.0\n",
      "Number of seen trajectories: 2700\n",
      "Number of unique trajectories: 2284\n",
      "iteration 27 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1357 - value_loss: 0.6073 - policy_loss: 1.6347 - val_loss: 6.1289 - val_value_loss: 0.6058 - val_policy_loss: 1.6226\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1332 - value_loss: 0.6025 - policy_loss: 1.6345 - val_loss: 6.1277 - val_value_loss: 0.6034 - val_policy_loss: 1.6225\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1309 - value_loss: 0.5979 - policy_loss: 1.6344 - val_loss: 6.1265 - val_value_loss: 0.6011 - val_policy_loss: 1.6224\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1285 - value_loss: 0.5937 - policy_loss: 1.6340 - val_loss: 6.1255 - val_value_loss: 0.5992 - val_policy_loss: 1.6223\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1278 - value_loss: 0.5917 - policy_loss: 1.6344 - val_loss: 6.1246 - val_value_loss: 0.5975 - val_policy_loss: 1.6223\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1258 - value_loss: 0.5884 - policy_loss: 1.6338 - val_loss: 6.1237 - val_value_loss: 0.5959 - val_policy_loss: 1.6222\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1243 - value_loss: 0.5858 - policy_loss: 1.6334 - val_loss: 6.1229 - val_value_loss: 0.5944 - val_policy_loss: 1.6221\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1229 - value_loss: 0.5828 - policy_loss: 1.6337 - val_loss: 6.1223 - val_value_loss: 0.5932 - val_policy_loss: 1.6221\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1218 - value_loss: 0.5806 - policy_loss: 1.6338 - val_loss: 6.1217 - val_value_loss: 0.5920 - val_policy_loss: 1.6220\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1206 - value_loss: 0.5786 - policy_loss: 1.6333 - val_loss: 6.1211 - val_value_loss: 0.5909 - val_policy_loss: 1.6220\n",
      "Saved model  tictactoe_num_sim_10_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.0\n",
      "Number of seen trajectories: 2800\n",
      "Number of unique trajectories: 2349\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1660 - value_loss: 0.6796 - policy_loss: 1.6231 - val_loss: 6.1693 - val_value_loss: 0.6796 - val_policy_loss: 1.6297\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1638 - value_loss: 0.6756 - policy_loss: 1.6228 - val_loss: 6.1686 - val_value_loss: 0.6783 - val_policy_loss: 1.6296\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1625 - value_loss: 0.6725 - policy_loss: 1.6232 - val_loss: 6.1680 - val_value_loss: 0.6774 - val_policy_loss: 1.6295\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1605 - value_loss: 0.6693 - policy_loss: 1.6226 - val_loss: 6.1676 - val_value_loss: 0.6766 - val_policy_loss: 1.6295\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1582 - value_loss: 0.6650 - policy_loss: 1.6222 - val_loss: 6.1673 - val_value_loss: 0.6760 - val_policy_loss: 1.6294\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1564 - value_loss: 0.6615 - policy_loss: 1.6222 - val_loss: 6.1669 - val_value_loss: 0.6754 - val_policy_loss: 1.6294\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1560 - value_loss: 0.6600 - policy_loss: 1.6229 - val_loss: 6.1667 - val_value_loss: 0.6749 - val_policy_loss: 1.6294\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1545 - value_loss: 0.6579 - policy_loss: 1.6220 - val_loss: 6.1665 - val_value_loss: 0.6746 - val_policy_loss: 1.6293\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1530 - value_loss: 0.6550 - policy_loss: 1.6220 - val_loss: 6.1663 - val_value_loss: 0.6742 - val_policy_loss: 1.6293\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1522 - value_loss: 0.6534 - policy_loss: 1.6219 - val_loss: 6.1661 - val_value_loss: 0.6739 - val_policy_loss: 1.6292\n",
      "Saved model  tictactoe_num_sim_10_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.0\n",
      "Number of seen trajectories: 2900\n",
      "Number of unique trajectories: 2421\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_10_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1340 - value_loss: 0.6161 - policy_loss: 1.6228 - val_loss: 6.1362 - val_value_loss: 0.6144 - val_policy_loss: 1.6289\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1299 - value_loss: 0.6083 - policy_loss: 1.6224 - val_loss: 6.1339 - val_value_loss: 0.6100 - val_policy_loss: 1.6288\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1260 - value_loss: 0.6003 - policy_loss: 1.6227 - val_loss: 6.1327 - val_value_loss: 0.6077 - val_policy_loss: 1.6287\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1246 - value_loss: 0.5982 - policy_loss: 1.6221 - val_loss: 6.1319 - val_value_loss: 0.6061 - val_policy_loss: 1.6286\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1237 - value_loss: 0.5963 - policy_loss: 1.6222 - val_loss: 6.1311 - val_value_loss: 0.6048 - val_policy_loss: 1.6285\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1219 - value_loss: 0.5928 - policy_loss: 1.6220 - val_loss: 6.1306 - val_value_loss: 0.6038 - val_policy_loss: 1.6284\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1198 - value_loss: 0.5890 - policy_loss: 1.6217 - val_loss: 6.1301 - val_value_loss: 0.6029 - val_policy_loss: 1.6284\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1188 - value_loss: 0.5874 - policy_loss: 1.6214 - val_loss: 6.1296 - val_value_loss: 0.6021 - val_policy_loss: 1.6283\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1166 - value_loss: 0.5832 - policy_loss: 1.6212 - val_loss: 6.1292 - val_value_loss: 0.6013 - val_policy_loss: 1.6282\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1159 - value_loss: 0.5821 - policy_loss: 1.6208 - val_loss: 6.1288 - val_value_loss: 0.6006 - val_policy_loss: 1.6282\n",
      "Saved model  tictactoe_num_sim_10_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.0\n",
      "Number of seen trajectories: 3000\n",
      "Number of unique trajectories: 2487\n"
     ]
    }
   ],
   "source": [
    "wins_3, draws_3, seen_trajectories_3, unique_trajectories_3 = test_pipeline.run(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - 10 simulations\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "losses_3 = np.ones(30) - wins_3 - draws_3\n",
    "\n",
    "plt.plot(x, wins_3, label=\"win ratio\")\n",
    "plt.plot(x, draws_3, label=\"draw ratio\")\n",
    "plt.plot(x, losses_3, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "exploration_rate_3 = unique_trajectories_3/seen_trajectories_3\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - 10 simulations\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "plt.plot(x, exploration_rate_3, label=\"unique/seen\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins_3 = [0.76, 0.78, 0.75, 0.76, 0.81, 0.88, 0.71, 0.75, 0.72, 0.85, 0.85, 0.89, 0.87, 0.87, 0.86, 0.86, 0.81, 0.85, 0.83, 0.87, 0.8, 0.83, 0.83, 0.88, 0.9, 0.87, 0.87, 0.86, 0.85, 0.86]\n",
      "draws_3 = [0.02, 0.06, 0.03, 0.03, 0.01, 0.01, 0.03, 0.02, 0.02, 0.03, 0.0, 0.01, 0.0, 0.0, 0.02, 0.0, 0.01, 0.0, 0.02, 0.02, 0.02, 0.04, 0.01, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "seen_trajectories_3 = [ 100.  200.  300.  400.  500.  600.  700.  800.  900. 1000. 1100. 1200.\n",
      " 1300. 1400. 1500. 1600. 1700. 1800. 1900. 2000. 2100. 2200. 2300. 2400.\n",
      " 2500. 2600. 2700. 2800. 2900. 3000.]\n",
      "unique_trajectories_3 = [  99.  198.  298.  396.  490.  585.  680.  778.  866.  956. 1051. 1138.\n",
      " 1216. 1292. 1377. 1455. 1539. 1628. 1705. 1779. 1860. 1929. 2004. 2080.\n",
      " 2145. 2216. 2284. 2349. 2421. 2487.]\n"
     ]
    }
   ],
   "source": [
    "print(\"wins_3 =\",wins_3)\n",
    "print(\"draws_3 =\",draws_3)\n",
    "print(\"seen_trajectories_3 =\", seen_trajectories_3)\n",
    "print(\"unique_trajectories_3 =\", unique_trajectories_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25 simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCTS = {\n",
    "    'c_puct': 5,\n",
    "    'dir_alpha': 0.6,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 10,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 10\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 0,\n",
    "    'show_games': False\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.002,\n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 512,\n",
    "    'num_filters_value': 512,\n",
    "    'num_filters_tower': 512,\n",
    "    'num_residual_blocks': 3,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 512\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"tictactoe_num_sim_25\", \"TicTacToe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 4s 1ms/step - loss: 6.6347 - value_loss: 0.8606 - policy_loss: 2.3201 - val_loss: 6.5286 - val_value_loss: 0.7688 - val_policy_loss: 2.2000\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.4638 - value_loss: 0.6961 - policy_loss: 2.1434 - val_loss: 6.4476 - val_value_loss: 0.7088 - val_policy_loss: 2.0986\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.3751 - value_loss: 0.6120 - policy_loss: 2.0508 - val_loss: 6.3995 - val_value_loss: 0.6838 - val_policy_loss: 2.0281\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.3297 - value_loss: 0.5858 - policy_loss: 1.9869 - val_loss: 6.3737 - val_value_loss: 0.6806 - val_policy_loss: 1.9804\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.3012 - value_loss: 0.5756 - policy_loss: 1.9407 - val_loss: 6.3486 - val_value_loss: 0.6683 - val_policy_loss: 1.9431\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.2500 - value_loss: 0.5101 - policy_loss: 1.9043 - val_loss: 6.3823 - val_value_loss: 0.7654 - val_policy_loss: 1.9142\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.2450 - value_loss: 0.5282 - policy_loss: 1.8769 - val_loss: 6.3024 - val_value_loss: 0.6288 - val_policy_loss: 1.8916\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2095 - value_loss: 0.4802 - policy_loss: 1.8546 - val_loss: 6.2886 - val_value_loss: 0.6214 - val_policy_loss: 1.8719\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.1905 - value_loss: 0.4618 - policy_loss: 1.8357 - val_loss: 6.2751 - val_value_loss: 0.6112 - val_policy_loss: 1.8557\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1837 - value_loss: 0.4630 - policy_loss: 1.8213 - val_loss: 6.2728 - val_value_loss: 0.6219 - val_policy_loss: 1.8411\n",
      "Saved model  tictactoe_num_sim_25_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.68 - draw ratio 0.07\n",
      "Number of seen trajectories: 100\n",
      "Number of unique trajectories: 100\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.3472 - value_loss: 0.7580 - policy_loss: 1.8540 - val_loss: 6.3221 - val_value_loss: 0.7194 - val_policy_loss: 1.8428\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.3029 - value_loss: 0.6908 - policy_loss: 1.8334 - val_loss: 6.3935 - val_value_loss: 0.8765 - val_policy_loss: 1.8292\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.2873 - value_loss: 0.6741 - policy_loss: 1.8194 - val_loss: 6.3188 - val_value_loss: 0.7383 - val_policy_loss: 1.8186\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.2709 - value_loss: 0.6560 - policy_loss: 1.8053 - val_loss: 6.3447 - val_value_loss: 0.8021 - val_policy_loss: 1.8073\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2571 - value_loss: 0.6399 - policy_loss: 1.7946 - val_loss: 6.2747 - val_value_loss: 0.6704 - val_policy_loss: 1.7995\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2219 - value_loss: 0.5801 - policy_loss: 1.7846 - val_loss: 6.3138 - val_value_loss: 0.7565 - val_policy_loss: 1.7923\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2156 - value_loss: 0.5758 - policy_loss: 1.7769 - val_loss: 6.2648 - val_value_loss: 0.6674 - val_policy_loss: 1.7841\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1984 - value_loss: 0.5502 - policy_loss: 1.7687 - val_loss: 6.2574 - val_value_loss: 0.6591 - val_policy_loss: 1.7782\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1816 - value_loss: 0.5235 - policy_loss: 1.7625 - val_loss: 6.2518 - val_value_loss: 0.6537 - val_policy_loss: 1.7730\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1811 - value_loss: 0.5283 - policy_loss: 1.7573 - val_loss: 6.2559 - val_value_loss: 0.6674 - val_policy_loss: 1.7682\n",
      "Saved model  tictactoe_num_sim_25_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.61 - draw ratio 0.05\n",
      "Number of seen trajectories: 200\n",
      "Number of unique trajectories: 198\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.3186 - value_loss: 0.7812 - policy_loss: 1.7801 - val_loss: 6.2770 - val_value_loss: 0.7096 - val_policy_loss: 1.7689\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2760 - value_loss: 0.7078 - policy_loss: 1.7690 - val_loss: 6.2815 - val_value_loss: 0.7252 - val_policy_loss: 1.7629\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.2616 - value_loss: 0.6871 - policy_loss: 1.7614 - val_loss: 6.2532 - val_value_loss: 0.6755 - val_policy_loss: 1.7566\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2507 - value_loss: 0.6732 - policy_loss: 1.7543 - val_loss: 6.2464 - val_value_loss: 0.6676 - val_policy_loss: 1.7517\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2152 - value_loss: 0.6096 - policy_loss: 1.7475 - val_loss: 6.2384 - val_value_loss: 0.6563 - val_policy_loss: 1.7475\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.2088 - value_loss: 0.6032 - policy_loss: 1.7417 - val_loss: 6.2328 - val_value_loss: 0.6499 - val_policy_loss: 1.7434\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2026 - value_loss: 0.5958 - policy_loss: 1.7373 - val_loss: 6.2496 - val_value_loss: 0.6874 - val_policy_loss: 1.7402\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1834 - value_loss: 0.5626 - policy_loss: 1.7327 - val_loss: 6.2325 - val_value_loss: 0.6576 - val_policy_loss: 1.7363\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1768 - value_loss: 0.5540 - policy_loss: 1.7288 - val_loss: 6.2203 - val_value_loss: 0.6372 - val_policy_loss: 1.7330\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1731 - value_loss: 0.5506 - policy_loss: 1.7254 - val_loss: 6.2243 - val_value_loss: 0.6488 - val_policy_loss: 1.7300\n",
      "Saved model  tictactoe_num_sim_25_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.03\n",
      "Number of seen trajectories: 300\n",
      "Number of unique trajectories: 297\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2870 - value_loss: 0.7738 - policy_loss: 1.7308 - val_loss: 6.2694 - val_value_loss: 0.7502 - val_policy_loss: 1.7195\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.2564 - value_loss: 0.7200 - policy_loss: 1.7239 - val_loss: 6.2753 - val_value_loss: 0.7661 - val_policy_loss: 1.7161\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.2431 - value_loss: 0.7007 - policy_loss: 1.7172 - val_loss: 6.2898 - val_value_loss: 0.7980 - val_policy_loss: 1.7138\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.2160 - value_loss: 0.6515 - policy_loss: 1.7129 - val_loss: 6.2360 - val_value_loss: 0.6942 - val_policy_loss: 1.7106\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1929 - value_loss: 0.6099 - policy_loss: 1.7089 - val_loss: 6.2337 - val_value_loss: 0.6927 - val_policy_loss: 1.7081\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1804 - value_loss: 0.5894 - policy_loss: 1.7050 - val_loss: 6.2254 - val_value_loss: 0.6794 - val_policy_loss: 1.7055\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.1809 - value_loss: 0.5945 - policy_loss: 1.7016 - val_loss: 6.2342 - val_value_loss: 0.6998 - val_policy_loss: 1.7034\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1768 - value_loss: 0.5902 - policy_loss: 1.6983 - val_loss: 6.2492 - val_value_loss: 0.7322 - val_policy_loss: 1.7015\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1681 - value_loss: 0.5761 - policy_loss: 1.6958 - val_loss: 6.2172 - val_value_loss: 0.6706 - val_policy_loss: 1.6997\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1467 - value_loss: 0.5365 - policy_loss: 1.6932 - val_loss: 6.2115 - val_value_loss: 0.6623 - val_policy_loss: 1.6973\n",
      "Saved model  tictactoe_num_sim_25_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.01\n",
      "Number of seen trajectories: 400\n",
      "Number of unique trajectories: 394\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2593 - value_loss: 0.7273 - policy_loss: 1.7282 - val_loss: 6.2547 - val_value_loss: 0.7225 - val_policy_loss: 1.7242\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.2197 - value_loss: 0.6545 - policy_loss: 1.7225 - val_loss: 6.2862 - val_value_loss: 0.7875 - val_policy_loss: 1.7227\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.2021 - value_loss: 0.6239 - policy_loss: 1.7185 - val_loss: 6.2415 - val_value_loss: 0.7011 - val_policy_loss: 1.7205\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1784 - value_loss: 0.5811 - policy_loss: 1.7145 - val_loss: 6.2589 - val_value_loss: 0.7381 - val_policy_loss: 1.7190\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1728 - value_loss: 0.5731 - policy_loss: 1.7120 - val_loss: 6.2410 - val_value_loss: 0.7048 - val_policy_loss: 1.7170\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1588 - value_loss: 0.5489 - policy_loss: 1.7089 - val_loss: 6.2329 - val_value_loss: 0.6910 - val_policy_loss: 1.7152\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1448 - value_loss: 0.5238 - policy_loss: 1.7066 - val_loss: 6.2496 - val_value_loss: 0.7268 - val_policy_loss: 1.7134\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1496 - value_loss: 0.5359 - policy_loss: 1.7047 - val_loss: 6.2285 - val_value_loss: 0.6864 - val_policy_loss: 1.7124\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1444 - value_loss: 0.5288 - policy_loss: 1.7021 - val_loss: 6.2295 - val_value_loss: 0.6903 - val_policy_loss: 1.7111\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1316 - value_loss: 0.5047 - policy_loss: 1.7012 - val_loss: 6.2310 - val_value_loss: 0.6946 - val_policy_loss: 1.7103\n",
      "Saved model  tictactoe_num_sim_25_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.0\n",
      "Number of seen trajectories: 500\n",
      "Number of unique trajectories: 491\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.2527 - value_loss: 0.7365 - policy_loss: 1.7122 - val_loss: 6.2310 - val_value_loss: 0.7056 - val_policy_loss: 1.6997\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2253 - value_loss: 0.6847 - policy_loss: 1.7095 - val_loss: 6.2216 - val_value_loss: 0.6882 - val_policy_loss: 1.6986\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2055 - value_loss: 0.6466 - policy_loss: 1.7082 - val_loss: 6.2175 - val_value_loss: 0.6811 - val_policy_loss: 1.6978\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1936 - value_loss: 0.6255 - policy_loss: 1.7057 - val_loss: 6.2131 - val_value_loss: 0.6739 - val_policy_loss: 1.6966\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1814 - value_loss: 0.6024 - policy_loss: 1.7048 - val_loss: 6.2154 - val_value_loss: 0.6794 - val_policy_loss: 1.6960\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1720 - value_loss: 0.5862 - policy_loss: 1.7026 - val_loss: 6.2115 - val_value_loss: 0.6727 - val_policy_loss: 1.6951\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1652 - value_loss: 0.5739 - policy_loss: 1.7016 - val_loss: 6.2088 - val_value_loss: 0.6684 - val_policy_loss: 1.6944\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1601 - value_loss: 0.5651 - policy_loss: 1.7004 - val_loss: 6.2102 - val_value_loss: 0.6725 - val_policy_loss: 1.6934\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1547 - value_loss: 0.5559 - policy_loss: 1.6993 - val_loss: 6.2108 - val_value_loss: 0.6745 - val_policy_loss: 1.6929\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1470 - value_loss: 0.5423 - policy_loss: 1.6978 - val_loss: 6.2136 - val_value_loss: 0.6813 - val_policy_loss: 1.6921\n",
      "Saved model  tictactoe_num_sim_25_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.81 - draw ratio 0.01\n",
      "Number of seen trajectories: 600\n",
      "Number of unique trajectories: 585\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2404 - value_loss: 0.7168 - policy_loss: 1.7104 - val_loss: 6.2414 - val_value_loss: 0.7117 - val_policy_loss: 1.7176\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2155 - value_loss: 0.6695 - policy_loss: 1.7082 - val_loss: 6.2343 - val_value_loss: 0.6990 - val_policy_loss: 1.7165\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1994 - value_loss: 0.6401 - policy_loss: 1.7056 - val_loss: 6.2318 - val_value_loss: 0.6950 - val_policy_loss: 1.7156\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1877 - value_loss: 0.6182 - policy_loss: 1.7046 - val_loss: 6.2279 - val_value_loss: 0.6885 - val_policy_loss: 1.7148\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1786 - value_loss: 0.6017 - policy_loss: 1.7032 - val_loss: 6.2293 - val_value_loss: 0.6924 - val_policy_loss: 1.7140\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1713 - value_loss: 0.5881 - policy_loss: 1.7024 - val_loss: 6.2263 - val_value_loss: 0.6874 - val_policy_loss: 1.7134\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1634 - value_loss: 0.5743 - policy_loss: 1.7007 - val_loss: 6.2246 - val_value_loss: 0.6849 - val_policy_loss: 1.7128\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1564 - value_loss: 0.5619 - policy_loss: 1.6995 - val_loss: 6.2227 - val_value_loss: 0.6820 - val_policy_loss: 1.7122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1548 - value_loss: 0.5599 - policy_loss: 1.6987 - val_loss: 6.2250 - val_value_loss: 0.6875 - val_policy_loss: 1.7116\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1482 - value_loss: 0.5480 - policy_loss: 1.6976 - val_loss: 6.2243 - val_value_loss: 0.6869 - val_policy_loss: 1.7111\n",
      "Saved model  tictactoe_num_sim_25_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.01\n",
      "Number of seen trajectories: 700\n",
      "Number of unique trajectories: 682\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1961 - value_loss: 0.6383 - policy_loss: 1.7034 - val_loss: 6.1893 - val_value_loss: 0.6086 - val_policy_loss: 1.7199\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1686 - value_loss: 0.5861 - policy_loss: 1.7009 - val_loss: 6.1874 - val_value_loss: 0.6056 - val_policy_loss: 1.7192\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1527 - value_loss: 0.5568 - policy_loss: 1.6988 - val_loss: 6.1846 - val_value_loss: 0.6010 - val_policy_loss: 1.7186\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1417 - value_loss: 0.5362 - policy_loss: 1.6977 - val_loss: 6.1887 - val_value_loss: 0.6102 - val_policy_loss: 1.7180\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1327 - value_loss: 0.5200 - policy_loss: 1.6962 - val_loss: 6.1840 - val_value_loss: 0.6015 - val_policy_loss: 1.7176\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1248 - value_loss: 0.5055 - policy_loss: 1.6953 - val_loss: 6.1818 - val_value_loss: 0.5979 - val_policy_loss: 1.7170\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1201 - value_loss: 0.4973 - policy_loss: 1.6943 - val_loss: 6.1835 - val_value_loss: 0.6021 - val_policy_loss: 1.7165\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1141 - value_loss: 0.4876 - policy_loss: 1.6924 - val_loss: 6.1810 - val_value_loss: 0.5977 - val_policy_loss: 1.7162\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1083 - value_loss: 0.4771 - policy_loss: 1.6917 - val_loss: 6.1816 - val_value_loss: 0.5998 - val_policy_loss: 1.7157\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1061 - value_loss: 0.4745 - policy_loss: 1.6902 - val_loss: 6.1803 - val_value_loss: 0.5977 - val_policy_loss: 1.7155\n",
      "Saved model  tictactoe_num_sim_25_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.01\n",
      "Number of seen trajectories: 800\n",
      "Number of unique trajectories: 777\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.2219 - value_loss: 0.7115 - policy_loss: 1.6851 - val_loss: 6.2450 - val_value_loss: 0.7186 - val_policy_loss: 1.7243\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1981 - value_loss: 0.6662 - policy_loss: 1.6831 - val_loss: 6.2367 - val_value_loss: 0.7031 - val_policy_loss: 1.7235\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1808 - value_loss: 0.6336 - policy_loss: 1.6814 - val_loss: 6.2321 - val_value_loss: 0.6946 - val_policy_loss: 1.7230\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1705 - value_loss: 0.6139 - policy_loss: 1.6809 - val_loss: 6.2279 - val_value_loss: 0.6872 - val_policy_loss: 1.7224\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1614 - value_loss: 0.5986 - policy_loss: 1.6782 - val_loss: 6.2244 - val_value_loss: 0.6814 - val_policy_loss: 1.7217\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1542 - value_loss: 0.5856 - policy_loss: 1.6772 - val_loss: 6.2258 - val_value_loss: 0.6848 - val_policy_loss: 1.7214\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1470 - value_loss: 0.5723 - policy_loss: 1.6765 - val_loss: 6.2210 - val_value_loss: 0.6760 - val_policy_loss: 1.7208\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1429 - value_loss: 0.5648 - policy_loss: 1.6759 - val_loss: 6.2188 - val_value_loss: 0.6725 - val_policy_loss: 1.7204\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1375 - value_loss: 0.5562 - policy_loss: 1.6741 - val_loss: 6.2157 - val_value_loss: 0.6670 - val_policy_loss: 1.7198\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1336 - value_loss: 0.5495 - policy_loss: 1.6735 - val_loss: 6.2169 - val_value_loss: 0.6703 - val_policy_loss: 1.7194\n",
      "Saved model  tictactoe_num_sim_25_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.72 - draw ratio 0.02\n",
      "Number of seen trajectories: 900\n",
      "Number of unique trajectories: 873\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.2528 - value_loss: 0.7588 - policy_loss: 1.7028 - val_loss: 6.2095 - val_value_loss: 0.7033 - val_policy_loss: 1.6719\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2220 - value_loss: 0.6992 - policy_loss: 1.7010 - val_loss: 6.2064 - val_value_loss: 0.6983 - val_policy_loss: 1.6710\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2061 - value_loss: 0.6686 - policy_loss: 1.7002 - val_loss: 6.2074 - val_value_loss: 0.7012 - val_policy_loss: 1.6703\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1927 - value_loss: 0.6442 - policy_loss: 1.6982 - val_loss: 6.2023 - val_value_loss: 0.6920 - val_policy_loss: 1.6697\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1852 - value_loss: 0.6306 - policy_loss: 1.6971 - val_loss: 6.2082 - val_value_loss: 0.7048 - val_policy_loss: 1.6691\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1796 - value_loss: 0.6207 - policy_loss: 1.6961 - val_loss: 6.2002 - val_value_loss: 0.6895 - val_policy_loss: 1.6687\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1725 - value_loss: 0.6075 - policy_loss: 1.6955 - val_loss: 6.2024 - val_value_loss: 0.6948 - val_policy_loss: 1.6682\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1670 - value_loss: 0.5974 - policy_loss: 1.6948 - val_loss: 6.2072 - val_value_loss: 0.7048 - val_policy_loss: 1.6679\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1609 - value_loss: 0.5866 - policy_loss: 1.6937 - val_loss: 6.1984 - val_value_loss: 0.6880 - val_policy_loss: 1.6675\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1587 - value_loss: 0.5833 - policy_loss: 1.6930 - val_loss: 6.1986 - val_value_loss: 0.6892 - val_policy_loss: 1.6671\n",
      "Saved model  tictactoe_num_sim_25_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.03\n",
      "Number of seen trajectories: 1000\n",
      "Number of unique trajectories: 963\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.2186 - value_loss: 0.6925 - policy_loss: 1.7038 - val_loss: 6.1904 - val_value_loss: 0.6611 - val_policy_loss: 1.6789\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2020 - value_loss: 0.6604 - policy_loss: 1.7028 - val_loss: 6.1857 - val_value_loss: 0.6524 - val_policy_loss: 1.6783\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1917 - value_loss: 0.6408 - policy_loss: 1.7019 - val_loss: 6.1827 - val_value_loss: 0.6471 - val_policy_loss: 1.6778\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1835 - value_loss: 0.6254 - policy_loss: 1.7011 - val_loss: 6.1821 - val_value_loss: 0.6465 - val_policy_loss: 1.6773\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1768 - value_loss: 0.6125 - policy_loss: 1.7008 - val_loss: 6.1803 - val_value_loss: 0.6435 - val_policy_loss: 1.6769\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1703 - value_loss: 0.6006 - policy_loss: 1.6999 - val_loss: 6.1767 - val_value_loss: 0.6369 - val_policy_loss: 1.6765\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1655 - value_loss: 0.5919 - policy_loss: 1.6990 - val_loss: 6.1752 - val_value_loss: 0.6345 - val_policy_loss: 1.6761\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1617 - value_loss: 0.5842 - policy_loss: 1.6995 - val_loss: 6.1732 - val_value_loss: 0.6309 - val_policy_loss: 1.6758\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1569 - value_loss: 0.5760 - policy_loss: 1.6982 - val_loss: 6.1718 - val_value_loss: 0.6285 - val_policy_loss: 1.6755\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1536 - value_loss: 0.5699 - policy_loss: 1.6979 - val_loss: 6.1700 - val_value_loss: 0.6254 - val_policy_loss: 1.6753\n",
      "Saved model  tictactoe_num_sim_25_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.9 - draw ratio 0.01\n",
      "Number of seen trajectories: 1100\n",
      "Number of unique trajectories: 1053\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1870 - value_loss: 0.6483 - policy_loss: 1.6864 - val_loss: 6.1756 - val_value_loss: 0.6211 - val_policy_loss: 1.6908\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1716 - value_loss: 0.6183 - policy_loss: 1.6857 - val_loss: 6.1713 - val_value_loss: 0.6132 - val_policy_loss: 1.6904\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1598 - value_loss: 0.5959 - policy_loss: 1.6847 - val_loss: 6.1674 - val_value_loss: 0.6057 - val_policy_loss: 1.6902\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1502 - value_loss: 0.5772 - policy_loss: 1.6843 - val_loss: 6.1651 - val_value_loss: 0.6014 - val_policy_loss: 1.6899\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1408 - value_loss: 0.5592 - policy_loss: 1.6837 - val_loss: 6.1629 - val_value_loss: 0.5975 - val_policy_loss: 1.6896\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1333 - value_loss: 0.5445 - policy_loss: 1.6835 - val_loss: 6.1598 - val_value_loss: 0.5918 - val_policy_loss: 1.6894\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1278 - value_loss: 0.5345 - policy_loss: 1.6828 - val_loss: 6.1596 - val_value_loss: 0.5917 - val_policy_loss: 1.6893\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1221 - value_loss: 0.5238 - policy_loss: 1.6822 - val_loss: 6.1571 - val_value_loss: 0.5871 - val_policy_loss: 1.6890\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1178 - value_loss: 0.5161 - policy_loss: 1.6816 - val_loss: 6.1555 - val_value_loss: 0.5842 - val_policy_loss: 1.6888\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1155 - value_loss: 0.5109 - policy_loss: 1.6822 - val_loss: 6.1554 - val_value_loss: 0.5843 - val_policy_loss: 1.6887\n",
      "Saved model  tictactoe_num_sim_25_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.02\n",
      "Number of seen trajectories: 1200\n",
      "Number of unique trajectories: 1139\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.2200 - value_loss: 0.7138 - policy_loss: 1.6884 - val_loss: 6.2088 - val_value_loss: 0.6888 - val_policy_loss: 1.6912\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.2073 - value_loss: 0.6895 - policy_loss: 1.6875 - val_loss: 6.2064 - val_value_loss: 0.6846 - val_policy_loss: 1.6908\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1954 - value_loss: 0.6665 - policy_loss: 1.6869 - val_loss: 6.2027 - val_value_loss: 0.6776 - val_policy_loss: 1.6905\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1866 - value_loss: 0.6496 - policy_loss: 1.6864 - val_loss: 6.2010 - val_value_loss: 0.6745 - val_policy_loss: 1.6903\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1781 - value_loss: 0.6334 - policy_loss: 1.6857 - val_loss: 6.1987 - val_value_loss: 0.6702 - val_policy_loss: 1.6901\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1732 - value_loss: 0.6242 - policy_loss: 1.6853 - val_loss: 6.1974 - val_value_loss: 0.6679 - val_policy_loss: 1.6900\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1663 - value_loss: 0.6111 - policy_loss: 1.6848 - val_loss: 6.1967 - val_value_loss: 0.6669 - val_policy_loss: 1.6899\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1607 - value_loss: 0.6006 - policy_loss: 1.6842 - val_loss: 6.1975 - val_value_loss: 0.6687 - val_policy_loss: 1.6897\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1572 - value_loss: 0.5937 - policy_loss: 1.6843 - val_loss: 6.1949 - val_value_loss: 0.6640 - val_policy_loss: 1.6896\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1518 - value_loss: 0.5841 - policy_loss: 1.6833 - val_loss: 6.1954 - val_value_loss: 0.6652 - val_policy_loss: 1.6895\n",
      "Saved model  tictactoe_num_sim_25_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.89 - draw ratio 0.0\n",
      "Number of seen trajectories: 1300\n",
      "Number of unique trajectories: 1231\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1946 - value_loss: 0.6590 - policy_loss: 1.6941 - val_loss: 6.1943 - val_value_loss: 0.6633 - val_policy_loss: 1.6893\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1793 - value_loss: 0.6299 - policy_loss: 1.6928 - val_loss: 6.1892 - val_value_loss: 0.6537 - val_policy_loss: 1.6889\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1700 - value_loss: 0.6122 - policy_loss: 1.6920 - val_loss: 6.1856 - val_value_loss: 0.6469 - val_policy_loss: 1.6886\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1615 - value_loss: 0.5961 - policy_loss: 1.6913 - val_loss: 6.1815 - val_value_loss: 0.6390 - val_policy_loss: 1.6884\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1552 - value_loss: 0.5841 - policy_loss: 1.6907 - val_loss: 6.1789 - val_value_loss: 0.6343 - val_policy_loss: 1.6881\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1478 - value_loss: 0.5705 - policy_loss: 1.6898 - val_loss: 6.1771 - val_value_loss: 0.6312 - val_policy_loss: 1.6878\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.1430 - value_loss: 0.5614 - policy_loss: 1.6894 - val_loss: 6.1753 - val_value_loss: 0.6280 - val_policy_loss: 1.6876\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1390 - value_loss: 0.5540 - policy_loss: 1.6891 - val_loss: 6.1739 - val_value_loss: 0.6255 - val_policy_loss: 1.6874\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1347 - value_loss: 0.5464 - policy_loss: 1.6882 - val_loss: 6.1730 - val_value_loss: 0.6240 - val_policy_loss: 1.6873\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1316 - value_loss: 0.5405 - policy_loss: 1.6879 - val_loss: 6.1715 - val_value_loss: 0.6215 - val_policy_loss: 1.6870\n",
      "Saved model  tictactoe_num_sim_25_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.81 - draw ratio 0.0\n",
      "Number of seen trajectories: 1400\n",
      "Number of unique trajectories: 1321\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 6.1726 - value_loss: 0.6530 - policy_loss: 1.6576 - val_loss: 6.1711 - val_value_loss: 0.6383 - val_policy_loss: 1.6695\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1588 - value_loss: 0.6265 - policy_loss: 1.6569 - val_loss: 6.1681 - val_value_loss: 0.6330 - val_policy_loss: 1.6690\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1484 - value_loss: 0.6070 - policy_loss: 1.6557 - val_loss: 6.1660 - val_value_loss: 0.6293 - val_policy_loss: 1.6687\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1402 - value_loss: 0.5909 - policy_loss: 1.6555 - val_loss: 6.1648 - val_value_loss: 0.6271 - val_policy_loss: 1.6685\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1336 - value_loss: 0.5787 - policy_loss: 1.6547 - val_loss: 6.1647 - val_value_loss: 0.6274 - val_policy_loss: 1.6683\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1284 - value_loss: 0.5686 - policy_loss: 1.6546 - val_loss: 6.1645 - val_value_loss: 0.6273 - val_policy_loss: 1.6681\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1226 - value_loss: 0.5577 - policy_loss: 1.6539 - val_loss: 6.1630 - val_value_loss: 0.6247 - val_policy_loss: 1.6679\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1183 - value_loss: 0.5496 - policy_loss: 1.6537 - val_loss: 6.1619 - val_value_loss: 0.6227 - val_policy_loss: 1.6678\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1127 - value_loss: 0.5393 - policy_loss: 1.6530 - val_loss: 6.1621 - val_value_loss: 0.6234 - val_policy_loss: 1.6677\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1089 - value_loss: 0.5322 - policy_loss: 1.6526 - val_loss: 6.1610 - val_value_loss: 0.6215 - val_policy_loss: 1.6675\n",
      "Saved model  tictactoe_num_sim_25_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.0\n",
      "Number of seen trajectories: 1500\n",
      "Number of unique trajectories: 1410\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2258 - value_loss: 0.7527 - policy_loss: 1.6661 - val_loss: 6.2266 - val_value_loss: 0.7357 - val_policy_loss: 1.6845\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2167 - value_loss: 0.7348 - policy_loss: 1.6658 - val_loss: 6.2236 - val_value_loss: 0.7301 - val_policy_loss: 1.6843\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2077 - value_loss: 0.7175 - policy_loss: 1.6652 - val_loss: 6.2220 - val_value_loss: 0.7269 - val_policy_loss: 1.6843\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.2014 - value_loss: 0.7050 - policy_loss: 1.6651 - val_loss: 6.2211 - val_value_loss: 0.7253 - val_policy_loss: 1.6842\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1941 - value_loss: 0.6916 - policy_loss: 1.6640 - val_loss: 6.2195 - val_value_loss: 0.7223 - val_policy_loss: 1.6842\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1900 - value_loss: 0.6833 - policy_loss: 1.6641 - val_loss: 6.2182 - val_value_loss: 0.7198 - val_policy_loss: 1.6841\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1860 - value_loss: 0.6758 - policy_loss: 1.6636 - val_loss: 6.2167 - val_value_loss: 0.7170 - val_policy_loss: 1.6841\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1819 - value_loss: 0.6683 - policy_loss: 1.6632 - val_loss: 6.2156 - val_value_loss: 0.7148 - val_policy_loss: 1.6840\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1771 - value_loss: 0.6590 - policy_loss: 1.6629 - val_loss: 6.2160 - val_value_loss: 0.7158 - val_policy_loss: 1.6839\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1738 - value_loss: 0.6524 - policy_loss: 1.6630 - val_loss: 6.2134 - val_value_loss: 0.7107 - val_policy_loss: 1.6839\n",
      "Saved model  tictactoe_num_sim_25_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.0\n",
      "Number of seen trajectories: 1600\n",
      "Number of unique trajectories: 1497\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2236 - value_loss: 0.7290 - policy_loss: 1.6861 - val_loss: 6.1875 - val_value_loss: 0.6769 - val_policy_loss: 1.6659\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.2144 - value_loss: 0.7116 - policy_loss: 1.6851 - val_loss: 6.1852 - val_value_loss: 0.6726 - val_policy_loss: 1.6657\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.2072 - value_loss: 0.6971 - policy_loss: 1.6852 - val_loss: 6.1824 - val_value_loss: 0.6674 - val_policy_loss: 1.6656\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2008 - value_loss: 0.6855 - policy_loss: 1.6843 - val_loss: 6.1804 - val_value_loss: 0.6636 - val_policy_loss: 1.6654\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1952 - value_loss: 0.6747 - policy_loss: 1.6839 - val_loss: 6.1791 - val_value_loss: 0.6613 - val_policy_loss: 1.6652\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1896 - value_loss: 0.6637 - policy_loss: 1.6837 - val_loss: 6.1784 - val_value_loss: 0.6600 - val_policy_loss: 1.6650\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1860 - value_loss: 0.6570 - policy_loss: 1.6834 - val_loss: 6.1770 - val_value_loss: 0.6574 - val_policy_loss: 1.6649\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.1809 - value_loss: 0.6472 - policy_loss: 1.6830 - val_loss: 6.1768 - val_value_loss: 0.6574 - val_policy_loss: 1.6648\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.1779 - value_loss: 0.6414 - policy_loss: 1.6828 - val_loss: 6.1768 - val_value_loss: 0.6574 - val_policy_loss: 1.6647\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1742 - value_loss: 0.6345 - policy_loss: 1.6824 - val_loss: 6.1754 - val_value_loss: 0.6550 - val_policy_loss: 1.6645\n",
      "Saved model  tictactoe_num_sim_25_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.03\n",
      "Number of seen trajectories: 1700\n",
      "Number of unique trajectories: 1577\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1606 - value_loss: 0.6300 - policy_loss: 1.6599 - val_loss: 6.1575 - val_value_loss: 0.6348 - val_policy_loss: 1.6490\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1536 - value_loss: 0.6168 - policy_loss: 1.6591 - val_loss: 6.1551 - val_value_loss: 0.6302 - val_policy_loss: 1.6489\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1487 - value_loss: 0.6071 - policy_loss: 1.6591 - val_loss: 6.1536 - val_value_loss: 0.6274 - val_policy_loss: 1.6487\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1428 - value_loss: 0.5961 - policy_loss: 1.6583 - val_loss: 6.1530 - val_value_loss: 0.6263 - val_policy_loss: 1.6486\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1399 - value_loss: 0.5905 - policy_loss: 1.6582 - val_loss: 6.1519 - val_value_loss: 0.6244 - val_policy_loss: 1.6485\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1362 - value_loss: 0.5837 - policy_loss: 1.6579 - val_loss: 6.1512 - val_value_loss: 0.6230 - val_policy_loss: 1.6484\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1334 - value_loss: 0.5779 - policy_loss: 1.6580 - val_loss: 6.1511 - val_value_loss: 0.6231 - val_policy_loss: 1.6483\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1294 - value_loss: 0.5706 - policy_loss: 1.6574 - val_loss: 6.1505 - val_value_loss: 0.6222 - val_policy_loss: 1.6482\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1269 - value_loss: 0.5663 - policy_loss: 1.6568 - val_loss: 6.1496 - val_value_loss: 0.6205 - val_policy_loss: 1.6481\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1243 - value_loss: 0.5614 - policy_loss: 1.6565 - val_loss: 6.1493 - val_value_loss: 0.6199 - val_policy_loss: 1.6480\n",
      "Saved model  tictactoe_num_sim_25_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.01\n",
      "Number of seen trajectories: 1800\n",
      "Number of unique trajectories: 1664\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1913 - value_loss: 0.6710 - policy_loss: 1.6810 - val_loss: 6.1999 - val_value_loss: 0.6963 - val_policy_loss: 1.6731\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1827 - value_loss: 0.6545 - policy_loss: 1.6805 - val_loss: 6.1977 - val_value_loss: 0.6921 - val_policy_loss: 1.6729\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.1761 - value_loss: 0.6409 - policy_loss: 1.6809 - val_loss: 6.1961 - val_value_loss: 0.6890 - val_policy_loss: 1.6729\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1698 - value_loss: 0.6292 - policy_loss: 1.6801 - val_loss: 6.1951 - val_value_loss: 0.6873 - val_policy_loss: 1.6727\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.1646 - value_loss: 0.6196 - policy_loss: 1.6793 - val_loss: 6.1939 - val_value_loss: 0.6850 - val_policy_loss: 1.6726\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1601 - value_loss: 0.6107 - policy_loss: 1.6794 - val_loss: 6.1928 - val_value_loss: 0.6830 - val_policy_loss: 1.6726\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1556 - value_loss: 0.6022 - policy_loss: 1.6790 - val_loss: 6.1917 - val_value_loss: 0.6808 - val_policy_loss: 1.6725\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1524 - value_loss: 0.5955 - policy_loss: 1.6792 - val_loss: 6.1913 - val_value_loss: 0.6802 - val_policy_loss: 1.6724\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1492 - value_loss: 0.5897 - policy_loss: 1.6788 - val_loss: 6.1900 - val_value_loss: 0.6779 - val_policy_loss: 1.6724\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1468 - value_loss: 0.5852 - policy_loss: 1.6786 - val_loss: 6.1905 - val_value_loss: 0.6789 - val_policy_loss: 1.6723\n",
      "Saved model  tictactoe_num_sim_25_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.0\n",
      "Number of seen trajectories: 1900\n",
      "Number of unique trajectories: 1754\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1546 - value_loss: 0.6067 - policy_loss: 1.6728 - val_loss: 6.1564 - val_value_loss: 0.5949 - val_policy_loss: 1.6882\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1434 - value_loss: 0.5846 - policy_loss: 1.6725 - val_loss: 6.1536 - val_value_loss: 0.5895 - val_policy_loss: 1.6880\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1383 - value_loss: 0.5748 - policy_loss: 1.6722 - val_loss: 6.1505 - val_value_loss: 0.5837 - val_policy_loss: 1.6878\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1334 - value_loss: 0.5653 - policy_loss: 1.6719 - val_loss: 6.1493 - val_value_loss: 0.5815 - val_policy_loss: 1.6877\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1293 - value_loss: 0.5576 - policy_loss: 1.6716 - val_loss: 6.1481 - val_value_loss: 0.5792 - val_policy_loss: 1.6876\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1257 - value_loss: 0.5505 - policy_loss: 1.6714 - val_loss: 6.1469 - val_value_loss: 0.5769 - val_policy_loss: 1.6875\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1227 - value_loss: 0.5449 - policy_loss: 1.6712 - val_loss: 6.1463 - val_value_loss: 0.5760 - val_policy_loss: 1.6874\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1204 - value_loss: 0.5404 - policy_loss: 1.6712 - val_loss: 6.1453 - val_value_loss: 0.5741 - val_policy_loss: 1.6873\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1172 - value_loss: 0.5346 - policy_loss: 1.6707 - val_loss: 6.1445 - val_value_loss: 0.5728 - val_policy_loss: 1.6872\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1143 - value_loss: 0.5294 - policy_loss: 1.6703 - val_loss: 6.1442 - val_value_loss: 0.5723 - val_policy_loss: 1.6872\n",
      "Saved model  tictactoe_num_sim_25_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.02\n",
      "Number of seen trajectories: 2000\n",
      "Number of unique trajectories: 1838\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1255 - value_loss: 0.5611 - policy_loss: 1.6610 - val_loss: 6.1272 - val_value_loss: 0.5792 - val_policy_loss: 1.6463\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1217 - value_loss: 0.5535 - policy_loss: 1.6610 - val_loss: 6.1260 - val_value_loss: 0.5769 - val_policy_loss: 1.6463\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1188 - value_loss: 0.5478 - policy_loss: 1.6609 - val_loss: 6.1248 - val_value_loss: 0.5745 - val_policy_loss: 1.6462\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.1152 - value_loss: 0.5410 - policy_loss: 1.6605 - val_loss: 6.1237 - val_value_loss: 0.5725 - val_policy_loss: 1.6462\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1134 - value_loss: 0.5371 - policy_loss: 1.6609 - val_loss: 6.1231 - val_value_loss: 0.5712 - val_policy_loss: 1.6461\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1101 - value_loss: 0.5310 - policy_loss: 1.6605 - val_loss: 6.1224 - val_value_loss: 0.5700 - val_policy_loss: 1.6461\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1076 - value_loss: 0.5264 - policy_loss: 1.6601 - val_loss: 6.1218 - val_value_loss: 0.5689 - val_policy_loss: 1.6461\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.1058 - value_loss: 0.5231 - policy_loss: 1.6599 - val_loss: 6.1212 - val_value_loss: 0.5676 - val_policy_loss: 1.6460\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.1051 - value_loss: 0.5212 - policy_loss: 1.6604 - val_loss: 6.1207 - val_value_loss: 0.5668 - val_policy_loss: 1.6460\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1027 - value_loss: 0.5170 - policy_loss: 1.6598 - val_loss: 6.1204 - val_value_loss: 0.5662 - val_policy_loss: 1.6460\n",
      "Saved model  tictactoe_num_sim_25_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.02\n",
      "Number of seen trajectories: 2100\n",
      "Number of unique trajectories: 1925\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1583 - value_loss: 0.6227 - policy_loss: 1.6653 - val_loss: 6.1690 - val_value_loss: 0.6254 - val_policy_loss: 1.6842\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1529 - value_loss: 0.6127 - policy_loss: 1.6647 - val_loss: 6.1672 - val_value_loss: 0.6219 - val_policy_loss: 1.6841\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1493 - value_loss: 0.6055 - policy_loss: 1.6647 - val_loss: 6.1662 - val_value_loss: 0.6199 - val_policy_loss: 1.6840\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1457 - value_loss: 0.5982 - policy_loss: 1.6647 - val_loss: 6.1651 - val_value_loss: 0.6178 - val_policy_loss: 1.6839\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1425 - value_loss: 0.5929 - policy_loss: 1.6637 - val_loss: 6.1642 - val_value_loss: 0.6161 - val_policy_loss: 1.6839\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1404 - value_loss: 0.5886 - policy_loss: 1.6639 - val_loss: 6.1635 - val_value_loss: 0.6148 - val_policy_loss: 1.6838\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1374 - value_loss: 0.5833 - policy_loss: 1.6633 - val_loss: 6.1629 - val_value_loss: 0.6138 - val_policy_loss: 1.6838\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1352 - value_loss: 0.5782 - policy_loss: 1.6639 - val_loss: 6.1623 - val_value_loss: 0.6127 - val_policy_loss: 1.6837\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1327 - value_loss: 0.5739 - policy_loss: 1.6632 - val_loss: 6.1619 - val_value_loss: 0.6118 - val_policy_loss: 1.6837\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1309 - value_loss: 0.5699 - policy_loss: 1.6637 - val_loss: 6.1615 - val_value_loss: 0.6111 - val_policy_loss: 1.6837\n",
      "Saved model  tictactoe_num_sim_25_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.0\n",
      "Number of seen trajectories: 2200\n",
      "Number of unique trajectories: 2004\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2091 - value_loss: 0.7129 - policy_loss: 1.6772 - val_loss: 6.2028 - val_value_loss: 0.6820 - val_policy_loss: 1.6955\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.2032 - value_loss: 0.7013 - policy_loss: 1.6770 - val_loss: 6.2022 - val_value_loss: 0.6808 - val_policy_loss: 1.6955\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1980 - value_loss: 0.6911 - policy_loss: 1.6769 - val_loss: 6.2011 - val_value_loss: 0.6788 - val_policy_loss: 1.6954\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1946 - value_loss: 0.6846 - policy_loss: 1.6765 - val_loss: 6.2004 - val_value_loss: 0.6775 - val_policy_loss: 1.6953\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1913 - value_loss: 0.6781 - policy_loss: 1.6765 - val_loss: 6.1997 - val_value_loss: 0.6761 - val_policy_loss: 1.6953\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1896 - value_loss: 0.6741 - policy_loss: 1.6770 - val_loss: 6.1990 - val_value_loss: 0.6749 - val_policy_loss: 1.6952\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1875 - value_loss: 0.6707 - policy_loss: 1.6765 - val_loss: 6.1983 - val_value_loss: 0.6736 - val_policy_loss: 1.6951\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1835 - value_loss: 0.6631 - policy_loss: 1.6760 - val_loss: 6.1977 - val_value_loss: 0.6724 - val_policy_loss: 1.6951\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1812 - value_loss: 0.6590 - policy_loss: 1.6756 - val_loss: 6.1972 - val_value_loss: 0.6716 - val_policy_loss: 1.6950\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1791 - value_loss: 0.6549 - policy_loss: 1.6755 - val_loss: 6.1967 - val_value_loss: 0.6707 - val_policy_loss: 1.6950\n",
      "Saved model  tictactoe_num_sim_25_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.03\n",
      "Number of seen trajectories: 2300\n",
      "Number of unique trajectories: 2089\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2042 - value_loss: 0.7025 - policy_loss: 1.6782 - val_loss: 6.1873 - val_value_loss: 0.6700 - val_policy_loss: 1.6768\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1998 - value_loss: 0.6933 - policy_loss: 1.6786 - val_loss: 6.1856 - val_value_loss: 0.6667 - val_policy_loss: 1.6767\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1967 - value_loss: 0.6876 - policy_loss: 1.6781 - val_loss: 6.1840 - val_value_loss: 0.6637 - val_policy_loss: 1.6767\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1907 - value_loss: 0.6767 - policy_loss: 1.6771 - val_loss: 6.1826 - val_value_loss: 0.6611 - val_policy_loss: 1.6766\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1883 - value_loss: 0.6717 - policy_loss: 1.6773 - val_loss: 6.1813 - val_value_loss: 0.6585 - val_policy_loss: 1.6765\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.1843 - value_loss: 0.6640 - policy_loss: 1.6770 - val_loss: 6.1803 - val_value_loss: 0.6565 - val_policy_loss: 1.6765\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1827 - value_loss: 0.6609 - policy_loss: 1.6770 - val_loss: 6.1792 - val_value_loss: 0.6545 - val_policy_loss: 1.6765\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.1800 - value_loss: 0.6557 - policy_loss: 1.6768 - val_loss: 6.1785 - val_value_loss: 0.6531 - val_policy_loss: 1.6764\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.1768 - value_loss: 0.6498 - policy_loss: 1.6765 - val_loss: 6.1776 - val_value_loss: 0.6515 - val_policy_loss: 1.6764\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1743 - value_loss: 0.6447 - policy_loss: 1.6765 - val_loss: 6.1769 - val_value_loss: 0.6501 - val_policy_loss: 1.6763\n",
      "Saved model  tictactoe_num_sim_25_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.0\n",
      "Number of seen trajectories: 2400\n",
      "Number of unique trajectories: 2164\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1755 - value_loss: 0.6528 - policy_loss: 1.6709 - val_loss: 6.1599 - val_value_loss: 0.6042 - val_policy_loss: 1.6882\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.1688 - value_loss: 0.6397 - policy_loss: 1.6707 - val_loss: 6.1564 - val_value_loss: 0.5973 - val_policy_loss: 1.6882\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.1640 - value_loss: 0.6305 - policy_loss: 1.6702 - val_loss: 6.1540 - val_value_loss: 0.5927 - val_policy_loss: 1.6881\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1597 - value_loss: 0.6220 - policy_loss: 1.6701 - val_loss: 6.1522 - val_value_loss: 0.5890 - val_policy_loss: 1.6881\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1579 - value_loss: 0.6187 - policy_loss: 1.6700 - val_loss: 6.1507 - val_value_loss: 0.5863 - val_policy_loss: 1.6881\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.1538 - value_loss: 0.6106 - policy_loss: 1.6699 - val_loss: 6.1498 - val_value_loss: 0.5845 - val_policy_loss: 1.6880\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1510 - value_loss: 0.6053 - policy_loss: 1.6697 - val_loss: 6.1490 - val_value_loss: 0.5829 - val_policy_loss: 1.6880\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1484 - value_loss: 0.6005 - policy_loss: 1.6693 - val_loss: 6.1482 - val_value_loss: 0.5814 - val_policy_loss: 1.6879\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1466 - value_loss: 0.5968 - policy_loss: 1.6694 - val_loss: 6.1476 - val_value_loss: 0.5804 - val_policy_loss: 1.6879\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1439 - value_loss: 0.5917 - policy_loss: 1.6692 - val_loss: 6.1470 - val_value_loss: 0.5791 - val_policy_loss: 1.6879\n",
      "Saved model  tictactoe_num_sim_25_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.01\n",
      "Number of seen trajectories: 2500\n",
      "Number of unique trajectories: 2239\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1471 - value_loss: 0.5873 - policy_loss: 1.6800 - val_loss: 6.1592 - val_value_loss: 0.5990 - val_policy_loss: 1.6925\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1441 - value_loss: 0.5817 - policy_loss: 1.6795 - val_loss: 6.1582 - val_value_loss: 0.5970 - val_policy_loss: 1.6924\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1419 - value_loss: 0.5774 - policy_loss: 1.6795 - val_loss: 6.1573 - val_value_loss: 0.5954 - val_policy_loss: 1.6923\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.1396 - value_loss: 0.5724 - policy_loss: 1.6799 - val_loss: 6.1566 - val_value_loss: 0.5941 - val_policy_loss: 1.6922\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1379 - value_loss: 0.5698 - policy_loss: 1.6792 - val_loss: 6.1561 - val_value_loss: 0.5931 - val_policy_loss: 1.6921\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1364 - value_loss: 0.5665 - policy_loss: 1.6794 - val_loss: 6.1556 - val_value_loss: 0.5923 - val_policy_loss: 1.6921\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1345 - value_loss: 0.5631 - policy_loss: 1.6791 - val_loss: 6.1552 - val_value_loss: 0.5917 - val_policy_loss: 1.6920\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1341 - value_loss: 0.5616 - policy_loss: 1.6797 - val_loss: 6.1550 - val_value_loss: 0.5912 - val_policy_loss: 1.6919\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1313 - value_loss: 0.5568 - policy_loss: 1.6790 - val_loss: 6.1547 - val_value_loss: 0.5907 - val_policy_loss: 1.6919\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1296 - value_loss: 0.5536 - policy_loss: 1.6788 - val_loss: 6.1543 - val_value_loss: 0.5900 - val_policy_loss: 1.6918\n",
      "Saved model  tictactoe_num_sim_25_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.01\n",
      "Number of seen trajectories: 2600\n",
      "Number of unique trajectories: 2309\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1694 - value_loss: 0.6333 - policy_loss: 1.6788 - val_loss: 6.1670 - val_value_loss: 0.6378 - val_policy_loss: 1.6693\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1659 - value_loss: 0.6262 - policy_loss: 1.6789 - val_loss: 6.1660 - val_value_loss: 0.6360 - val_policy_loss: 1.6692\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1635 - value_loss: 0.6218 - policy_loss: 1.6784 - val_loss: 6.1652 - val_value_loss: 0.6346 - val_policy_loss: 1.6692\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1617 - value_loss: 0.6178 - policy_loss: 1.6788 - val_loss: 6.1646 - val_value_loss: 0.6334 - val_policy_loss: 1.6691\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1606 - value_loss: 0.6161 - policy_loss: 1.6783 - val_loss: 6.1641 - val_value_loss: 0.6324 - val_policy_loss: 1.6690\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1588 - value_loss: 0.6119 - policy_loss: 1.6790 - val_loss: 6.1636 - val_value_loss: 0.6316 - val_policy_loss: 1.6689\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1572 - value_loss: 0.6092 - policy_loss: 1.6786 - val_loss: 6.1632 - val_value_loss: 0.6308 - val_policy_loss: 1.6689\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1556 - value_loss: 0.6064 - policy_loss: 1.6782 - val_loss: 6.1627 - val_value_loss: 0.6300 - val_policy_loss: 1.6688\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1540 - value_loss: 0.6034 - policy_loss: 1.6781 - val_loss: 6.1624 - val_value_loss: 0.6294 - val_policy_loss: 1.6688\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.1531 - value_loss: 0.6014 - policy_loss: 1.6782 - val_loss: 6.1620 - val_value_loss: 0.6288 - val_policy_loss: 1.6687\n",
      "Saved model  tictactoe_num_sim_25_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.03\n",
      "Number of seen trajectories: 2700\n",
      "Number of unique trajectories: 2385\n",
      "iteration 27 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1738 - value_loss: 0.6239 - policy_loss: 1.6972 - val_loss: 6.1578 - val_value_loss: 0.6230 - val_policy_loss: 1.6660\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1710 - value_loss: 0.6186 - policy_loss: 1.6969 - val_loss: 6.1564 - val_value_loss: 0.6204 - val_policy_loss: 1.6659\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.1683 - value_loss: 0.6130 - policy_loss: 1.6971 - val_loss: 6.1553 - val_value_loss: 0.6183 - val_policy_loss: 1.6658\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.1669 - value_loss: 0.6106 - policy_loss: 1.6967 - val_loss: 6.1543 - val_value_loss: 0.6163 - val_policy_loss: 1.6657\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.1654 - value_loss: 0.6074 - policy_loss: 1.6968 - val_loss: 6.1533 - val_value_loss: 0.6145 - val_policy_loss: 1.6657\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.1638 - value_loss: 0.6043 - policy_loss: 1.6969 - val_loss: 6.1524 - val_value_loss: 0.6127 - val_policy_loss: 1.6656\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1621 - value_loss: 0.6015 - policy_loss: 1.6964 - val_loss: 6.1516 - val_value_loss: 0.6112 - val_policy_loss: 1.6655\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1608 - value_loss: 0.5990 - policy_loss: 1.6962 - val_loss: 6.1508 - val_value_loss: 0.6097 - val_policy_loss: 1.6655\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1602 - value_loss: 0.5976 - policy_loss: 1.6965 - val_loss: 6.1501 - val_value_loss: 0.6083 - val_policy_loss: 1.6654\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1585 - value_loss: 0.5941 - policy_loss: 1.6965 - val_loss: 6.1494 - val_value_loss: 0.6070 - val_policy_loss: 1.6654\n",
      "Saved model  tictactoe_num_sim_25_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.77 - draw ratio 0.0\n",
      "Number of seen trajectories: 2800\n",
      "Number of unique trajectories: 2463\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1733 - value_loss: 0.6387 - policy_loss: 1.6814 - val_loss: 6.1487 - val_value_loss: 0.6036 - val_policy_loss: 1.6675\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1714 - value_loss: 0.6351 - policy_loss: 1.6814 - val_loss: 6.1481 - val_value_loss: 0.6024 - val_policy_loss: 1.6674\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1710 - value_loss: 0.6340 - policy_loss: 1.6817 - val_loss: 6.1475 - val_value_loss: 0.6014 - val_policy_loss: 1.6674\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1692 - value_loss: 0.6307 - policy_loss: 1.6815 - val_loss: 6.1470 - val_value_loss: 0.6003 - val_policy_loss: 1.6674\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1672 - value_loss: 0.6270 - policy_loss: 1.6812 - val_loss: 6.1464 - val_value_loss: 0.5992 - val_policy_loss: 1.6673\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1663 - value_loss: 0.6252 - policy_loss: 1.6812 - val_loss: 6.1459 - val_value_loss: 0.5982 - val_policy_loss: 1.6673\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1650 - value_loss: 0.6229 - policy_loss: 1.6809 - val_loss: 6.1454 - val_value_loss: 0.5972 - val_policy_loss: 1.6673\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1637 - value_loss: 0.6203 - policy_loss: 1.6810 - val_loss: 6.1448 - val_value_loss: 0.5962 - val_policy_loss: 1.6673\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1620 - value_loss: 0.6173 - policy_loss: 1.6805 - val_loss: 6.1443 - val_value_loss: 0.5952 - val_policy_loss: 1.6672\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1606 - value_loss: 0.6142 - policy_loss: 1.6809 - val_loss: 6.1439 - val_value_loss: 0.5944 - val_policy_loss: 1.6672\n",
      "Saved model  tictactoe_num_sim_25_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.02\n",
      "Number of seen trajectories: 2900\n",
      "Number of unique trajectories: 2541\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_25_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1917 - value_loss: 0.7008 - policy_loss: 1.6565 - val_loss: 6.2299 - val_value_loss: 0.7339 - val_policy_loss: 1.6998\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1895 - value_loss: 0.6963 - policy_loss: 1.6565 - val_loss: 6.2292 - val_value_loss: 0.7323 - val_policy_loss: 1.6999\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1870 - value_loss: 0.6913 - policy_loss: 1.6566 - val_loss: 6.2286 - val_value_loss: 0.7311 - val_policy_loss: 1.6999\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1856 - value_loss: 0.6887 - policy_loss: 1.6563 - val_loss: 6.2282 - val_value_loss: 0.7303 - val_policy_loss: 1.6999\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.1837 - value_loss: 0.6849 - policy_loss: 1.6563 - val_loss: 6.2276 - val_value_loss: 0.7292 - val_policy_loss: 1.7000\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.1819 - value_loss: 0.6817 - policy_loss: 1.6560 - val_loss: 6.2271 - val_value_loss: 0.7282 - val_policy_loss: 1.7000\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.1800 - value_loss: 0.6781 - policy_loss: 1.6558 - val_loss: 6.2268 - val_value_loss: 0.7275 - val_policy_loss: 1.7000\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 166us/step - loss: 6.1790 - value_loss: 0.6758 - policy_loss: 1.6562 - val_loss: 6.2265 - val_value_loss: 0.7269 - val_policy_loss: 1.7001\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 167us/step - loss: 6.1776 - value_loss: 0.6735 - policy_loss: 1.6558 - val_loss: 6.2262 - val_value_loss: 0.7263 - val_policy_loss: 1.7001\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.1746 - value_loss: 0.6678 - policy_loss: 1.6555 - val_loss: 6.2259 - val_value_loss: 0.7258 - val_policy_loss: 1.7001\n",
      "Saved model  tictactoe_num_sim_25_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.01\n",
      "Number of seen trajectories: 3000\n",
      "Number of unique trajectories: 2619\n"
     ]
    }
   ],
   "source": [
    "wins_4, draws_4, seen_trajectories_4, unique_trajectories_4 = test_pipeline.run(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - 25 simulations\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "losses_4 = np.ones(30) - wins_4 - draws_4\n",
    "\n",
    "plt.plot(x, wins_4, label=\"win ratio\")\n",
    "plt.plot(x, draws_4, label=\"draw ratio\")\n",
    "plt.plot(x, losses_4, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "exploration_rate_4 = unique_trajectories_4/seen_trajectories_4\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - 25 simulations\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "plt.plot(x, exploration_rate_4, label=\"unique/seen\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins_4 = [0.68, 0.61, 0.76, 0.79, 0.76, 0.81, 0.74, 0.87, 0.72, 0.8, 0.9, 0.76, 0.89, 0.81, 0.86, 0.86, 0.8, 0.88, 0.82, 0.83, 0.83, 0.87, 0.85, 0.88, 0.82, 0.8, 0.85, 0.77, 0.76, 0.83]\n",
      "draws_4 = [0.07, 0.05, 0.03, 0.01, 0.0, 0.01, 0.01, 0.01, 0.02, 0.03, 0.01, 0.02, 0.0, 0.0, 0.0, 0.0, 0.03, 0.01, 0.0, 0.02, 0.02, 0.0, 0.03, 0.0, 0.01, 0.01, 0.03, 0.0, 0.02, 0.01]\n",
      "seen_trajectories_4= [ 100.  200.  300.  400.  500.  600.  700.  800.  900. 1000. 1100. 1200.\n",
      " 1300. 1400. 1500. 1600. 1700. 1800. 1900. 2000. 2100. 2200. 2300. 2400.\n",
      " 2500. 2600. 2700. 2800. 2900. 3000.]\n",
      "unique_trajectories_4 = [ 100.  198.  297.  394.  491.  585.  682.  777.  873.  963. 1053. 1139.\n",
      " 1231. 1321. 1410. 1497. 1577. 1664. 1754. 1838. 1925. 2004. 2089. 2164.\n",
      " 2239. 2309. 2385. 2463. 2541. 2619.]\n"
     ]
    }
   ],
   "source": [
    "print(\"wins_4 =\",wins_4)\n",
    "print(\"draws_4 =\",draws_4)\n",
    "print(\"seen_trajectories_4=\", seen_trajectories_4)\n",
    "print(\"unique_trajectories_4 =\", unique_trajectories_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50 simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCTS = {\n",
    "    'c_puct': 5,\n",
    "    'dir_alpha': 0.6,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 10,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 10\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 50,\n",
    "    'temperature': 0,\n",
    "    'show_games': False\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 50,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.002,\n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 512,\n",
    "    'num_filters_value': 512,\n",
    "    'num_filters_tower': 512,\n",
    "    'num_residual_blocks': 3,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 512\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"tictactoe_num_sim_50\", \"TicTacToe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5112, 3, 3, 3)\n",
      "model_y_outcomes: (5112,)\n",
      "model_y_probabilities: (5112, 9)\n",
      "Train on 4089 samples, validate on 1023 samples\n",
      "Epoch 1/10\n",
      "4089/4089 [==============================] - 5s 1ms/step - loss: 6.6526 - value_loss: 0.9030 - policy_loss: 2.3199 - val_loss: 6.5253 - val_value_loss: 0.7559 - val_policy_loss: 2.2128\n",
      "Epoch 2/10\n",
      "4089/4089 [==============================] - 1s 172us/step - loss: 6.4782 - value_loss: 0.7237 - policy_loss: 2.1511 - val_loss: 6.4981 - val_value_loss: 0.7931 - val_policy_loss: 2.1218\n",
      "Epoch 3/10\n",
      "4089/4089 [==============================] - 1s 173us/step - loss: 6.4055 - value_loss: 0.6626 - policy_loss: 2.0675 - val_loss: 6.4519 - val_value_loss: 0.7637 - val_policy_loss: 2.0595\n",
      "Epoch 4/10\n",
      "4089/4089 [==============================] - 1s 172us/step - loss: 6.3551 - value_loss: 0.6206 - policy_loss: 2.0094 - val_loss: 6.4107 - val_value_loss: 0.7274 - val_policy_loss: 2.0140\n",
      "Epoch 5/10\n",
      "4089/4089 [==============================] - 1s 172us/step - loss: 6.3098 - value_loss: 0.5752 - policy_loss: 1.9648 - val_loss: 6.4506 - val_value_loss: 0.8417 - val_policy_loss: 1.9801\n",
      "Epoch 6/10\n",
      "4089/4089 [==============================] - 1s 172us/step - loss: 6.3022 - value_loss: 0.5955 - policy_loss: 1.9298 - val_loss: 6.4112 - val_value_loss: 0.7919 - val_policy_loss: 1.9518\n",
      "Epoch 7/10\n",
      "4089/4089 [==============================] - 1s 172us/step - loss: 6.2659 - value_loss: 0.5498 - policy_loss: 1.9035 - val_loss: 6.3871 - val_value_loss: 0.7670 - val_policy_loss: 1.9291\n",
      "Epoch 8/10\n",
      "4089/4089 [==============================] - 1s 173us/step - loss: 6.2527 - value_loss: 0.5463 - policy_loss: 1.8814 - val_loss: 6.4013 - val_value_loss: 0.8164 - val_policy_loss: 1.9088\n",
      "Epoch 9/10\n",
      "4089/4089 [==============================] - 1s 173us/step - loss: 6.2285 - value_loss: 0.5171 - policy_loss: 1.8628 - val_loss: 6.3835 - val_value_loss: 0.7964 - val_policy_loss: 1.8938\n",
      "Epoch 10/10\n",
      "4089/4089 [==============================] - 1s 172us/step - loss: 6.2121 - value_loss: 0.5018 - policy_loss: 1.8458 - val_loss: 6.3762 - val_value_loss: 0.7979 - val_policy_loss: 1.8784\n",
      "Saved model  tictactoe_num_sim_50_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.1\n",
      "Number of seen trajectories: 100\n",
      "Number of unique trajectories: 100\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2992 - value_loss: 0.6675 - policy_loss: 1.8551 - val_loss: 6.3010 - val_value_loss: 0.6909 - val_policy_loss: 1.8356\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2774 - value_loss: 0.6449 - policy_loss: 1.8346 - val_loss: 6.2890 - val_value_loss: 0.6802 - val_policy_loss: 1.8230\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2572 - value_loss: 0.6205 - policy_loss: 1.8192 - val_loss: 6.2968 - val_value_loss: 0.7070 - val_policy_loss: 1.8124\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2264 - value_loss: 0.5730 - policy_loss: 1.8058 - val_loss: 6.3048 - val_value_loss: 0.7319 - val_policy_loss: 1.8041\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2124 - value_loss: 0.5567 - policy_loss: 1.7948 - val_loss: 6.2567 - val_value_loss: 0.6454 - val_policy_loss: 1.7952\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1816 - value_loss: 0.5061 - policy_loss: 1.7844 - val_loss: 6.2797 - val_value_loss: 0.6993 - val_policy_loss: 1.7878\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1873 - value_loss: 0.5264 - policy_loss: 1.7762 - val_loss: 6.2779 - val_value_loss: 0.7033 - val_policy_loss: 1.7808\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1820 - value_loss: 0.5235 - policy_loss: 1.7690 - val_loss: 6.2711 - val_value_loss: 0.6954 - val_policy_loss: 1.7757\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2062 - value_loss: 0.5787 - policy_loss: 1.7630 - val_loss: 6.2797 - val_value_loss: 0.7176 - val_policy_loss: 1.7713\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1681 - value_loss: 0.5090 - policy_loss: 1.7570 - val_loss: 6.2345 - val_value_loss: 0.6339 - val_policy_loss: 1.7654\n",
      "Saved model  tictactoe_num_sim_50_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.71 - draw ratio 0.04\n",
      "Number of seen trajectories: 200\n",
      "Number of unique trajectories: 198\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.3268 - value_loss: 0.7991 - policy_loss: 1.7850 - val_loss: 6.2858 - val_value_loss: 0.7357 - val_policy_loss: 1.7668\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2788 - value_loss: 0.7138 - policy_loss: 1.7750 - val_loss: 6.2557 - val_value_loss: 0.6840 - val_policy_loss: 1.7590\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2677 - value_loss: 0.7002 - policy_loss: 1.7670 - val_loss: 6.2644 - val_value_loss: 0.7075 - val_policy_loss: 1.7535\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2274 - value_loss: 0.6277 - policy_loss: 1.7596 - val_loss: 6.2344 - val_value_loss: 0.6530 - val_policy_loss: 1.7485\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1995 - value_loss: 0.5787 - policy_loss: 1.7533 - val_loss: 6.2578 - val_value_loss: 0.7048 - val_policy_loss: 1.7442\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2081 - value_loss: 0.6023 - policy_loss: 1.7477 - val_loss: 6.2355 - val_value_loss: 0.6647 - val_policy_loss: 1.7403\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1901 - value_loss: 0.5723 - policy_loss: 1.7423 - val_loss: 6.2588 - val_value_loss: 0.7158 - val_policy_loss: 1.7365\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1861 - value_loss: 0.5696 - policy_loss: 1.7377 - val_loss: 6.2268 - val_value_loss: 0.6554 - val_policy_loss: 1.7336\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1858 - value_loss: 0.5733 - policy_loss: 1.7340 - val_loss: 6.2257 - val_value_loss: 0.6571 - val_policy_loss: 1.7302\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1729 - value_loss: 0.5512 - policy_loss: 1.7308 - val_loss: 6.2457 - val_value_loss: 0.7010 - val_policy_loss: 1.7269\n",
      "Saved model  tictactoe_num_sim_50_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.72 - draw ratio 0.05\n",
      "Number of seen trajectories: 300\n",
      "Number of unique trajectories: 295\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.3110 - value_loss: 0.8144 - policy_loss: 1.7445 - val_loss: 6.2486 - val_value_loss: 0.7079 - val_policy_loss: 1.7265\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2537 - value_loss: 0.7069 - policy_loss: 1.7380 - val_loss: 6.2339 - val_value_loss: 0.6834 - val_policy_loss: 1.7224\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2442 - value_loss: 0.6939 - policy_loss: 1.7327 - val_loss: 6.2336 - val_value_loss: 0.6869 - val_policy_loss: 1.7189\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2261 - value_loss: 0.6639 - policy_loss: 1.7273 - val_loss: 6.2476 - val_value_loss: 0.7177 - val_policy_loss: 1.7167\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2075 - value_loss: 0.6311 - policy_loss: 1.7234 - val_loss: 6.2597 - val_value_loss: 0.7457 - val_policy_loss: 1.7136\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2205 - value_loss: 0.6613 - policy_loss: 1.7198 - val_loss: 6.2155 - val_value_loss: 0.6602 - val_policy_loss: 1.7114\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1861 - value_loss: 0.5961 - policy_loss: 1.7169 - val_loss: 6.2077 - val_value_loss: 0.6471 - val_policy_loss: 1.7094\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1842 - value_loss: 0.5962 - policy_loss: 1.7137 - val_loss: 6.2074 - val_value_loss: 0.6495 - val_policy_loss: 1.7070\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1728 - value_loss: 0.5767 - policy_loss: 1.7110 - val_loss: 6.2490 - val_value_loss: 0.7348 - val_policy_loss: 1.7055\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1980 - value_loss: 0.6299 - policy_loss: 1.7088 - val_loss: 6.2029 - val_value_loss: 0.6449 - val_policy_loss: 1.7039\n",
      "Saved model  tictactoe_num_sim_50_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.01\n",
      "Number of seen trajectories: 400\n",
      "Number of unique trajectories: 393\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2433 - value_loss: 0.7171 - policy_loss: 1.7129 - val_loss: 6.2106 - val_value_loss: 0.6566 - val_policy_loss: 1.7083\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1995 - value_loss: 0.6364 - policy_loss: 1.7066 - val_loss: 6.2080 - val_value_loss: 0.6549 - val_policy_loss: 1.7054\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1772 - value_loss: 0.5960 - policy_loss: 1.7030 - val_loss: 6.2142 - val_value_loss: 0.6705 - val_policy_loss: 1.7028\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1699 - value_loss: 0.5844 - policy_loss: 1.7006 - val_loss: 6.2034 - val_value_loss: 0.6514 - val_policy_loss: 1.7010\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1518 - value_loss: 0.5526 - policy_loss: 1.6969 - val_loss: 6.1977 - val_value_loss: 0.6424 - val_policy_loss: 1.6992\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1390 - value_loss: 0.5294 - policy_loss: 1.6950 - val_loss: 6.1932 - val_value_loss: 0.6356 - val_policy_loss: 1.6977\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1308 - value_loss: 0.5157 - policy_loss: 1.6929 - val_loss: 6.2110 - val_value_loss: 0.6731 - val_policy_loss: 1.6965\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1283 - value_loss: 0.5146 - policy_loss: 1.6897 - val_loss: 6.2216 - val_value_loss: 0.6953 - val_policy_loss: 1.6960\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1360 - value_loss: 0.5320 - policy_loss: 1.6885 - val_loss: 6.1945 - val_value_loss: 0.6436 - val_policy_loss: 1.6941\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1228 - value_loss: 0.5085 - policy_loss: 1.6861 - val_loss: 6.2035 - val_value_loss: 0.6637 - val_policy_loss: 1.6928\n",
      "Saved model  tictactoe_num_sim_50_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.75 - draw ratio 0.02\n",
      "Number of seen trajectories: 500\n",
      "Number of unique trajectories: 489\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.2181 - value_loss: 0.7005 - policy_loss: 1.6852 - val_loss: 6.2261 - val_value_loss: 0.7047 - val_policy_loss: 1.6972\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1923 - value_loss: 0.6517 - policy_loss: 1.6827 - val_loss: 6.2214 - val_value_loss: 0.6967 - val_policy_loss: 1.6961\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1781 - value_loss: 0.6257 - policy_loss: 1.6806 - val_loss: 6.2173 - val_value_loss: 0.6895 - val_policy_loss: 1.6955\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1657 - value_loss: 0.6025 - policy_loss: 1.6795 - val_loss: 6.2161 - val_value_loss: 0.6882 - val_policy_loss: 1.6947\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1537 - value_loss: 0.5807 - policy_loss: 1.6774 - val_loss: 6.2124 - val_value_loss: 0.6815 - val_policy_loss: 1.6943\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1446 - value_loss: 0.5643 - policy_loss: 1.6760 - val_loss: 6.2145 - val_value_loss: 0.6869 - val_policy_loss: 1.6935\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1382 - value_loss: 0.5533 - policy_loss: 1.6746 - val_loss: 6.2114 - val_value_loss: 0.6815 - val_policy_loss: 1.6929\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1333 - value_loss: 0.5448 - policy_loss: 1.6737 - val_loss: 6.2097 - val_value_loss: 0.6790 - val_policy_loss: 1.6925\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1304 - value_loss: 0.5403 - policy_loss: 1.6725 - val_loss: 6.2098 - val_value_loss: 0.6802 - val_policy_loss: 1.6917\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1252 - value_loss: 0.5319 - policy_loss: 1.6709 - val_loss: 6.2095 - val_value_loss: 0.6806 - val_policy_loss: 1.6911\n",
      "Saved model  tictactoe_num_sim_50_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.04\n",
      "Number of seen trajectories: 600\n",
      "Number of unique trajectories: 585\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2161 - value_loss: 0.6903 - policy_loss: 1.6948 - val_loss: 6.1861 - val_value_loss: 0.6383 - val_policy_loss: 1.6867\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1896 - value_loss: 0.6396 - policy_loss: 1.6926 - val_loss: 6.1807 - val_value_loss: 0.6285 - val_policy_loss: 1.6861\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1719 - value_loss: 0.6062 - policy_loss: 1.6911 - val_loss: 6.1780 - val_value_loss: 0.6240 - val_policy_loss: 1.6856\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1568 - value_loss: 0.5774 - policy_loss: 1.6901 - val_loss: 6.1774 - val_value_loss: 0.6236 - val_policy_loss: 1.6851\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1473 - value_loss: 0.5601 - policy_loss: 1.6886 - val_loss: 6.1745 - val_value_loss: 0.6189 - val_policy_loss: 1.6844\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1376 - value_loss: 0.5421 - policy_loss: 1.6876 - val_loss: 6.1716 - val_value_loss: 0.6138 - val_policy_loss: 1.6840\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1315 - value_loss: 0.5312 - policy_loss: 1.6866 - val_loss: 6.1686 - val_value_loss: 0.6084 - val_policy_loss: 1.6836\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1259 - value_loss: 0.5211 - policy_loss: 1.6858 - val_loss: 6.1683 - val_value_loss: 0.6088 - val_policy_loss: 1.6830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1206 - value_loss: 0.5116 - policy_loss: 1.6850 - val_loss: 6.1702 - val_value_loss: 0.6133 - val_policy_loss: 1.6826\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1168 - value_loss: 0.5058 - policy_loss: 1.6834 - val_loss: 6.1684 - val_value_loss: 0.6108 - val_policy_loss: 1.6819\n",
      "Saved model  tictactoe_num_sim_50_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.04\n",
      "Number of seen trajectories: 700\n",
      "Number of unique trajectories: 682\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2398 - value_loss: 0.7271 - policy_loss: 1.7084 - val_loss: 6.2525 - val_value_loss: 0.7303 - val_policy_loss: 1.7309\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2144 - value_loss: 0.6786 - policy_loss: 1.7066 - val_loss: 6.2421 - val_value_loss: 0.7107 - val_policy_loss: 1.7301\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1970 - value_loss: 0.6453 - policy_loss: 1.7053 - val_loss: 6.2363 - val_value_loss: 0.6996 - val_policy_loss: 1.7297\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1850 - value_loss: 0.6228 - policy_loss: 1.7042 - val_loss: 6.2309 - val_value_loss: 0.6897 - val_policy_loss: 1.7292\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1797 - value_loss: 0.6127 - policy_loss: 1.7040 - val_loss: 6.2293 - val_value_loss: 0.6872 - val_policy_loss: 1.7288\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1699 - value_loss: 0.5951 - policy_loss: 1.7023 - val_loss: 6.2282 - val_value_loss: 0.6859 - val_policy_loss: 1.7282\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1670 - value_loss: 0.5901 - policy_loss: 1.7019 - val_loss: 6.2328 - val_value_loss: 0.6958 - val_policy_loss: 1.7278\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1594 - value_loss: 0.5761 - policy_loss: 1.7009 - val_loss: 6.2242 - val_value_loss: 0.6795 - val_policy_loss: 1.7274\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1535 - value_loss: 0.5654 - policy_loss: 1.7001 - val_loss: 6.2223 - val_value_loss: 0.6765 - val_policy_loss: 1.7269\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1476 - value_loss: 0.5551 - policy_loss: 1.6991 - val_loss: 6.2232 - val_value_loss: 0.6790 - val_policy_loss: 1.7265\n",
      "Saved model  tictactoe_num_sim_50_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.0\n",
      "Number of seen trajectories: 800\n",
      "Number of unique trajectories: 770\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.2364 - value_loss: 0.7319 - policy_loss: 1.7001 - val_loss: 6.2336 - val_value_loss: 0.7274 - val_policy_loss: 1.6991\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2165 - value_loss: 0.6938 - policy_loss: 1.6987 - val_loss: 6.2243 - val_value_loss: 0.7096 - val_policy_loss: 1.6986\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2023 - value_loss: 0.6671 - policy_loss: 1.6973 - val_loss: 6.2156 - val_value_loss: 0.6931 - val_policy_loss: 1.6982\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1910 - value_loss: 0.6460 - policy_loss: 1.6963 - val_loss: 6.2090 - val_value_loss: 0.6808 - val_policy_loss: 1.6976\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1801 - value_loss: 0.6249 - policy_loss: 1.6957 - val_loss: 6.2060 - val_value_loss: 0.6752 - val_policy_loss: 1.6974\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1716 - value_loss: 0.6094 - policy_loss: 1.6946 - val_loss: 6.2006 - val_value_loss: 0.6651 - val_policy_loss: 1.6971\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1653 - value_loss: 0.5980 - policy_loss: 1.6937 - val_loss: 6.2009 - val_value_loss: 0.6663 - val_policy_loss: 1.6967\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1592 - value_loss: 0.5871 - policy_loss: 1.6928 - val_loss: 6.2003 - val_value_loss: 0.6658 - val_policy_loss: 1.6964\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1537 - value_loss: 0.5764 - policy_loss: 1.6927 - val_loss: 6.2008 - val_value_loss: 0.6677 - val_policy_loss: 1.6959\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1512 - value_loss: 0.5726 - policy_loss: 1.6918 - val_loss: 6.1960 - val_value_loss: 0.6586 - val_policy_loss: 1.6957\n",
      "Saved model  tictactoe_num_sim_50_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.0\n",
      "Number of seen trajectories: 900\n",
      "Number of unique trajectories: 861\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1882 - value_loss: 0.6398 - policy_loss: 1.6990 - val_loss: 6.1622 - val_value_loss: 0.6185 - val_policy_loss: 1.6685\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1657 - value_loss: 0.5964 - policy_loss: 1.6977 - val_loss: 6.1602 - val_value_loss: 0.6153 - val_policy_loss: 1.6680\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1504 - value_loss: 0.5679 - policy_loss: 1.6959 - val_loss: 6.1579 - val_value_loss: 0.6118 - val_policy_loss: 1.6672\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1402 - value_loss: 0.5482 - policy_loss: 1.6954 - val_loss: 6.1575 - val_value_loss: 0.6119 - val_policy_loss: 1.6666\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1328 - value_loss: 0.5348 - policy_loss: 1.6946 - val_loss: 6.1582 - val_value_loss: 0.6143 - val_policy_loss: 1.6659\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1244 - value_loss: 0.5195 - policy_loss: 1.6932 - val_loss: 6.1557 - val_value_loss: 0.6102 - val_policy_loss: 1.6654\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1186 - value_loss: 0.5091 - policy_loss: 1.6924 - val_loss: 6.1586 - val_value_loss: 0.6167 - val_policy_loss: 1.6650\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1161 - value_loss: 0.5049 - policy_loss: 1.6920 - val_loss: 6.1570 - val_value_loss: 0.6141 - val_policy_loss: 1.6646\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1111 - value_loss: 0.4959 - policy_loss: 1.6913 - val_loss: 6.1570 - val_value_loss: 0.6150 - val_policy_loss: 1.6641\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1081 - value_loss: 0.4906 - policy_loss: 1.6909 - val_loss: 6.1576 - val_value_loss: 0.6171 - val_policy_loss: 1.6636\n",
      "Saved model  tictactoe_num_sim_50_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.77 - draw ratio 0.01\n",
      "Number of seen trajectories: 1000\n",
      "Number of unique trajectories: 950\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.2029 - value_loss: 0.6818 - policy_loss: 1.6895 - val_loss: 6.1811 - val_value_loss: 0.6476 - val_policy_loss: 1.6802\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1870 - value_loss: 0.6510 - policy_loss: 1.6887 - val_loss: 6.1768 - val_value_loss: 0.6396 - val_policy_loss: 1.6797\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1746 - value_loss: 0.6267 - policy_loss: 1.6882 - val_loss: 6.1748 - val_value_loss: 0.6360 - val_policy_loss: 1.6795\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1667 - value_loss: 0.6113 - policy_loss: 1.6880 - val_loss: 6.1733 - val_value_loss: 0.6333 - val_policy_loss: 1.6793\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1585 - value_loss: 0.5961 - policy_loss: 1.6870 - val_loss: 6.1735 - val_value_loss: 0.6341 - val_policy_loss: 1.6791\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1524 - value_loss: 0.5840 - policy_loss: 1.6871 - val_loss: 6.1730 - val_value_loss: 0.6334 - val_policy_loss: 1.6789\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1450 - value_loss: 0.5710 - policy_loss: 1.6855 - val_loss: 6.1712 - val_value_loss: 0.6303 - val_policy_loss: 1.6787\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1411 - value_loss: 0.5630 - policy_loss: 1.6859 - val_loss: 6.1707 - val_value_loss: 0.6295 - val_policy_loss: 1.6786\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1363 - value_loss: 0.5546 - policy_loss: 1.6848 - val_loss: 6.1695 - val_value_loss: 0.6274 - val_policy_loss: 1.6785\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1315 - value_loss: 0.5451 - policy_loss: 1.6848 - val_loss: 6.1696 - val_value_loss: 0.6279 - val_policy_loss: 1.6783\n",
      "Saved model  tictactoe_num_sim_50_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.03\n",
      "Number of seen trajectories: 1100\n",
      "Number of unique trajectories: 1044\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1974 - value_loss: 0.7026 - policy_loss: 1.6594 - val_loss: 6.2100 - val_value_loss: 0.7177 - val_policy_loss: 1.6695\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1819 - value_loss: 0.6729 - policy_loss: 1.6583 - val_loss: 6.2067 - val_value_loss: 0.7115 - val_policy_loss: 1.6692\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1715 - value_loss: 0.6534 - policy_loss: 1.6571 - val_loss: 6.2030 - val_value_loss: 0.7044 - val_policy_loss: 1.6690\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1624 - value_loss: 0.6358 - policy_loss: 1.6566 - val_loss: 6.2004 - val_value_loss: 0.6997 - val_policy_loss: 1.6688\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1564 - value_loss: 0.6239 - policy_loss: 1.6567 - val_loss: 6.1978 - val_value_loss: 0.6949 - val_policy_loss: 1.6686\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1497 - value_loss: 0.6119 - policy_loss: 1.6553 - val_loss: 6.1957 - val_value_loss: 0.6910 - val_policy_loss: 1.6684\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1430 - value_loss: 0.5990 - policy_loss: 1.6550 - val_loss: 6.1932 - val_value_loss: 0.6863 - val_policy_loss: 1.6683\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1388 - value_loss: 0.5915 - policy_loss: 1.6545 - val_loss: 6.1918 - val_value_loss: 0.6838 - val_policy_loss: 1.6681\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1334 - value_loss: 0.5809 - policy_loss: 1.6543 - val_loss: 6.1916 - val_value_loss: 0.6838 - val_policy_loss: 1.6680\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1292 - value_loss: 0.5736 - policy_loss: 1.6533 - val_loss: 6.1897 - val_value_loss: 0.6802 - val_policy_loss: 1.6678\n",
      "Saved model  tictactoe_num_sim_50_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.05\n",
      "Number of seen trajectories: 1200\n",
      "Number of unique trajectories: 1136\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1718 - value_loss: 0.6483 - policy_loss: 1.6640 - val_loss: 6.2065 - val_value_loss: 0.7041 - val_policy_loss: 1.6777\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1584 - value_loss: 0.6223 - policy_loss: 1.6634 - val_loss: 6.2000 - val_value_loss: 0.6915 - val_policy_loss: 1.6774\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1484 - value_loss: 0.6025 - policy_loss: 1.6632 - val_loss: 6.1996 - val_value_loss: 0.6910 - val_policy_loss: 1.6772\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1417 - value_loss: 0.5899 - policy_loss: 1.6626 - val_loss: 6.1964 - val_value_loss: 0.6850 - val_policy_loss: 1.6770\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1347 - value_loss: 0.5769 - policy_loss: 1.6619 - val_loss: 6.1952 - val_value_loss: 0.6828 - val_policy_loss: 1.6770\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1292 - value_loss: 0.5664 - policy_loss: 1.6615 - val_loss: 6.1940 - val_value_loss: 0.6807 - val_policy_loss: 1.6768\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1233 - value_loss: 0.5555 - policy_loss: 1.6608 - val_loss: 6.1927 - val_value_loss: 0.6783 - val_policy_loss: 1.6767\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1199 - value_loss: 0.5491 - policy_loss: 1.6606 - val_loss: 6.1914 - val_value_loss: 0.6761 - val_policy_loss: 1.6766\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1153 - value_loss: 0.5404 - policy_loss: 1.6603 - val_loss: 6.1898 - val_value_loss: 0.6732 - val_policy_loss: 1.6765\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1122 - value_loss: 0.5351 - policy_loss: 1.6595 - val_loss: 6.1894 - val_value_loss: 0.6726 - val_policy_loss: 1.6763\n",
      "Saved model  tictactoe_num_sim_50_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.01\n",
      "Number of seen trajectories: 1300\n",
      "Number of unique trajectories: 1228\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1512 - value_loss: 0.5961 - policy_loss: 1.6766 - val_loss: 6.1513 - val_value_loss: 0.5956 - val_policy_loss: 1.6774\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1391 - value_loss: 0.5729 - policy_loss: 1.6757 - val_loss: 6.1485 - val_value_loss: 0.5905 - val_policy_loss: 1.6771\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1316 - value_loss: 0.5589 - policy_loss: 1.6749 - val_loss: 6.1479 - val_value_loss: 0.5897 - val_policy_loss: 1.6768\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1263 - value_loss: 0.5490 - policy_loss: 1.6744 - val_loss: 6.1471 - val_value_loss: 0.5886 - val_policy_loss: 1.6765\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1210 - value_loss: 0.5393 - policy_loss: 1.6736 - val_loss: 6.1465 - val_value_loss: 0.5878 - val_policy_loss: 1.6762\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1168 - value_loss: 0.5313 - policy_loss: 1.6735 - val_loss: 6.1456 - val_value_loss: 0.5863 - val_policy_loss: 1.6760\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1131 - value_loss: 0.5245 - policy_loss: 1.6729 - val_loss: 6.1449 - val_value_loss: 0.5853 - val_policy_loss: 1.6758\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1088 - value_loss: 0.5166 - policy_loss: 1.6724 - val_loss: 6.1439 - val_value_loss: 0.5838 - val_policy_loss: 1.6756\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1051 - value_loss: 0.5097 - policy_loss: 1.6721 - val_loss: 6.1434 - val_value_loss: 0.5830 - val_policy_loss: 1.6755\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1026 - value_loss: 0.5054 - policy_loss: 1.6716 - val_loss: 6.1422 - val_value_loss: 0.5808 - val_policy_loss: 1.6754\n",
      "Saved model  tictactoe_num_sim_50_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.01\n",
      "Number of seen trajectories: 1400\n",
      "Number of unique trajectories: 1311\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1776 - value_loss: 0.6383 - policy_loss: 1.6889 - val_loss: 6.1764 - val_value_loss: 0.6377 - val_policy_loss: 1.6871\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1633 - value_loss: 0.6105 - policy_loss: 1.6882 - val_loss: 6.1703 - val_value_loss: 0.6261 - val_policy_loss: 1.6867\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1536 - value_loss: 0.5916 - policy_loss: 1.6878 - val_loss: 6.1658 - val_value_loss: 0.6176 - val_policy_loss: 1.6864\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1446 - value_loss: 0.5743 - policy_loss: 1.6872 - val_loss: 6.1629 - val_value_loss: 0.6121 - val_policy_loss: 1.6861\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1384 - value_loss: 0.5628 - policy_loss: 1.6866 - val_loss: 6.1602 - val_value_loss: 0.6072 - val_policy_loss: 1.6859\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1322 - value_loss: 0.5504 - policy_loss: 1.6868 - val_loss: 6.1593 - val_value_loss: 0.6056 - val_policy_loss: 1.6857\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1282 - value_loss: 0.5429 - policy_loss: 1.6864 - val_loss: 6.1576 - val_value_loss: 0.6027 - val_policy_loss: 1.6855\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1222 - value_loss: 0.5320 - policy_loss: 1.6855 - val_loss: 6.1560 - val_value_loss: 0.5998 - val_policy_loss: 1.6853\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1181 - value_loss: 0.5243 - policy_loss: 1.6851 - val_loss: 6.1550 - val_value_loss: 0.5981 - val_policy_loss: 1.6851\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1156 - value_loss: 0.5197 - policy_loss: 1.6849 - val_loss: 6.1541 - val_value_loss: 0.5966 - val_policy_loss: 1.6850\n",
      "Saved model  tictactoe_num_sim_50_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.89 - draw ratio 0.0\n",
      "Number of seen trajectories: 1500\n",
      "Number of unique trajectories: 1393\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1997 - value_loss: 0.6979 - policy_loss: 1.6750 - val_loss: 6.1852 - val_value_loss: 0.6947 - val_policy_loss: 1.6493\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1913 - value_loss: 0.6819 - policy_loss: 1.6742 - val_loss: 6.1849 - val_value_loss: 0.6943 - val_policy_loss: 1.6490\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1847 - value_loss: 0.6691 - policy_loss: 1.6739 - val_loss: 6.1795 - val_value_loss: 0.6839 - val_policy_loss: 1.6488\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1787 - value_loss: 0.6578 - policy_loss: 1.6732 - val_loss: 6.1773 - val_value_loss: 0.6797 - val_policy_loss: 1.6486\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1736 - value_loss: 0.6479 - policy_loss: 1.6731 - val_loss: 6.1745 - val_value_loss: 0.6745 - val_policy_loss: 1.6484\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1695 - value_loss: 0.6397 - policy_loss: 1.6731 - val_loss: 6.1705 - val_value_loss: 0.6667 - val_policy_loss: 1.6482\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1653 - value_loss: 0.6317 - policy_loss: 1.6729 - val_loss: 6.1729 - val_value_loss: 0.6717 - val_policy_loss: 1.6481\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1609 - value_loss: 0.6232 - policy_loss: 1.6726 - val_loss: 6.1681 - val_value_loss: 0.6623 - val_policy_loss: 1.6479\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1569 - value_loss: 0.6155 - policy_loss: 1.6725 - val_loss: 6.1679 - val_value_loss: 0.6622 - val_policy_loss: 1.6478\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1531 - value_loss: 0.6085 - policy_loss: 1.6720 - val_loss: 6.1660 - val_value_loss: 0.6586 - val_policy_loss: 1.6477\n",
      "Saved model  tictactoe_num_sim_50_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.02\n",
      "Number of seen trajectories: 1600\n",
      "Number of unique trajectories: 1481\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2001 - value_loss: 0.7076 - policy_loss: 1.6670 - val_loss: 6.1944 - val_value_loss: 0.6857 - val_policy_loss: 1.6775\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1927 - value_loss: 0.6934 - policy_loss: 1.6663 - val_loss: 6.1933 - val_value_loss: 0.6838 - val_policy_loss: 1.6773\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1864 - value_loss: 0.6810 - policy_loss: 1.6662 - val_loss: 6.1902 - val_value_loss: 0.6778 - val_policy_loss: 1.6771\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1814 - value_loss: 0.6714 - policy_loss: 1.6660 - val_loss: 6.1886 - val_value_loss: 0.6747 - val_policy_loss: 1.6770\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1754 - value_loss: 0.6600 - policy_loss: 1.6654 - val_loss: 6.1864 - val_value_loss: 0.6707 - val_policy_loss: 1.6768\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1709 - value_loss: 0.6513 - policy_loss: 1.6651 - val_loss: 6.1858 - val_value_loss: 0.6697 - val_policy_loss: 1.6767\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1669 - value_loss: 0.6434 - policy_loss: 1.6650 - val_loss: 6.1862 - val_value_loss: 0.6706 - val_policy_loss: 1.6766\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1637 - value_loss: 0.6370 - policy_loss: 1.6652 - val_loss: 6.1850 - val_value_loss: 0.6683 - val_policy_loss: 1.6765\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1606 - value_loss: 0.6316 - policy_loss: 1.6645 - val_loss: 6.1832 - val_value_loss: 0.6648 - val_policy_loss: 1.6764\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1570 - value_loss: 0.6244 - policy_loss: 1.6646 - val_loss: 6.1824 - val_value_loss: 0.6634 - val_policy_loss: 1.6763\n",
      "Saved model  tictactoe_num_sim_50_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.04\n",
      "Number of seen trajectories: 1700\n",
      "Number of unique trajectories: 1564\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.2291 - value_loss: 0.7491 - policy_loss: 1.6842 - val_loss: 6.2349 - val_value_loss: 0.7752 - val_policy_loss: 1.6697\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2211 - value_loss: 0.7331 - policy_loss: 1.6843 - val_loss: 6.2318 - val_value_loss: 0.7692 - val_policy_loss: 1.6695\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2142 - value_loss: 0.7202 - policy_loss: 1.6835 - val_loss: 6.2292 - val_value_loss: 0.7644 - val_policy_loss: 1.6694\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2086 - value_loss: 0.7092 - policy_loss: 1.6833 - val_loss: 6.2263 - val_value_loss: 0.7588 - val_policy_loss: 1.6692\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2041 - value_loss: 0.7006 - policy_loss: 1.6830 - val_loss: 6.2243 - val_value_loss: 0.7549 - val_policy_loss: 1.6691\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1991 - value_loss: 0.6905 - policy_loss: 1.6830 - val_loss: 6.2231 - val_value_loss: 0.7527 - val_policy_loss: 1.6690\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1962 - value_loss: 0.6855 - policy_loss: 1.6824 - val_loss: 6.2218 - val_value_loss: 0.7503 - val_policy_loss: 1.6689\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1920 - value_loss: 0.6775 - policy_loss: 1.6821 - val_loss: 6.2208 - val_value_loss: 0.7484 - val_policy_loss: 1.6688\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1891 - value_loss: 0.6715 - policy_loss: 1.6823 - val_loss: 6.2192 - val_value_loss: 0.7454 - val_policy_loss: 1.6687\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1855 - value_loss: 0.6648 - policy_loss: 1.6821 - val_loss: 6.2188 - val_value_loss: 0.7447 - val_policy_loss: 1.6687\n",
      "Saved model  tictactoe_num_sim_50_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.03\n",
      "Number of seen trajectories: 1800\n",
      "Number of unique trajectories: 1652\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1797 - value_loss: 0.6794 - policy_loss: 1.6559 - val_loss: 6.1641 - val_value_loss: 0.6494 - val_policy_loss: 1.6547\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1715 - value_loss: 0.6635 - policy_loss: 1.6555 - val_loss: 6.1601 - val_value_loss: 0.6416 - val_policy_loss: 1.6546\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1646 - value_loss: 0.6505 - policy_loss: 1.6547 - val_loss: 6.1595 - val_value_loss: 0.6405 - val_policy_loss: 1.6545\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1581 - value_loss: 0.6378 - policy_loss: 1.6544 - val_loss: 6.1572 - val_value_loss: 0.6361 - val_policy_loss: 1.6545\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1530 - value_loss: 0.6277 - policy_loss: 1.6544 - val_loss: 6.1570 - val_value_loss: 0.6358 - val_policy_loss: 1.6544\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1483 - value_loss: 0.6188 - policy_loss: 1.6541 - val_loss: 6.1557 - val_value_loss: 0.6333 - val_policy_loss: 1.6544\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1440 - value_loss: 0.6108 - policy_loss: 1.6536 - val_loss: 6.1549 - val_value_loss: 0.6319 - val_policy_loss: 1.6544\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1404 - value_loss: 0.6038 - policy_loss: 1.6535 - val_loss: 6.1530 - val_value_loss: 0.6282 - val_policy_loss: 1.6543\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1377 - value_loss: 0.5986 - policy_loss: 1.6534 - val_loss: 6.1530 - val_value_loss: 0.6283 - val_policy_loss: 1.6543\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1333 - value_loss: 0.5901 - policy_loss: 1.6530 - val_loss: 6.1530 - val_value_loss: 0.6284 - val_policy_loss: 1.6543\n",
      "Saved model  tictactoe_num_sim_50_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.0\n",
      "Number of seen trajectories: 1900\n",
      "Number of unique trajectories: 1735\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1663 - value_loss: 0.6510 - policy_loss: 1.6582 - val_loss: 6.1426 - val_value_loss: 0.6140 - val_policy_loss: 1.6478\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1573 - value_loss: 0.6339 - policy_loss: 1.6575 - val_loss: 6.1406 - val_value_loss: 0.6103 - val_policy_loss: 1.6478\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1505 - value_loss: 0.6206 - policy_loss: 1.6573 - val_loss: 6.1388 - val_value_loss: 0.6068 - val_policy_loss: 1.6477\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1459 - value_loss: 0.6114 - policy_loss: 1.6574 - val_loss: 6.1375 - val_value_loss: 0.6043 - val_policy_loss: 1.6477\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1406 - value_loss: 0.6014 - policy_loss: 1.6568 - val_loss: 6.1368 - val_value_loss: 0.6030 - val_policy_loss: 1.6476\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1365 - value_loss: 0.5939 - policy_loss: 1.6561 - val_loss: 6.1354 - val_value_loss: 0.6003 - val_policy_loss: 1.6476\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1325 - value_loss: 0.5860 - policy_loss: 1.6562 - val_loss: 6.1350 - val_value_loss: 0.5997 - val_policy_loss: 1.6475\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1284 - value_loss: 0.5783 - policy_loss: 1.6556 - val_loss: 6.1342 - val_value_loss: 0.5982 - val_policy_loss: 1.6475\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1255 - value_loss: 0.5725 - policy_loss: 1.6558 - val_loss: 6.1333 - val_value_loss: 0.5965 - val_policy_loss: 1.6474\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1216 - value_loss: 0.5652 - policy_loss: 1.6553 - val_loss: 6.1338 - val_value_loss: 0.5977 - val_policy_loss: 1.6474\n",
      "Saved model  tictactoe_num_sim_50_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.02\n",
      "Number of seen trajectories: 2000\n",
      "Number of unique trajectories: 1815\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1829 - value_loss: 0.6834 - policy_loss: 1.6598 - val_loss: 6.1975 - val_value_loss: 0.6947 - val_policy_loss: 1.6779\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1774 - value_loss: 0.6724 - policy_loss: 1.6598 - val_loss: 6.1951 - val_value_loss: 0.6898 - val_policy_loss: 1.6778\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1734 - value_loss: 0.6647 - policy_loss: 1.6596 - val_loss: 6.1932 - val_value_loss: 0.6861 - val_policy_loss: 1.6777\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1692 - value_loss: 0.6565 - policy_loss: 1.6595 - val_loss: 6.1916 - val_value_loss: 0.6831 - val_policy_loss: 1.6777\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1658 - value_loss: 0.6504 - policy_loss: 1.6589 - val_loss: 6.1901 - val_value_loss: 0.6803 - val_policy_loss: 1.6776\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1624 - value_loss: 0.6436 - policy_loss: 1.6589 - val_loss: 6.1889 - val_value_loss: 0.6779 - val_policy_loss: 1.6776\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1592 - value_loss: 0.6371 - policy_loss: 1.6591 - val_loss: 6.1878 - val_value_loss: 0.6759 - val_policy_loss: 1.6775\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1566 - value_loss: 0.6322 - policy_loss: 1.6587 - val_loss: 6.1870 - val_value_loss: 0.6742 - val_policy_loss: 1.6775\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1548 - value_loss: 0.6281 - policy_loss: 1.6592 - val_loss: 6.1861 - val_value_loss: 0.6725 - val_policy_loss: 1.6774\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1516 - value_loss: 0.6221 - policy_loss: 1.6589 - val_loss: 6.1853 - val_value_loss: 0.6710 - val_policy_loss: 1.6774\n",
      "Saved model  tictactoe_num_sim_50_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.73 - draw ratio 0.03\n",
      "Number of seen trajectories: 2100\n",
      "Number of unique trajectories: 1905\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1836 - value_loss: 0.6709 - policy_loss: 1.6743 - val_loss: 6.1574 - val_value_loss: 0.6121 - val_policy_loss: 1.6806\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1795 - value_loss: 0.6630 - policy_loss: 1.6738 - val_loss: 6.1561 - val_value_loss: 0.6096 - val_policy_loss: 1.6805\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1754 - value_loss: 0.6546 - policy_loss: 1.6740 - val_loss: 6.1551 - val_value_loss: 0.6077 - val_policy_loss: 1.6804\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1721 - value_loss: 0.6488 - policy_loss: 1.6734 - val_loss: 6.1541 - val_value_loss: 0.6060 - val_policy_loss: 1.6802\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1693 - value_loss: 0.6430 - policy_loss: 1.6735 - val_loss: 6.1529 - val_value_loss: 0.6037 - val_policy_loss: 1.6801\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1659 - value_loss: 0.6366 - policy_loss: 1.6733 - val_loss: 6.1522 - val_value_loss: 0.6024 - val_policy_loss: 1.6800\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1628 - value_loss: 0.6304 - policy_loss: 1.6733 - val_loss: 6.1514 - val_value_loss: 0.6009 - val_policy_loss: 1.6800\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1608 - value_loss: 0.6265 - policy_loss: 1.6732 - val_loss: 6.1505 - val_value_loss: 0.5992 - val_policy_loss: 1.6799\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1585 - value_loss: 0.6220 - policy_loss: 1.6732 - val_loss: 6.1500 - val_value_loss: 0.5984 - val_policy_loss: 1.6798\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1547 - value_loss: 0.6150 - policy_loss: 1.6726 - val_loss: 6.1492 - val_value_loss: 0.5970 - val_policy_loss: 1.6797\n",
      "Saved model  tictactoe_num_sim_50_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.01\n",
      "Number of seen trajectories: 2200\n",
      "Number of unique trajectories: 1991\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1509 - value_loss: 0.6182 - policy_loss: 1.6620 - val_loss: 6.1726 - val_value_loss: 0.6601 - val_policy_loss: 1.6635\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1452 - value_loss: 0.6073 - policy_loss: 1.6614 - val_loss: 6.1708 - val_value_loss: 0.6565 - val_policy_loss: 1.6634\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1422 - value_loss: 0.6012 - policy_loss: 1.6615 - val_loss: 6.1689 - val_value_loss: 0.6528 - val_policy_loss: 1.6633\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1392 - value_loss: 0.5952 - policy_loss: 1.6615 - val_loss: 6.1669 - val_value_loss: 0.6490 - val_policy_loss: 1.6632\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1360 - value_loss: 0.5894 - policy_loss: 1.6609 - val_loss: 6.1659 - val_value_loss: 0.6472 - val_policy_loss: 1.6632\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1336 - value_loss: 0.5844 - policy_loss: 1.6612 - val_loss: 6.1644 - val_value_loss: 0.6441 - val_policy_loss: 1.6631\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1304 - value_loss: 0.5783 - policy_loss: 1.6610 - val_loss: 6.1630 - val_value_loss: 0.6415 - val_policy_loss: 1.6631\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1278 - value_loss: 0.5735 - policy_loss: 1.6605 - val_loss: 6.1619 - val_value_loss: 0.6393 - val_policy_loss: 1.6630\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1255 - value_loss: 0.5693 - policy_loss: 1.6603 - val_loss: 6.1609 - val_value_loss: 0.6375 - val_policy_loss: 1.6630\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1247 - value_loss: 0.5677 - policy_loss: 1.6602 - val_loss: 6.1600 - val_value_loss: 0.6357 - val_policy_loss: 1.6629\n",
      "Saved model  tictactoe_num_sim_50_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.0\n",
      "Number of seen trajectories: 2300\n",
      "Number of unique trajectories: 2076\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1655 - value_loss: 0.6454 - policy_loss: 1.6642 - val_loss: 6.1571 - val_value_loss: 0.6317 - val_policy_loss: 1.6611\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1604 - value_loss: 0.6352 - policy_loss: 1.6643 - val_loss: 6.1540 - val_value_loss: 0.6257 - val_policy_loss: 1.6610\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1553 - value_loss: 0.6253 - policy_loss: 1.6640 - val_loss: 6.1516 - val_value_loss: 0.6209 - val_policy_loss: 1.6610\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1520 - value_loss: 0.6187 - policy_loss: 1.6640 - val_loss: 6.1491 - val_value_loss: 0.6161 - val_policy_loss: 1.6610\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1482 - value_loss: 0.6112 - policy_loss: 1.6639 - val_loss: 6.1474 - val_value_loss: 0.6126 - val_policy_loss: 1.6609\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1448 - value_loss: 0.6043 - policy_loss: 1.6643 - val_loss: 6.1460 - val_value_loss: 0.6099 - val_policy_loss: 1.6609\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1418 - value_loss: 0.5985 - policy_loss: 1.6640 - val_loss: 6.1445 - val_value_loss: 0.6070 - val_policy_loss: 1.6609\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1388 - value_loss: 0.5930 - policy_loss: 1.6635 - val_loss: 6.1433 - val_value_loss: 0.6047 - val_policy_loss: 1.6608\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1381 - value_loss: 0.5915 - policy_loss: 1.6637 - val_loss: 6.1423 - val_value_loss: 0.6027 - val_policy_loss: 1.6608\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1349 - value_loss: 0.5854 - policy_loss: 1.6633 - val_loss: 6.1414 - val_value_loss: 0.6011 - val_policy_loss: 1.6608\n",
      "Saved model  tictactoe_num_sim_50_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.0\n",
      "Number of seen trajectories: 2400\n",
      "Number of unique trajectories: 2157\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1832 - value_loss: 0.6480 - policy_loss: 1.6973 - val_loss: 6.1744 - val_value_loss: 0.6335 - val_policy_loss: 1.6943\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1775 - value_loss: 0.6367 - policy_loss: 1.6973 - val_loss: 6.1727 - val_value_loss: 0.6302 - val_policy_loss: 1.6942\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1735 - value_loss: 0.6286 - policy_loss: 1.6976 - val_loss: 6.1716 - val_value_loss: 0.6282 - val_policy_loss: 1.6941\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1692 - value_loss: 0.6206 - policy_loss: 1.6970 - val_loss: 6.1706 - val_value_loss: 0.6264 - val_policy_loss: 1.6940\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1666 - value_loss: 0.6153 - policy_loss: 1.6971 - val_loss: 6.1699 - val_value_loss: 0.6251 - val_policy_loss: 1.6939\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1630 - value_loss: 0.6086 - policy_loss: 1.6966 - val_loss: 6.1692 - val_value_loss: 0.6239 - val_policy_loss: 1.6938\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1601 - value_loss: 0.6028 - policy_loss: 1.6966 - val_loss: 6.1686 - val_value_loss: 0.6228 - val_policy_loss: 1.6937\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1581 - value_loss: 0.5987 - policy_loss: 1.6968 - val_loss: 6.1682 - val_value_loss: 0.6221 - val_policy_loss: 1.6937\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1560 - value_loss: 0.5945 - policy_loss: 1.6967 - val_loss: 6.1677 - val_value_loss: 0.6212 - val_policy_loss: 1.6936\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1532 - value_loss: 0.5897 - policy_loss: 1.6962 - val_loss: 6.1675 - val_value_loss: 0.6209 - val_policy_loss: 1.6935\n",
      "Saved model  tictactoe_num_sim_50_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.02\n",
      "Number of seen trajectories: 2500\n",
      "Number of unique trajectories: 2228\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1612 - value_loss: 0.6442 - policy_loss: 1.6577 - val_loss: 6.1707 - val_value_loss: 0.6332 - val_policy_loss: 1.6876\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1592 - value_loss: 0.6401 - policy_loss: 1.6578 - val_loss: 6.1691 - val_value_loss: 0.6302 - val_policy_loss: 1.6876\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1559 - value_loss: 0.6337 - policy_loss: 1.6575 - val_loss: 6.1679 - val_value_loss: 0.6278 - val_policy_loss: 1.6876\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1537 - value_loss: 0.6293 - policy_loss: 1.6576 - val_loss: 6.1669 - val_value_loss: 0.6258 - val_policy_loss: 1.6876\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1518 - value_loss: 0.6255 - policy_loss: 1.6577 - val_loss: 6.1661 - val_value_loss: 0.6241 - val_policy_loss: 1.6875\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1504 - value_loss: 0.6229 - policy_loss: 1.6574 - val_loss: 6.1653 - val_value_loss: 0.6227 - val_policy_loss: 1.6875\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1485 - value_loss: 0.6191 - policy_loss: 1.6573 - val_loss: 6.1647 - val_value_loss: 0.6214 - val_policy_loss: 1.6875\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1466 - value_loss: 0.6157 - policy_loss: 1.6569 - val_loss: 6.1641 - val_value_loss: 0.6202 - val_policy_loss: 1.6875\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1456 - value_loss: 0.6136 - policy_loss: 1.6572 - val_loss: 6.1636 - val_value_loss: 0.6192 - val_policy_loss: 1.6875\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1429 - value_loss: 0.6086 - policy_loss: 1.6568 - val_loss: 6.1631 - val_value_loss: 0.6183 - val_policy_loss: 1.6875\n",
      "Saved model  tictactoe_num_sim_50_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.81 - draw ratio 0.02\n",
      "Number of seen trajectories: 2600\n",
      "Number of unique trajectories: 2308\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1616 - value_loss: 0.6340 - policy_loss: 1.6689 - val_loss: 6.1712 - val_value_loss: 0.6389 - val_policy_loss: 1.6832\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1590 - value_loss: 0.6286 - policy_loss: 1.6690 - val_loss: 6.1696 - val_value_loss: 0.6357 - val_policy_loss: 1.6832\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1551 - value_loss: 0.6213 - policy_loss: 1.6686 - val_loss: 6.1682 - val_value_loss: 0.6330 - val_policy_loss: 1.6832\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1538 - value_loss: 0.6188 - policy_loss: 1.6686 - val_loss: 6.1673 - val_value_loss: 0.6311 - val_policy_loss: 1.6831\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1522 - value_loss: 0.6152 - policy_loss: 1.6689 - val_loss: 6.1665 - val_value_loss: 0.6295 - val_policy_loss: 1.6831\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1516 - value_loss: 0.6140 - policy_loss: 1.6689 - val_loss: 6.1658 - val_value_loss: 0.6282 - val_policy_loss: 1.6831\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1490 - value_loss: 0.6092 - policy_loss: 1.6686 - val_loss: 6.1652 - val_value_loss: 0.6270 - val_policy_loss: 1.6831\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1469 - value_loss: 0.6051 - policy_loss: 1.6684 - val_loss: 6.1647 - val_value_loss: 0.6261 - val_policy_loss: 1.6831\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1454 - value_loss: 0.6021 - policy_loss: 1.6685 - val_loss: 6.1644 - val_value_loss: 0.6255 - val_policy_loss: 1.6831\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1441 - value_loss: 0.5998 - policy_loss: 1.6682 - val_loss: 6.1641 - val_value_loss: 0.6249 - val_policy_loss: 1.6830\n",
      "Saved model  tictactoe_num_sim_50_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.0\n",
      "Number of seen trajectories: 2700\n",
      "Number of unique trajectories: 2381\n",
      "iteration 27 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1846 - value_loss: 0.6828 - policy_loss: 1.6662 - val_loss: 6.1691 - val_value_loss: 0.6478 - val_policy_loss: 1.6703\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1827 - value_loss: 0.6786 - policy_loss: 1.6666 - val_loss: 6.1687 - val_value_loss: 0.6470 - val_policy_loss: 1.6702\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1797 - value_loss: 0.6732 - policy_loss: 1.6660 - val_loss: 6.1682 - val_value_loss: 0.6462 - val_policy_loss: 1.6701\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1778 - value_loss: 0.6697 - policy_loss: 1.6658 - val_loss: 6.1677 - val_value_loss: 0.6452 - val_policy_loss: 1.6701\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1764 - value_loss: 0.6665 - policy_loss: 1.6662 - val_loss: 6.1673 - val_value_loss: 0.6445 - val_policy_loss: 1.6701\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1732 - value_loss: 0.6608 - policy_loss: 1.6656 - val_loss: 6.1668 - val_value_loss: 0.6436 - val_policy_loss: 1.6700\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1720 - value_loss: 0.6585 - policy_loss: 1.6654 - val_loss: 6.1664 - val_value_loss: 0.6427 - val_policy_loss: 1.6700\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1694 - value_loss: 0.6532 - policy_loss: 1.6655 - val_loss: 6.1658 - val_value_loss: 0.6417 - val_policy_loss: 1.6700\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1695 - value_loss: 0.6527 - policy_loss: 1.6663 - val_loss: 6.1653 - val_value_loss: 0.6408 - val_policy_loss: 1.6699\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1677 - value_loss: 0.6500 - policy_loss: 1.6654 - val_loss: 6.1648 - val_value_loss: 0.6397 - val_policy_loss: 1.6699\n",
      "Saved model  tictactoe_num_sim_50_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.02\n",
      "Number of seen trajectories: 2800\n",
      "Number of unique trajectories: 2455\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.2133 - value_loss: 0.7556 - policy_loss: 1.6511 - val_loss: 6.1675 - val_value_loss: 0.6997 - val_policy_loss: 1.6153\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2051 - value_loss: 0.7385 - policy_loss: 1.6517 - val_loss: 6.1641 - val_value_loss: 0.6929 - val_policy_loss: 1.6153\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2007 - value_loss: 0.7303 - policy_loss: 1.6512 - val_loss: 6.1620 - val_value_loss: 0.6888 - val_policy_loss: 1.6154\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1977 - value_loss: 0.7244 - policy_loss: 1.6510 - val_loss: 6.1605 - val_value_loss: 0.6857 - val_policy_loss: 1.6154\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1943 - value_loss: 0.7178 - policy_loss: 1.6509 - val_loss: 6.1591 - val_value_loss: 0.6829 - val_policy_loss: 1.6154\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1916 - value_loss: 0.7124 - policy_loss: 1.6509 - val_loss: 6.1579 - val_value_loss: 0.6806 - val_policy_loss: 1.6155\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1897 - value_loss: 0.7090 - policy_loss: 1.6506 - val_loss: 6.1569 - val_value_loss: 0.6785 - val_policy_loss: 1.6155\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1869 - value_loss: 0.7030 - policy_loss: 1.6511 - val_loss: 6.1560 - val_value_loss: 0.6766 - val_policy_loss: 1.6155\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1863 - value_loss: 0.7020 - policy_loss: 1.6508 - val_loss: 6.1551 - val_value_loss: 0.6748 - val_policy_loss: 1.6156\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1844 - value_loss: 0.6980 - policy_loss: 1.6509 - val_loss: 6.1543 - val_value_loss: 0.6732 - val_policy_loss: 1.6156\n",
      "Saved model  tictactoe_num_sim_50_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.75 - draw ratio 0.07\n",
      "Number of seen trajectories: 2900\n",
      "Number of unique trajectories: 2531\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_tictactoe_num_sim_50_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1828 - value_loss: 0.6886 - policy_loss: 1.6573 - val_loss: 6.1745 - val_value_loss: 0.6711 - val_policy_loss: 1.6581\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1807 - value_loss: 0.6844 - policy_loss: 1.6572 - val_loss: 6.1737 - val_value_loss: 0.6695 - val_policy_loss: 1.6581\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1779 - value_loss: 0.6789 - policy_loss: 1.6571 - val_loss: 6.1730 - val_value_loss: 0.6682 - val_policy_loss: 1.6581\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1752 - value_loss: 0.6740 - policy_loss: 1.6567 - val_loss: 6.1725 - val_value_loss: 0.6672 - val_policy_loss: 1.6580\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1736 - value_loss: 0.6710 - policy_loss: 1.6566 - val_loss: 6.1719 - val_value_loss: 0.6661 - val_policy_loss: 1.6580\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1723 - value_loss: 0.6686 - policy_loss: 1.6563 - val_loss: 6.1715 - val_value_loss: 0.6654 - val_policy_loss: 1.6580\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1711 - value_loss: 0.6664 - policy_loss: 1.6561 - val_loss: 6.1712 - val_value_loss: 0.6648 - val_policy_loss: 1.6580\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1706 - value_loss: 0.6647 - policy_loss: 1.6569 - val_loss: 6.1707 - val_value_loss: 0.6638 - val_policy_loss: 1.6580\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1674 - value_loss: 0.6587 - policy_loss: 1.6564 - val_loss: 6.1704 - val_value_loss: 0.6631 - val_policy_loss: 1.6580\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1668 - value_loss: 0.6581 - policy_loss: 1.6561 - val_loss: 6.1701 - val_value_loss: 0.6626 - val_policy_loss: 1.6580\n",
      "Saved model  tictactoe_num_sim_50_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.03\n",
      "Number of seen trajectories: 3000\n",
      "Number of unique trajectories: 2609\n"
     ]
    }
   ],
   "source": [
    "wins_5, draws_5, seen_trajectories_5, unique_trajectories_5 = test_pipeline.run(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - 50 simulations\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "losses_5 = np.ones(30) - wins_5 - draws_5\n",
    "\n",
    "plt.plot(x, wins_5, label=\"win ratio\")\n",
    "plt.plot(x, draws_5, label=\"draw ratio\")\n",
    "plt.plot(x, losses_5, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "exploration_rate_5 = unique_trajectories_5/seen_trajectories_5\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - 50 simulations\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "plt.plot(x, exploration_rate_5, label=\"unique/seen\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins_5 = [0.7, 0.71, 0.72, 0.83, 0.75, 0.87, 0.8, 0.86, 0.83, 0.77, 0.86, 0.84, 0.83, 0.78, 0.89, 0.82, 0.79, 0.84, 0.8, 0.83, 0.73, 0.86, 0.87, 0.83, 0.76, 0.81, 0.78, 0.8, 0.75, 0.84]\n",
      "draws_5 = [0.1, 0.04, 0.05, 0.01, 0.02, 0.04, 0.04, 0.0, 0.0, 0.01, 0.03, 0.05, 0.01, 0.01, 0.0, 0.02, 0.04, 0.03, 0.0, 0.02, 0.03, 0.01, 0.0, 0.0, 0.02, 0.02, 0.0, 0.02, 0.07, 0.03]\n",
      "seen_trajectories_5 = [ 100.  200.  300.  400.  500.  600.  700.  800.  900. 1000. 1100. 1200.\n",
      " 1300. 1400. 1500. 1600. 1700. 1800. 1900. 2000. 2100. 2200. 2300. 2400.\n",
      " 2500. 2600. 2700. 2800. 2900. 3000.]\n",
      "unique_trajectories_5 = [ 100.  198.  295.  393.  489.  585.  682.  770.  861.  950. 1044. 1136.\n",
      " 1228. 1311. 1393. 1481. 1564. 1652. 1735. 1815. 1905. 1991. 2076. 2157.\n",
      " 2228. 2308. 2381. 2455. 2531. 2609.]\n"
     ]
    }
   ],
   "source": [
    "print(\"wins_5 =\",wins_5)\n",
    "print(\"draws_5 =\",draws_5)\n",
    "print(\"seen_trajectories_5 =\", seen_trajectories_5)\n",
    "print(\"unique_trajectories_5 =\", unique_trajectories_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(data, window_size):\n",
    "    return np.convolve(data, np.ones((window_size,))/window_size, mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 simulation\n",
    "wins_1 = [0.54, 0.48, 0.56, 0.57, 0.57, 0.58, 0.67, 0.6, 0.61, 0.57, 0.66, 0.62, 0.62, 0.66, 0.55, 0.57, 0.52, 0.59, 0.55, 0.65, 0.68, 0.56, 0.7, 0.57, 0.54, 0.6, 0.58, 0.72, 0.67, 0.59]\n",
    "draws_1 = [0.23, 0.16, 0.04, 0.1, 0.09, 0.05, 0.07, 0.06, 0.09, 0.07, 0.02, 0.06, 0.04, 0.06, 0.02, 0.03, 0.07, 0.07, 0.12, 0.11, 0.1, 0.11, 0.03, 0.07, 0.11, 0.08, 0.02, 0.09, 0.04, 0.08]\n",
    "seen_trajectories_1 = [ 100,  200,  300,  400,  500,  600,  700,  800,  900, 1000, 1100, 1200,\n",
    " 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400,\n",
    " 2500, 2600, 2700, 2800, 2900, 3000,]\n",
    "unique_trajectories_1 = [ 100,  199,  292,  379,  449,  508,  568,  624,  660,  709,  748,  788,\n",
    "  813,  843,  874,  899,  924,  943,  966,  978,  990, 1007, 1021, 1037,\n",
    " 1047, 1060, 1070, 1077, 1090, 1104]\n",
    "\n",
    "# 5 simulations\n",
    "wins_2 = [0.67, 0.66, 0.77, 0.78, 0.74, 0.76, 0.83, 0.83, 0.8, 0.78, 0.87, 0.74, 0.87, 0.79, 0.78, 0.79, 0.79, 0.88, 0.82, 0.67, 0.82, 0.72, 0.83, 0.79, 0.84, 0.8, 0.8, 0.69, 0.79, 0.73]\n",
    "draws_2 = [0.07, 0.05, 0.01, 0.0, 0.01, 0.02, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "seen_trajectories_2 = [ 100,  200,  300,  400,  500,  600,  700,  800,  900, 1000, 1100, 1200,\n",
    " 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400,\n",
    " 2500, 2600, 2700, 2800, 2900, 3000]\n",
    "unique_trajectories_2 = [ 100,  200,  298,  394,  487,  580,  657,  730,  798,  869,  919,  957,\n",
    "  981, 1006, 1013, 1027, 1032, 1037, 1039, 1042, 1042, 1042, 1044, 1046,\n",
    " 1047, 1051, 1052, 1055, 1055, 1057]\n",
    "\n",
    "# 10 simulations\n",
    "wins_3 = [0.76, 0.78, 0.75, 0.76, 0.81, 0.88, 0.71, 0.75, 0.72, 0.85, 0.85, 0.89, 0.87, 0.87, 0.86, 0.86, 0.81, 0.85, 0.83, 0.87, 0.8, 0.83, 0.83, 0.88, 0.9, 0.87, 0.87, 0.86, 0.85, 0.86]\n",
    "draws_3 = [0.02, 0.06, 0.03, 0.03, 0.01, 0.01, 0.03, 0.02, 0.02, 0.03, 0.0, 0.01, 0.0, 0.0, 0.02, 0.0, 0.01, 0.0, 0.02, 0.02, 0.02, 0.04, 0.01, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "seen_trajectories_3 = [ 100,  200,  300,  400,  500,  600,  700,  800,  900, 1000, 1100, 1200,\n",
    " 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400,\n",
    " 2500, 2600, 2700, 2800, 2900, 3000]\n",
    "unique_trajectories_3 = [  99,  198,  298,  396,  490,  585,  680,  778,  866,  956, 1051, 1138,\n",
    " 1216, 1292, 1377, 1455, 1539, 1628, 1705, 1779, 1860, 1929, 2004, 2080,\n",
    " 2145, 2216, 2284, 2349, 2421, 2487,]\n",
    "\n",
    "# 25 simulations\n",
    "wins_4 = [0.68, 0.61, 0.76, 0.79, 0.76, 0.81, 0.74, 0.87, 0.72, 0.8, 0.9, 0.76, 0.89, 0.81, 0.86, 0.86, 0.8, 0.88, 0.82, 0.83, 0.83, 0.87, 0.85, 0.88, 0.82, 0.8, 0.85, 0.77, 0.76, 0.83]\n",
    "draws_4 = [0.07, 0.05, 0.03, 0.01, 0.0, 0.01, 0.01, 0.01, 0.02, 0.03, 0.01, 0.02, 0.0, 0.0, 0.0, 0.0, 0.03, 0.01, 0.0, 0.02, 0.02, 0.0, 0.03, 0.0, 0.01, 0.01, 0.03, 0.0, 0.02, 0.01]\n",
    "seen_trajectories_4= [ 100,  200,  300,  400,  500,  600,  700,  800,  900, 1000, 1100, 1200,\n",
    " 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400,\n",
    " 2500, 2600, 2700, 2800, 2900, 3000]\n",
    "unique_trajectories_4 = [ 100,  198,  297,  394,  491,  585,  682,  777,  873,  963, 1053, 1139,\n",
    " 1231, 1321, 1410, 1497, 1577, 1664, 1754, 1838, 1925, 2004, 2089, 2164,\n",
    " 2239, 2309, 2385, 2463, 2541, 2619,]\n",
    "\n",
    "# 50 simulations\n",
    "wins_5 = [0.7, 0.71, 0.72, 0.83, 0.75, 0.87, 0.8, 0.86, 0.83, 0.77, 0.86, 0.84, 0.83, 0.78, 0.89, 0.82, 0.79, 0.84, 0.8, 0.83, 0.73, 0.86, 0.87, 0.83, 0.76, 0.81, 0.78, 0.8, 0.75, 0.84]\n",
    "draws_5 = [0.1, 0.04, 0.05, 0.01, 0.02, 0.04, 0.04, 0.0, 0.0, 0.01, 0.03, 0.05, 0.01, 0.01, 0.0, 0.02, 0.04, 0.03, 0.0, 0.02, 0.03, 0.01, 0.0, 0.0, 0.02, 0.02, 0.0, 0.02, 0.07, 0.03]\n",
    "seen_trajectories_5 = [ 100,  200,  300,  400,  500,  600,  700,  800,  900, 1000, 1100, 1200,\n",
    " 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400,\n",
    " 2500, 2600, 2700, 2800, 2900, 3000,]\n",
    "unique_trajectories_5 = [ 100,  198,  295,  393,  489,  585,  682,  770,  861,  950, 1044, 1136,\n",
    " 1228, 1311, 1393, 1481, 1564, 1652, 1735, 1815, 1905, 1991, 2076, 2157,\n",
    " 2228, 2308, 2381, 2455, 2531, 2609,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_size = 1\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "\n",
    "plt.title(\"Evaluation - Win ratio\")\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Win ratio\")\n",
    "\n",
    "x = np.arange(30 - window_size + 1)\n",
    "\n",
    "plt.plot(x, smooth(wins_1, window_size), label=\"1 simulation\")\n",
    "plt.plot(x, smooth(wins_2, window_size), label=\"5 simulations\")\n",
    "plt.plot(x, smooth(wins_3, window_size), label=\"10 simulations\")\n",
    "plt.plot(x, smooth(wins_4, window_size), label=\"25 simulations\")\n",
    "plt.plot(x, smooth(wins_5, window_size), label=\"50 simulations\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_rate_1 = np.array(unique_trajectories_1)/np.array(seen_trajectories_1)\n",
    "exp_rate_2 = np.array(unique_trajectories_2)/np.array(seen_trajectories_2)\n",
    "exp_rate_3 = np.array(unique_trajectories_3)/np.array(seen_trajectories_3)\n",
    "exp_rate_4 = np.array(unique_trajectories_4)/np.array(seen_trajectories_4)\n",
    "exp_rate_5 = np.array(unique_trajectories_5)/np.array(seen_trajectories_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_size = 3\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "\n",
    "plt.title(\"Evaluation - Exploration rate\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"exploration rate (unique/seen)\")\n",
    "\n",
    "x = np.arange(30 - window_size + 1)\n",
    "\n",
    "plt.plot(x, smooth(exp_rate_1, window_size), label=\"1 simulation\")\n",
    "plt.plot(x, smooth(exp_rate_2, window_size), label=\"5 simulations\")\n",
    "plt.plot(x, smooth(exp_rate_3, window_size), label=\"10 simulations\")\n",
    "plt.plot(x, smooth(exp_rate_4, window_size), label=\"25 simulations\")\n",
    "plt.plot(x, smooth(exp_rate_5, window_size), label=\"50 simulations\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play against agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1 simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_num_sim_1_29\n"
     ]
    }
   ],
   "source": [
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "last_model_1 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_num_sim_1\"\n",
    ")\n",
    "last_model_1.load(29)\n",
    "last_agent_1 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=last_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 1 | 0 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.711866021156311\n",
      "policy:\n",
      " 0.0 | 0.12257396429777145 | 0.12419667094945908\n",
      " 0.12407302111387253 | 0.12753811478614807 | 0.12530553340911865\n",
      " 0.12396594882011414 | 0.12518030405044556 | 0.1271665096282959\n",
      "===========\n",
      "choose from [0 1 1 1 1 1 1 1 1] :4\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: -0.37590357661247253\n",
      "policy:\n",
      " 0.0 | 0.0020327346865087748 | 0.5183062553405762\n",
      " 0.003529558191075921 | 0.0 | 0.0014635485131293535\n",
      " 0.46861571073532104 | 0.00167736760340631 | 0.004374813288450241\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 1\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.48715829849243164\n",
      "policy:\n",
      " 0.0 | 0.1685009002685547 | 0.0\n",
      " 0.16415110230445862 | 0.0 | 0.16959606111049652\n",
      " 0.16284164786338806 | 0.1740127056837082 | 0.16089759767055511\n",
      "===========\n",
      "choose from [0 1 0 1 0 1 1 1 1] :1\n",
      "===========\n",
      " 1 | 2 | 1\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.8098182678222656\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.02507132850587368 | 0.0 | 0.023622995242476463\n",
      " 0.4726221561431885 | 0.0035724397748708725 | 0.47511106729507446\n",
      "===========\n",
      "===========\n",
      " 1 | 2 | 1\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 1\n",
      "-----------\n",
      "value: -0.801848292350769\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.23973308503627777 | 0.0 | 0.2945384085178375\n",
      " 0.20676611363887787 | 0.2589624226093292 | 0.0\n",
      "===========\n",
      "choose from [0 0 0 1 0 1 1 1 0] :7\n",
      "===========\n",
      " 1 | 2 | 1\n",
      " 0 | 2 | 0\n",
      " 0 | 2 | 1\n",
      "-----------\n",
      "value: 0.8137645721435547\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.09966915100812912 | 0.0 | 0.8891100287437439\n",
      " 0.011220821179449558 | 0.0 | 0.0\n",
      "===========\n",
      "Player -1 won the game after 6 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(last_agent_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_num_sim_1_27\n"
     ]
    }
   ],
   "source": [
    "best_version = np.argmax(wins_1)\n",
    "\n",
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "best_model_1 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_num_sim_1\"\n",
    ")\n",
    "best_model_1.load(best_version)\n",
    "best_agent_1 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=best_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 1 | 0 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.6922861337661743\n",
      "policy:\n",
      " 0.0 | 0.12274239957332611 | 0.12388904392719269\n",
      " 0.12443283945322037 | 0.12714330852031708 | 0.12608842551708221\n",
      " 0.12513135373592377 | 0.12429550290107727 | 0.12627707421779633\n",
      "===========\n",
      "choose from [0 1 1 1 1 1 1 1 1] :4\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: -0.626474142074585\n",
      "policy:\n",
      " 0.0 | 0.001964862458407879 | 0.5256150960922241\n",
      " 0.0033094121608883142 | 0.0 | 0.00135122484061867\n",
      " 0.4624120593070984 | 0.0015447043115273118 | 0.0038026440888643265\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 1\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.5683318972587585\n",
      "policy:\n",
      " 0.0 | 0.1708863228559494 | 0.0\n",
      " 0.16853787004947662 | 0.0 | 0.16573548316955566\n",
      " 0.16030126810073853 | 0.17600077390670776 | 0.1585383415222168\n",
      "===========\n",
      "choose from [0 1 0 1 0 1 1 1 1] :1\n",
      "===========\n",
      " 1 | 2 | 1\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.7796698808670044\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0274482574313879 | 0.0 | 0.0242726169526577\n",
      " 0.4788435995578766 | 0.003356839995831251 | 0.4660786986351013\n",
      "===========\n",
      "===========\n",
      " 1 | 2 | 1\n",
      " 0 | 2 | 0\n",
      " 1 | 0 | 0\n",
      "-----------\n",
      "value: -0.7973103523254395\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.2645600438117981 | 0.0 | 0.24139203131198883\n",
      " 0.0 | 0.2770766019821167 | 0.216971293091774\n",
      "===========\n",
      "choose from [0 0 0 1 0 1 0 1 1] :7\n",
      "===========\n",
      " 1 | 2 | 1\n",
      " 0 | 2 | 0\n",
      " 1 | 2 | 0\n",
      "-----------\n",
      "value: 0.5618090629577637\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.5639448165893555 | 0.0 | 0.3088671863079071\n",
      " 0.0 | 0.0 | 0.1271880567073822\n",
      "===========\n",
      "Player -1 won the game after 6 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(best_agent_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_num_sim_5_29\n"
     ]
    }
   ],
   "source": [
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "last_model_5 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_num_sim_5\"\n",
    ")\n",
    "last_model_5.load(29)\n",
    "last_agent_5 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=last_model_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 0 | 1\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.5724469423294067\n",
      "policy:\n",
      " 0.0017893679905682802 | 0.49553078413009644 | 0.0\n",
      " 0.004711893852800131 | 0.005014672875404358 | 0.4858652353286743\n",
      " 0.0010226625017821789 | 0.00438831327483058 | 0.0016770695801824331\n",
      "===========\n",
      "choose from [1 1 0 1 1 1 1 1 1] :4\n",
      "===========\n",
      " 0 | 0 | 1\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: -0.848258376121521\n",
      "policy:\n",
      " 0.4328027665615082 | 0.1066092848777771 | 0.0\n",
      " 0.011434826999902725 | 0.0 | 0.07263320684432983\n",
      " 0.03686542809009552 | 0.008465996943414211 | 0.331188440322876\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 1\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.6074105501174927\n",
      "policy:\n",
      " 0.0 | 0.12368340790271759 | 0.0\n",
      " 0.2435501366853714 | 0.0 | 0.38455289602279663\n",
      " 0.004988158121705055 | 0.2386942356824875 | 0.00453117024153471\n",
      "===========\n",
      "choose from [0 1 0 1 0 1 1 1 1] :1\n",
      "===========\n",
      " 1 | 2 | 1\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.7649186849594116\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.05389039218425751 | 0.0 | 0.047110769897699356\n",
      " 0.5621837377548218 | 0.005623773206025362 | 0.3311913013458252\n",
      "===========\n",
      "===========\n",
      " 1 | 2 | 1\n",
      " 0 | 2 | 0\n",
      " 1 | 0 | 0\n",
      "-----------\n",
      "value: -0.9847828149795532\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.002245355164632201 | 0.0 | 0.002480623312294483\n",
      " 0.0 | 0.995034396648407 | 0.00023960541875567287\n",
      "===========\n",
      "choose from [0 0 0 1 0 1 0 1 1] :7\n",
      "===========\n",
      " 1 | 2 | 1\n",
      " 0 | 2 | 0\n",
      " 1 | 2 | 0\n",
      "-----------\n",
      "value: -0.7502163648605347\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.9588682651519775 | 0.0 | 0.005150439217686653\n",
      " 0.0 | 0.0 | 0.03598127141594887\n",
      "===========\n",
      "Player -1 won the game after 6 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(last_agent_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_num_sim_5_17\n"
     ]
    }
   ],
   "source": [
    "best_version = np.argmax(wins_2)\n",
    "\n",
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "best_model_5 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_num_sim_5\"\n",
    ")\n",
    "best_model_5.load(best_version)\n",
    "best_agent_5 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=best_model_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: -0.07387059181928635\n",
      "policy:\n",
      " 0.017696963623166084 | 0.22929993271827698 | 0.020827094092965126\n",
      " 0.2271636426448822 | 0.0 | 0.23698647320270538\n",
      " 0.02083319053053856 | 0.2220897227525711 | 0.025102995336055756\n",
      "===========\n",
      "choose from [1 1 1 1 0 1 1 1 1] :0\n",
      "===========\n",
      " 2 | 0 | 0\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: -0.171963632106781\n",
      "policy:\n",
      " 0.0 | 0.04342084378004074 | 0.2495594024658203\n",
      " 0.05717974901199341 | 0.0 | 0.07606644183397293\n",
      " 0.3829653859138489 | 0.12162541598081589 | 0.06918275356292725\n",
      "===========\n",
      "===========\n",
      " 2 | 0 | 0\n",
      " 0 | 1 | 0\n",
      " 1 | 0 | 0\n",
      "-----------\n",
      "value: 0.42682763934135437\n",
      "policy:\n",
      " 0.0 | 0.17396633327007294 | 0.4139486253261566\n",
      " 0.20220328867435455 | 0.0 | 0.05469713360071182\n",
      " 0.0 | 0.07301262766122818 | 0.08217199146747589\n",
      "===========\n",
      "choose from [0 1 1 1 0 1 0 1 1] :2\n",
      "===========\n",
      " 2 | 0 | 2\n",
      " 0 | 1 | 0\n",
      " 1 | 0 | 0\n",
      "-----------\n",
      "value: 0.4325946271419525\n",
      "policy:\n",
      " 0.0 | 0.012927654199302197 | 0.0\n",
      " 0.1063714399933815 | 0.0 | 0.07489924132823944\n",
      " 0.0 | 0.4448843002319336 | 0.3609173893928528\n",
      "===========\n",
      "===========\n",
      " 2 | 0 | 2\n",
      " 0 | 1 | 0\n",
      " 1 | 1 | 0\n",
      "-----------\n",
      "value: -0.9529510140419006\n",
      "policy:\n",
      " 0.0 | 0.6427503824234009 | 0.0\n",
      " 0.07380406558513641 | 0.0 | 0.2034529149532318\n",
      " 0.0 | 0.0 | 0.07999259233474731\n",
      "===========\n",
      "choose from [0 1 0 1 0 1 0 0 1] :1\n",
      "===========\n",
      " 2 | 2 | 2\n",
      " 0 | 1 | 0\n",
      " 1 | 1 | 0\n",
      "-----------\n",
      "value: -0.9828329086303711\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.05543643236160278 | 0.0 | 0.006886724848300219\n",
      " 0.0 | 0.0 | 0.9376768469810486\n",
      "===========\n",
      "Player -1 won the game after 6 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(best_agent_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_num_sim_10_29\n"
     ]
    }
   ],
   "source": [
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "last_model_10 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_num_sim_10\"\n",
    ")\n",
    "last_model_10.load(29)\n",
    "last_agent_10 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=last_model_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.2994835078716278\n",
      "policy:\n",
      " 0.1277066320180893 | 0.0 | 0.1250852793455124\n",
      " 0.12715134024620056 | 0.11835954338312149 | 0.12429244071245193\n",
      " 0.12466376274824142 | 0.1256548911333084 | 0.1270861029624939\n",
      "===========\n",
      "choose from [1 0 1 1 1 1 1 1 1] :4\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.26716136932373047\n",
      "policy:\n",
      " 0.18026530742645264 | 0.0 | 0.1725406050682068\n",
      " 0.1423434317111969 | 0.0 | 0.143246591091156\n",
      " 0.11479576677083969 | 0.13169504702091217 | 0.1151132583618164\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.6341065764427185\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.21283935010433197\n",
      " 0.13250420987606049 | 0.0 | 0.18218372762203217\n",
      " 0.18358026444911957 | 0.1567244827747345 | 0.1321680247783661\n",
      "===========\n",
      "choose from [0 0 1 1 0 1 1 1 1] :2\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.6217366456985474\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.272451788187027 | 0.0 | 0.11194491386413574\n",
      " 0.38688188791275024 | 0.14207716286182404 | 0.08664431422948837\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 2 | 0\n",
      " 1 | 0 | 0\n",
      "-----------\n",
      "value: 0.7926491498947144\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.2077859342098236 | 0.0 | 0.37872615456581116\n",
      " 0.0 | 0.06831888854503632 | 0.3451690375804901\n",
      "===========\n",
      "choose from [0 0 0 1 0 1 0 1 1] :3\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 2 | 2 | 0\n",
      " 1 | 0 | 0\n",
      "-----------\n",
      "value: 0.8253110647201538\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.10157930850982666\n",
      " 0.0 | 0.5885008573532104 | 0.3099198341369629\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 2 | 2 | 0\n",
      " 1 | 1 | 0\n",
      "-----------\n",
      "value: -0.7315388917922974\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.6987506747245789\n",
      " 0.0 | 0.0 | 0.30124932527542114\n",
      "===========\n",
      "choose from [0 0 0 0 0 1 0 0 1] :5\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 2 | 2 | 2\n",
      " 1 | 1 | 0\n",
      "-----------\n",
      "value: -0.38603582978248596\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 1.0\n",
      "===========\n",
      "Player -1 won the game after 8 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(last_agent_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_num_sim_10_24\n"
     ]
    }
   ],
   "source": [
    "best_version = np.argmax(wins_3)\n",
    "\n",
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "best_model_10 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_num_sim_10\"\n",
    ")\n",
    "best_model_10.load(best_version)\n",
    "best_agent_10 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=best_model_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.36284852027893066\n",
      "policy:\n",
      " 0.12995851039886475 | 0.0 | 0.12237095087766647\n",
      " 0.12261730432510376 | 0.12102408707141876 | 0.12280742824077606\n",
      " 0.1280800998210907 | 0.12364552915096283 | 0.12949611246585846\n",
      "===========\n",
      "choose from [1 0 1 1 1 1 1 1 1] :4\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: -0.23899570107460022\n",
      "policy:\n",
      " 0.19100123643875122 | 0.0 | 0.1719706654548645\n",
      " 0.13126355409622192 | 0.0 | 0.14417625963687897\n",
      " 0.12369199842214584 | 0.12231487780809402 | 0.11558141559362411\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.8429874777793884\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.20668621361255646\n",
      " 0.1230028048157692 | 0.0 | 0.18941427767276764\n",
      " 0.186287060379982 | 0.15682940185070038 | 0.13778021931648254\n",
      "===========\n",
      "choose from [0 0 1 1 0 1 1 1 1] :2\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.7400569915771484\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.27499672770500183 | 0.0 | 0.11078060418367386\n",
      " 0.39611437916755676 | 0.1359831690788269 | 0.08212509006261826\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 2 | 0\n",
      " 1 | 0 | 0\n",
      "-----------\n",
      "value: 0.8960341811180115\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.19544918835163116 | 0.0 | 0.39034008979797363\n",
      " 0.0 | 0.06745383143424988 | 0.3467569053173065\n",
      "===========\n",
      "choose from [0 0 0 1 0 1 0 1 1] :3\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 2 | 2 | 0\n",
      " 1 | 0 | 0\n",
      "-----------\n",
      "value: 0.8358655571937561\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.1065002828836441\n",
      " 0.0 | 0.5920937657356262 | 0.30140596628189087\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 2 | 2 | 0\n",
      " 1 | 1 | 0\n",
      "-----------\n",
      "value: -0.5881682634353638\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.7005702257156372\n",
      " 0.0 | 0.0 | 0.2994297742843628\n",
      "===========\n",
      "choose from [0 0 0 0 0 1 0 0 1] :5\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 2 | 2 | 2\n",
      " 1 | 1 | 0\n",
      "-----------\n",
      "value: -0.25397178530693054\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 1.0\n",
      "===========\n",
      "Player -1 won the game after 8 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(best_agent_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25 simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_num_sim_25_29\n"
     ]
    }
   ],
   "source": [
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "last_model_25 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_num_sim_25\"\n",
    ")\n",
    "last_model_25.load(29)\n",
    "last_agent_25 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=last_model_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.18942998349666595\n",
      "policy:\n",
      " 0.13265259563922882 | 0.0 | 0.13237188756465912\n",
      " 0.12343176454305649 | 0.12292442470788956 | 0.11978807300329208\n",
      " 0.11554447561502457 | 0.12788130342960358 | 0.12540557980537415\n",
      "===========\n",
      "choose from [1 0 1 1 1 1 1 1 1] :4\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.26299843192100525\n",
      "policy:\n",
      " 0.16118228435516357 | 0.0 | 0.16194212436676025\n",
      " 0.1372983604669571 | 0.0 | 0.14062388241291046\n",
      " 0.1282852292060852 | 0.14033710956573486 | 0.13033097982406616\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.46800050139427185\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.18568183481693268\n",
      " 0.19251246750354767 | 0.0 | 0.17482376098632812\n",
      " 0.2030743956565857 | 0.10834822058677673 | 0.13555927574634552\n",
      "===========\n",
      "choose from [0 0 1 1 0 1 1 1 1] :2\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.6463099122047424\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.3047381043434143 | 0.0 | 0.11342392861843109\n",
      " 0.28833475708961487 | 0.15709353983402252 | 0.13640962541103363\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 1 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: -0.7698773145675659\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.101125068962574\n",
      " 0.7962546944618225 | 0.04463757202029228 | 0.0579826720058918\n",
      "===========\n",
      "choose from [0 0 0 0 0 1 1 1 1] :6\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 1 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "value: -0.08608276396989822\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.21279963850975037\n",
      " 0.0 | 0.6413969993591309 | 0.14580337703227997\n",
      "===========\n",
      "Player -1 won the game after 6 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(last_agent_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_num_sim_25_10\n"
     ]
    }
   ],
   "source": [
    "best_version = np.argmax(wins_4)\n",
    "\n",
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "best_model_25 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_num_sim_25\"\n",
    ")\n",
    "best_model_25.load(best_version)\n",
    "best_agent_25 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=best_model_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 1 | 0\n",
      "-----------\n",
      "value: 0.14598684012889862\n",
      "policy:\n",
      " 0.11884108930826187 | 0.1258239895105362 | 0.1271355152130127\n",
      " 0.12747058272361755 | 0.12493299692869186 | 0.12389162182807922\n",
      " 0.12647902965545654 | 0.0 | 0.12542520463466644\n",
      "===========\n",
      "choose from [1 1 1 1 1 1 1 0 1] :4\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 1 | 0\n",
      "-----------\n",
      "value: 0.13837186992168427\n",
      "policy:\n",
      " 0.0887887254357338 | 0.14568401873111725 | 0.14036254584789276\n",
      " 0.15094037353992462 | 0.0 | 0.13974769413471222\n",
      " 0.15831148624420166 | 0.0 | 0.1761651188135147\n",
      "===========\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 1 | 1\n",
      "-----------\n",
      "value: 0.6193112730979919\n",
      "policy:\n",
      " 0.13634832203388214 | 0.1402982473373413 | 0.22404076159000397\n",
      " 0.14693664014339447 | 0.0 | 0.2230035811662674\n",
      " 0.1293724626302719 | 0.0 | 0.0\n",
      "===========\n",
      "choose from [1 1 1 1 0 1 1 0 0] :6\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 2 | 1 | 1\n",
      "-----------\n",
      "value: 0.5485832691192627\n",
      "policy:\n",
      " 0.1234283298254013 | 0.10103730857372284 | 0.18482866883277893\n",
      " 0.1919664889574051 | 0.0 | 0.39873918890953064\n",
      " 0.0 | 0.0 | 0.0\n",
      "===========\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 1\n",
      " 2 | 1 | 1\n",
      "-----------\n",
      "value: -0.06254974007606506\n",
      "policy:\n",
      " 0.12371599674224854 | 0.17686404287815094 | 0.5847273468971252\n",
      " 0.11469268798828125 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.0\n",
      "===========\n",
      "choose from [1 1 1 1 0 0 0 0 0] :2\n",
      "===========\n",
      " 0 | 0 | 2\n",
      " 0 | 2 | 1\n",
      " 2 | 1 | 1\n",
      "-----------\n",
      "value: 0.44782009720802307\n",
      "policy:\n",
      " 0.3588124215602875 | 0.33266299962997437 | 0.0\n",
      " 0.30852454900741577 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.0\n",
      "===========\n",
      "Player -1 won the game after 6 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(best_agent_25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50 simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_num_sim_50_29\n"
     ]
    }
   ],
   "source": [
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "last_model_50 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_num_sim_50\"\n",
    ")\n",
    "last_model_50.load(29)\n",
    "last_agent_50 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=last_model_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 0 | 0\n",
      " 1 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.11961159110069275\n",
      "policy:\n",
      " 0.12827013432979584 | 0.12767603993415833 | 0.11347468942403793\n",
      " 0.0 | 0.12763318419456482 | 0.12615370750427246\n",
      " 0.12883061170578003 | 0.12275339663028717 | 0.12520818412303925\n",
      "===========\n",
      "choose from [1 1 1 0 1 1 1 1 1] :4\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 1 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: -0.15868309140205383\n",
      "policy:\n",
      " 0.14051812887191772 | 0.16274631023406982 | 0.12299371510744095\n",
      " 0.0 | 0.0 | 0.13898049294948578\n",
      " 0.16554057598114014 | 0.15114058554172516 | 0.11808015406131744\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 1 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.792395830154419\n",
      "policy:\n",
      " 0.0 | 0.19189420342445374 | 0.17256633937358856\n",
      " 0.0 | 0.0 | 0.11748599261045456\n",
      " 0.17251893877983093 | 0.20054695010185242 | 0.1449875384569168\n",
      "===========\n",
      "choose from [0 1 1 0 0 1 1 1 1] :6\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 1 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "value: 0.6242400407791138\n",
      "policy:\n",
      " 0.0 | 0.27938756346702576 | 0.18132571876049042\n",
      " 0.0 | 0.0 | 0.19060064852237701\n",
      " 0.0 | 0.15727505087852478 | 0.19141100347042084\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 1 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "value: -0.34095412492752075\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.8397639393806458\n",
      " 0.0 | 0.0 | 0.03568089380860329\n",
      " 0.0 | 0.06642521917819977 | 0.05812995135784149\n",
      "===========\n",
      "choose from [0 0 1 0 0 1 0 1 1] :2\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 1 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "value: -0.36841458082199097\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.2623995840549469\n",
      " 0.0 | 0.2061784267425537 | 0.5314220190048218\n",
      "===========\n",
      "Player -1 won the game after 6 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(last_agent_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_num_sim_50_14\n"
     ]
    }
   ],
   "source": [
    "best_version = np.argmax(wins_5)\n",
    "\n",
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "best_model_50 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_num_sim_50\"\n",
    ")\n",
    "best_model_50.load(best_version)\n",
    "best_agent_50 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=best_model_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 1\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.2764529287815094\n",
      "policy:\n",
      " 0.12305056303739548 | 0.130971759557724 | 0.12512312829494476\n",
      " 0.12865273654460907 | 0.12457046657800674 | 0.0\n",
      " 0.12727676331996918 | 0.11598651856184006 | 0.12436805665493011\n",
      "===========\n",
      "choose from [1 1 1 1 1 0 1 1 1] :4\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 1\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.025134701281785965\n",
      "policy:\n",
      " 0.12587858736515045 | 0.14419545233249664 | 0.1893060803413391\n",
      " 0.14415279030799866 | 0.0 | 0.0\n",
      " 0.09181634336709976 | 0.14241370558738708 | 0.16223706305027008\n",
      "===========\n",
      "===========\n",
      " 0 | 0 | 1\n",
      " 0 | 2 | 1\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.8838173747062683\n",
      "policy:\n",
      " 0.14246252179145813 | 0.21850432455539703 | 0.0\n",
      " 0.14929452538490295 | 0.0 | 0.0\n",
      " 0.12389225512742996 | 0.1908511072397232 | 0.1749953031539917\n",
      "===========\n",
      "choose from [1 1 0 1 0 0 1 1 1] :8\n",
      "===========\n",
      " 0 | 0 | 1\n",
      " 0 | 2 | 1\n",
      " 0 | 0 | 2\n",
      "-----------\n",
      "value: 0.08368376642465591\n",
      "policy:\n",
      " 0.238701730966568 | 0.2900160253047943 | 0.0\n",
      " 0.16842328011989594 | 0.0 | 0.0\n",
      " 0.17612476646900177 | 0.12673419713974 | 0.0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 1\n",
      " 0 | 2 | 1\n",
      " 0 | 0 | 2\n",
      "-----------\n",
      "value: -0.32686808705329895\n",
      "policy:\n",
      " 0.7636496424674988 | 0.0 | 0.0\n",
      " 0.06863585114479065 | 0.0 | 0.0\n",
      " 0.09739571809768677 | 0.07031877338886261 | 0.0\n",
      "===========\n",
      "choose from [1 0 0 1 0 0 1 1 0] :0\n",
      "===========\n",
      " 2 | 1 | 1\n",
      " 0 | 2 | 1\n",
      " 0 | 0 | 2\n",
      "-----------\n",
      "value: 0.44541746377944946\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.35860031843185425 | 0.0 | 0.0\n",
      " 0.20376868546009064 | 0.43763092160224915 | 0.0\n",
      "===========\n",
      "Player -1 won the game after 6 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(best_agent_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
