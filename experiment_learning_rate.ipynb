{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: TicTacToe - Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from pipeline import Pipeline, agent_vs_player, agent_vs_agent\n",
    "import memory\n",
    "import model\n",
    "import agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every 5 iterations the learning rate will be decreased to (learning rate)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCTS = {\n",
    "    'c_puct': 1.0,\n",
    "    'dir_alpha': 0.6,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 10,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 10\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 0,\n",
    "    'show_games': False\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.2,\n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 512,\n",
    "    'num_filters_value': 512,\n",
    "    'num_filters_tower': 512,\n",
    "    'num_residual_blocks': 3,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 512\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"tictactoe_lr_0_2\", \"TicTacToe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5000, 3, 3, 3)\n",
      "model_y_outcomes: (5000,)\n",
      "model_y_probabilities: (5000, 9)\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 16.2961 - value_loss: 1.8824 - policy_loss: 20.5502 - val_loss: 33.5617 - val_value_loss: 2.0560 - val_policy_loss: 54.8915\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 1s 172us/step - loss: 12.5458 - value_loss: 2.1520 - policy_loss: 12.7830 - val_loss: 8.3320 - val_value_loss: 2.0560 - val_policy_loss: 4.4839\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 1s 171us/step - loss: 8.3846 - value_loss: 2.1520 - policy_loss: 4.5207 - val_loss: 7.5944 - val_value_loss: 2.0560 - val_policy_loss: 3.0737\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 1s 171us/step - loss: 7.2967 - value_loss: 2.1519 - policy_loss: 2.4097 - val_loss: 7.2844 - val_value_loss: 2.0560 - val_policy_loss: 2.5176\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 1s 172us/step - loss: 7.1589 - value_loss: 2.1519 - policy_loss: 2.1979 - val_loss: 7.1570 - val_value_loss: 2.0560 - val_policy_loss: 2.3263\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 1s 171us/step - loss: 7.1428 - value_loss: 2.1519 - policy_loss: 2.2289 - val_loss: 7.0418 - val_value_loss: 2.0560 - val_policy_loss: 2.1589\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 1s 171us/step - loss: 7.0752 - value_loss: 2.1519 - policy_loss: 2.1565 - val_loss: 6.9916 - val_value_loss: 2.0560 - val_policy_loss: 2.1210\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 1s 172us/step - loss: 7.0408 - value_loss: 2.1519 - policy_loss: 2.1501 - val_loss: 6.9397 - val_value_loss: 2.0559 - val_policy_loss: 2.0791\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 1s 172us/step - loss: 6.9936 - value_loss: 2.1518 - policy_loss: 2.1175 - val_loss: 6.8923 - val_value_loss: 2.0559 - val_policy_loss: 2.0461\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 1s 171us/step - loss: 6.9087 - value_loss: 2.1518 - policy_loss: 2.0092 - val_loss: 6.8332 - val_value_loss: 2.0559 - val_policy_loss: 1.9892\n",
      "Saved model  tictactoe_lr_0_2_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.01\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.9008 - value_loss: 2.2182 - policy_loss: 1.9886 - val_loss: 6.8316 - val_value_loss: 2.1716 - val_policy_loss: 1.9310\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.8555 - value_loss: 2.2126 - policy_loss: 1.9641 - val_loss: 6.6534 - val_value_loss: 1.8060 - val_policy_loss: 2.0005\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.4319 - value_loss: 1.4061 - policy_loss: 1.9837 - val_loss: 6.3387 - val_value_loss: 1.3082 - val_policy_loss: 1.9290\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2604 - value_loss: 1.1592 - policy_loss: 1.9474 - val_loss: 6.2441 - val_value_loss: 1.1374 - val_policy_loss: 1.9698\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0939 - value_loss: 0.9372 - policy_loss: 1.8957 - val_loss: 6.0950 - val_value_loss: 0.9495 - val_policy_loss: 1.9190\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1085 - value_loss: 0.9929 - policy_loss: 1.9221 - val_loss: 6.1388 - val_value_loss: 1.0501 - val_policy_loss: 1.9523\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0188 - value_loss: 0.8843 - policy_loss: 1.9038 - val_loss: 6.0584 - val_value_loss: 0.9530 - val_policy_loss: 1.9471\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0501 - value_loss: 0.9004 - policy_loss: 2.0080 - val_loss: 6.1778 - val_value_loss: 1.0627 - val_policy_loss: 2.1336\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9554 - value_loss: 0.8489 - policy_loss: 1.9280 - val_loss: 5.9891 - val_value_loss: 0.9731 - val_policy_loss: 1.9036\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.8810 - value_loss: 0.8307 - policy_loss: 1.8550 - val_loss: 5.9194 - val_value_loss: 0.9202 - val_policy_loss: 1.8746\n",
      "Saved model  tictactoe_lr_0_2_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.0\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.8576 - value_loss: 0.8486 - policy_loss: 1.8476 - val_loss: 5.8423 - val_value_loss: 0.8711 - val_policy_loss: 1.8266\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.7987 - value_loss: 0.8151 - policy_loss: 1.8202 - val_loss: 5.7912 - val_value_loss: 0.8369 - val_policy_loss: 1.8152\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.7707 - value_loss: 0.7890 - policy_loss: 1.8467 - val_loss: 5.7396 - val_value_loss: 0.8162 - val_policy_loss: 1.7890\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.6966 - value_loss: 0.7577 - policy_loss: 1.7860 - val_loss: 5.7125 - val_value_loss: 0.8098 - val_policy_loss: 1.7973\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.6850 - value_loss: 0.7918 - policy_loss: 1.7842 - val_loss: 5.7022 - val_value_loss: 0.8204 - val_policy_loss: 1.8214\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.6134 - value_loss: 0.7278 - policy_loss: 1.7604 - val_loss: 5.6519 - val_value_loss: 0.8038 - val_policy_loss: 1.7925\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.6049 - value_loss: 0.7241 - policy_loss: 1.8023 - val_loss: 5.6244 - val_value_loss: 0.7849 - val_policy_loss: 1.8111\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.5602 - value_loss: 0.7421 - policy_loss: 1.7493 - val_loss: 5.5918 - val_value_loss: 0.8203 - val_policy_loss: 1.7648\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.5054 - value_loss: 0.6844 - policy_loss: 1.7516 - val_loss: 5.5662 - val_value_loss: 0.7938 - val_policy_loss: 1.7942\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.4967 - value_loss: 0.7043 - policy_loss: 1.7683 - val_loss: 5.5160 - val_value_loss: 0.7944 - val_policy_loss: 1.7469\n",
      "Saved model  tictactoe_lr_0_2_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.02\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.4962 - value_loss: 0.7919 - policy_loss: 1.7332 - val_loss: 5.5056 - val_value_loss: 0.8551 - val_policy_loss: 1.7188\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.4377 - value_loss: 0.7404 - policy_loss: 1.7210 - val_loss: 5.5416 - val_value_loss: 0.9172 - val_policy_loss: 1.7817\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 5.4173 - value_loss: 0.7052 - policy_loss: 1.7681 - val_loss: 5.4712 - val_value_loss: 0.9010 - val_policy_loss: 1.7097\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.3619 - value_loss: 0.7275 - policy_loss: 1.6874 - val_loss: 5.4333 - val_value_loss: 0.8467 - val_policy_loss: 1.7403\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.3151 - value_loss: 0.6286 - policy_loss: 1.7449 - val_loss: 5.4194 - val_value_loss: 0.8364 - val_policy_loss: 1.7749\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.2961 - value_loss: 0.6594 - policy_loss: 1.7278 - val_loss: 5.3440 - val_value_loss: 0.8229 - val_policy_loss: 1.6892\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.2360 - value_loss: 0.6165 - policy_loss: 1.7019 - val_loss: 5.3645 - val_value_loss: 0.8571 - val_policy_loss: 1.7473\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.2124 - value_loss: 0.6264 - policy_loss: 1.6960 - val_loss: 5.3488 - val_value_loss: 0.8911 - val_policy_loss: 1.7327\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.1652 - value_loss: 0.6007 - policy_loss: 1.6780 - val_loss: 5.2843 - val_value_loss: 0.7904 - val_policy_loss: 1.7550\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.1564 - value_loss: 0.6347 - policy_loss: 1.6769 - val_loss: 5.2338 - val_value_loss: 0.7914 - val_policy_loss: 1.7033\n",
      "Saved model  tictactoe_lr_0_2_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.9 - draw ratio 0.0\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.1459 - value_loss: 0.6811 - policy_loss: 1.6599 - val_loss: 5.2209 - val_value_loss: 0.8031 - val_policy_loss: 1.7161\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.1030 - value_loss: 0.6426 - policy_loss: 1.6628 - val_loss: 5.1878 - val_value_loss: 0.8202 - val_policy_loss: 1.6828\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.0528 - value_loss: 0.6179 - policy_loss: 1.6367 - val_loss: 5.1635 - val_value_loss: 0.8041 - val_policy_loss: 1.6997\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.0324 - value_loss: 0.6003 - policy_loss: 1.6628 - val_loss: 5.0978 - val_value_loss: 0.7303 - val_policy_loss: 1.6913\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.9729 - value_loss: 0.5549 - policy_loss: 1.6384 - val_loss: 5.0998 - val_value_loss: 0.7590 - val_policy_loss: 1.7155\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.9432 - value_loss: 0.5439 - policy_loss: 1.6388 - val_loss: 5.1044 - val_value_loss: 0.7934 - val_policy_loss: 1.7392\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.9270 - value_loss: 0.5377 - policy_loss: 1.6612 - val_loss: 5.0246 - val_value_loss: 0.7338 - val_policy_loss: 1.6875\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.8744 - value_loss: 0.5282 - policy_loss: 1.6138 - val_loss: 5.0038 - val_value_loss: 0.7479 - val_policy_loss: 1.6799\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.8478 - value_loss: 0.5137 - policy_loss: 1.6231 - val_loss: 4.9690 - val_value_loss: 0.7230 - val_policy_loss: 1.6831\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.8171 - value_loss: 0.5098 - policy_loss: 1.6134 - val_loss: 4.9224 - val_value_loss: 0.6936 - val_policy_loss: 1.6669\n",
      "Saved model  tictactoe_lr_0_2_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.0\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 4.8747 - value_loss: 0.6724 - policy_loss: 1.6033 - val_loss: 4.9098 - val_value_loss: 0.7189 - val_policy_loss: 1.6404\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.8261 - value_loss: 0.6061 - policy_loss: 1.5961 - val_loss: 4.8850 - val_value_loss: 0.6958 - val_policy_loss: 1.6376\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.8003 - value_loss: 0.5802 - policy_loss: 1.5941 - val_loss: 4.8670 - val_value_loss: 0.6846 - val_policy_loss: 1.6362\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.7805 - value_loss: 0.5663 - policy_loss: 1.5919 - val_loss: 4.8845 - val_value_loss: 0.7435 - val_policy_loss: 1.6360\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.7629 - value_loss: 0.5566 - policy_loss: 1.5899 - val_loss: 4.8483 - val_value_loss: 0.6980 - val_policy_loss: 1.6324\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.7432 - value_loss: 0.5420 - policy_loss: 1.5886 - val_loss: 4.8264 - val_value_loss: 0.6788 - val_policy_loss: 1.6312\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.7262 - value_loss: 0.5325 - policy_loss: 1.5873 - val_loss: 4.7993 - val_value_loss: 0.6505 - val_policy_loss: 1.6285\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.7133 - value_loss: 0.5311 - policy_loss: 1.5862 - val_loss: 4.7887 - val_value_loss: 0.6540 - val_policy_loss: 1.6270\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.6999 - value_loss: 0.5277 - policy_loss: 1.5859 - val_loss: 4.7725 - val_value_loss: 0.6476 - val_policy_loss: 1.6244\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.6848 - value_loss: 0.5221 - policy_loss: 1.5845 - val_loss: 4.7559 - val_value_loss: 0.6366 - val_policy_loss: 1.6252\n",
      "Saved model  tictactoe_lr_0_2_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.75 - draw ratio 0.02\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 4.7322 - value_loss: 0.6233 - policy_loss: 1.6012 - val_loss: 4.7356 - val_value_loss: 0.6590 - val_policy_loss: 1.5853\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.6902 - value_loss: 0.5650 - policy_loss: 1.5987 - val_loss: 4.7217 - val_value_loss: 0.6540 - val_policy_loss: 1.5854\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.6659 - value_loss: 0.5391 - policy_loss: 1.5989 - val_loss: 4.7088 - val_value_loss: 0.6553 - val_policy_loss: 1.5813\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.6464 - value_loss: 0.5250 - policy_loss: 1.5967 - val_loss: 4.6890 - val_value_loss: 0.6378 - val_policy_loss: 1.5819\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.6332 - value_loss: 0.5228 - policy_loss: 1.5951 - val_loss: 4.7001 - val_value_loss: 0.6835 - val_policy_loss: 1.5811\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.6170 - value_loss: 0.5128 - policy_loss: 1.5955 - val_loss: 4.6657 - val_value_loss: 0.6399 - val_policy_loss: 1.5784\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.6003 - value_loss: 0.5040 - policy_loss: 1.5935 - val_loss: 4.6579 - val_value_loss: 0.6478 - val_policy_loss: 1.5777\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.5903 - value_loss: 0.5065 - policy_loss: 1.5936 - val_loss: 4.6534 - val_value_loss: 0.6641 - val_policy_loss: 1.5749\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.5779 - value_loss: 0.5038 - policy_loss: 1.5941 - val_loss: 4.6264 - val_value_loss: 0.6285 - val_policy_loss: 1.5788\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.5645 - value_loss: 0.5004 - policy_loss: 1.5931 - val_loss: 4.6152 - val_value_loss: 0.6346 - val_policy_loss: 1.5727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_lr_0_2_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.77 - draw ratio 0.02\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 4.6460 - value_loss: 0.6924 - policy_loss: 1.5864 - val_loss: 4.6388 - val_value_loss: 0.6849 - val_policy_loss: 1.5922\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.5927 - value_loss: 0.6105 - policy_loss: 1.5840 - val_loss: 4.6232 - val_value_loss: 0.6752 - val_policy_loss: 1.5928\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.5663 - value_loss: 0.5821 - policy_loss: 1.5818 - val_loss: 4.6085 - val_value_loss: 0.6692 - val_policy_loss: 1.5916\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.5473 - value_loss: 0.5669 - policy_loss: 1.5811 - val_loss: 4.6020 - val_value_loss: 0.6788 - val_policy_loss: 1.5911\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.5341 - value_loss: 0.5624 - policy_loss: 1.5812 - val_loss: 4.5864 - val_value_loss: 0.6714 - val_policy_loss: 1.5893\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.5219 - value_loss: 0.5604 - policy_loss: 1.5809 - val_loss: 4.5781 - val_value_loss: 0.6769 - val_policy_loss: 1.5892\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.5054 - value_loss: 0.5508 - policy_loss: 1.5795 - val_loss: 4.5649 - val_value_loss: 0.6713 - val_policy_loss: 1.5901\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.4915 - value_loss: 0.5456 - policy_loss: 1.5787 - val_loss: 4.5562 - val_value_loss: 0.6774 - val_policy_loss: 1.5886\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.4793 - value_loss: 0.5426 - policy_loss: 1.5791 - val_loss: 4.5455 - val_value_loss: 0.6757 - val_policy_loss: 1.5907\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.4668 - value_loss: 0.5400 - policy_loss: 1.5784 - val_loss: 4.5392 - val_value_loss: 0.6884 - val_policy_loss: 1.5870\n",
      "Saved model  tictactoe_lr_0_2_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.01\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 4.4937 - value_loss: 0.6042 - policy_loss: 1.5897 - val_loss: 4.5361 - val_value_loss: 0.6594 - val_policy_loss: 1.6316\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.4544 - value_loss: 0.5482 - policy_loss: 1.5888 - val_loss: 4.4941 - val_value_loss: 0.6042 - val_policy_loss: 1.6243\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.4276 - value_loss: 0.5209 - policy_loss: 1.5838 - val_loss: 4.4884 - val_value_loss: 0.6136 - val_policy_loss: 1.6249\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.4154 - value_loss: 0.5100 - policy_loss: 1.5918 - val_loss: 4.4636 - val_value_loss: 0.5809 - val_policy_loss: 1.6294\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.3964 - value_loss: 0.4986 - policy_loss: 1.5866 - val_loss: 4.4524 - val_value_loss: 0.5855 - val_policy_loss: 1.6237\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.3888 - value_loss: 0.5055 - policy_loss: 1.5858 - val_loss: 4.4398 - val_value_loss: 0.5746 - val_policy_loss: 1.6307\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.3795 - value_loss: 0.5027 - policy_loss: 1.5913 - val_loss: 4.4313 - val_value_loss: 0.5811 - val_policy_loss: 1.6284\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.3575 - value_loss: 0.4864 - policy_loss: 1.5848 - val_loss: 4.4154 - val_value_loss: 0.5771 - val_policy_loss: 1.6218\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.3449 - value_loss: 0.4829 - policy_loss: 1.5841 - val_loss: 4.4059 - val_value_loss: 0.5719 - val_policy_loss: 1.6291\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.3360 - value_loss: 0.4847 - policy_loss: 1.5856 - val_loss: 4.4002 - val_value_loss: 0.5874 - val_policy_loss: 1.6231\n",
      "Saved model  tictactoe_lr_0_2_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.03\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 4.3697 - value_loss: 0.5700 - policy_loss: 1.5887 - val_loss: 4.3347 - val_value_loss: 0.5154 - val_policy_loss: 1.5850\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.3272 - value_loss: 0.5077 - policy_loss: 1.5870 - val_loss: 4.3128 - val_value_loss: 0.4910 - val_policy_loss: 1.5865\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.3006 - value_loss: 0.4738 - policy_loss: 1.5885 - val_loss: 4.2981 - val_value_loss: 0.4860 - val_policy_loss: 1.5830\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2829 - value_loss: 0.4609 - policy_loss: 1.5867 - val_loss: 4.2925 - val_value_loss: 0.4930 - val_policy_loss: 1.5855\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2706 - value_loss: 0.4568 - policy_loss: 1.5869 - val_loss: 4.2798 - val_value_loss: 0.4899 - val_policy_loss: 1.5837\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2560 - value_loss: 0.4478 - policy_loss: 1.5875 - val_loss: 4.2686 - val_value_loss: 0.4870 - val_policy_loss: 1.5850\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2408 - value_loss: 0.4405 - policy_loss: 1.5848 - val_loss: 4.2740 - val_value_loss: 0.5188 - val_policy_loss: 1.5844\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.2281 - value_loss: 0.4400 - policy_loss: 1.5805 - val_loss: 4.2533 - val_value_loss: 0.5025 - val_policy_loss: 1.5798\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2145 - value_loss: 0.4355 - policy_loss: 1.5782 - val_loss: 4.2366 - val_value_loss: 0.4896 - val_policy_loss: 1.5797\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.2045 - value_loss: 0.4355 - policy_loss: 1.5787 - val_loss: 4.2288 - val_value_loss: 0.4929 - val_policy_loss: 1.5811\n",
      "Saved model  tictactoe_lr_0_2_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.81 - draw ratio 0.03\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 4.3104 - value_loss: 0.6529 - policy_loss: 1.5889 - val_loss: 4.3140 - val_value_loss: 0.6676 - val_policy_loss: 1.5871\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2730 - value_loss: 0.5895 - policy_loss: 1.5877 - val_loss: 4.2965 - val_value_loss: 0.6448 - val_policy_loss: 1.5852\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2562 - value_loss: 0.5666 - policy_loss: 1.5872 - val_loss: 4.2966 - val_value_loss: 0.6552 - val_policy_loss: 1.5850\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2430 - value_loss: 0.5509 - policy_loss: 1.5865 - val_loss: 4.2934 - val_value_loss: 0.6588 - val_policy_loss: 1.5851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2328 - value_loss: 0.5409 - policy_loss: 1.5863 - val_loss: 4.2797 - val_value_loss: 0.6418 - val_policy_loss: 1.5847\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.2237 - value_loss: 0.5335 - policy_loss: 1.5856 - val_loss: 4.2733 - val_value_loss: 0.6393 - val_policy_loss: 1.5846\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2161 - value_loss: 0.5289 - policy_loss: 1.5850 - val_loss: 4.2594 - val_value_loss: 0.6224 - val_policy_loss: 1.5838\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2077 - value_loss: 0.5228 - policy_loss: 1.5845 - val_loss: 4.2571 - val_value_loss: 0.6279 - val_policy_loss: 1.5838\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2006 - value_loss: 0.5183 - policy_loss: 1.5847 - val_loss: 4.2537 - val_value_loss: 0.6313 - val_policy_loss: 1.5835\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.1951 - value_loss: 0.5178 - policy_loss: 1.5842 - val_loss: 4.2485 - val_value_loss: 0.6312 - val_policy_loss: 1.5831\n",
      "Saved model  tictactoe_lr_0_2_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.72 - draw ratio 0.04\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 4.2913 - value_loss: 0.7081 - policy_loss: 1.5962 - val_loss: 4.2739 - val_value_loss: 0.6916 - val_policy_loss: 1.5837\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2585 - value_loss: 0.6539 - policy_loss: 1.5950 - val_loss: 4.2551 - val_value_loss: 0.6649 - val_policy_loss: 1.5827\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2381 - value_loss: 0.6234 - policy_loss: 1.5945 - val_loss: 4.2489 - val_value_loss: 0.6630 - val_policy_loss: 1.5822\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.2230 - value_loss: 0.6039 - policy_loss: 1.5940 - val_loss: 4.2453 - val_value_loss: 0.6660 - val_policy_loss: 1.5819\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2135 - value_loss: 0.5951 - policy_loss: 1.5935 - val_loss: 4.2306 - val_value_loss: 0.6465 - val_policy_loss: 1.5819\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.2038 - value_loss: 0.5861 - policy_loss: 1.5930 - val_loss: 4.2438 - val_value_loss: 0.6832 - val_policy_loss: 1.5815\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.1952 - value_loss: 0.5788 - policy_loss: 1.5931 - val_loss: 4.2234 - val_value_loss: 0.6518 - val_policy_loss: 1.5819\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.1876 - value_loss: 0.5743 - policy_loss: 1.5923 - val_loss: 4.2171 - val_value_loss: 0.6503 - val_policy_loss: 1.5808\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.1813 - value_loss: 0.5717 - policy_loss: 1.5921 - val_loss: 4.2091 - val_value_loss: 0.6443 - val_policy_loss: 1.5808\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.1753 - value_loss: 0.5689 - policy_loss: 1.5928 - val_loss: 4.2044 - val_value_loss: 0.6448 - val_policy_loss: 1.5806\n",
      "Saved model  tictactoe_lr_0_2_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.0\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 4.2062 - value_loss: 0.6492 - policy_loss: 1.5841 - val_loss: 4.1643 - val_value_loss: 0.6042 - val_policy_loss: 1.5510\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.1730 - value_loss: 0.5935 - policy_loss: 1.5834 - val_loss: 4.1547 - val_value_loss: 0.5949 - val_policy_loss: 1.5509\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.1576 - value_loss: 0.5729 - policy_loss: 1.5829 - val_loss: 4.1495 - val_value_loss: 0.5939 - val_policy_loss: 1.5512\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.1458 - value_loss: 0.5602 - policy_loss: 1.5819 - val_loss: 4.1420 - val_value_loss: 0.5898 - val_policy_loss: 1.5501\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.1368 - value_loss: 0.5522 - policy_loss: 1.5816 - val_loss: 4.1388 - val_value_loss: 0.5932 - val_policy_loss: 1.5502\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.1289 - value_loss: 0.5468 - policy_loss: 1.5811 - val_loss: 4.1330 - val_value_loss: 0.5910 - val_policy_loss: 1.5505\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.1207 - value_loss: 0.5404 - policy_loss: 1.5808 - val_loss: 4.1292 - val_value_loss: 0.5934 - val_policy_loss: 1.5502\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.1130 - value_loss: 0.5349 - policy_loss: 1.5807 - val_loss: 4.1244 - val_value_loss: 0.5944 - val_policy_loss: 1.5494\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.1074 - value_loss: 0.5334 - policy_loss: 1.5806 - val_loss: 4.1201 - val_value_loss: 0.5957 - val_policy_loss: 1.5491\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.1010 - value_loss: 0.5308 - policy_loss: 1.5802 - val_loss: 4.1156 - val_value_loss: 0.5961 - val_policy_loss: 1.5496\n",
      "Saved model  tictactoe_lr_0_2_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.05\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 4.1393 - value_loss: 0.6176 - policy_loss: 1.5797 - val_loss: 4.1259 - val_value_loss: 0.6061 - val_policy_loss: 1.5698\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.1070 - value_loss: 0.5639 - policy_loss: 1.5785 - val_loss: 4.1148 - val_value_loss: 0.5945 - val_policy_loss: 1.5689\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 4.0882 - value_loss: 0.5369 - policy_loss: 1.5776 - val_loss: 4.1059 - val_value_loss: 0.5856 - val_policy_loss: 1.5696\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.0754 - value_loss: 0.5214 - policy_loss: 1.5770 - val_loss: 4.0988 - val_value_loss: 0.5819 - val_policy_loss: 1.5688\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.0649 - value_loss: 0.5106 - policy_loss: 1.5765 - val_loss: 4.0917 - val_value_loss: 0.5770 - val_policy_loss: 1.5692\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.0591 - value_loss: 0.5085 - policy_loss: 1.5766 - val_loss: 4.0863 - val_value_loss: 0.5765 - val_policy_loss: 1.5685\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.0488 - value_loss: 0.4980 - policy_loss: 1.5761 - val_loss: 4.0813 - val_value_loss: 0.5761 - val_policy_loss: 1.5685\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.0415 - value_loss: 0.4933 - policy_loss: 1.5759 - val_loss: 4.0745 - val_value_loss: 0.5726 - val_policy_loss: 1.5679\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.0355 - value_loss: 0.4911 - policy_loss: 1.5757 - val_loss: 4.0700 - val_value_loss: 0.5730 - val_policy_loss: 1.5681\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.0296 - value_loss: 0.4889 - policy_loss: 1.5756 - val_loss: 4.0657 - val_value_loss: 0.5734 - val_policy_loss: 1.5685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_lr_0_2_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.72 - draw ratio 0.05\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 4.0914 - value_loss: 0.6110 - policy_loss: 1.5866 - val_loss: 4.0521 - val_value_loss: 0.5638 - val_policy_loss: 1.5605\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.0580 - value_loss: 0.5553 - policy_loss: 1.5850 - val_loss: 4.0410 - val_value_loss: 0.5512 - val_policy_loss: 1.5605\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.0438 - value_loss: 0.5373 - policy_loss: 1.5841 - val_loss: 4.0379 - val_value_loss: 0.5539 - val_policy_loss: 1.5610\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.0304 - value_loss: 0.5210 - policy_loss: 1.5832 - val_loss: 4.0295 - val_value_loss: 0.5458 - val_policy_loss: 1.5618\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.0230 - value_loss: 0.5156 - policy_loss: 1.5830 - val_loss: 4.0219 - val_value_loss: 0.5410 - val_policy_loss: 1.5609\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.0149 - value_loss: 0.5099 - policy_loss: 1.5820 - val_loss: 4.0189 - val_value_loss: 0.5454 - val_policy_loss: 1.5597\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.0081 - value_loss: 0.5056 - policy_loss: 1.5823 - val_loss: 4.0160 - val_value_loss: 0.5482 - val_policy_loss: 1.5607\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.0028 - value_loss: 0.5049 - policy_loss: 1.5817 - val_loss: 4.0192 - val_value_loss: 0.5645 - val_policy_loss: 1.5603\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9964 - value_loss: 0.5016 - policy_loss: 1.5817 - val_loss: 4.0065 - val_value_loss: 0.5484 - val_policy_loss: 1.5603\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9905 - value_loss: 0.4995 - policy_loss: 1.5813 - val_loss: 4.0049 - val_value_loss: 0.5549 - val_policy_loss: 1.5602\n",
      "Saved model  tictactoe_lr_0_2_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.73 - draw ratio 0.04\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 4.0093 - value_loss: 0.5564 - policy_loss: 1.5694 - val_loss: 3.9926 - val_value_loss: 0.5094 - val_policy_loss: 1.5856\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9905 - value_loss: 0.5242 - policy_loss: 1.5686 - val_loss: 3.9874 - val_value_loss: 0.5043 - val_policy_loss: 1.5851\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9791 - value_loss: 0.5066 - policy_loss: 1.5682 - val_loss: 3.9834 - val_value_loss: 0.5012 - val_policy_loss: 1.5849\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9701 - value_loss: 0.4939 - policy_loss: 1.5676 - val_loss: 3.9807 - val_value_loss: 0.5005 - val_policy_loss: 1.5848\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.9631 - value_loss: 0.4851 - policy_loss: 1.5671 - val_loss: 3.9775 - val_value_loss: 0.4989 - val_policy_loss: 1.5847\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9573 - value_loss: 0.4784 - policy_loss: 1.5669 - val_loss: 3.9752 - val_value_loss: 0.4991 - val_policy_loss: 1.5846\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9528 - value_loss: 0.4741 - policy_loss: 1.5667 - val_loss: 3.9719 - val_value_loss: 0.4968 - val_policy_loss: 1.5850\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9472 - value_loss: 0.4679 - policy_loss: 1.5665 - val_loss: 3.9688 - val_value_loss: 0.4958 - val_policy_loss: 1.5846\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.9436 - value_loss: 0.4656 - policy_loss: 1.5662 - val_loss: 3.9663 - val_value_loss: 0.4954 - val_policy_loss: 1.5846\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9381 - value_loss: 0.4595 - policy_loss: 1.5661 - val_loss: 3.9639 - val_value_loss: 0.4953 - val_policy_loss: 1.5844\n",
      "Saved model  tictactoe_lr_0_2_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.02\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 3.9864 - value_loss: 0.5491 - policy_loss: 1.5778 - val_loss: 4.0364 - val_value_loss: 0.6215 - val_policy_loss: 1.6079\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9652 - value_loss: 0.5123 - policy_loss: 1.5769 - val_loss: 4.0319 - val_value_loss: 0.6172 - val_policy_loss: 1.6078\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9536 - value_loss: 0.4943 - policy_loss: 1.5764 - val_loss: 4.0274 - val_value_loss: 0.6132 - val_policy_loss: 1.6076\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9444 - value_loss: 0.4809 - policy_loss: 1.5760 - val_loss: 4.0213 - val_value_loss: 0.6059 - val_policy_loss: 1.6073\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.9369 - value_loss: 0.4709 - policy_loss: 1.5755 - val_loss: 4.0182 - val_value_loss: 0.6047 - val_policy_loss: 1.6070\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9311 - value_loss: 0.4641 - policy_loss: 1.5755 - val_loss: 4.0157 - val_value_loss: 0.6043 - val_policy_loss: 1.6071\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9242 - value_loss: 0.4554 - policy_loss: 1.5750 - val_loss: 4.0122 - val_value_loss: 0.6018 - val_policy_loss: 1.6072\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9210 - value_loss: 0.4537 - policy_loss: 1.5750 - val_loss: 4.0123 - val_value_loss: 0.6068 - val_policy_loss: 1.6071\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9153 - value_loss: 0.4474 - policy_loss: 1.5746 - val_loss: 4.0100 - val_value_loss: 0.6070 - val_policy_loss: 1.6068\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9118 - value_loss: 0.4449 - policy_loss: 1.5745 - val_loss: 4.0068 - val_value_loss: 0.6052 - val_policy_loss: 1.6068\n",
      "Saved model  tictactoe_lr_0_2_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.66 - draw ratio 0.03\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 4.0255 - value_loss: 0.6763 - policy_loss: 1.5752 - val_loss: 3.9811 - val_value_loss: 0.6155 - val_policy_loss: 1.5498\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.0008 - value_loss: 0.6326 - policy_loss: 1.5743 - val_loss: 3.9729 - val_value_loss: 0.6039 - val_policy_loss: 1.5496\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9885 - value_loss: 0.6127 - policy_loss: 1.5741 - val_loss: 3.9683 - val_value_loss: 0.5993 - val_policy_loss: 1.5497\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9771 - value_loss: 0.5951 - policy_loss: 1.5735 - val_loss: 3.9617 - val_value_loss: 0.5909 - val_policy_loss: 1.5495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9685 - value_loss: 0.5826 - policy_loss: 1.5733 - val_loss: 3.9605 - val_value_loss: 0.5926 - val_policy_loss: 1.5500\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.9615 - value_loss: 0.5736 - policy_loss: 1.5730 - val_loss: 3.9547 - val_value_loss: 0.5861 - val_policy_loss: 1.5496\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.9546 - value_loss: 0.5644 - policy_loss: 1.5729 - val_loss: 3.9510 - val_value_loss: 0.5831 - val_policy_loss: 1.5498\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.9486 - value_loss: 0.5577 - policy_loss: 1.5723 - val_loss: 3.9479 - val_value_loss: 0.5815 - val_policy_loss: 1.5496\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9446 - value_loss: 0.5540 - policy_loss: 1.5726 - val_loss: 3.9483 - val_value_loss: 0.5864 - val_policy_loss: 1.5500\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9400 - value_loss: 0.5496 - policy_loss: 1.5722 - val_loss: 3.9442 - val_value_loss: 0.5834 - val_policy_loss: 1.5496\n",
      "Saved model  tictactoe_lr_0_2_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.03\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 3.9934 - value_loss: 0.6542 - policy_loss: 1.5792 - val_loss: 3.9684 - val_value_loss: 0.6126 - val_policy_loss: 1.5733\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9697 - value_loss: 0.6124 - policy_loss: 1.5783 - val_loss: 3.9649 - val_value_loss: 0.6106 - val_policy_loss: 1.5729\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9542 - value_loss: 0.5868 - policy_loss: 1.5774 - val_loss: 3.9647 - val_value_loss: 0.6147 - val_policy_loss: 1.5730\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9443 - value_loss: 0.5717 - policy_loss: 1.5771 - val_loss: 3.9619 - val_value_loss: 0.6138 - val_policy_loss: 1.5729\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9356 - value_loss: 0.5593 - policy_loss: 1.5768 - val_loss: 3.9594 - val_value_loss: 0.6132 - val_policy_loss: 1.5730\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9285 - value_loss: 0.5498 - policy_loss: 1.5766 - val_loss: 3.9573 - val_value_loss: 0.6135 - val_policy_loss: 1.5731\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9228 - value_loss: 0.5437 - policy_loss: 1.5760 - val_loss: 3.9575 - val_value_loss: 0.6182 - val_policy_loss: 1.5734\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.9174 - value_loss: 0.5375 - policy_loss: 1.5758 - val_loss: 3.9559 - val_value_loss: 0.6197 - val_policy_loss: 1.5731\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9133 - value_loss: 0.5339 - policy_loss: 1.5758 - val_loss: 3.9530 - val_value_loss: 0.6187 - val_policy_loss: 1.5730\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.9077 - value_loss: 0.5276 - policy_loss: 1.5755 - val_loss: 3.9501 - val_value_loss: 0.6174 - val_policy_loss: 1.5730\n",
      "Saved model  tictactoe_lr_0_2_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.71 - draw ratio 0.09\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 3.9285 - value_loss: 0.5816 - policy_loss: 1.5676 - val_loss: 3.9400 - val_value_loss: 0.5855 - val_policy_loss: 1.5892\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9004 - value_loss: 0.5314 - policy_loss: 1.5661 - val_loss: 3.9337 - val_value_loss: 0.5778 - val_policy_loss: 1.5889\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8868 - value_loss: 0.5087 - policy_loss: 1.5661 - val_loss: 3.9301 - val_value_loss: 0.5750 - val_policy_loss: 1.5891\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8779 - value_loss: 0.4962 - policy_loss: 1.5653 - val_loss: 3.9241 - val_value_loss: 0.5676 - val_policy_loss: 1.5889\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8705 - value_loss: 0.4864 - policy_loss: 1.5650 - val_loss: 3.9215 - val_value_loss: 0.5672 - val_policy_loss: 1.5888\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8641 - value_loss: 0.4783 - policy_loss: 1.5647 - val_loss: 3.9200 - val_value_loss: 0.5683 - val_policy_loss: 1.5892\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8596 - value_loss: 0.4740 - policy_loss: 1.5646 - val_loss: 3.9172 - val_value_loss: 0.5674 - val_policy_loss: 1.5889\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8553 - value_loss: 0.4699 - policy_loss: 1.5647 - val_loss: 3.9147 - val_value_loss: 0.5671 - val_policy_loss: 1.5888\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8537 - value_loss: 0.4715 - policy_loss: 1.5642 - val_loss: 3.9116 - val_value_loss: 0.5656 - val_policy_loss: 1.5886\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8467 - value_loss: 0.4624 - policy_loss: 1.5639 - val_loss: 3.9110 - val_value_loss: 0.5690 - val_policy_loss: 1.5885\n",
      "Saved model  tictactoe_lr_0_2_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.03\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 3.9043 - value_loss: 0.5750 - policy_loss: 1.5702 - val_loss: 3.9197 - val_value_loss: 0.5850 - val_policy_loss: 1.5921\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8907 - value_loss: 0.5507 - policy_loss: 1.5694 - val_loss: 3.9173 - val_value_loss: 0.5825 - val_policy_loss: 1.5920\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8808 - value_loss: 0.5335 - policy_loss: 1.5691 - val_loss: 3.9157 - val_value_loss: 0.5814 - val_policy_loss: 1.5923\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8737 - value_loss: 0.5218 - policy_loss: 1.5689 - val_loss: 3.9147 - val_value_loss: 0.5817 - val_policy_loss: 1.5923\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8687 - value_loss: 0.5145 - policy_loss: 1.5684 - val_loss: 3.9139 - val_value_loss: 0.5825 - val_policy_loss: 1.5922\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8639 - value_loss: 0.5073 - policy_loss: 1.5683 - val_loss: 3.9135 - val_value_loss: 0.5837 - val_policy_loss: 1.5924\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8595 - value_loss: 0.5008 - policy_loss: 1.5682 - val_loss: 3.9125 - val_value_loss: 0.5841 - val_policy_loss: 1.5923\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8558 - value_loss: 0.4959 - policy_loss: 1.5680 - val_loss: 3.9117 - val_value_loss: 0.5845 - val_policy_loss: 1.5925\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8529 - value_loss: 0.4926 - policy_loss: 1.5678 - val_loss: 3.9110 - val_value_loss: 0.5853 - val_policy_loss: 1.5924\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8498 - value_loss: 0.4889 - policy_loss: 1.5675 - val_loss: 3.9099 - val_value_loss: 0.5853 - val_policy_loss: 1.5925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_lr_0_2_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.07\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 3.9195 - value_loss: 0.6267 - policy_loss: 1.5713 - val_loss: 3.9181 - val_value_loss: 0.6274 - val_policy_loss: 1.5692\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9032 - value_loss: 0.5969 - policy_loss: 1.5708 - val_loss: 3.9134 - val_value_loss: 0.6204 - val_policy_loss: 1.5690\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8934 - value_loss: 0.5795 - policy_loss: 1.5708 - val_loss: 3.9096 - val_value_loss: 0.6154 - val_policy_loss: 1.5687\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8849 - value_loss: 0.5657 - policy_loss: 1.5700 - val_loss: 3.9084 - val_value_loss: 0.6151 - val_policy_loss: 1.5688\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8794 - value_loss: 0.5569 - policy_loss: 1.5699 - val_loss: 3.9055 - val_value_loss: 0.6118 - val_policy_loss: 1.5686\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8748 - value_loss: 0.5502 - policy_loss: 1.5696 - val_loss: 3.9034 - val_value_loss: 0.6095 - val_policy_loss: 1.5689\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8703 - value_loss: 0.5435 - policy_loss: 1.5696 - val_loss: 3.9023 - val_value_loss: 0.6099 - val_policy_loss: 1.5685\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8667 - value_loss: 0.5389 - policy_loss: 1.5693 - val_loss: 3.9017 - val_value_loss: 0.6111 - val_policy_loss: 1.5684\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8640 - value_loss: 0.5358 - policy_loss: 1.5691 - val_loss: 3.8998 - val_value_loss: 0.6095 - val_policy_loss: 1.5684\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8618 - value_loss: 0.5338 - policy_loss: 1.5691 - val_loss: 3.8983 - val_value_loss: 0.6091 - val_policy_loss: 1.5680\n",
      "Saved model  tictactoe_lr_0_2_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.67 - draw ratio 0.1\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 3.9139 - value_loss: 0.6288 - policy_loss: 1.5804 - val_loss: 3.9299 - val_value_loss: 0.6409 - val_policy_loss: 1.6016\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9024 - value_loss: 0.6089 - policy_loss: 1.5795 - val_loss: 3.9275 - val_value_loss: 0.6385 - val_policy_loss: 1.6015\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8925 - value_loss: 0.5920 - policy_loss: 1.5789 - val_loss: 3.9257 - val_value_loss: 0.6373 - val_policy_loss: 1.6014\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8863 - value_loss: 0.5821 - policy_loss: 1.5789 - val_loss: 3.9248 - val_value_loss: 0.6378 - val_policy_loss: 1.6013\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8811 - value_loss: 0.5742 - policy_loss: 1.5784 - val_loss: 3.9233 - val_value_loss: 0.6370 - val_policy_loss: 1.6013\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8768 - value_loss: 0.5679 - policy_loss: 1.5783 - val_loss: 3.9224 - val_value_loss: 0.6376 - val_policy_loss: 1.6012\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8734 - value_loss: 0.5637 - policy_loss: 1.5781 - val_loss: 3.9232 - val_value_loss: 0.6416 - val_policy_loss: 1.6011\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8701 - value_loss: 0.5597 - policy_loss: 1.5778 - val_loss: 3.9214 - val_value_loss: 0.6401 - val_policy_loss: 1.6011\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8676 - value_loss: 0.5568 - policy_loss: 1.5778 - val_loss: 3.9216 - val_value_loss: 0.6428 - val_policy_loss: 1.6011\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8645 - value_loss: 0.5532 - policy_loss: 1.5775 - val_loss: 3.9194 - val_value_loss: 0.6408 - val_policy_loss: 1.6010\n",
      "Saved model  tictactoe_lr_0_2_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.71 - draw ratio 0.05\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 3.8984 - value_loss: 0.5843 - policy_loss: 1.6164 - val_loss: 3.8472 - val_value_loss: 0.5692 - val_policy_loss: 1.5304\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8816 - value_loss: 0.5536 - policy_loss: 1.6157 - val_loss: 3.8436 - val_value_loss: 0.5641 - val_policy_loss: 1.5305\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8721 - value_loss: 0.5374 - policy_loss: 1.6152 - val_loss: 3.8420 - val_value_loss: 0.5631 - val_policy_loss: 1.5306\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8662 - value_loss: 0.5277 - policy_loss: 1.6152 - val_loss: 3.8383 - val_value_loss: 0.5580 - val_policy_loss: 1.5304\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8596 - value_loss: 0.5170 - policy_loss: 1.6150 - val_loss: 3.8358 - val_value_loss: 0.5553 - val_policy_loss: 1.5304\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8542 - value_loss: 0.5088 - policy_loss: 1.6146 - val_loss: 3.8336 - val_value_loss: 0.5532 - val_policy_loss: 1.5303\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8501 - value_loss: 0.5031 - policy_loss: 1.6144 - val_loss: 3.8323 - val_value_loss: 0.5529 - val_policy_loss: 1.5303\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8472 - value_loss: 0.4995 - policy_loss: 1.6145 - val_loss: 3.8309 - val_value_loss: 0.5524 - val_policy_loss: 1.5303\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8444 - value_loss: 0.4964 - policy_loss: 1.6142 - val_loss: 3.8299 - val_value_loss: 0.5527 - val_policy_loss: 1.5301\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8420 - value_loss: 0.4938 - policy_loss: 1.6142 - val_loss: 3.8282 - val_value_loss: 0.5517 - val_policy_loss: 1.5300\n",
      "Saved model  tictactoe_lr_0_2_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.73 - draw ratio 0.08\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 3.8982 - value_loss: 0.6444 - policy_loss: 1.5781 - val_loss: 3.8775 - val_value_loss: 0.6409 - val_policy_loss: 1.5416\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8793 - value_loss: 0.6098 - policy_loss: 1.5771 - val_loss: 3.8696 - val_value_loss: 0.6274 - val_policy_loss: 1.5414\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8672 - value_loss: 0.5881 - policy_loss: 1.5769 - val_loss: 3.8657 - val_value_loss: 0.6218 - val_policy_loss: 1.5415\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8564 - value_loss: 0.5692 - policy_loss: 1.5765 - val_loss: 3.8627 - val_value_loss: 0.6183 - val_policy_loss: 1.5413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8492 - value_loss: 0.5574 - policy_loss: 1.5761 - val_loss: 3.8611 - val_value_loss: 0.6169 - val_policy_loss: 1.5417\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8429 - value_loss: 0.5471 - policy_loss: 1.5761 - val_loss: 3.8588 - val_value_loss: 0.6147 - val_policy_loss: 1.5414\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8386 - value_loss: 0.5409 - policy_loss: 1.5758 - val_loss: 3.8564 - val_value_loss: 0.6123 - val_policy_loss: 1.5412\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8342 - value_loss: 0.5344 - policy_loss: 1.5757 - val_loss: 3.8549 - val_value_loss: 0.6115 - val_policy_loss: 1.5414\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8304 - value_loss: 0.5292 - policy_loss: 1.5756 - val_loss: 3.8526 - val_value_loss: 0.6092 - val_policy_loss: 1.5412\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8271 - value_loss: 0.5247 - policy_loss: 1.5756 - val_loss: 3.8510 - val_value_loss: 0.6082 - val_policy_loss: 1.5412\n",
      "Saved model  tictactoe_lr_0_2_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.67 - draw ratio 0.09\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 3.8997 - value_loss: 0.6536 - policy_loss: 1.5938 - val_loss: 3.8901 - val_value_loss: 0.6269 - val_policy_loss: 1.6019\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8889 - value_loss: 0.6335 - policy_loss: 1.5933 - val_loss: 3.8875 - val_value_loss: 0.6228 - val_policy_loss: 1.6019\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8805 - value_loss: 0.6180 - policy_loss: 1.5932 - val_loss: 3.8863 - val_value_loss: 0.6215 - val_policy_loss: 1.6019\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8741 - value_loss: 0.6067 - policy_loss: 1.5928 - val_loss: 3.8848 - val_value_loss: 0.6196 - val_policy_loss: 1.6019\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8690 - value_loss: 0.5974 - policy_loss: 1.5928 - val_loss: 3.8837 - val_value_loss: 0.6185 - val_policy_loss: 1.6018\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8645 - value_loss: 0.5897 - policy_loss: 1.5927 - val_loss: 3.8830 - val_value_loss: 0.6183 - val_policy_loss: 1.6018\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8607 - value_loss: 0.5834 - policy_loss: 1.5924 - val_loss: 3.8823 - val_value_loss: 0.6181 - val_policy_loss: 1.6017\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8573 - value_loss: 0.5777 - policy_loss: 1.5925 - val_loss: 3.8813 - val_value_loss: 0.6173 - val_policy_loss: 1.6016\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8545 - value_loss: 0.5734 - policy_loss: 1.5924 - val_loss: 3.8810 - val_value_loss: 0.6179 - val_policy_loss: 1.6016\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8516 - value_loss: 0.5688 - policy_loss: 1.5922 - val_loss: 3.8806 - val_value_loss: 0.6182 - val_policy_loss: 1.6016\n",
      "Saved model  tictactoe_lr_0_2_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.77 - draw ratio 0.02\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 3.8696 - value_loss: 0.6043 - policy_loss: 1.5938 - val_loss: 3.8799 - val_value_loss: 0.6008 - val_policy_loss: 1.6186\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8583 - value_loss: 0.5835 - policy_loss: 1.5932 - val_loss: 3.8765 - val_value_loss: 0.5951 - val_policy_loss: 1.6187\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8503 - value_loss: 0.5686 - policy_loss: 1.5931 - val_loss: 3.8741 - val_value_loss: 0.5913 - val_policy_loss: 1.6187\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8440 - value_loss: 0.5574 - policy_loss: 1.5930 - val_loss: 3.8722 - val_value_loss: 0.5887 - val_policy_loss: 1.6186\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8386 - value_loss: 0.5478 - policy_loss: 1.5928 - val_loss: 3.8707 - val_value_loss: 0.5869 - val_policy_loss: 1.6186\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8345 - value_loss: 0.5409 - policy_loss: 1.5927 - val_loss: 3.8694 - val_value_loss: 0.5854 - val_policy_loss: 1.6186\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8299 - value_loss: 0.5327 - policy_loss: 1.5926 - val_loss: 3.8683 - val_value_loss: 0.5843 - val_policy_loss: 1.6186\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8263 - value_loss: 0.5270 - policy_loss: 1.5924 - val_loss: 3.8674 - val_value_loss: 0.5836 - val_policy_loss: 1.6185\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8226 - value_loss: 0.5207 - policy_loss: 1.5923 - val_loss: 3.8665 - val_value_loss: 0.5830 - val_policy_loss: 1.6185\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8192 - value_loss: 0.5151 - policy_loss: 1.5922 - val_loss: 3.8656 - val_value_loss: 0.5823 - val_policy_loss: 1.6185\n",
      "Saved model  tictactoe_lr_0_2_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.63 - draw ratio 0.09\n",
      "iteration 27 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 3.9044 - value_loss: 0.6831 - policy_loss: 1.5957 - val_loss: 3.8797 - val_value_loss: 0.6660 - val_policy_loss: 1.5640\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8936 - value_loss: 0.6630 - policy_loss: 1.5953 - val_loss: 3.8757 - val_value_loss: 0.6592 - val_policy_loss: 1.5639\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8849 - value_loss: 0.6470 - policy_loss: 1.5951 - val_loss: 3.8732 - val_value_loss: 0.6554 - val_policy_loss: 1.5638\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8784 - value_loss: 0.6351 - policy_loss: 1.5951 - val_loss: 3.8712 - val_value_loss: 0.6525 - val_policy_loss: 1.5638\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8731 - value_loss: 0.6257 - policy_loss: 1.5949 - val_loss: 3.8694 - val_value_loss: 0.6501 - val_policy_loss: 1.5638\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8704 - value_loss: 0.6215 - policy_loss: 1.5948 - val_loss: 3.8682 - val_value_loss: 0.6489 - val_policy_loss: 1.5637\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8649 - value_loss: 0.6117 - policy_loss: 1.5947 - val_loss: 3.8668 - val_value_loss: 0.6473 - val_policy_loss: 1.5636\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8610 - value_loss: 0.6050 - policy_loss: 1.5948 - val_loss: 3.8661 - val_value_loss: 0.6469 - val_policy_loss: 1.5637\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8579 - value_loss: 0.6003 - policy_loss: 1.5944 - val_loss: 3.8648 - val_value_loss: 0.6455 - val_policy_loss: 1.5636\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8556 - value_loss: 0.5966 - policy_loss: 1.5946 - val_loss: 3.8641 - val_value_loss: 0.6451 - val_policy_loss: 1.5636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_lr_0_2_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.65 - draw ratio 0.09\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 3.9041 - value_loss: 0.6950 - policy_loss: 1.5943 - val_loss: 3.8676 - val_value_loss: 0.6590 - val_policy_loss: 1.5579\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8944 - value_loss: 0.6770 - policy_loss: 1.5939 - val_loss: 3.8640 - val_value_loss: 0.6529 - val_policy_loss: 1.5579\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8881 - value_loss: 0.6657 - policy_loss: 1.5937 - val_loss: 3.8618 - val_value_loss: 0.6495 - val_policy_loss: 1.5579\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8834 - value_loss: 0.6575 - policy_loss: 1.5937 - val_loss: 3.8599 - val_value_loss: 0.6469 - val_policy_loss: 1.5579\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8790 - value_loss: 0.6499 - policy_loss: 1.5936 - val_loss: 3.8584 - val_value_loss: 0.6451 - val_policy_loss: 1.5578\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8753 - value_loss: 0.6439 - policy_loss: 1.5933 - val_loss: 3.8571 - val_value_loss: 0.6436 - val_policy_loss: 1.5578\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8709 - value_loss: 0.6363 - policy_loss: 1.5931 - val_loss: 3.8564 - val_value_loss: 0.6434 - val_policy_loss: 1.5578\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8678 - value_loss: 0.6315 - policy_loss: 1.5929 - val_loss: 3.8558 - val_value_loss: 0.6433 - val_policy_loss: 1.5577\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8655 - value_loss: 0.6279 - policy_loss: 1.5929 - val_loss: 3.8552 - val_value_loss: 0.6432 - val_policy_loss: 1.5577\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8631 - value_loss: 0.6243 - policy_loss: 1.5929 - val_loss: 3.8546 - val_value_loss: 0.6432 - val_policy_loss: 1.5576\n",
      "Saved model  tictactoe_lr_0_2_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.56 - draw ratio 0.05\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 3.8600 - value_loss: 0.6348 - policy_loss: 1.5774 - val_loss: 3.8548 - val_value_loss: 0.6580 - val_policy_loss: 1.5444\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8506 - value_loss: 0.6173 - policy_loss: 1.5770 - val_loss: 3.8505 - val_value_loss: 0.6504 - val_policy_loss: 1.5444\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8444 - value_loss: 0.6064 - policy_loss: 1.5767 - val_loss: 3.8476 - val_value_loss: 0.6457 - val_policy_loss: 1.5444\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8391 - value_loss: 0.5971 - policy_loss: 1.5765 - val_loss: 3.8447 - val_value_loss: 0.6410 - val_policy_loss: 1.5444\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8334 - value_loss: 0.5870 - policy_loss: 1.5762 - val_loss: 3.8428 - val_value_loss: 0.6383 - val_policy_loss: 1.5444\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8299 - value_loss: 0.5812 - policy_loss: 1.5762 - val_loss: 3.8409 - val_value_loss: 0.6355 - val_policy_loss: 1.5444\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8268 - value_loss: 0.5761 - policy_loss: 1.5762 - val_loss: 3.8392 - val_value_loss: 0.6333 - val_policy_loss: 1.5445\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8239 - value_loss: 0.5715 - policy_loss: 1.5761 - val_loss: 3.8372 - val_value_loss: 0.6303 - val_policy_loss: 1.5445\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8215 - value_loss: 0.5680 - policy_loss: 1.5760 - val_loss: 3.8364 - val_value_loss: 0.6298 - val_policy_loss: 1.5444\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8182 - value_loss: 0.5625 - policy_loss: 1.5758 - val_loss: 3.8353 - val_value_loss: 0.6288 - val_policy_loss: 1.5444\n",
      "Saved model  tictactoe_lr_0_2_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.65 - draw ratio 0.08\n"
     ]
    }
   ],
   "source": [
    "wins_1, draws_1 = test_pipeline.run(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - learning rate 0.2\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "losses_1 = np.ones(30) - wins_1 - draws_1\n",
    "# no_loss = np.zeros(50) + wins +draws\n",
    "\n",
    "plt.plot(x, wins_1, label=\"win ratio\")\n",
    "plt.plot(x, draws_1, label=\"draw ratio\")\n",
    "#plt.plot(x, no_loss, label=\"no loss ratio\")\n",
    "plt.plot(x, losses_1, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins_1 = [0.7, 0.79, 0.84, 0.9, 0.83, 0.75, 0.77, 0.8, 0.86, 0.81, 0.72, 0.85, 0.76, 0.72, 0.73, 0.74, 0.66, 0.78, 0.71, 0.78, 0.74, 0.67, 0.71, 0.73, 0.67, 0.77, 0.63, 0.65, 0.56, 0.65]\n",
      "draws_1 = [0.01, 0.0, 0.02, 0.0, 0.0, 0.02, 0.02, 0.01, 0.03, 0.03, 0.04, 0.0, 0.05, 0.05, 0.04, 0.02, 0.03, 0.03, 0.09, 0.03, 0.07, 0.1, 0.05, 0.08, 0.09, 0.02, 0.09, 0.09, 0.05, 0.08]\n",
      "losses_1 = [0.29 0.21 0.14 0.1  0.17 0.23 0.21 0.19 0.11 0.16 0.24 0.15 0.19 0.23\n",
      " 0.23 0.24 0.31 0.19 0.2  0.19 0.19 0.23 0.24 0.19 0.24 0.21 0.28 0.26\n",
      " 0.39 0.27]\n"
     ]
    }
   ],
   "source": [
    "print(\"wins_1 =\", wins_1)\n",
    "print(\"draws_1 =\", draws_1)\n",
    "print(\"losses_1 =\", losses_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCTS = {\n",
    "    'c_puct': 1.0,\n",
    "    'dir_alpha': 0.6,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 10,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 10\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 0,\n",
    "    'show_games': False\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.02,\n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 512,\n",
    "    'num_filters_value': 512,\n",
    "    'num_filters_tower': 512,\n",
    "    'num_residual_blocks': 3,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 512\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"tictactoe_lr_0_02\", \"TicTacToe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (4928, 3, 3, 3)\n",
      "model_y_outcomes: (4928,)\n",
      "model_y_probabilities: (4928, 9)\n",
      "Train on 3942 samples, validate on 986 samples\n",
      "Epoch 1/10\n",
      "3942/3942 [==============================] - 5s 1ms/step - loss: 7.4229 - value_loss: 1.4613 - policy_loss: 3.3020 - val_loss: 7.3672 - val_value_loss: 0.9624 - val_policy_loss: 3.6932\n",
      "Epoch 2/10\n",
      "3942/3942 [==============================] - 1s 174us/step - loss: 6.7429 - value_loss: 0.9173 - policy_loss: 2.4924 - val_loss: 6.6433 - val_value_loss: 0.9558 - val_policy_loss: 2.2583\n",
      "Epoch 3/10\n",
      "3942/3942 [==============================] - 1s 175us/step - loss: 6.4907 - value_loss: 0.8651 - policy_loss: 2.0466 - val_loss: 6.5399 - val_value_loss: 0.9490 - val_policy_loss: 2.0647\n",
      "Epoch 4/10\n",
      "3942/3942 [==============================] - 1s 176us/step - loss: 6.3721 - value_loss: 0.8135 - policy_loss: 1.8674 - val_loss: 6.4815 - val_value_loss: 0.9743 - val_policy_loss: 1.9288\n",
      "Epoch 5/10\n",
      "3942/3942 [==============================] - 1s 174us/step - loss: 6.3645 - value_loss: 0.8335 - policy_loss: 1.8385 - val_loss: 6.5067 - val_value_loss: 1.0151 - val_policy_loss: 1.9448\n",
      "Epoch 6/10\n",
      "3942/3942 [==============================] - 1s 173us/step - loss: 6.3298 - value_loss: 0.8001 - policy_loss: 1.8088 - val_loss: 6.4353 - val_value_loss: 0.9252 - val_policy_loss: 1.8983\n",
      "Epoch 7/10\n",
      "3942/3942 [==============================] - 1s 173us/step - loss: 6.3021 - value_loss: 0.7809 - policy_loss: 1.7790 - val_loss: 6.4144 - val_value_loss: 0.9801 - val_policy_loss: 1.8082\n",
      "Epoch 8/10\n",
      "3942/3942 [==============================] - 1s 174us/step - loss: 6.2426 - value_loss: 0.7372 - policy_loss: 1.7100 - val_loss: 6.3754 - val_value_loss: 0.9228 - val_policy_loss: 1.7939\n",
      "Epoch 9/10\n",
      "3942/3942 [==============================] - 1s 176us/step - loss: 6.2211 - value_loss: 0.7210 - policy_loss: 1.6897 - val_loss: 6.3592 - val_value_loss: 0.9186 - val_policy_loss: 1.7719\n",
      "Epoch 10/10\n",
      "3942/3942 [==============================] - 1s 176us/step - loss: 6.2255 - value_loss: 0.7349 - policy_loss: 1.6909 - val_loss: 6.3667 - val_value_loss: 0.9454 - val_policy_loss: 1.7665\n",
      "Saved model  tictactoe_lr_0_02_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.01\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 6.2817 - value_loss: 0.8534 - policy_loss: 1.6913 - val_loss: 6.2966 - val_value_loss: 0.8798 - val_policy_loss: 1.6984\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2390 - value_loss: 0.8100 - policy_loss: 1.6558 - val_loss: 6.2460 - val_value_loss: 0.7779 - val_policy_loss: 1.7054\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2225 - value_loss: 0.7810 - policy_loss: 1.6580 - val_loss: 6.2617 - val_value_loss: 0.7944 - val_policy_loss: 1.7266\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2024 - value_loss: 0.7617 - policy_loss: 1.6435 - val_loss: 6.2111 - val_value_loss: 0.7671 - val_policy_loss: 1.6591\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1797 - value_loss: 0.7534 - policy_loss: 1.6128 - val_loss: 6.2026 - val_value_loss: 0.7601 - val_policy_loss: 1.6556\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1741 - value_loss: 0.7481 - policy_loss: 1.6133 - val_loss: 6.2026 - val_value_loss: 0.7683 - val_policy_loss: 1.6536\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1665 - value_loss: 0.7470 - policy_loss: 1.6056 - val_loss: 6.1949 - val_value_loss: 0.7591 - val_policy_loss: 1.6539\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1617 - value_loss: 0.7453 - policy_loss: 1.6040 - val_loss: 6.1867 - val_value_loss: 0.7554 - val_policy_loss: 1.6476\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1639 - value_loss: 0.7489 - policy_loss: 1.6113 - val_loss: 6.1868 - val_value_loss: 0.7568 - val_policy_loss: 1.6527\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1558 - value_loss: 0.7487 - policy_loss: 1.6015 - val_loss: 6.1841 - val_value_loss: 0.7606 - val_policy_loss: 1.6499\n",
      "Saved model  tictactoe_lr_0_02_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.66 - draw ratio 0.02\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.2665 - value_loss: 0.9335 - policy_loss: 1.6445 - val_loss: 6.2370 - val_value_loss: 0.8968 - val_policy_loss: 1.6258\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2212 - value_loss: 0.8609 - policy_loss: 1.6328 - val_loss: 6.2377 - val_value_loss: 0.8806 - val_policy_loss: 1.6497\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2043 - value_loss: 0.8378 - policy_loss: 1.6285 - val_loss: 6.2144 - val_value_loss: 0.8717 - val_policy_loss: 1.6183\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1783 - value_loss: 0.8046 - policy_loss: 1.6159 - val_loss: 6.2130 - val_value_loss: 0.8747 - val_policy_loss: 1.6188\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1738 - value_loss: 0.8021 - policy_loss: 1.6159 - val_loss: 6.2000 - val_value_loss: 0.8602 - val_policy_loss: 1.6137\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1704 - value_loss: 0.8075 - policy_loss: 1.6100 - val_loss: 6.1970 - val_value_loss: 0.8639 - val_policy_loss: 1.6104\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1575 - value_loss: 0.7921 - policy_loss: 1.6059 - val_loss: 6.1946 - val_value_loss: 0.8751 - val_policy_loss: 1.6006\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1576 - value_loss: 0.8056 - policy_loss: 1.5989 - val_loss: 6.1827 - val_value_loss: 0.8562 - val_policy_loss: 1.6020\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1508 - value_loss: 0.7882 - policy_loss: 1.6091 - val_loss: 6.1829 - val_value_loss: 0.8549 - val_policy_loss: 1.6100\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1463 - value_loss: 0.7888 - policy_loss: 1.6057 - val_loss: 6.1781 - val_value_loss: 0.8604 - val_policy_loss: 1.6012\n",
      "Saved model  tictactoe_lr_0_02_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.6 - draw ratio 0.1\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2280 - value_loss: 0.9264 - policy_loss: 1.6379 - val_loss: 6.2447 - val_value_loss: 0.9536 - val_policy_loss: 1.6475\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2142 - value_loss: 0.9008 - policy_loss: 1.6421 - val_loss: 6.2393 - val_value_loss: 0.9495 - val_policy_loss: 1.6472\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1885 - value_loss: 0.8650 - policy_loss: 1.6328 - val_loss: 6.2290 - val_value_loss: 0.9441 - val_policy_loss: 1.6383\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1713 - value_loss: 0.8527 - policy_loss: 1.6170 - val_loss: 6.2209 - val_value_loss: 0.9429 - val_policy_loss: 1.6296\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1691 - value_loss: 0.8518 - policy_loss: 1.6200 - val_loss: 6.2143 - val_value_loss: 0.9352 - val_policy_loss: 1.6303\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1556 - value_loss: 0.8430 - policy_loss: 1.6080 - val_loss: 6.2076 - val_value_loss: 0.9386 - val_policy_loss: 1.6199\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1528 - value_loss: 0.8403 - policy_loss: 1.6113 - val_loss: 6.2091 - val_value_loss: 0.9408 - val_policy_loss: 1.6269\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1485 - value_loss: 0.8430 - policy_loss: 1.6063 - val_loss: 6.2034 - val_value_loss: 0.9433 - val_policy_loss: 1.6195\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1475 - value_loss: 0.8482 - policy_loss: 1.6053 - val_loss: 6.2032 - val_value_loss: 0.9399 - val_policy_loss: 1.6287\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1423 - value_loss: 0.8423 - policy_loss: 1.6072 - val_loss: 6.2022 - val_value_loss: 0.9513 - val_policy_loss: 1.6214\n",
      "Saved model  tictactoe_lr_0_02_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.68 - draw ratio 0.04\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1653 - value_loss: 0.8946 - policy_loss: 1.6071 - val_loss: 6.1533 - val_value_loss: 0.8845 - val_policy_loss: 1.5967\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1404 - value_loss: 0.8620 - policy_loss: 1.5962 - val_loss: 6.1456 - val_value_loss: 0.8731 - val_policy_loss: 1.5990\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1293 - value_loss: 0.8534 - policy_loss: 1.5889 - val_loss: 6.1347 - val_value_loss: 0.8637 - val_policy_loss: 1.5928\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1193 - value_loss: 0.8412 - policy_loss: 1.5873 - val_loss: 6.1332 - val_value_loss: 0.8636 - val_policy_loss: 1.5963\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1169 - value_loss: 0.8434 - policy_loss: 1.5865 - val_loss: 6.1348 - val_value_loss: 0.8783 - val_policy_loss: 1.5910\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1126 - value_loss: 0.8428 - policy_loss: 1.5849 - val_loss: 6.1246 - val_value_loss: 0.8641 - val_policy_loss: 1.5911\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1072 - value_loss: 0.8367 - policy_loss: 1.5863 - val_loss: 6.1267 - val_value_loss: 0.8757 - val_policy_loss: 1.5899\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1018 - value_loss: 0.8378 - policy_loss: 1.5808 - val_loss: 6.1216 - val_value_loss: 0.8707 - val_policy_loss: 1.5910\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0980 - value_loss: 0.8361 - policy_loss: 1.5810 - val_loss: 6.1130 - val_value_loss: 0.8670 - val_policy_loss: 1.5838\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0958 - value_loss: 0.8373 - policy_loss: 1.5818 - val_loss: 6.1149 - val_value_loss: 0.8714 - val_policy_loss: 1.5893\n",
      "Saved model  tictactoe_lr_0_02_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.69 - draw ratio 0.02\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1278 - value_loss: 0.8949 - policy_loss: 1.5930 - val_loss: 6.1674 - val_value_loss: 0.9625 - val_policy_loss: 1.6064\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1104 - value_loss: 0.8676 - policy_loss: 1.5887 - val_loss: 6.1629 - val_value_loss: 0.9573 - val_policy_loss: 1.6058\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1015 - value_loss: 0.8553 - policy_loss: 1.5863 - val_loss: 6.1577 - val_value_loss: 0.9505 - val_policy_loss: 1.6052\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0943 - value_loss: 0.8454 - policy_loss: 1.5850 - val_loss: 6.1570 - val_value_loss: 0.9535 - val_policy_loss: 1.6040\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0906 - value_loss: 0.8420 - policy_loss: 1.5840 - val_loss: 6.1544 - val_value_loss: 0.9513 - val_policy_loss: 1.6040\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0848 - value_loss: 0.8349 - policy_loss: 1.5827 - val_loss: 6.1560 - val_value_loss: 0.9565 - val_policy_loss: 1.6051\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0821 - value_loss: 0.8333 - policy_loss: 1.5819 - val_loss: 6.1523 - val_value_loss: 0.9541 - val_policy_loss: 1.6033\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0797 - value_loss: 0.8324 - policy_loss: 1.5812 - val_loss: 6.1512 - val_value_loss: 0.9547 - val_policy_loss: 1.6036\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0756 - value_loss: 0.8280 - policy_loss: 1.5806 - val_loss: 6.1530 - val_value_loss: 0.9621 - val_policy_loss: 1.6029\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0742 - value_loss: 0.8290 - policy_loss: 1.5798 - val_loss: 6.1491 - val_value_loss: 0.9578 - val_policy_loss: 1.6025\n",
      "Saved model  tictactoe_lr_0_02_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.03\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9962 - value_loss: 0.6763 - policy_loss: 1.5796 - val_loss: 6.0200 - val_value_loss: 0.7200 - val_policy_loss: 1.5851\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9828 - value_loss: 0.6559 - policy_loss: 1.5762 - val_loss: 6.0151 - val_value_loss: 0.7152 - val_policy_loss: 1.5834\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9737 - value_loss: 0.6432 - policy_loss: 1.5738 - val_loss: 6.0131 - val_value_loss: 0.7144 - val_policy_loss: 1.5833\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9682 - value_loss: 0.6366 - policy_loss: 1.5727 - val_loss: 6.0115 - val_value_loss: 0.7149 - val_policy_loss: 1.5826\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9652 - value_loss: 0.6347 - policy_loss: 1.5716 - val_loss: 6.0089 - val_value_loss: 0.7132 - val_policy_loss: 1.5823\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9621 - value_loss: 0.6321 - policy_loss: 1.5711 - val_loss: 6.0085 - val_value_loss: 0.7154 - val_policy_loss: 1.5823\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.9591 - value_loss: 0.6301 - policy_loss: 1.5701 - val_loss: 6.0074 - val_value_loss: 0.7159 - val_policy_loss: 1.5827\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9581 - value_loss: 0.6316 - policy_loss: 1.5698 - val_loss: 6.0053 - val_value_loss: 0.7160 - val_policy_loss: 1.5816\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9539 - value_loss: 0.6270 - policy_loss: 1.5692 - val_loss: 6.0033 - val_value_loss: 0.7156 - val_policy_loss: 1.5810\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9518 - value_loss: 0.6253 - policy_loss: 1.5696 - val_loss: 6.0019 - val_value_loss: 0.7159 - val_policy_loss: 1.5811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_lr_0_02_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.73 - draw ratio 0.04\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0405 - value_loss: 0.7785 - policy_loss: 1.5971 - val_loss: 5.9787 - val_value_loss: 0.6456 - val_policy_loss: 1.6081\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0244 - value_loss: 0.7524 - policy_loss: 1.5940 - val_loss: 5.9757 - val_value_loss: 0.6432 - val_policy_loss: 1.6076\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0154 - value_loss: 0.7389 - policy_loss: 1.5926 - val_loss: 5.9729 - val_value_loss: 0.6417 - val_policy_loss: 1.6065\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0076 - value_loss: 0.7282 - policy_loss: 1.5909 - val_loss: 5.9701 - val_value_loss: 0.6396 - val_policy_loss: 1.6062\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0019 - value_loss: 0.7210 - policy_loss: 1.5898 - val_loss: 5.9696 - val_value_loss: 0.6418 - val_policy_loss: 1.6060\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9977 - value_loss: 0.7159 - policy_loss: 1.5895 - val_loss: 5.9674 - val_value_loss: 0.6406 - val_policy_loss: 1.6059\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9942 - value_loss: 0.7129 - policy_loss: 1.5885 - val_loss: 5.9662 - val_value_loss: 0.6417 - val_policy_loss: 1.6055\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9925 - value_loss: 0.7135 - policy_loss: 1.5877 - val_loss: 5.9651 - val_value_loss: 0.6422 - val_policy_loss: 1.6058\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9892 - value_loss: 0.7103 - policy_loss: 1.5875 - val_loss: 5.9622 - val_value_loss: 0.6403 - val_policy_loss: 1.6052\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9879 - value_loss: 0.7108 - policy_loss: 1.5874 - val_loss: 5.9613 - val_value_loss: 0.6418 - val_policy_loss: 1.6050\n",
      "Saved model  tictactoe_lr_0_02_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.62 - draw ratio 0.08\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.0525 - value_loss: 0.8485 - policy_loss: 1.5819 - val_loss: 6.0307 - val_value_loss: 0.8319 - val_policy_loss: 1.5568\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0354 - value_loss: 0.8205 - policy_loss: 1.5789 - val_loss: 6.0272 - val_value_loss: 0.8285 - val_policy_loss: 1.5563\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0270 - value_loss: 0.8076 - policy_loss: 1.5780 - val_loss: 6.0231 - val_value_loss: 0.8243 - val_policy_loss: 1.5553\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0202 - value_loss: 0.7992 - policy_loss: 1.5759 - val_loss: 6.0244 - val_value_loss: 0.8299 - val_policy_loss: 1.5555\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0172 - value_loss: 0.7971 - policy_loss: 1.5752 - val_loss: 6.0214 - val_value_loss: 0.8272 - val_policy_loss: 1.5551\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0137 - value_loss: 0.7942 - policy_loss: 1.5742 - val_loss: 6.0215 - val_value_loss: 0.8304 - val_policy_loss: 1.5553\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0107 - value_loss: 0.7919 - policy_loss: 1.5735 - val_loss: 6.0195 - val_value_loss: 0.8300 - val_policy_loss: 1.5547\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0074 - value_loss: 0.7886 - policy_loss: 1.5732 - val_loss: 6.0186 - val_value_loss: 0.8315 - val_policy_loss: 1.5544\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0055 - value_loss: 0.7881 - policy_loss: 1.5730 - val_loss: 6.0173 - val_value_loss: 0.8323 - val_policy_loss: 1.5542\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0045 - value_loss: 0.7897 - policy_loss: 1.5726 - val_loss: 6.0163 - val_value_loss: 0.8330 - val_policy_loss: 1.5547\n",
      "Saved model  tictactoe_lr_0_02_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.05\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0806 - value_loss: 0.9229 - policy_loss: 1.5946 - val_loss: 6.0216 - val_value_loss: 0.8004 - val_policy_loss: 1.6008\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0590 - value_loss: 0.8854 - policy_loss: 1.5921 - val_loss: 6.0193 - val_value_loss: 0.8000 - val_policy_loss: 1.5997\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0469 - value_loss: 0.8660 - policy_loss: 1.5902 - val_loss: 6.0165 - val_value_loss: 0.7970 - val_policy_loss: 1.6002\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0405 - value_loss: 0.8575 - policy_loss: 1.5891 - val_loss: 6.0150 - val_value_loss: 0.7979 - val_policy_loss: 1.5995\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0365 - value_loss: 0.8528 - policy_loss: 1.5887 - val_loss: 6.0131 - val_value_loss: 0.7971 - val_policy_loss: 1.5994\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0330 - value_loss: 0.8500 - policy_loss: 1.5877 - val_loss: 6.0141 - val_value_loss: 0.8022 - val_policy_loss: 1.5995\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0297 - value_loss: 0.8470 - policy_loss: 1.5871 - val_loss: 6.0144 - val_value_loss: 0.8068 - val_policy_loss: 1.5986\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0257 - value_loss: 0.8422 - policy_loss: 1.5870 - val_loss: 6.0141 - val_value_loss: 0.8087 - val_policy_loss: 1.5990\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0249 - value_loss: 0.8437 - policy_loss: 1.5871 - val_loss: 6.0120 - val_value_loss: 0.8076 - val_policy_loss: 1.5990\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0218 - value_loss: 0.8416 - policy_loss: 1.5861 - val_loss: 6.0116 - val_value_loss: 0.8100 - val_policy_loss: 1.5989\n",
      "Saved model  tictactoe_lr_0_02_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.03\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.0577 - value_loss: 0.8965 - policy_loss: 1.6053 - val_loss: 5.9860 - val_value_loss: 0.7936 - val_policy_loss: 1.5657\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0428 - value_loss: 0.8701 - policy_loss: 1.6034 - val_loss: 5.9830 - val_value_loss: 0.7902 - val_policy_loss: 1.5646\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0345 - value_loss: 0.8559 - policy_loss: 1.6027 - val_loss: 5.9814 - val_value_loss: 0.7883 - val_policy_loss: 1.5648\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0275 - value_loss: 0.8453 - policy_loss: 1.6007 - val_loss: 5.9811 - val_value_loss: 0.7893 - val_policy_loss: 1.5649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0245 - value_loss: 0.8412 - policy_loss: 1.6004 - val_loss: 5.9808 - val_value_loss: 0.7905 - val_policy_loss: 1.5646\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0213 - value_loss: 0.8373 - policy_loss: 1.5995 - val_loss: 5.9804 - val_value_loss: 0.7918 - val_policy_loss: 1.5640\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0184 - value_loss: 0.8335 - policy_loss: 1.5990 - val_loss: 5.9806 - val_value_loss: 0.7935 - val_policy_loss: 1.5642\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0164 - value_loss: 0.8318 - policy_loss: 1.5983 - val_loss: 5.9809 - val_value_loss: 0.7956 - val_policy_loss: 1.5643\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0146 - value_loss: 0.8300 - policy_loss: 1.5980 - val_loss: 5.9804 - val_value_loss: 0.7965 - val_policy_loss: 1.5639\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0126 - value_loss: 0.8273 - policy_loss: 1.5981 - val_loss: 5.9806 - val_value_loss: 0.7982 - val_policy_loss: 1.5642\n",
      "Saved model  tictactoe_lr_0_02_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.73 - draw ratio 0.03\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0976 - value_loss: 1.0056 - policy_loss: 1.5914 - val_loss: 6.0536 - val_value_loss: 0.9043 - val_policy_loss: 1.6057\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0824 - value_loss: 0.9790 - policy_loss: 1.5891 - val_loss: 6.0487 - val_value_loss: 0.8964 - val_policy_loss: 1.6052\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0733 - value_loss: 0.9631 - policy_loss: 1.5884 - val_loss: 6.0451 - val_value_loss: 0.8909 - val_policy_loss: 1.6050\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0679 - value_loss: 0.9550 - policy_loss: 1.5872 - val_loss: 6.0430 - val_value_loss: 0.8883 - val_policy_loss: 1.6049\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0642 - value_loss: 0.9496 - policy_loss: 1.5866 - val_loss: 6.0409 - val_value_loss: 0.8856 - val_policy_loss: 1.6049\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0610 - value_loss: 0.9450 - policy_loss: 1.5865 - val_loss: 6.0398 - val_value_loss: 0.8852 - val_policy_loss: 1.6047\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0575 - value_loss: 0.9400 - policy_loss: 1.5859 - val_loss: 6.0384 - val_value_loss: 0.8842 - val_policy_loss: 1.6044\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0559 - value_loss: 0.9389 - policy_loss: 1.5854 - val_loss: 6.0372 - val_value_loss: 0.8834 - val_policy_loss: 1.6044\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0532 - value_loss: 0.9353 - policy_loss: 1.5851 - val_loss: 6.0368 - val_value_loss: 0.8842 - val_policy_loss: 1.6043\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0503 - value_loss: 0.9316 - policy_loss: 1.5846 - val_loss: 6.0345 - val_value_loss: 0.8815 - val_policy_loss: 1.6040\n",
      "Saved model  tictactoe_lr_0_02_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.71 - draw ratio 0.06\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0102 - value_loss: 0.8711 - policy_loss: 1.5664 - val_loss: 6.0641 - val_value_loss: 0.9495 - val_policy_loss: 1.5967\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9990 - value_loss: 0.8522 - policy_loss: 1.5644 - val_loss: 6.0586 - val_value_loss: 0.9405 - val_policy_loss: 1.5963\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9918 - value_loss: 0.8402 - policy_loss: 1.5635 - val_loss: 6.0549 - val_value_loss: 0.9347 - val_policy_loss: 1.5961\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9865 - value_loss: 0.8320 - policy_loss: 1.5627 - val_loss: 6.0514 - val_value_loss: 0.9298 - val_policy_loss: 1.5955\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9815 - value_loss: 0.8244 - policy_loss: 1.5618 - val_loss: 6.0502 - val_value_loss: 0.9290 - val_policy_loss: 1.5955\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9786 - value_loss: 0.8209 - policy_loss: 1.5611 - val_loss: 6.0473 - val_value_loss: 0.9251 - val_policy_loss: 1.5952\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9764 - value_loss: 0.8183 - policy_loss: 1.5607 - val_loss: 6.0461 - val_value_loss: 0.9239 - val_policy_loss: 1.5953\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9743 - value_loss: 0.8163 - policy_loss: 1.5601 - val_loss: 6.0447 - val_value_loss: 0.9226 - val_policy_loss: 1.5955\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9729 - value_loss: 0.8150 - policy_loss: 1.5600 - val_loss: 6.0431 - val_value_loss: 0.9216 - val_policy_loss: 1.5949\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9708 - value_loss: 0.8129 - policy_loss: 1.5596 - val_loss: 6.0418 - val_value_loss: 0.9207 - val_policy_loss: 1.5947\n",
      "Saved model  tictactoe_lr_0_02_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.77 - draw ratio 0.01\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.9785 - value_loss: 0.8272 - policy_loss: 1.5622 - val_loss: 5.9831 - val_value_loss: 0.8321 - val_policy_loss: 1.5673\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9674 - value_loss: 0.8083 - policy_loss: 1.5604 - val_loss: 5.9789 - val_value_loss: 0.8255 - val_policy_loss: 1.5671\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9603 - value_loss: 0.7962 - policy_loss: 1.5599 - val_loss: 5.9769 - val_value_loss: 0.8228 - val_policy_loss: 1.5673\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9559 - value_loss: 0.7897 - policy_loss: 1.5591 - val_loss: 5.9754 - val_value_loss: 0.8215 - val_policy_loss: 1.5671\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9517 - value_loss: 0.7833 - policy_loss: 1.5586 - val_loss: 5.9732 - val_value_loss: 0.8186 - val_policy_loss: 1.5671\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9489 - value_loss: 0.7798 - policy_loss: 1.5580 - val_loss: 5.9711 - val_value_loss: 0.8161 - val_policy_loss: 1.5670\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9474 - value_loss: 0.7788 - policy_loss: 1.5575 - val_loss: 5.9695 - val_value_loss: 0.8142 - val_policy_loss: 1.5671\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9449 - value_loss: 0.7757 - policy_loss: 1.5572 - val_loss: 5.9687 - val_value_loss: 0.8142 - val_policy_loss: 1.5671\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9429 - value_loss: 0.7736 - policy_loss: 1.5568 - val_loss: 5.9683 - val_value_loss: 0.8151 - val_policy_loss: 1.5669\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9413 - value_loss: 0.7723 - policy_loss: 1.5564 - val_loss: 5.9670 - val_value_loss: 0.8144 - val_policy_loss: 1.5667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_lr_0_02_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.03\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.0093 - value_loss: 0.8775 - policy_loss: 1.5887 - val_loss: 5.9936 - val_value_loss: 0.8685 - val_policy_loss: 1.5672\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9966 - value_loss: 0.8551 - policy_loss: 1.5872 - val_loss: 5.9901 - val_value_loss: 0.8627 - val_policy_loss: 1.5676\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9906 - value_loss: 0.8459 - policy_loss: 1.5861 - val_loss: 5.9888 - val_value_loss: 0.8622 - val_policy_loss: 1.5669\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9868 - value_loss: 0.8402 - policy_loss: 1.5856 - val_loss: 5.9879 - val_value_loss: 0.8617 - val_policy_loss: 1.5671\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9837 - value_loss: 0.8360 - policy_loss: 1.5851 - val_loss: 5.9855 - val_value_loss: 0.8587 - val_policy_loss: 1.5669\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9808 - value_loss: 0.8321 - policy_loss: 1.5849 - val_loss: 5.9854 - val_value_loss: 0.8603 - val_policy_loss: 1.5667\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9791 - value_loss: 0.8309 - policy_loss: 1.5841 - val_loss: 5.9841 - val_value_loss: 0.8597 - val_policy_loss: 1.5661\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9780 - value_loss: 0.8300 - policy_loss: 1.5844 - val_loss: 5.9824 - val_value_loss: 0.8581 - val_policy_loss: 1.5660\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9748 - value_loss: 0.8257 - policy_loss: 1.5837 - val_loss: 5.9813 - val_value_loss: 0.8571 - val_policy_loss: 1.5663\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9734 - value_loss: 0.8247 - policy_loss: 1.5834 - val_loss: 5.9803 - val_value_loss: 0.8572 - val_policy_loss: 1.5657\n",
      "Saved model  tictactoe_lr_0_02_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.66 - draw ratio 0.02\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9891 - value_loss: 0.8773 - policy_loss: 1.5635 - val_loss: 5.9266 - val_value_loss: 0.7579 - val_policy_loss: 1.5582\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9817 - value_loss: 0.8644 - policy_loss: 1.5623 - val_loss: 5.9247 - val_value_loss: 0.7552 - val_policy_loss: 1.5580\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9771 - value_loss: 0.8568 - policy_loss: 1.5615 - val_loss: 5.9226 - val_value_loss: 0.7521 - val_policy_loss: 1.5577\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9733 - value_loss: 0.8507 - policy_loss: 1.5608 - val_loss: 5.9211 - val_value_loss: 0.7498 - val_policy_loss: 1.5576\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9703 - value_loss: 0.8458 - policy_loss: 1.5605 - val_loss: 5.9203 - val_value_loss: 0.7491 - val_policy_loss: 1.5575\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9679 - value_loss: 0.8420 - policy_loss: 1.5601 - val_loss: 5.9190 - val_value_loss: 0.7475 - val_policy_loss: 1.5574\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9659 - value_loss: 0.8389 - policy_loss: 1.5600 - val_loss: 5.9184 - val_value_loss: 0.7471 - val_policy_loss: 1.5574\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9639 - value_loss: 0.8361 - policy_loss: 1.5597 - val_loss: 5.9178 - val_value_loss: 0.7467 - val_policy_loss: 1.5572\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9621 - value_loss: 0.8337 - policy_loss: 1.5592 - val_loss: 5.9175 - val_value_loss: 0.7469 - val_policy_loss: 1.5571\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9605 - value_loss: 0.8312 - policy_loss: 1.5593 - val_loss: 5.9168 - val_value_loss: 0.7464 - val_policy_loss: 1.5571\n",
      "Saved model  tictactoe_lr_0_02_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.04\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.9971 - value_loss: 0.8692 - policy_loss: 1.5952 - val_loss: 5.9606 - val_value_loss: 0.8172 - val_policy_loss: 1.5745\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9886 - value_loss: 0.8539 - policy_loss: 1.5944 - val_loss: 5.9574 - val_value_loss: 0.8118 - val_policy_loss: 1.5743\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9822 - value_loss: 0.8426 - policy_loss: 1.5936 - val_loss: 5.9550 - val_value_loss: 0.8080 - val_policy_loss: 1.5742\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9772 - value_loss: 0.8340 - policy_loss: 1.5929 - val_loss: 5.9533 - val_value_loss: 0.8055 - val_policy_loss: 1.5741\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9730 - value_loss: 0.8266 - policy_loss: 1.5926 - val_loss: 5.9516 - val_value_loss: 0.8030 - val_policy_loss: 1.5739\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9689 - value_loss: 0.8197 - policy_loss: 1.5920 - val_loss: 5.9493 - val_value_loss: 0.7992 - val_policy_loss: 1.5739\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9621 - value_loss: 0.8070 - policy_loss: 1.5919 - val_loss: 5.9352 - val_value_loss: 0.7714 - val_policy_loss: 1.5741\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9425 - value_loss: 0.7687 - policy_loss: 1.5918 - val_loss: 5.9231 - val_value_loss: 0.7481 - val_policy_loss: 1.5741\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9381 - value_loss: 0.7609 - policy_loss: 1.5916 - val_loss: 5.9200 - val_value_loss: 0.7427 - val_policy_loss: 1.5741\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9370 - value_loss: 0.7592 - policy_loss: 1.5918 - val_loss: 5.9196 - val_value_loss: 0.7428 - val_policy_loss: 1.5739\n",
      "Saved model  tictactoe_lr_0_02_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.69 - draw ratio 0.02\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9744 - value_loss: 0.8314 - policy_loss: 1.5952 - val_loss: 5.9792 - val_value_loss: 0.8532 - val_policy_loss: 1.5835\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9697 - value_loss: 0.8239 - policy_loss: 1.5941 - val_loss: 5.9851 - val_value_loss: 0.8661 - val_policy_loss: 1.5832\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9632 - value_loss: 0.8125 - policy_loss: 1.5933 - val_loss: 5.9789 - val_value_loss: 0.8544 - val_policy_loss: 1.5831\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9611 - value_loss: 0.8091 - policy_loss: 1.5931 - val_loss: 5.9729 - val_value_loss: 0.8436 - val_policy_loss: 1.5827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9575 - value_loss: 0.8033 - policy_loss: 1.5926 - val_loss: 5.9763 - val_value_loss: 0.8514 - val_policy_loss: 1.5826\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9581 - value_loss: 0.8055 - policy_loss: 1.5923 - val_loss: 5.9720 - val_value_loss: 0.8434 - val_policy_loss: 1.5826\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9553 - value_loss: 0.8010 - policy_loss: 1.5921 - val_loss: 5.9756 - val_value_loss: 0.8515 - val_policy_loss: 1.5825\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9509 - value_loss: 0.7935 - policy_loss: 1.5915 - val_loss: 5.9757 - val_value_loss: 0.8526 - val_policy_loss: 1.5823\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9505 - value_loss: 0.7933 - policy_loss: 1.5917 - val_loss: 5.9836 - val_value_loss: 0.8693 - val_policy_loss: 1.5822\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9486 - value_loss: 0.7904 - policy_loss: 1.5914 - val_loss: 5.9719 - val_value_loss: 0.8469 - val_policy_loss: 1.5821\n",
      "Saved model  tictactoe_lr_0_02_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.77 - draw ratio 0.02\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.9128 - value_loss: 0.7553 - policy_loss: 1.5558 - val_loss: 5.9280 - val_value_loss: 0.7895 - val_policy_loss: 1.5524\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9043 - value_loss: 0.7404 - policy_loss: 1.5544 - val_loss: 5.9242 - val_value_loss: 0.7829 - val_policy_loss: 1.5520\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9003 - value_loss: 0.7340 - policy_loss: 1.5535 - val_loss: 5.9225 - val_value_loss: 0.7805 - val_policy_loss: 1.5519\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.8984 - value_loss: 0.7314 - policy_loss: 1.5531 - val_loss: 5.9207 - val_value_loss: 0.7779 - val_policy_loss: 1.5517\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.8942 - value_loss: 0.7247 - policy_loss: 1.5522 - val_loss: 5.9188 - val_value_loss: 0.7750 - val_policy_loss: 1.5514\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.8921 - value_loss: 0.7215 - policy_loss: 1.5520 - val_loss: 5.9184 - val_value_loss: 0.7751 - val_policy_loss: 1.5514\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.8901 - value_loss: 0.7187 - policy_loss: 1.5515 - val_loss: 5.9179 - val_value_loss: 0.7749 - val_policy_loss: 1.5513\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.8879 - value_loss: 0.7154 - policy_loss: 1.5511 - val_loss: 5.9160 - val_value_loss: 0.7720 - val_policy_loss: 1.5512\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.8876 - value_loss: 0.7158 - policy_loss: 1.5509 - val_loss: 5.9155 - val_value_loss: 0.7717 - val_policy_loss: 1.5512\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.8852 - value_loss: 0.7120 - policy_loss: 1.5506 - val_loss: 5.9152 - val_value_loss: 0.7720 - val_policy_loss: 1.5511\n",
      "Saved model  tictactoe_lr_0_02_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.02\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9062 - value_loss: 0.7315 - policy_loss: 1.5739 - val_loss: 5.8863 - val_value_loss: 0.7126 - val_policy_loss: 1.5534\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9005 - value_loss: 0.7221 - policy_loss: 1.5728 - val_loss: 5.8839 - val_value_loss: 0.7088 - val_policy_loss: 1.5532\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.8963 - value_loss: 0.7149 - policy_loss: 1.5723 - val_loss: 5.8819 - val_value_loss: 0.7055 - val_policy_loss: 1.5532\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.8939 - value_loss: 0.7116 - policy_loss: 1.5715 - val_loss: 5.8824 - val_value_loss: 0.7074 - val_policy_loss: 1.5531\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.8905 - value_loss: 0.7058 - policy_loss: 1.5712 - val_loss: 5.8804 - val_value_loss: 0.7043 - val_policy_loss: 1.5530\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.8882 - value_loss: 0.7023 - policy_loss: 1.5709 - val_loss: 5.8798 - val_value_loss: 0.7040 - val_policy_loss: 1.5528\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.8864 - value_loss: 0.6999 - policy_loss: 1.5704 - val_loss: 5.8791 - val_value_loss: 0.7034 - val_policy_loss: 1.5527\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.8841 - value_loss: 0.6963 - policy_loss: 1.5702 - val_loss: 5.8795 - val_value_loss: 0.7050 - val_policy_loss: 1.5528\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.8841 - value_loss: 0.6975 - policy_loss: 1.5697 - val_loss: 5.8783 - val_value_loss: 0.7034 - val_policy_loss: 1.5526\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.8817 - value_loss: 0.6936 - policy_loss: 1.5697 - val_loss: 5.8771 - val_value_loss: 0.7019 - val_policy_loss: 1.5527\n",
      "Saved model  tictactoe_lr_0_02_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.02\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.9516 - value_loss: 0.8163 - policy_loss: 1.5874 - val_loss: 5.9613 - val_value_loss: 0.8282 - val_policy_loss: 1.5951\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9472 - value_loss: 0.8088 - policy_loss: 1.5864 - val_loss: 5.9601 - val_value_loss: 0.8264 - val_policy_loss: 1.5949\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9420 - value_loss: 0.7993 - policy_loss: 1.5858 - val_loss: 5.9581 - val_value_loss: 0.8228 - val_policy_loss: 1.5947\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9388 - value_loss: 0.7936 - policy_loss: 1.5856 - val_loss: 5.9578 - val_value_loss: 0.8228 - val_policy_loss: 1.5946\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9357 - value_loss: 0.7878 - policy_loss: 1.5856 - val_loss: 5.9559 - val_value_loss: 0.8195 - val_policy_loss: 1.5945\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9322 - value_loss: 0.7818 - policy_loss: 1.5850 - val_loss: 5.9557 - val_value_loss: 0.8194 - val_policy_loss: 1.5945\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9303 - value_loss: 0.7785 - policy_loss: 1.5848 - val_loss: 5.9551 - val_value_loss: 0.8188 - val_policy_loss: 1.5944\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9283 - value_loss: 0.7751 - policy_loss: 1.5845 - val_loss: 5.9563 - val_value_loss: 0.8215 - val_policy_loss: 1.5943\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9265 - value_loss: 0.7723 - policy_loss: 1.5843 - val_loss: 5.9566 - val_value_loss: 0.8225 - val_policy_loss: 1.5943\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9248 - value_loss: 0.7695 - policy_loss: 1.5840 - val_loss: 5.9557 - val_value_loss: 0.8212 - val_policy_loss: 1.5943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_lr_0_02_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.01\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.9722 - value_loss: 0.8466 - policy_loss: 1.6021 - val_loss: 5.9809 - val_value_loss: 0.8795 - val_policy_loss: 1.5867\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9670 - value_loss: 0.8374 - policy_loss: 1.6012 - val_loss: 5.9815 - val_value_loss: 0.8813 - val_policy_loss: 1.5865\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9637 - value_loss: 0.8313 - policy_loss: 1.6011 - val_loss: 5.9792 - val_value_loss: 0.8773 - val_policy_loss: 1.5863\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9607 - value_loss: 0.8264 - policy_loss: 1.6004 - val_loss: 5.9789 - val_value_loss: 0.8772 - val_policy_loss: 1.5862\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9578 - value_loss: 0.8215 - policy_loss: 1.5999 - val_loss: 5.9787 - val_value_loss: 0.8773 - val_policy_loss: 1.5861\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9561 - value_loss: 0.8183 - policy_loss: 1.6000 - val_loss: 5.9786 - val_value_loss: 0.8774 - val_policy_loss: 1.5860\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9538 - value_loss: 0.8147 - policy_loss: 1.5995 - val_loss: 5.9784 - val_value_loss: 0.8775 - val_policy_loss: 1.5860\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9531 - value_loss: 0.8139 - policy_loss: 1.5993 - val_loss: 5.9795 - val_value_loss: 0.8801 - val_policy_loss: 1.5860\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9506 - value_loss: 0.8094 - policy_loss: 1.5991 - val_loss: 5.9787 - val_value_loss: 0.8790 - val_policy_loss: 1.5859\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9498 - value_loss: 0.8082 - policy_loss: 1.5990 - val_loss: 5.9780 - val_value_loss: 0.8781 - val_policy_loss: 1.5858\n",
      "Saved model  tictactoe_lr_0_02_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.03\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9766 - value_loss: 0.8852 - policy_loss: 1.5760 - val_loss: 5.9757 - val_value_loss: 0.8919 - val_policy_loss: 1.5679\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9711 - value_loss: 0.8751 - policy_loss: 1.5755 - val_loss: 5.9742 - val_value_loss: 0.8891 - val_policy_loss: 1.5678\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9681 - value_loss: 0.8696 - policy_loss: 1.5754 - val_loss: 5.9728 - val_value_loss: 0.8869 - val_policy_loss: 1.5677\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9642 - value_loss: 0.8629 - policy_loss: 1.5747 - val_loss: 5.9720 - val_value_loss: 0.8858 - val_policy_loss: 1.5677\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9613 - value_loss: 0.8577 - policy_loss: 1.5745 - val_loss: 5.9711 - val_value_loss: 0.8843 - val_policy_loss: 1.5676\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9600 - value_loss: 0.8557 - policy_loss: 1.5742 - val_loss: 5.9704 - val_value_loss: 0.8835 - val_policy_loss: 1.5675\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9574 - value_loss: 0.8512 - policy_loss: 1.5739 - val_loss: 5.9702 - val_value_loss: 0.8834 - val_policy_loss: 1.5675\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9554 - value_loss: 0.8476 - policy_loss: 1.5740 - val_loss: 5.9695 - val_value_loss: 0.8824 - val_policy_loss: 1.5675\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9541 - value_loss: 0.8454 - policy_loss: 1.5739 - val_loss: 5.9691 - val_value_loss: 0.8821 - val_policy_loss: 1.5675\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9525 - value_loss: 0.8426 - policy_loss: 1.5738 - val_loss: 5.9688 - val_value_loss: 0.8819 - val_policy_loss: 1.5674\n",
      "Saved model  tictactoe_lr_0_02_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.03\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9687 - value_loss: 0.8820 - policy_loss: 1.5673 - val_loss: 6.0079 - val_value_loss: 0.9484 - val_policy_loss: 1.5794\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9643 - value_loss: 0.8741 - policy_loss: 1.5667 - val_loss: 6.0081 - val_value_loss: 0.9493 - val_policy_loss: 1.5792\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9599 - value_loss: 0.8659 - policy_loss: 1.5665 - val_loss: 6.0051 - val_value_loss: 0.9439 - val_policy_loss: 1.5791\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9580 - value_loss: 0.8623 - policy_loss: 1.5667 - val_loss: 6.0085 - val_value_loss: 0.9513 - val_policy_loss: 1.5790\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9551 - value_loss: 0.8575 - policy_loss: 1.5660 - val_loss: 6.0072 - val_value_loss: 0.9492 - val_policy_loss: 1.5788\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.9520 - value_loss: 0.8520 - policy_loss: 1.5657 - val_loss: 6.0054 - val_value_loss: 0.9460 - val_policy_loss: 1.5787\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9501 - value_loss: 0.8489 - policy_loss: 1.5654 - val_loss: 6.0035 - val_value_loss: 0.9426 - val_policy_loss: 1.5786\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9489 - value_loss: 0.8466 - policy_loss: 1.5657 - val_loss: 6.0037 - val_value_loss: 0.9435 - val_policy_loss: 1.5786\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9470 - value_loss: 0.8434 - policy_loss: 1.5655 - val_loss: 6.0035 - val_value_loss: 0.9436 - val_policy_loss: 1.5785\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9449 - value_loss: 0.8401 - policy_loss: 1.5649 - val_loss: 6.0040 - val_value_loss: 0.9449 - val_policy_loss: 1.5785\n",
      "Saved model  tictactoe_lr_0_02_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.64 - draw ratio 0.06\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.9938 - value_loss: 0.9216 - policy_loss: 1.5817 - val_loss: 5.9641 - val_value_loss: 0.8732 - val_policy_loss: 1.5707\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9885 - value_loss: 0.9116 - policy_loss: 1.5813 - val_loss: 5.9612 - val_value_loss: 0.8681 - val_policy_loss: 1.5706\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9849 - value_loss: 0.9052 - policy_loss: 1.5810 - val_loss: 5.9624 - val_value_loss: 0.8709 - val_policy_loss: 1.5705\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9810 - value_loss: 0.8979 - policy_loss: 1.5810 - val_loss: 5.9602 - val_value_loss: 0.8669 - val_policy_loss: 1.5704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9776 - value_loss: 0.8917 - policy_loss: 1.5807 - val_loss: 5.9635 - val_value_loss: 0.8741 - val_policy_loss: 1.5704\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9767 - value_loss: 0.8906 - policy_loss: 1.5803 - val_loss: 5.9615 - val_value_loss: 0.8705 - val_policy_loss: 1.5703\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9733 - value_loss: 0.8840 - policy_loss: 1.5805 - val_loss: 5.9585 - val_value_loss: 0.8649 - val_policy_loss: 1.5703\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9718 - value_loss: 0.8817 - policy_loss: 1.5803 - val_loss: 5.9566 - val_value_loss: 0.8614 - val_policy_loss: 1.5703\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9701 - value_loss: 0.8788 - policy_loss: 1.5799 - val_loss: 5.9570 - val_value_loss: 0.8625 - val_policy_loss: 1.5703\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9685 - value_loss: 0.8761 - policy_loss: 1.5798 - val_loss: 5.9575 - val_value_loss: 0.8640 - val_policy_loss: 1.5702\n",
      "Saved model  tictactoe_lr_0_02_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.71 - draw ratio 0.09\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.9333 - value_loss: 0.8025 - policy_loss: 1.5834 - val_loss: 5.9208 - val_value_loss: 0.8023 - val_policy_loss: 1.5587\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9301 - value_loss: 0.7968 - policy_loss: 1.5830 - val_loss: 5.9197 - val_value_loss: 0.8005 - val_policy_loss: 1.5586\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9279 - value_loss: 0.7926 - policy_loss: 1.5829 - val_loss: 5.9180 - val_value_loss: 0.7974 - val_policy_loss: 1.5585\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9264 - value_loss: 0.7902 - policy_loss: 1.5824 - val_loss: 5.9179 - val_value_loss: 0.7975 - val_policy_loss: 1.5584\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9247 - value_loss: 0.7872 - policy_loss: 1.5823 - val_loss: 5.9172 - val_value_loss: 0.7963 - val_policy_loss: 1.5583\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9232 - value_loss: 0.7846 - policy_loss: 1.5820 - val_loss: 5.9162 - val_value_loss: 0.7946 - val_policy_loss: 1.5582\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9220 - value_loss: 0.7824 - policy_loss: 1.5821 - val_loss: 5.9156 - val_value_loss: 0.7937 - val_policy_loss: 1.5581\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9200 - value_loss: 0.7785 - policy_loss: 1.5822 - val_loss: 5.9155 - val_value_loss: 0.7936 - val_policy_loss: 1.5581\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9193 - value_loss: 0.7774 - policy_loss: 1.5819 - val_loss: 5.9156 - val_value_loss: 0.7941 - val_policy_loss: 1.5580\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9175 - value_loss: 0.7746 - policy_loss: 1.5814 - val_loss: 5.9146 - val_value_loss: 0.7923 - val_policy_loss: 1.5580\n",
      "Saved model  tictactoe_lr_0_02_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.66 - draw ratio 0.04\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.9537 - value_loss: 0.8540 - policy_loss: 1.5747 - val_loss: 5.9622 - val_value_loss: 0.8311 - val_policy_loss: 1.6147\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9512 - value_loss: 0.8499 - policy_loss: 1.5739 - val_loss: 5.9620 - val_value_loss: 0.8311 - val_policy_loss: 1.6145\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9489 - value_loss: 0.8461 - policy_loss: 1.5734 - val_loss: 5.9617 - val_value_loss: 0.8308 - val_policy_loss: 1.6144\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9476 - value_loss: 0.8436 - policy_loss: 1.5733 - val_loss: 5.9614 - val_value_loss: 0.8305 - val_policy_loss: 1.6143\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9458 - value_loss: 0.8409 - policy_loss: 1.5727 - val_loss: 5.9610 - val_value_loss: 0.8300 - val_policy_loss: 1.6142\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9443 - value_loss: 0.8383 - policy_loss: 1.5725 - val_loss: 5.9610 - val_value_loss: 0.8302 - val_policy_loss: 1.6141\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9430 - value_loss: 0.8356 - policy_loss: 1.5727 - val_loss: 5.9605 - val_value_loss: 0.8295 - val_policy_loss: 1.6140\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9421 - value_loss: 0.8344 - policy_loss: 1.5723 - val_loss: 5.9606 - val_value_loss: 0.8298 - val_policy_loss: 1.6140\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9410 - value_loss: 0.8325 - policy_loss: 1.5723 - val_loss: 5.9602 - val_value_loss: 0.8294 - val_policy_loss: 1.6139\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9394 - value_loss: 0.8296 - policy_loss: 1.5722 - val_loss: 5.9601 - val_value_loss: 0.8293 - val_policy_loss: 1.6139\n",
      "Saved model  tictactoe_lr_0_02_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.66 - draw ratio 0.05\n",
      "iteration 27 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 5.9560 - value_loss: 0.8615 - policy_loss: 1.5736 - val_loss: 5.9827 - val_value_loss: 0.8704 - val_policy_loss: 1.6182\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9535 - value_loss: 0.8573 - policy_loss: 1.5731 - val_loss: 5.9812 - val_value_loss: 0.8677 - val_policy_loss: 1.6181\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9516 - value_loss: 0.8534 - policy_loss: 1.5732 - val_loss: 5.9805 - val_value_loss: 0.8666 - val_policy_loss: 1.6180\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9499 - value_loss: 0.8507 - policy_loss: 1.5728 - val_loss: 5.9795 - val_value_loss: 0.8648 - val_policy_loss: 1.6180\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9483 - value_loss: 0.8477 - policy_loss: 1.5728 - val_loss: 5.9788 - val_value_loss: 0.8637 - val_policy_loss: 1.6179\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9469 - value_loss: 0.8453 - policy_loss: 1.5727 - val_loss: 5.9785 - val_value_loss: 0.8633 - val_policy_loss: 1.6178\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9454 - value_loss: 0.8427 - policy_loss: 1.5723 - val_loss: 5.9780 - val_value_loss: 0.8626 - val_policy_loss: 1.6177\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9440 - value_loss: 0.8402 - policy_loss: 1.5722 - val_loss: 5.9777 - val_value_loss: 0.8623 - val_policy_loss: 1.6177\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9430 - value_loss: 0.8383 - policy_loss: 1.5723 - val_loss: 5.9773 - val_value_loss: 0.8618 - val_policy_loss: 1.6176\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9422 - value_loss: 0.8372 - policy_loss: 1.5719 - val_loss: 5.9766 - val_value_loss: 0.8606 - val_policy_loss: 1.6176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_lr_0_02_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.71 - draw ratio 0.03\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.9411 - value_loss: 0.8155 - policy_loss: 1.5917 - val_loss: 5.9060 - val_value_loss: 0.7563 - val_policy_loss: 1.5808\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9385 - value_loss: 0.8109 - policy_loss: 1.5914 - val_loss: 5.9046 - val_value_loss: 0.7537 - val_policy_loss: 1.5808\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9367 - value_loss: 0.8076 - policy_loss: 1.5912 - val_loss: 5.9042 - val_value_loss: 0.7531 - val_policy_loss: 1.5808\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9349 - value_loss: 0.8043 - policy_loss: 1.5910 - val_loss: 5.9036 - val_value_loss: 0.7520 - val_policy_loss: 1.5808\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9333 - value_loss: 0.8015 - policy_loss: 1.5909 - val_loss: 5.9022 - val_value_loss: 0.7495 - val_policy_loss: 1.5807\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9320 - value_loss: 0.7995 - policy_loss: 1.5906 - val_loss: 5.9022 - val_value_loss: 0.7497 - val_policy_loss: 1.5807\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9307 - value_loss: 0.7970 - policy_loss: 1.5906 - val_loss: 5.9008 - val_value_loss: 0.7473 - val_policy_loss: 1.5806\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9295 - value_loss: 0.7950 - policy_loss: 1.5904 - val_loss: 5.9011 - val_value_loss: 0.7481 - val_policy_loss: 1.5806\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9285 - value_loss: 0.7929 - policy_loss: 1.5907 - val_loss: 5.9007 - val_value_loss: 0.7475 - val_policy_loss: 1.5806\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9271 - value_loss: 0.7908 - policy_loss: 1.5901 - val_loss: 5.9010 - val_value_loss: 0.7484 - val_policy_loss: 1.5805\n",
      "Saved model  tictactoe_lr_0_02_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.03\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.9598 - value_loss: 0.8357 - policy_loss: 1.6108 - val_loss: 5.9674 - val_value_loss: 0.8792 - val_policy_loss: 1.5827\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9575 - value_loss: 0.8315 - policy_loss: 1.6106 - val_loss: 5.9666 - val_value_loss: 0.8777 - val_policy_loss: 1.5826\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9555 - value_loss: 0.8278 - policy_loss: 1.6104 - val_loss: 5.9654 - val_value_loss: 0.8756 - val_policy_loss: 1.5825\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9535 - value_loss: 0.8245 - policy_loss: 1.6100 - val_loss: 5.9647 - val_value_loss: 0.8745 - val_policy_loss: 1.5825\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9521 - value_loss: 0.8220 - policy_loss: 1.6099 - val_loss: 5.9632 - val_value_loss: 0.8717 - val_policy_loss: 1.5824\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9501 - value_loss: 0.8182 - policy_loss: 1.6099 - val_loss: 5.9623 - val_value_loss: 0.8701 - val_policy_loss: 1.5824\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9485 - value_loss: 0.8155 - policy_loss: 1.6096 - val_loss: 5.9613 - val_value_loss: 0.8683 - val_policy_loss: 1.5824\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9476 - value_loss: 0.8140 - policy_loss: 1.6095 - val_loss: 5.9604 - val_value_loss: 0.8668 - val_policy_loss: 1.5824\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9469 - value_loss: 0.8125 - policy_loss: 1.6096 - val_loss: 5.9599 - val_value_loss: 0.8659 - val_policy_loss: 1.5823\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9459 - value_loss: 0.8106 - policy_loss: 1.6099 - val_loss: 5.9595 - val_value_loss: 0.8653 - val_policy_loss: 1.5823\n",
      "Saved model  tictactoe_lr_0_02_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.04\n"
     ]
    }
   ],
   "source": [
    "wins_2, draws_2 = test_pipeline.run(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - learning rate 0.02\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "losses_2 = np.ones(30) - wins_2 - draws_2\n",
    "# no_loss = np.zeros(50) + wins +draws\n",
    "\n",
    "plt.plot(x, wins_2, label=\"win ratio\")\n",
    "plt.plot(x, draws_2, label=\"draw ratio\")\n",
    "#plt.plot(x, no_loss, label=\"no loss ratio\")\n",
    "plt.plot(x, losses_2, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins_2 = [0.8, 0.66, 0.6, 0.68, 0.69, 0.78, 0.73, 0.62, 0.79, 0.76, 0.73, 0.71, 0.77, 0.7, 0.66, 0.76, 0.69, 0.77, 0.7, 0.88, 0.79, 0.82, 0.7, 0.64, 0.71, 0.66, 0.66, 0.71, 0.8, 0.76]\n",
      "draws_2 = [0.01, 0.02, 0.1, 0.04, 0.02, 0.03, 0.04, 0.08, 0.05, 0.03, 0.03, 0.06, 0.01, 0.03, 0.02, 0.04, 0.02, 0.02, 0.02, 0.02, 0.01, 0.03, 0.03, 0.06, 0.09, 0.04, 0.05, 0.03, 0.03, 0.04]\n",
      "losses_2 = [0.19 0.32 0.3  0.28 0.29 0.19 0.23 0.3  0.16 0.21 0.24 0.23 0.22 0.27\n",
      " 0.32 0.2  0.29 0.21 0.28 0.1  0.2  0.15 0.27 0.3  0.2  0.3  0.29 0.26\n",
      " 0.17 0.2 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"wins_2 =\",wins_2)\n",
    "print(\"draws_2 =\",draws_2)\n",
    "print(\"losses_2 =\",losses_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCTS = {\n",
    "    'c_puct': 1.0,\n",
    "    'dir_alpha': 0.6,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 10,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 10\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 0,\n",
    "    'show_games': False\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.002,\n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 512,\n",
    "    'num_filters_value': 512,\n",
    "    'num_filters_tower': 512,\n",
    "    'num_residual_blocks': 3,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 512\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"tictactoe_lr_0_002\", \"TicTacToe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5056, 3, 3, 3)\n",
      "model_y_outcomes: (5056,)\n",
      "model_y_probabilities: (5056, 9)\n",
      "Train on 4044 samples, validate on 1012 samples\n",
      "Epoch 1/10\n",
      "4044/4044 [==============================] - 5s 1ms/step - loss: 6.6496 - value_loss: 0.8509 - policy_loss: 2.3654 - val_loss: 6.8887 - val_value_loss: 1.4779 - val_policy_loss: 2.2170\n",
      "Epoch 2/10\n",
      "4044/4044 [==============================] - 1s 174us/step - loss: 6.4779 - value_loss: 0.7282 - policy_loss: 2.1453 - val_loss: 6.7463 - val_value_loss: 1.2840 - val_policy_loss: 2.1266\n",
      "Epoch 3/10\n",
      "4044/4044 [==============================] - 1s 174us/step - loss: 6.3940 - value_loss: 0.6515 - policy_loss: 2.0548 - val_loss: 6.6695 - val_value_loss: 1.1934 - val_policy_loss: 2.0643\n",
      "Epoch 4/10\n",
      "4044/4044 [==============================] - 1s 173us/step - loss: 6.3459 - value_loss: 0.6200 - policy_loss: 1.9908 - val_loss: 6.6509 - val_value_loss: 1.2026 - val_policy_loss: 2.0186\n",
      "Epoch 5/10\n",
      "4044/4044 [==============================] - 1s 173us/step - loss: 6.2971 - value_loss: 0.5720 - policy_loss: 1.9418 - val_loss: 6.6079 - val_value_loss: 1.1540 - val_policy_loss: 1.9819\n",
      "Epoch 6/10\n",
      "4044/4044 [==============================] - 1s 173us/step - loss: 6.2691 - value_loss: 0.5544 - policy_loss: 1.9041 - val_loss: 6.5272 - val_value_loss: 1.0198 - val_policy_loss: 1.9552\n",
      "Epoch 7/10\n",
      "4044/4044 [==============================] - 1s 173us/step - loss: 6.2318 - value_loss: 0.5102 - policy_loss: 1.8744 - val_loss: 6.6110 - val_value_loss: 1.2119 - val_policy_loss: 1.9314\n",
      "Epoch 8/10\n",
      "4044/4044 [==============================] - 1s 173us/step - loss: 6.2277 - value_loss: 0.5280 - policy_loss: 1.8490 - val_loss: 6.5168 - val_value_loss: 1.0462 - val_policy_loss: 1.9094\n",
      "Epoch 9/10\n",
      "4044/4044 [==============================] - 1s 173us/step - loss: 6.2047 - value_loss: 0.5042 - policy_loss: 1.8273 - val_loss: 6.5284 - val_value_loss: 1.0870 - val_policy_loss: 1.8924\n",
      "Epoch 10/10\n",
      "4044/4044 [==============================] - 1s 173us/step - loss: 6.1930 - value_loss: 0.4994 - policy_loss: 1.8094 - val_loss: 6.4574 - val_value_loss: 0.9605 - val_policy_loss: 1.8776\n",
      "Saved model  tictactoe_lr_0_002_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.06\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2608 - value_loss: 0.6303 - policy_loss: 1.8148 - val_loss: 6.2241 - val_value_loss: 0.5705 - val_policy_loss: 1.8016\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2056 - value_loss: 0.5452 - policy_loss: 1.7902 - val_loss: 6.2370 - val_value_loss: 0.6096 - val_policy_loss: 1.7888\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1949 - value_loss: 0.5432 - policy_loss: 1.7713 - val_loss: 6.2124 - val_value_loss: 0.5720 - val_policy_loss: 1.7780\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1696 - value_loss: 0.5094 - policy_loss: 1.7551 - val_loss: 6.2252 - val_value_loss: 0.6070 - val_policy_loss: 1.7692\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1746 - value_loss: 0.5343 - policy_loss: 1.7410 - val_loss: 6.2021 - val_value_loss: 0.5700 - val_policy_loss: 1.7606\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1538 - value_loss: 0.5057 - policy_loss: 1.7286 - val_loss: 6.1957 - val_value_loss: 0.5658 - val_policy_loss: 1.7526\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1337 - value_loss: 0.4766 - policy_loss: 1.7181 - val_loss: 6.1766 - val_value_loss: 0.5353 - val_policy_loss: 1.7455\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1186 - value_loss: 0.4557 - policy_loss: 1.7093 - val_loss: 6.2113 - val_value_loss: 0.6103 - val_policy_loss: 1.7406\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1220 - value_loss: 0.4711 - policy_loss: 1.7015 - val_loss: 6.1614 - val_value_loss: 0.5180 - val_policy_loss: 1.7339\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1168 - value_loss: 0.4686 - policy_loss: 1.6943 - val_loss: 6.1769 - val_value_loss: 0.5546 - val_policy_loss: 1.7287\n",
      "Saved model  tictactoe_lr_0_002_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.03\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1999 - value_loss: 0.6159 - policy_loss: 1.7138 - val_loss: 6.2156 - val_value_loss: 0.6161 - val_policy_loss: 1.7454\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1587 - value_loss: 0.5506 - policy_loss: 1.6973 - val_loss: 6.1945 - val_value_loss: 0.5837 - val_policy_loss: 1.7363\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1500 - value_loss: 0.5441 - policy_loss: 1.6870 - val_loss: 6.1971 - val_value_loss: 0.5970 - val_policy_loss: 1.7287\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1264 - value_loss: 0.5084 - policy_loss: 1.6762 - val_loss: 6.1724 - val_value_loss: 0.5548 - val_policy_loss: 1.7221\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1042 - value_loss: 0.4727 - policy_loss: 1.6681 - val_loss: 6.1835 - val_value_loss: 0.5832 - val_policy_loss: 1.7166\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1009 - value_loss: 0.4759 - policy_loss: 1.6591 - val_loss: 6.1738 - val_value_loss: 0.5693 - val_policy_loss: 1.7118\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0964 - value_loss: 0.4736 - policy_loss: 1.6528 - val_loss: 6.1827 - val_value_loss: 0.5925 - val_policy_loss: 1.7070\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0856 - value_loss: 0.4587 - policy_loss: 1.6469 - val_loss: 6.1607 - val_value_loss: 0.5537 - val_policy_loss: 1.7024\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0690 - value_loss: 0.4313 - policy_loss: 1.6417 - val_loss: 6.1730 - val_value_loss: 0.5832 - val_policy_loss: 1.6982\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0801 - value_loss: 0.4597 - policy_loss: 1.6362 - val_loss: 6.1738 - val_value_loss: 0.5886 - val_policy_loss: 1.6949\n",
      "Saved model  tictactoe_lr_0_002_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.07\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2012 - value_loss: 0.6581 - policy_loss: 1.6806 - val_loss: 6.2004 - val_value_loss: 0.6480 - val_policy_loss: 1.6894\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1607 - value_loss: 0.5872 - policy_loss: 1.6711 - val_loss: 6.1939 - val_value_loss: 0.6396 - val_policy_loss: 1.6854\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1478 - value_loss: 0.5708 - policy_loss: 1.6624 - val_loss: 6.1954 - val_value_loss: 0.6473 - val_policy_loss: 1.6814\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1418 - value_loss: 0.5652 - policy_loss: 1.6566 - val_loss: 6.2524 - val_value_loss: 0.7650 - val_policy_loss: 1.6783\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1455 - value_loss: 0.5792 - policy_loss: 1.6507 - val_loss: 6.2056 - val_value_loss: 0.6754 - val_policy_loss: 1.6751\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1211 - value_loss: 0.5354 - policy_loss: 1.6463 - val_loss: 6.1740 - val_value_loss: 0.6162 - val_policy_loss: 1.6716\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0983 - value_loss: 0.4957 - policy_loss: 1.6410 - val_loss: 6.1769 - val_value_loss: 0.6257 - val_policy_loss: 1.6686\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0894 - value_loss: 0.4820 - policy_loss: 1.6375 - val_loss: 6.1755 - val_value_loss: 0.6255 - val_policy_loss: 1.6666\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0860 - value_loss: 0.4794 - policy_loss: 1.6339 - val_loss: 6.1778 - val_value_loss: 0.6337 - val_policy_loss: 1.6636\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0955 - value_loss: 0.5025 - policy_loss: 1.6304 - val_loss: 6.2089 - val_value_loss: 0.6986 - val_policy_loss: 1.6615\n",
      "Saved model  tictactoe_lr_0_002_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.89 - draw ratio 0.0\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1904 - value_loss: 0.6467 - policy_loss: 1.6768 - val_loss: 6.1429 - val_value_loss: 0.5731 - val_policy_loss: 1.6556\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1523 - value_loss: 0.5795 - policy_loss: 1.6684 - val_loss: 6.1471 - val_value_loss: 0.5851 - val_policy_loss: 1.6528\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1362 - value_loss: 0.5536 - policy_loss: 1.6626 - val_loss: 6.1517 - val_value_loss: 0.5970 - val_policy_loss: 1.6508\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1209 - value_loss: 0.5277 - policy_loss: 1.6587 - val_loss: 6.1504 - val_value_loss: 0.5968 - val_policy_loss: 1.6489\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1035 - value_loss: 0.4986 - policy_loss: 1.6537 - val_loss: 6.1350 - val_value_loss: 0.5697 - val_policy_loss: 1.6459\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0929 - value_loss: 0.4815 - policy_loss: 1.6501 - val_loss: 6.1274 - val_value_loss: 0.5571 - val_policy_loss: 1.6440\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0859 - value_loss: 0.4720 - policy_loss: 1.6463 - val_loss: 6.1158 - val_value_loss: 0.5365 - val_policy_loss: 1.6420\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0761 - value_loss: 0.4549 - policy_loss: 1.6444 - val_loss: 6.1136 - val_value_loss: 0.5342 - val_policy_loss: 1.6404\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0799 - value_loss: 0.4671 - policy_loss: 1.6406 - val_loss: 6.1198 - val_value_loss: 0.5493 - val_policy_loss: 1.6384\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0685 - value_loss: 0.4469 - policy_loss: 1.6385 - val_loss: 6.1177 - val_value_loss: 0.5473 - val_policy_loss: 1.6369\n",
      "Saved model  tictactoe_lr_0_002_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.03\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1722 - value_loss: 0.6376 - policy_loss: 1.6557 - val_loss: 6.1631 - val_value_loss: 0.6318 - val_policy_loss: 1.6436\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1471 - value_loss: 0.5915 - policy_loss: 1.6520 - val_loss: 6.1502 - val_value_loss: 0.6084 - val_policy_loss: 1.6413\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1332 - value_loss: 0.5667 - policy_loss: 1.6493 - val_loss: 6.1492 - val_value_loss: 0.6085 - val_policy_loss: 1.6397\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1217 - value_loss: 0.5463 - policy_loss: 1.6469 - val_loss: 6.1401 - val_value_loss: 0.5916 - val_policy_loss: 1.6385\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1129 - value_loss: 0.5319 - policy_loss: 1.6442 - val_loss: 6.1416 - val_value_loss: 0.5961 - val_policy_loss: 1.6374\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1064 - value_loss: 0.5214 - policy_loss: 1.6419 - val_loss: 6.1388 - val_value_loss: 0.5921 - val_policy_loss: 1.6360\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1011 - value_loss: 0.5128 - policy_loss: 1.6403 - val_loss: 6.1394 - val_value_loss: 0.5947 - val_policy_loss: 1.6350\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0973 - value_loss: 0.5070 - policy_loss: 1.6387 - val_loss: 6.1388 - val_value_loss: 0.5947 - val_policy_loss: 1.6342\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0951 - value_loss: 0.5045 - policy_loss: 1.6371 - val_loss: 6.1372 - val_value_loss: 0.5929 - val_policy_loss: 1.6332\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0917 - value_loss: 0.4999 - policy_loss: 1.6353 - val_loss: 6.1350 - val_value_loss: 0.5900 - val_policy_loss: 1.6320\n",
      "Saved model  tictactoe_lr_0_002_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.04\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1389 - value_loss: 0.5994 - policy_loss: 1.6305 - val_loss: 6.1807 - val_value_loss: 0.6382 - val_policy_loss: 1.6755\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1193 - value_loss: 0.5616 - policy_loss: 1.6294 - val_loss: 6.1774 - val_value_loss: 0.6326 - val_policy_loss: 1.6749\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1051 - value_loss: 0.5369 - policy_loss: 1.6261 - val_loss: 6.1748 - val_value_loss: 0.6286 - val_policy_loss: 1.6739\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0972 - value_loss: 0.5236 - policy_loss: 1.6239 - val_loss: 6.1760 - val_value_loss: 0.6319 - val_policy_loss: 1.6732\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0909 - value_loss: 0.5128 - policy_loss: 1.6224 - val_loss: 6.1709 - val_value_loss: 0.6228 - val_policy_loss: 1.6725\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0838 - value_loss: 0.5004 - policy_loss: 1.6209 - val_loss: 6.1694 - val_value_loss: 0.6210 - val_policy_loss: 1.6717\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0788 - value_loss: 0.4914 - policy_loss: 1.6201 - val_loss: 6.1693 - val_value_loss: 0.6217 - val_policy_loss: 1.6711\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0760 - value_loss: 0.4879 - policy_loss: 1.6185 - val_loss: 6.1668 - val_value_loss: 0.6177 - val_policy_loss: 1.6704\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0719 - value_loss: 0.4815 - policy_loss: 1.6169 - val_loss: 6.1667 - val_value_loss: 0.6184 - val_policy_loss: 1.6699\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0688 - value_loss: 0.4768 - policy_loss: 1.6158 - val_loss: 6.1657 - val_value_loss: 0.6173 - val_policy_loss: 1.6693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_lr_0_002_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.03\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1061 - value_loss: 0.5271 - policy_loss: 1.6405 - val_loss: 6.1272 - val_value_loss: 0.5659 - val_policy_loss: 1.6441\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0899 - value_loss: 0.4974 - policy_loss: 1.6379 - val_loss: 6.1257 - val_value_loss: 0.5643 - val_policy_loss: 1.6429\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0768 - value_loss: 0.4740 - policy_loss: 1.6355 - val_loss: 6.1189 - val_value_loss: 0.5520 - val_policy_loss: 1.6419\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0688 - value_loss: 0.4595 - policy_loss: 1.6343 - val_loss: 6.1185 - val_value_loss: 0.5521 - val_policy_loss: 1.6413\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0631 - value_loss: 0.4503 - policy_loss: 1.6325 - val_loss: 6.1167 - val_value_loss: 0.5497 - val_policy_loss: 1.6405\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0584 - value_loss: 0.4426 - policy_loss: 1.6310 - val_loss: 6.1186 - val_value_loss: 0.5545 - val_policy_loss: 1.6398\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0550 - value_loss: 0.4370 - policy_loss: 1.6303 - val_loss: 6.1174 - val_value_loss: 0.5532 - val_policy_loss: 1.6389\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0508 - value_loss: 0.4303 - policy_loss: 1.6287 - val_loss: 6.1120 - val_value_loss: 0.5436 - val_policy_loss: 1.6381\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0473 - value_loss: 0.4255 - policy_loss: 1.6269 - val_loss: 6.1147 - val_value_loss: 0.5499 - val_policy_loss: 1.6375\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0474 - value_loss: 0.4262 - policy_loss: 1.6268 - val_loss: 6.1094 - val_value_loss: 0.5401 - val_policy_loss: 1.6369\n",
      "Saved model  tictactoe_lr_0_002_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.03\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1010 - value_loss: 0.5447 - policy_loss: 1.6158 - val_loss: 6.1001 - val_value_loss: 0.5283 - val_policy_loss: 1.6305\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0823 - value_loss: 0.5105 - policy_loss: 1.6130 - val_loss: 6.0923 - val_value_loss: 0.5135 - val_policy_loss: 1.6300\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0694 - value_loss: 0.4864 - policy_loss: 1.6115 - val_loss: 6.0883 - val_value_loss: 0.5066 - val_policy_loss: 1.6293\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0625 - value_loss: 0.4741 - policy_loss: 1.6103 - val_loss: 6.0855 - val_value_loss: 0.5019 - val_policy_loss: 1.6288\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0550 - value_loss: 0.4609 - policy_loss: 1.6089 - val_loss: 6.0852 - val_value_loss: 0.5019 - val_policy_loss: 1.6283\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0511 - value_loss: 0.4545 - policy_loss: 1.6078 - val_loss: 6.0881 - val_value_loss: 0.5088 - val_policy_loss: 1.6277\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0469 - value_loss: 0.4482 - policy_loss: 1.6061 - val_loss: 6.0854 - val_value_loss: 0.5041 - val_policy_loss: 1.6272\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0446 - value_loss: 0.4451 - policy_loss: 1.6049 - val_loss: 6.0847 - val_value_loss: 0.5036 - val_policy_loss: 1.6267\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0403 - value_loss: 0.4373 - policy_loss: 1.6042 - val_loss: 6.0854 - val_value_loss: 0.5058 - val_policy_loss: 1.6262\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0396 - value_loss: 0.4375 - policy_loss: 1.6031 - val_loss: 6.0842 - val_value_loss: 0.5042 - val_policy_loss: 1.6256\n",
      "Saved model  tictactoe_lr_0_002_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.01\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0888 - value_loss: 0.5140 - policy_loss: 1.6253 - val_loss: 6.1201 - val_value_loss: 0.5412 - val_policy_loss: 1.6609\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0679 - value_loss: 0.4746 - policy_loss: 1.6232 - val_loss: 6.1255 - val_value_loss: 0.5537 - val_policy_loss: 1.6595\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0551 - value_loss: 0.4511 - policy_loss: 1.6215 - val_loss: 6.1152 - val_value_loss: 0.5342 - val_policy_loss: 1.6586\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0481 - value_loss: 0.4391 - policy_loss: 1.6197 - val_loss: 6.1143 - val_value_loss: 0.5338 - val_policy_loss: 1.6577\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0429 - value_loss: 0.4301 - policy_loss: 1.6186 - val_loss: 6.1115 - val_value_loss: 0.5290 - val_policy_loss: 1.6570\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0380 - value_loss: 0.4213 - policy_loss: 1.6179 - val_loss: 6.1104 - val_value_loss: 0.5278 - val_policy_loss: 1.6564\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0328 - value_loss: 0.4128 - policy_loss: 1.6163 - val_loss: 6.1048 - val_value_loss: 0.5175 - val_policy_loss: 1.6558\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0315 - value_loss: 0.4116 - policy_loss: 1.6154 - val_loss: 6.1072 - val_value_loss: 0.5232 - val_policy_loss: 1.6554\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0288 - value_loss: 0.4067 - policy_loss: 1.6150 - val_loss: 6.1056 - val_value_loss: 0.5211 - val_policy_loss: 1.6546\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0270 - value_loss: 0.4049 - policy_loss: 1.6137 - val_loss: 6.1047 - val_value_loss: 0.5200 - val_policy_loss: 1.6541\n",
      "Saved model  tictactoe_lr_0_002_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.0\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1024 - value_loss: 0.5407 - policy_loss: 1.6289 - val_loss: 6.0968 - val_value_loss: 0.5116 - val_policy_loss: 1.6468\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0907 - value_loss: 0.5190 - policy_loss: 1.6273 - val_loss: 6.0934 - val_value_loss: 0.5054 - val_policy_loss: 1.6464\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0848 - value_loss: 0.5082 - policy_loss: 1.6265 - val_loss: 6.0905 - val_value_loss: 0.5001 - val_policy_loss: 1.6460\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0794 - value_loss: 0.4980 - policy_loss: 1.6260 - val_loss: 6.0877 - val_value_loss: 0.4952 - val_policy_loss: 1.6456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0735 - value_loss: 0.4871 - policy_loss: 1.6254 - val_loss: 6.0861 - val_value_loss: 0.4924 - val_policy_loss: 1.6453\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0700 - value_loss: 0.4810 - policy_loss: 1.6245 - val_loss: 6.0850 - val_value_loss: 0.4908 - val_policy_loss: 1.6449\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0660 - value_loss: 0.4740 - policy_loss: 1.6238 - val_loss: 6.0838 - val_value_loss: 0.4887 - val_policy_loss: 1.6446\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0634 - value_loss: 0.4690 - policy_loss: 1.6237 - val_loss: 6.0835 - val_value_loss: 0.4886 - val_policy_loss: 1.6443\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0598 - value_loss: 0.4630 - policy_loss: 1.6226 - val_loss: 6.0819 - val_value_loss: 0.4859 - val_policy_loss: 1.6440\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0580 - value_loss: 0.4604 - policy_loss: 1.6217 - val_loss: 6.0817 - val_value_loss: 0.4859 - val_policy_loss: 1.6438\n",
      "Saved model  tictactoe_lr_0_002_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.01\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 6.1202 - value_loss: 0.5902 - policy_loss: 1.6165 - val_loss: 6.1257 - val_value_loss: 0.5596 - val_policy_loss: 1.6583\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1072 - value_loss: 0.5655 - policy_loss: 1.6155 - val_loss: 6.1225 - val_value_loss: 0.5540 - val_policy_loss: 1.6577\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0961 - value_loss: 0.5442 - policy_loss: 1.6147 - val_loss: 6.1208 - val_value_loss: 0.5512 - val_policy_loss: 1.6572\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0888 - value_loss: 0.5306 - policy_loss: 1.6139 - val_loss: 6.1207 - val_value_loss: 0.5514 - val_policy_loss: 1.6569\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0821 - value_loss: 0.5185 - policy_loss: 1.6127 - val_loss: 6.1208 - val_value_loss: 0.5521 - val_policy_loss: 1.6565\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0774 - value_loss: 0.5102 - policy_loss: 1.6119 - val_loss: 6.1200 - val_value_loss: 0.5511 - val_policy_loss: 1.6562\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.0737 - value_loss: 0.5034 - policy_loss: 1.6112 - val_loss: 6.1208 - val_value_loss: 0.5531 - val_policy_loss: 1.6559\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0705 - value_loss: 0.4976 - policy_loss: 1.6109 - val_loss: 6.1208 - val_value_loss: 0.5536 - val_policy_loss: 1.6557\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0694 - value_loss: 0.4964 - policy_loss: 1.6101 - val_loss: 6.1193 - val_value_loss: 0.5511 - val_policy_loss: 1.6553\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0658 - value_loss: 0.4901 - policy_loss: 1.6093 - val_loss: 6.1217 - val_value_loss: 0.5563 - val_policy_loss: 1.6551\n",
      "Saved model  tictactoe_lr_0_002_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.89 - draw ratio 0.01\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1126 - value_loss: 0.5821 - policy_loss: 1.6111 - val_loss: 6.1642 - val_value_loss: 0.6393 - val_policy_loss: 1.6572\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0962 - value_loss: 0.5510 - policy_loss: 1.6096 - val_loss: 6.1598 - val_value_loss: 0.6309 - val_policy_loss: 1.6568\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0862 - value_loss: 0.5319 - policy_loss: 1.6088 - val_loss: 6.1553 - val_value_loss: 0.6223 - val_policy_loss: 1.6566\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0813 - value_loss: 0.5233 - policy_loss: 1.6078 - val_loss: 6.1552 - val_value_loss: 0.6225 - val_policy_loss: 1.6564\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0741 - value_loss: 0.5098 - policy_loss: 1.6071 - val_loss: 6.1523 - val_value_loss: 0.6171 - val_policy_loss: 1.6562\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0695 - value_loss: 0.5014 - policy_loss: 1.6065 - val_loss: 6.1511 - val_value_loss: 0.6151 - val_policy_loss: 1.6560\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0656 - value_loss: 0.4941 - policy_loss: 1.6059 - val_loss: 6.1504 - val_value_loss: 0.6140 - val_policy_loss: 1.6558\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0620 - value_loss: 0.4877 - policy_loss: 1.6053 - val_loss: 6.1506 - val_value_loss: 0.6147 - val_policy_loss: 1.6556\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0585 - value_loss: 0.4823 - policy_loss: 1.6040 - val_loss: 6.1497 - val_value_loss: 0.6135 - val_policy_loss: 1.6553\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0574 - value_loss: 0.4806 - policy_loss: 1.6037 - val_loss: 6.1479 - val_value_loss: 0.6102 - val_policy_loss: 1.6551\n",
      "Saved model  tictactoe_lr_0_002_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.03\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1082 - value_loss: 0.5711 - policy_loss: 1.6150 - val_loss: 6.1217 - val_value_loss: 0.5777 - val_policy_loss: 1.6355\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0942 - value_loss: 0.5447 - policy_loss: 1.6135 - val_loss: 6.1180 - val_value_loss: 0.5710 - val_policy_loss: 1.6349\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0863 - value_loss: 0.5302 - policy_loss: 1.6123 - val_loss: 6.1157 - val_value_loss: 0.5672 - val_policy_loss: 1.6343\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0807 - value_loss: 0.5198 - policy_loss: 1.6117 - val_loss: 6.1156 - val_value_loss: 0.5675 - val_policy_loss: 1.6337\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0755 - value_loss: 0.5101 - policy_loss: 1.6111 - val_loss: 6.1160 - val_value_loss: 0.5690 - val_policy_loss: 1.6333\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0714 - value_loss: 0.5033 - policy_loss: 1.6100 - val_loss: 6.1130 - val_value_loss: 0.5636 - val_policy_loss: 1.6329\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0690 - value_loss: 0.4988 - policy_loss: 1.6098 - val_loss: 6.1130 - val_value_loss: 0.5641 - val_policy_loss: 1.6326\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0647 - value_loss: 0.4917 - policy_loss: 1.6083 - val_loss: 6.1119 - val_value_loss: 0.5623 - val_policy_loss: 1.6322\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0624 - value_loss: 0.4875 - policy_loss: 1.6081 - val_loss: 6.1113 - val_value_loss: 0.5618 - val_policy_loss: 1.6318\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0598 - value_loss: 0.4829 - policy_loss: 1.6078 - val_loss: 6.1105 - val_value_loss: 0.5607 - val_policy_loss: 1.6314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_lr_0_002_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.01\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1017 - value_loss: 0.5482 - policy_loss: 1.6264 - val_loss: 6.1074 - val_value_loss: 0.5679 - val_policy_loss: 1.6182\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0926 - value_loss: 0.5314 - policy_loss: 1.6252 - val_loss: 6.1047 - val_value_loss: 0.5632 - val_policy_loss: 1.6176\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0871 - value_loss: 0.5204 - policy_loss: 1.6253 - val_loss: 6.1021 - val_value_loss: 0.5587 - val_policy_loss: 1.6171\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0813 - value_loss: 0.5103 - policy_loss: 1.6239 - val_loss: 6.0999 - val_value_loss: 0.5548 - val_policy_loss: 1.6167\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0781 - value_loss: 0.5054 - policy_loss: 1.6226 - val_loss: 6.1015 - val_value_loss: 0.5585 - val_policy_loss: 1.6163\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0749 - value_loss: 0.4989 - policy_loss: 1.6230 - val_loss: 6.0988 - val_value_loss: 0.5538 - val_policy_loss: 1.6159\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0705 - value_loss: 0.4912 - policy_loss: 1.6220 - val_loss: 6.0971 - val_value_loss: 0.5508 - val_policy_loss: 1.6156\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0681 - value_loss: 0.4866 - policy_loss: 1.6218 - val_loss: 6.0977 - val_value_loss: 0.5526 - val_policy_loss: 1.6152\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0662 - value_loss: 0.4836 - policy_loss: 1.6212 - val_loss: 6.0983 - val_value_loss: 0.5542 - val_policy_loss: 1.6149\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0640 - value_loss: 0.4801 - policy_loss: 1.6206 - val_loss: 6.0969 - val_value_loss: 0.5520 - val_policy_loss: 1.6146\n",
      "Saved model  tictactoe_lr_0_002_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.0\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1294 - value_loss: 0.6270 - policy_loss: 1.6045 - val_loss: 6.0956 - val_value_loss: 0.5695 - val_policy_loss: 1.5944\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1175 - value_loss: 0.6039 - policy_loss: 1.6040 - val_loss: 6.0926 - val_value_loss: 0.5639 - val_policy_loss: 1.5942\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1100 - value_loss: 0.5898 - policy_loss: 1.6032 - val_loss: 6.0902 - val_value_loss: 0.5593 - val_policy_loss: 1.5941\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1045 - value_loss: 0.5786 - policy_loss: 1.6034 - val_loss: 6.0906 - val_value_loss: 0.5603 - val_policy_loss: 1.5939\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0996 - value_loss: 0.5696 - policy_loss: 1.6026 - val_loss: 6.0871 - val_value_loss: 0.5534 - val_policy_loss: 1.5938\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0958 - value_loss: 0.5629 - policy_loss: 1.6019 - val_loss: 6.0873 - val_value_loss: 0.5541 - val_policy_loss: 1.5937\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0920 - value_loss: 0.5558 - policy_loss: 1.6015 - val_loss: 6.0841 - val_value_loss: 0.5479 - val_policy_loss: 1.5936\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0902 - value_loss: 0.5517 - policy_loss: 1.6020 - val_loss: 6.0826 - val_value_loss: 0.5451 - val_policy_loss: 1.5935\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0870 - value_loss: 0.5463 - policy_loss: 1.6011 - val_loss: 6.0811 - val_value_loss: 0.5423 - val_policy_loss: 1.5934\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0855 - value_loss: 0.5432 - policy_loss: 1.6011 - val_loss: 6.0812 - val_value_loss: 0.5426 - val_policy_loss: 1.5933\n",
      "Saved model  tictactoe_lr_0_002_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.01\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0935 - value_loss: 0.5571 - policy_loss: 1.6034 - val_loss: 6.0866 - val_value_loss: 0.5473 - val_policy_loss: 1.5995\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.0863 - value_loss: 0.5437 - policy_loss: 1.6026 - val_loss: 6.0837 - val_value_loss: 0.5418 - val_policy_loss: 1.5993\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.0809 - value_loss: 0.5335 - policy_loss: 1.6019 - val_loss: 6.0824 - val_value_loss: 0.5393 - val_policy_loss: 1.5991\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.0777 - value_loss: 0.5273 - policy_loss: 1.6019 - val_loss: 6.0816 - val_value_loss: 0.5380 - val_policy_loss: 1.5990\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.0738 - value_loss: 0.5204 - policy_loss: 1.6011 - val_loss: 6.0810 - val_value_loss: 0.5370 - val_policy_loss: 1.5989\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.0709 - value_loss: 0.5149 - policy_loss: 1.6008 - val_loss: 6.0799 - val_value_loss: 0.5350 - val_policy_loss: 1.5987\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0677 - value_loss: 0.5094 - policy_loss: 1.6001 - val_loss: 6.0813 - val_value_loss: 0.5380 - val_policy_loss: 1.5986\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0655 - value_loss: 0.5047 - policy_loss: 1.6004 - val_loss: 6.0809 - val_value_loss: 0.5375 - val_policy_loss: 1.5985\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0637 - value_loss: 0.5012 - policy_loss: 1.6004 - val_loss: 6.0790 - val_value_loss: 0.5339 - val_policy_loss: 1.5984\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0605 - value_loss: 0.4963 - policy_loss: 1.5989 - val_loss: 6.0802 - val_value_loss: 0.5364 - val_policy_loss: 1.5983\n",
      "Saved model  tictactoe_lr_0_002_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.01\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0922 - value_loss: 0.5492 - policy_loss: 1.6095 - val_loss: 6.1206 - val_value_loss: 0.5798 - val_policy_loss: 1.6359\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0859 - value_loss: 0.5371 - policy_loss: 1.6091 - val_loss: 6.1184 - val_value_loss: 0.5757 - val_policy_loss: 1.6356\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0810 - value_loss: 0.5279 - policy_loss: 1.6087 - val_loss: 6.1170 - val_value_loss: 0.5731 - val_policy_loss: 1.6354\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0773 - value_loss: 0.5204 - policy_loss: 1.6087 - val_loss: 6.1164 - val_value_loss: 0.5721 - val_policy_loss: 1.6352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0731 - value_loss: 0.5132 - policy_loss: 1.6076 - val_loss: 6.1158 - val_value_loss: 0.5713 - val_policy_loss: 1.6350\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0704 - value_loss: 0.5076 - policy_loss: 1.6079 - val_loss: 6.1152 - val_value_loss: 0.5702 - val_policy_loss: 1.6349\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0677 - value_loss: 0.5028 - policy_loss: 1.6075 - val_loss: 6.1148 - val_value_loss: 0.5696 - val_policy_loss: 1.6347\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0660 - value_loss: 0.4997 - policy_loss: 1.6073 - val_loss: 6.1144 - val_value_loss: 0.5691 - val_policy_loss: 1.6346\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0626 - value_loss: 0.4937 - policy_loss: 1.6066 - val_loss: 6.1143 - val_value_loss: 0.5690 - val_policy_loss: 1.6345\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0618 - value_loss: 0.4922 - policy_loss: 1.6065 - val_loss: 6.1144 - val_value_loss: 0.5694 - val_policy_loss: 1.6344\n",
      "Saved model  tictactoe_lr_0_002_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.02\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1044 - value_loss: 0.5715 - policy_loss: 1.6124 - val_loss: 6.1300 - val_value_loss: 0.5981 - val_policy_loss: 1.6370\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0967 - value_loss: 0.5572 - policy_loss: 1.6114 - val_loss: 6.1271 - val_value_loss: 0.5928 - val_policy_loss: 1.6368\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0923 - value_loss: 0.5488 - policy_loss: 1.6111 - val_loss: 6.1248 - val_value_loss: 0.5884 - val_policy_loss: 1.6366\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0870 - value_loss: 0.5390 - policy_loss: 1.6105 - val_loss: 6.1237 - val_value_loss: 0.5863 - val_policy_loss: 1.6365\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0836 - value_loss: 0.5324 - policy_loss: 1.6102 - val_loss: 6.1217 - val_value_loss: 0.5826 - val_policy_loss: 1.6363\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0807 - value_loss: 0.5266 - policy_loss: 1.6103 - val_loss: 6.1206 - val_value_loss: 0.5805 - val_policy_loss: 1.6362\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0764 - value_loss: 0.5190 - policy_loss: 1.6095 - val_loss: 6.1202 - val_value_loss: 0.5799 - val_policy_loss: 1.6361\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0745 - value_loss: 0.5153 - policy_loss: 1.6095 - val_loss: 6.1190 - val_value_loss: 0.5777 - val_policy_loss: 1.6359\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0721 - value_loss: 0.5101 - policy_loss: 1.6099 - val_loss: 6.1189 - val_value_loss: 0.5777 - val_policy_loss: 1.6358\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0708 - value_loss: 0.5078 - policy_loss: 1.6096 - val_loss: 6.1188 - val_value_loss: 0.5777 - val_policy_loss: 1.6357\n",
      "Saved model  tictactoe_lr_0_002_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.9 - draw ratio 0.03\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1297 - value_loss: 0.6051 - policy_loss: 1.6302 - val_loss: 6.1058 - val_value_loss: 0.5936 - val_policy_loss: 1.5939\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1219 - value_loss: 0.5899 - policy_loss: 1.6298 - val_loss: 6.1028 - val_value_loss: 0.5880 - val_policy_loss: 1.5936\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1178 - value_loss: 0.5818 - policy_loss: 1.6299 - val_loss: 6.1007 - val_value_loss: 0.5842 - val_policy_loss: 1.5934\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1118 - value_loss: 0.5705 - policy_loss: 1.6293 - val_loss: 6.0990 - val_value_loss: 0.5811 - val_policy_loss: 1.5932\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1089 - value_loss: 0.5653 - policy_loss: 1.6289 - val_loss: 6.0970 - val_value_loss: 0.5772 - val_policy_loss: 1.5931\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1052 - value_loss: 0.5589 - policy_loss: 1.6279 - val_loss: 6.0964 - val_value_loss: 0.5763 - val_policy_loss: 1.5929\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1023 - value_loss: 0.5531 - policy_loss: 1.6280 - val_loss: 6.0949 - val_value_loss: 0.5734 - val_policy_loss: 1.5927\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0994 - value_loss: 0.5477 - policy_loss: 1.6276 - val_loss: 6.0938 - val_value_loss: 0.5716 - val_policy_loss: 1.5926\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0984 - value_loss: 0.5461 - policy_loss: 1.6273 - val_loss: 6.0928 - val_value_loss: 0.5698 - val_policy_loss: 1.5925\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0948 - value_loss: 0.5391 - policy_loss: 1.6272 - val_loss: 6.0919 - val_value_loss: 0.5682 - val_policy_loss: 1.5923\n",
      "Saved model  tictactoe_lr_0_002_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.92 - draw ratio 0.01\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1289 - value_loss: 0.6233 - policy_loss: 1.6112 - val_loss: 6.1139 - val_value_loss: 0.5993 - val_policy_loss: 1.6053\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1243 - value_loss: 0.6145 - policy_loss: 1.6109 - val_loss: 6.1131 - val_value_loss: 0.5977 - val_policy_loss: 1.6052\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1215 - value_loss: 0.6095 - policy_loss: 1.6103 - val_loss: 6.1116 - val_value_loss: 0.5949 - val_policy_loss: 1.6051\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1177 - value_loss: 0.6020 - policy_loss: 1.6102 - val_loss: 6.1104 - val_value_loss: 0.5926 - val_policy_loss: 1.6050\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1146 - value_loss: 0.5962 - policy_loss: 1.6099 - val_loss: 6.1102 - val_value_loss: 0.5924 - val_policy_loss: 1.6049\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1118 - value_loss: 0.5910 - policy_loss: 1.6096 - val_loss: 6.1097 - val_value_loss: 0.5916 - val_policy_loss: 1.6048\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1096 - value_loss: 0.5866 - policy_loss: 1.6094 - val_loss: 6.1090 - val_value_loss: 0.5902 - val_policy_loss: 1.6048\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1080 - value_loss: 0.5832 - policy_loss: 1.6098 - val_loss: 6.1087 - val_value_loss: 0.5897 - val_policy_loss: 1.6047\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1047 - value_loss: 0.5773 - policy_loss: 1.6091 - val_loss: 6.1083 - val_value_loss: 0.5889 - val_policy_loss: 1.6047\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1036 - value_loss: 0.5754 - policy_loss: 1.6089 - val_loss: 6.1077 - val_value_loss: 0.5878 - val_policy_loss: 1.6046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_lr_0_002_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.89 - draw ratio 0.01\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1403 - value_loss: 0.6262 - policy_loss: 1.6316 - val_loss: 6.1194 - val_value_loss: 0.6057 - val_policy_loss: 1.6103\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1349 - value_loss: 0.6160 - policy_loss: 1.6311 - val_loss: 6.1172 - val_value_loss: 0.6015 - val_policy_loss: 1.6102\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1312 - value_loss: 0.6079 - policy_loss: 1.6316 - val_loss: 6.1157 - val_value_loss: 0.5985 - val_policy_loss: 1.6101\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1285 - value_loss: 0.6033 - policy_loss: 1.6309 - val_loss: 6.1146 - val_value_loss: 0.5965 - val_policy_loss: 1.6100\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1259 - value_loss: 0.5985 - policy_loss: 1.6307 - val_loss: 6.1136 - val_value_loss: 0.5945 - val_policy_loss: 1.6100\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1234 - value_loss: 0.5934 - policy_loss: 1.6307 - val_loss: 6.1129 - val_value_loss: 0.5932 - val_policy_loss: 1.6099\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1212 - value_loss: 0.5897 - policy_loss: 1.6301 - val_loss: 6.1121 - val_value_loss: 0.5918 - val_policy_loss: 1.6099\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1191 - value_loss: 0.5855 - policy_loss: 1.6300 - val_loss: 6.1117 - val_value_loss: 0.5909 - val_policy_loss: 1.6098\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1170 - value_loss: 0.5816 - policy_loss: 1.6299 - val_loss: 6.1112 - val_value_loss: 0.5901 - val_policy_loss: 1.6098\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1153 - value_loss: 0.5787 - policy_loss: 1.6294 - val_loss: 6.1108 - val_value_loss: 0.5893 - val_policy_loss: 1.6097\n",
      "Saved model  tictactoe_lr_0_002_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.94 - draw ratio 0.01\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1120 - value_loss: 0.6016 - policy_loss: 1.5999 - val_loss: 6.1084 - val_value_loss: 0.5596 - val_policy_loss: 1.6347\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1086 - value_loss: 0.5947 - policy_loss: 1.6000 - val_loss: 6.1070 - val_value_loss: 0.5570 - val_policy_loss: 1.6346\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1046 - value_loss: 0.5874 - policy_loss: 1.5994 - val_loss: 6.1061 - val_value_loss: 0.5552 - val_policy_loss: 1.6346\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1021 - value_loss: 0.5830 - policy_loss: 1.5989 - val_loss: 6.1054 - val_value_loss: 0.5538 - val_policy_loss: 1.6346\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0994 - value_loss: 0.5772 - policy_loss: 1.5993 - val_loss: 6.1048 - val_value_loss: 0.5527 - val_policy_loss: 1.6345\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0961 - value_loss: 0.5713 - policy_loss: 1.5985 - val_loss: 6.1043 - val_value_loss: 0.5517 - val_policy_loss: 1.6345\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0935 - value_loss: 0.5664 - policy_loss: 1.5983 - val_loss: 6.1038 - val_value_loss: 0.5508 - val_policy_loss: 1.6345\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0923 - value_loss: 0.5640 - policy_loss: 1.5983 - val_loss: 6.1037 - val_value_loss: 0.5508 - val_policy_loss: 1.6345\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0898 - value_loss: 0.5593 - policy_loss: 1.5982 - val_loss: 6.1031 - val_value_loss: 0.5495 - val_policy_loss: 1.6345\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0879 - value_loss: 0.5561 - policy_loss: 1.5977 - val_loss: 6.1025 - val_value_loss: 0.5485 - val_policy_loss: 1.6344\n",
      "Saved model  tictactoe_lr_0_002_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.92 - draw ratio 0.0\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1193 - value_loss: 0.6115 - policy_loss: 1.6050 - val_loss: 6.1268 - val_value_loss: 0.6116 - val_policy_loss: 1.6199\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1153 - value_loss: 0.6037 - policy_loss: 1.6048 - val_loss: 6.1246 - val_value_loss: 0.6073 - val_policy_loss: 1.6198\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1111 - value_loss: 0.5958 - policy_loss: 1.6043 - val_loss: 6.1236 - val_value_loss: 0.6056 - val_policy_loss: 1.6197\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1070 - value_loss: 0.5878 - policy_loss: 1.6042 - val_loss: 6.1228 - val_value_loss: 0.6039 - val_policy_loss: 1.6197\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1039 - value_loss: 0.5821 - policy_loss: 1.6037 - val_loss: 6.1216 - val_value_loss: 0.6018 - val_policy_loss: 1.6196\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1006 - value_loss: 0.5757 - policy_loss: 1.6037 - val_loss: 6.1212 - val_value_loss: 0.6009 - val_policy_loss: 1.6196\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0984 - value_loss: 0.5711 - policy_loss: 1.6038 - val_loss: 6.1202 - val_value_loss: 0.5990 - val_policy_loss: 1.6195\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0960 - value_loss: 0.5661 - policy_loss: 1.6042 - val_loss: 6.1198 - val_value_loss: 0.5983 - val_policy_loss: 1.6195\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0935 - value_loss: 0.5618 - policy_loss: 1.6033 - val_loss: 6.1193 - val_value_loss: 0.5973 - val_policy_loss: 1.6195\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0916 - value_loss: 0.5581 - policy_loss: 1.6033 - val_loss: 6.1186 - val_value_loss: 0.5960 - val_policy_loss: 1.6195\n",
      "Saved model  tictactoe_lr_0_002_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.81 - draw ratio 0.04\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1273 - value_loss: 0.6117 - policy_loss: 1.6212 - val_loss: 6.1063 - val_value_loss: 0.5920 - val_policy_loss: 1.5991\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1234 - value_loss: 0.6045 - policy_loss: 1.6207 - val_loss: 6.1055 - val_value_loss: 0.5904 - val_policy_loss: 1.5989\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1200 - value_loss: 0.5981 - policy_loss: 1.6202 - val_loss: 6.1042 - val_value_loss: 0.5881 - val_policy_loss: 1.5988\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1175 - value_loss: 0.5928 - policy_loss: 1.6205 - val_loss: 6.1031 - val_value_loss: 0.5859 - val_policy_loss: 1.5987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1139 - value_loss: 0.5866 - policy_loss: 1.6197 - val_loss: 6.1024 - val_value_loss: 0.5848 - val_policy_loss: 1.5986\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1118 - value_loss: 0.5820 - policy_loss: 1.6200 - val_loss: 6.1029 - val_value_loss: 0.5859 - val_policy_loss: 1.5985\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1103 - value_loss: 0.5793 - policy_loss: 1.6199 - val_loss: 6.1028 - val_value_loss: 0.5857 - val_policy_loss: 1.5984\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1072 - value_loss: 0.5735 - policy_loss: 1.6196 - val_loss: 6.1023 - val_value_loss: 0.5848 - val_policy_loss: 1.5983\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1068 - value_loss: 0.5726 - policy_loss: 1.6196 - val_loss: 6.1019 - val_value_loss: 0.5842 - val_policy_loss: 1.5982\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1054 - value_loss: 0.5703 - policy_loss: 1.6191 - val_loss: 6.1014 - val_value_loss: 0.5834 - val_policy_loss: 1.5982\n",
      "Saved model  tictactoe_lr_0_002_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.03\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1346 - value_loss: 0.6241 - policy_loss: 1.6238 - val_loss: 6.1346 - val_value_loss: 0.6098 - val_policy_loss: 1.6380\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1299 - value_loss: 0.6152 - policy_loss: 1.6233 - val_loss: 6.1328 - val_value_loss: 0.6063 - val_policy_loss: 1.6379\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1278 - value_loss: 0.6108 - policy_loss: 1.6235 - val_loss: 6.1314 - val_value_loss: 0.6037 - val_policy_loss: 1.6379\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1260 - value_loss: 0.6075 - policy_loss: 1.6232 - val_loss: 6.1303 - val_value_loss: 0.6015 - val_policy_loss: 1.6378\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1229 - value_loss: 0.6013 - policy_loss: 1.6234 - val_loss: 6.1292 - val_value_loss: 0.5995 - val_policy_loss: 1.6377\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1214 - value_loss: 0.5989 - policy_loss: 1.6228 - val_loss: 6.1285 - val_value_loss: 0.5981 - val_policy_loss: 1.6377\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1198 - value_loss: 0.5952 - policy_loss: 1.6232 - val_loss: 6.1279 - val_value_loss: 0.5970 - val_policy_loss: 1.6376\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1184 - value_loss: 0.5924 - policy_loss: 1.6231 - val_loss: 6.1272 - val_value_loss: 0.5956 - val_policy_loss: 1.6376\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1158 - value_loss: 0.5881 - policy_loss: 1.6224 - val_loss: 6.1266 - val_value_loss: 0.5946 - val_policy_loss: 1.6375\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1140 - value_loss: 0.5844 - policy_loss: 1.6224 - val_loss: 6.1260 - val_value_loss: 0.5935 - val_policy_loss: 1.6375\n",
      "Saved model  tictactoe_lr_0_002_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.01\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1027 - value_loss: 0.5832 - policy_loss: 1.6012 - val_loss: 6.1277 - val_value_loss: 0.6097 - val_policy_loss: 1.6246\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0996 - value_loss: 0.5774 - policy_loss: 1.6008 - val_loss: 6.1257 - val_value_loss: 0.6058 - val_policy_loss: 1.6246\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0965 - value_loss: 0.5716 - policy_loss: 1.6004 - val_loss: 6.1242 - val_value_loss: 0.6028 - val_policy_loss: 1.6246\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0937 - value_loss: 0.5661 - policy_loss: 1.6002 - val_loss: 6.1229 - val_value_loss: 0.6003 - val_policy_loss: 1.6246\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0913 - value_loss: 0.5616 - policy_loss: 1.6001 - val_loss: 6.1219 - val_value_loss: 0.5981 - val_policy_loss: 1.6246\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0904 - value_loss: 0.5593 - policy_loss: 1.6004 - val_loss: 6.1208 - val_value_loss: 0.5961 - val_policy_loss: 1.6246\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0878 - value_loss: 0.5547 - policy_loss: 1.6000 - val_loss: 6.1201 - val_value_loss: 0.5947 - val_policy_loss: 1.6246\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0878 - value_loss: 0.5538 - policy_loss: 1.6009 - val_loss: 6.1194 - val_value_loss: 0.5932 - val_policy_loss: 1.6246\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0851 - value_loss: 0.5499 - policy_loss: 1.5995 - val_loss: 6.1187 - val_value_loss: 0.5919 - val_policy_loss: 1.6246\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0839 - value_loss: 0.5472 - policy_loss: 1.5998 - val_loss: 6.1181 - val_value_loss: 0.5908 - val_policy_loss: 1.6246\n",
      "Saved model  tictactoe_lr_0_002_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.0\n",
      "iteration 27 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1155 - value_loss: 0.5795 - policy_loss: 1.6305 - val_loss: 6.1114 - val_value_loss: 0.5714 - val_policy_loss: 1.6306\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1124 - value_loss: 0.5731 - policy_loss: 1.6309 - val_loss: 6.1104 - val_value_loss: 0.5694 - val_policy_loss: 1.6306\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1108 - value_loss: 0.5703 - policy_loss: 1.6304 - val_loss: 6.1097 - val_value_loss: 0.5681 - val_policy_loss: 1.6305\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1079 - value_loss: 0.5648 - policy_loss: 1.6302 - val_loss: 6.1090 - val_value_loss: 0.5667 - val_policy_loss: 1.6305\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1074 - value_loss: 0.5633 - policy_loss: 1.6306 - val_loss: 6.1084 - val_value_loss: 0.5655 - val_policy_loss: 1.6305\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1053 - value_loss: 0.5595 - policy_loss: 1.6303 - val_loss: 6.1078 - val_value_loss: 0.5643 - val_policy_loss: 1.6305\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1033 - value_loss: 0.5557 - policy_loss: 1.6300 - val_loss: 6.1073 - val_value_loss: 0.5634 - val_policy_loss: 1.6305\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1020 - value_loss: 0.5535 - policy_loss: 1.6297 - val_loss: 6.1070 - val_value_loss: 0.5628 - val_policy_loss: 1.6304\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1008 - value_loss: 0.5511 - policy_loss: 1.6298 - val_loss: 6.1065 - val_value_loss: 0.5618 - val_policy_loss: 1.6304\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0990 - value_loss: 0.5475 - policy_loss: 1.6298 - val_loss: 6.1061 - val_value_loss: 0.5610 - val_policy_loss: 1.6304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_lr_0_002_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.0\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0844 - value_loss: 0.5248 - policy_loss: 1.6233 - val_loss: 6.0627 - val_value_loss: 0.4943 - val_policy_loss: 1.6103\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0775 - value_loss: 0.5108 - policy_loss: 1.6236 - val_loss: 6.0591 - val_value_loss: 0.4872 - val_policy_loss: 1.6103\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0742 - value_loss: 0.5041 - policy_loss: 1.6236 - val_loss: 6.0568 - val_value_loss: 0.4828 - val_policy_loss: 1.6102\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0712 - value_loss: 0.4984 - policy_loss: 1.6233 - val_loss: 6.0552 - val_value_loss: 0.4796 - val_policy_loss: 1.6102\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0692 - value_loss: 0.4946 - policy_loss: 1.6231 - val_loss: 6.0540 - val_value_loss: 0.4773 - val_policy_loss: 1.6101\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0670 - value_loss: 0.4905 - policy_loss: 1.6230 - val_loss: 6.0530 - val_value_loss: 0.4754 - val_policy_loss: 1.6100\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0661 - value_loss: 0.4884 - policy_loss: 1.6232 - val_loss: 6.0521 - val_value_loss: 0.4737 - val_policy_loss: 1.6100\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0651 - value_loss: 0.4862 - policy_loss: 1.6234 - val_loss: 6.0514 - val_value_loss: 0.4723 - val_policy_loss: 1.6099\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0630 - value_loss: 0.4824 - policy_loss: 1.6230 - val_loss: 6.0507 - val_value_loss: 0.4710 - val_policy_loss: 1.6099\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0627 - value_loss: 0.4817 - policy_loss: 1.6232 - val_loss: 6.0501 - val_value_loss: 0.4698 - val_policy_loss: 1.6098\n",
      "Saved model  tictactoe_lr_0_002_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.93 - draw ratio 0.02\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.0920 - value_loss: 0.5394 - policy_loss: 1.6241 - val_loss: 6.0602 - val_value_loss: 0.4852 - val_policy_loss: 1.6146\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0898 - value_loss: 0.5354 - policy_loss: 1.6237 - val_loss: 6.0585 - val_value_loss: 0.4819 - val_policy_loss: 1.6146\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0872 - value_loss: 0.5301 - policy_loss: 1.6238 - val_loss: 6.0572 - val_value_loss: 0.4794 - val_policy_loss: 1.6146\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0853 - value_loss: 0.5261 - policy_loss: 1.6241 - val_loss: 6.0562 - val_value_loss: 0.4774 - val_policy_loss: 1.6145\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0831 - value_loss: 0.5218 - policy_loss: 1.6240 - val_loss: 6.0553 - val_value_loss: 0.4757 - val_policy_loss: 1.6145\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0804 - value_loss: 0.5172 - policy_loss: 1.6232 - val_loss: 6.0545 - val_value_loss: 0.4742 - val_policy_loss: 1.6145\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0789 - value_loss: 0.5143 - policy_loss: 1.6231 - val_loss: 6.0538 - val_value_loss: 0.4728 - val_policy_loss: 1.6144\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0775 - value_loss: 0.5116 - policy_loss: 1.6230 - val_loss: 6.0531 - val_value_loss: 0.4715 - val_policy_loss: 1.6144\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0761 - value_loss: 0.5091 - policy_loss: 1.6228 - val_loss: 6.0526 - val_value_loss: 0.4705 - val_policy_loss: 1.6144\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0750 - value_loss: 0.5067 - policy_loss: 1.6229 - val_loss: 6.0521 - val_value_loss: 0.4695 - val_policy_loss: 1.6143\n",
      "Saved model  tictactoe_lr_0_002_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.02\n"
     ]
    }
   ],
   "source": [
    "wins_3, draws_3 = test_pipeline.run(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - Learning rate 0.002\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "losses_3 = np.ones(30) - wins_3 - draws_3\n",
    "# no_loss = np.zeros(50) + wins +draws\n",
    "\n",
    "plt.plot(x, wins_3, label=\"win ratio\")\n",
    "plt.plot(x, draws_3, label=\"draw ratio\")\n",
    "#plt.plot(x, no_loss, label=\"no loss ratio\")\n",
    "plt.plot(x, losses_3, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins_3 = [0.7, 0.67, 0.78, 0.66, 0.71, 0.75, 0.77, 0.77, 0.82, 0.84, 0.78, 0.81, 0.86, 0.87, 0.87, 0.78, 0.78, 0.78, 0.78, 0.84, 0.88, 0.8, 0.8, 0.82, 0.79, 0.77, 0.79, 0.83, 0.77, 0.75]\n",
      "draws_3 = [0.06, 0.09, 0.07, 0.08, 0.08, 0.03, 0.05, 0.01, 0.01, 0.02, 0.03, 0.03, 0.02, 0.01, 0.01, 0.0, 0.03, 0.03, 0.03, 0.02, 0.01, 0.0, 0.0, 0.01, 0.0, 0.02, 0.03, 0.01, 0.03, 0.04]\n",
      "losses_3 = [0.24 0.24 0.15 0.26 0.21 0.22 0.18 0.22 0.17 0.14 0.19 0.16 0.12 0.12\n",
      " 0.12 0.22 0.19 0.19 0.19 0.14 0.11 0.2  0.2  0.17 0.21 0.21 0.18 0.16\n",
      " 0.2  0.21]\n"
     ]
    }
   ],
   "source": [
    "print(\"wins_3 =\", wins_3)\n",
    "print(\"draws_3 =\",draws_3)\n",
    "print(\"losses_3 =\",losses_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCTS = {\n",
    "    'c_puct': 1.0,\n",
    "    'dir_alpha': 0.6,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 10,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 10\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 0,\n",
    "    'show_games': False\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.0002,\n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 512,\n",
    "    'num_filters_value': 512,\n",
    "    'num_filters_tower': 512,\n",
    "    'num_residual_blocks': 3,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 512\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"tictactoe_lr_0_0002\", \"TicTacToe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (4960, 3, 3, 3)\n",
      "model_y_outcomes: (4960,)\n",
      "model_y_probabilities: (4960, 9)\n",
      "Train on 3968 samples, validate on 992 samples\n",
      "Epoch 1/10\n",
      "3968/3968 [==============================] - 4s 1ms/step - loss: 6.8130 - value_loss: 1.0097 - policy_loss: 2.5334 - val_loss: 6.7064 - val_value_loss: 0.7914 - val_policy_loss: 2.5386\n",
      "Epoch 2/10\n",
      "3968/3968 [==============================] - 1s 173us/step - loss: 6.7198 - value_loss: 0.8973 - policy_loss: 2.4595 - val_loss: 6.6420 - val_value_loss: 0.7278 - val_policy_loss: 2.4736\n",
      "Epoch 3/10\n",
      "3968/3968 [==============================] - 1s 173us/step - loss: 6.6703 - value_loss: 0.8514 - policy_loss: 2.4065 - val_loss: 6.6030 - val_value_loss: 0.6973 - val_policy_loss: 2.4261\n",
      "Epoch 4/10\n",
      "3968/3968 [==============================] - 1s 173us/step - loss: 6.6336 - value_loss: 0.8161 - policy_loss: 2.3685 - val_loss: 6.5771 - val_value_loss: 0.6820 - val_policy_loss: 2.3895\n",
      "Epoch 5/10\n",
      "3968/3968 [==============================] - 1s 174us/step - loss: 6.6038 - value_loss: 0.7874 - policy_loss: 2.3377 - val_loss: 6.5540 - val_value_loss: 0.6657 - val_policy_loss: 2.3598\n",
      "Epoch 6/10\n",
      "3968/3968 [==============================] - 1s 174us/step - loss: 6.5811 - value_loss: 0.7677 - policy_loss: 2.3121 - val_loss: 6.5358 - val_value_loss: 0.6543 - val_policy_loss: 2.3348\n",
      "Epoch 7/10\n",
      "3968/3968 [==============================] - 1s 174us/step - loss: 6.5588 - value_loss: 0.7458 - policy_loss: 2.2895 - val_loss: 6.5156 - val_value_loss: 0.6354 - val_policy_loss: 2.3135\n",
      "Epoch 8/10\n",
      "3968/3968 [==============================] - 1s 174us/step - loss: 6.5394 - value_loss: 0.7273 - policy_loss: 2.2692 - val_loss: 6.5056 - val_value_loss: 0.6343 - val_policy_loss: 2.2945\n",
      "Epoch 9/10\n",
      "3968/3968 [==============================] - 1s 174us/step - loss: 6.5267 - value_loss: 0.7198 - policy_loss: 2.2514 - val_loss: 6.4944 - val_value_loss: 0.6290 - val_policy_loss: 2.2775\n",
      "Epoch 10/10\n",
      "3968/3968 [==============================] - 1s 175us/step - loss: 6.5090 - value_loss: 0.7015 - policy_loss: 2.2343 - val_loss: 6.4809 - val_value_loss: 0.6175 - val_policy_loss: 2.2622\n",
      "Saved model  tictactoe_lr_0_0002_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.75 - draw ratio 0.05\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.4910 - value_loss: 0.6831 - policy_loss: 2.2168 - val_loss: 6.4896 - val_value_loss: 0.6838 - val_policy_loss: 2.2134\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.4754 - value_loss: 0.6679 - policy_loss: 2.2008 - val_loss: 6.4774 - val_value_loss: 0.6728 - val_policy_loss: 2.1999\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.4617 - value_loss: 0.6539 - policy_loss: 2.1875 - val_loss: 6.4672 - val_value_loss: 0.6653 - val_policy_loss: 2.1872\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.4494 - value_loss: 0.6426 - policy_loss: 2.1743 - val_loss: 6.4590 - val_value_loss: 0.6609 - val_policy_loss: 2.1753\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.4366 - value_loss: 0.6312 - policy_loss: 2.1600 - val_loss: 6.4514 - val_value_loss: 0.6570 - val_policy_loss: 2.1639\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.4248 - value_loss: 0.6190 - policy_loss: 2.1488 - val_loss: 6.4428 - val_value_loss: 0.6508 - val_policy_loss: 2.1530\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.4146 - value_loss: 0.6104 - policy_loss: 2.1370 - val_loss: 6.4372 - val_value_loss: 0.6500 - val_policy_loss: 2.1426\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.4048 - value_loss: 0.6026 - policy_loss: 2.1254 - val_loss: 6.4293 - val_value_loss: 0.6443 - val_policy_loss: 2.1326\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.3966 - value_loss: 0.5968 - policy_loss: 2.1148 - val_loss: 6.4227 - val_value_loss: 0.6408 - val_policy_loss: 2.1231\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.3895 - value_loss: 0.5912 - policy_loss: 2.1062 - val_loss: 6.4178 - val_value_loss: 0.6401 - val_policy_loss: 2.1139\n",
      "Saved model  tictactoe_lr_0_0002_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.77 - draw ratio 0.04\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.4749 - value_loss: 0.7524 - policy_loss: 2.1158 - val_loss: 6.4509 - val_value_loss: 0.7163 - val_policy_loss: 2.1042\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.4613 - value_loss: 0.7366 - policy_loss: 2.1047 - val_loss: 6.4440 - val_value_loss: 0.7107 - val_policy_loss: 2.0959\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.4484 - value_loss: 0.7207 - policy_loss: 2.0948 - val_loss: 6.4383 - val_value_loss: 0.7071 - val_policy_loss: 2.0881\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.4378 - value_loss: 0.7100 - policy_loss: 2.0842 - val_loss: 6.4315 - val_value_loss: 0.7015 - val_policy_loss: 2.0804\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.4261 - value_loss: 0.6951 - policy_loss: 2.0758 - val_loss: 6.4257 - val_value_loss: 0.6973 - val_policy_loss: 2.0730\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.4179 - value_loss: 0.6872 - policy_loss: 2.0675 - val_loss: 6.4201 - val_value_loss: 0.6932 - val_policy_loss: 2.0659\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.4096 - value_loss: 0.6795 - policy_loss: 2.0585 - val_loss: 6.4155 - val_value_loss: 0.6911 - val_policy_loss: 2.0588\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.4014 - value_loss: 0.6708 - policy_loss: 2.0509 - val_loss: 6.4091 - val_value_loss: 0.6850 - val_policy_loss: 2.0521\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.3928 - value_loss: 0.6622 - policy_loss: 2.0424 - val_loss: 6.4056 - val_value_loss: 0.6845 - val_policy_loss: 2.0457\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.3852 - value_loss: 0.6546 - policy_loss: 2.0349 - val_loss: 6.3992 - val_value_loss: 0.6781 - val_policy_loss: 2.0393\n",
      "Saved model  tictactoe_lr_0_0002_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.01\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.4115 - value_loss: 0.7030 - policy_loss: 2.0391 - val_loss: 6.4323 - val_value_loss: 0.7475 - val_policy_loss: 2.0363\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.3970 - value_loss: 0.6830 - policy_loss: 2.0303 - val_loss: 6.4260 - val_value_loss: 0.7413 - val_policy_loss: 2.0299\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3878 - value_loss: 0.6714 - policy_loss: 2.0236 - val_loss: 6.4202 - val_value_loss: 0.7360 - val_policy_loss: 2.0237\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3778 - value_loss: 0.6603 - policy_loss: 2.0146 - val_loss: 6.4146 - val_value_loss: 0.7307 - val_policy_loss: 2.0178\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3693 - value_loss: 0.6500 - policy_loss: 2.0080 - val_loss: 6.4119 - val_value_loss: 0.7313 - val_policy_loss: 2.0120\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3610 - value_loss: 0.6406 - policy_loss: 2.0008 - val_loss: 6.4059 - val_value_loss: 0.7249 - val_policy_loss: 2.0065\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3546 - value_loss: 0.6343 - policy_loss: 1.9944 - val_loss: 6.4006 - val_value_loss: 0.7196 - val_policy_loss: 2.0011\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3467 - value_loss: 0.6248 - policy_loss: 1.9882 - val_loss: 6.3975 - val_value_loss: 0.7187 - val_policy_loss: 1.9960\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.3407 - value_loss: 0.6197 - policy_loss: 1.9813 - val_loss: 6.3937 - val_value_loss: 0.7162 - val_policy_loss: 1.9910\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3345 - value_loss: 0.6132 - policy_loss: 1.9755 - val_loss: 6.3907 - val_value_loss: 0.7151 - val_policy_loss: 1.9861\n",
      "Saved model  tictactoe_lr_0_0002_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.66 - draw ratio 0.05\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.3720 - value_loss: 0.6724 - policy_loss: 1.9913 - val_loss: 6.3492 - val_value_loss: 0.6426 - val_policy_loss: 1.9756\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.3613 - value_loss: 0.6576 - policy_loss: 1.9847 - val_loss: 6.3440 - val_value_loss: 0.6375 - val_policy_loss: 1.9705\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3531 - value_loss: 0.6465 - policy_loss: 1.9796 - val_loss: 6.3401 - val_value_loss: 0.6346 - val_policy_loss: 1.9656\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3447 - value_loss: 0.6366 - policy_loss: 1.9728 - val_loss: 6.3364 - val_value_loss: 0.6319 - val_policy_loss: 1.9609\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.3381 - value_loss: 0.6288 - policy_loss: 1.9675 - val_loss: 6.3351 - val_value_loss: 0.6338 - val_policy_loss: 1.9564\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3304 - value_loss: 0.6200 - policy_loss: 1.9609 - val_loss: 6.3307 - val_value_loss: 0.6296 - val_policy_loss: 1.9521\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3248 - value_loss: 0.6144 - policy_loss: 1.9554 - val_loss: 6.3282 - val_value_loss: 0.6286 - val_policy_loss: 1.9479\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3184 - value_loss: 0.6068 - policy_loss: 1.9502 - val_loss: 6.3250 - val_value_loss: 0.6264 - val_policy_loss: 1.9439\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3117 - value_loss: 0.5996 - policy_loss: 1.9442 - val_loss: 6.3228 - val_value_loss: 0.6260 - val_policy_loss: 1.9399\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3064 - value_loss: 0.5936 - policy_loss: 1.9396 - val_loss: 6.3209 - val_value_loss: 0.6261 - val_policy_loss: 1.9361\n",
      "Saved model  tictactoe_lr_0_0002_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.03\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.3178 - value_loss: 0.6146 - policy_loss: 1.9415 - val_loss: 6.3281 - val_value_loss: 0.6363 - val_policy_loss: 1.9403\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3102 - value_loss: 0.6031 - policy_loss: 1.9377 - val_loss: 6.3258 - val_value_loss: 0.6344 - val_policy_loss: 1.9377\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3055 - value_loss: 0.5968 - policy_loss: 1.9346 - val_loss: 6.3237 - val_value_loss: 0.6326 - val_policy_loss: 1.9352\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3003 - value_loss: 0.5898 - policy_loss: 1.9314 - val_loss: 6.3219 - val_value_loss: 0.6316 - val_policy_loss: 1.9328\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2965 - value_loss: 0.5848 - policy_loss: 1.9287 - val_loss: 6.3202 - val_value_loss: 0.6305 - val_policy_loss: 1.9305\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2931 - value_loss: 0.5812 - policy_loss: 1.9255 - val_loss: 6.3186 - val_value_loss: 0.6295 - val_policy_loss: 1.9283\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2899 - value_loss: 0.5762 - policy_loss: 1.9243 - val_loss: 6.3170 - val_value_loss: 0.6285 - val_policy_loss: 1.9262\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2850 - value_loss: 0.5709 - policy_loss: 1.9197 - val_loss: 6.3158 - val_value_loss: 0.6283 - val_policy_loss: 1.9241\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2806 - value_loss: 0.5652 - policy_loss: 1.9168 - val_loss: 6.3143 - val_value_loss: 0.6274 - val_policy_loss: 1.9220\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2782 - value_loss: 0.5628 - policy_loss: 1.9144 - val_loss: 6.3131 - val_value_loss: 0.6269 - val_policy_loss: 1.9199\n",
      "Saved model  tictactoe_lr_0_0002_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.01\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.3302 - value_loss: 0.6650 - policy_loss: 1.9162 - val_loss: 6.3031 - val_value_loss: 0.6055 - val_policy_loss: 1.9214\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3231 - value_loss: 0.6542 - policy_loss: 1.9127 - val_loss: 6.2997 - val_value_loss: 0.6011 - val_policy_loss: 1.9192\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3177 - value_loss: 0.6457 - policy_loss: 1.9107 - val_loss: 6.2965 - val_value_loss: 0.5968 - val_policy_loss: 1.9170\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3130 - value_loss: 0.6386 - policy_loss: 1.9082 - val_loss: 6.2939 - val_value_loss: 0.5938 - val_policy_loss: 1.9149\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3079 - value_loss: 0.6310 - policy_loss: 1.9057 - val_loss: 6.2922 - val_value_loss: 0.5923 - val_policy_loss: 1.9129\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3056 - value_loss: 0.6283 - policy_loss: 1.9039 - val_loss: 6.2898 - val_value_loss: 0.5896 - val_policy_loss: 1.9109\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2997 - value_loss: 0.6202 - policy_loss: 1.9001 - val_loss: 6.2874 - val_value_loss: 0.5868 - val_policy_loss: 1.9089\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2956 - value_loss: 0.6135 - policy_loss: 1.8986 - val_loss: 6.2858 - val_value_loss: 0.5855 - val_policy_loss: 1.9070\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2917 - value_loss: 0.6088 - policy_loss: 1.8956 - val_loss: 6.2836 - val_value_loss: 0.5830 - val_policy_loss: 1.9051\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2882 - value_loss: 0.6044 - policy_loss: 1.8930 - val_loss: 6.2818 - val_value_loss: 0.5815 - val_policy_loss: 1.9033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_lr_0_0002_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.0\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.3463 - value_loss: 0.7037 - policy_loss: 1.9100 - val_loss: 6.3458 - val_value_loss: 0.7045 - val_policy_loss: 1.9082\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.3420 - value_loss: 0.6974 - policy_loss: 1.9076 - val_loss: 6.3434 - val_value_loss: 0.7013 - val_policy_loss: 1.9066\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.3375 - value_loss: 0.6907 - policy_loss: 1.9054 - val_loss: 6.3410 - val_value_loss: 0.6982 - val_policy_loss: 1.9050\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3335 - value_loss: 0.6841 - policy_loss: 1.9040 - val_loss: 6.3389 - val_value_loss: 0.6955 - val_policy_loss: 1.9035\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.3289 - value_loss: 0.6780 - policy_loss: 1.9010 - val_loss: 6.3367 - val_value_loss: 0.6926 - val_policy_loss: 1.9020\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.3246 - value_loss: 0.6715 - policy_loss: 1.8991 - val_loss: 6.3347 - val_value_loss: 0.6902 - val_policy_loss: 1.9005\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.3209 - value_loss: 0.6664 - policy_loss: 1.8967 - val_loss: 6.3326 - val_value_loss: 0.6873 - val_policy_loss: 1.8991\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.3173 - value_loss: 0.6610 - policy_loss: 1.8949 - val_loss: 6.3312 - val_value_loss: 0.6860 - val_policy_loss: 1.8976\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3135 - value_loss: 0.6559 - policy_loss: 1.8924 - val_loss: 6.3295 - val_value_loss: 0.6841 - val_policy_loss: 1.8963\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3103 - value_loss: 0.6515 - policy_loss: 1.8906 - val_loss: 6.3276 - val_value_loss: 0.6817 - val_policy_loss: 1.8949\n",
      "Saved model  tictactoe_lr_0_0002_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.0\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.3005 - value_loss: 0.6315 - policy_loss: 1.8909 - val_loss: 6.3006 - val_value_loss: 0.6199 - val_policy_loss: 1.9026\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2942 - value_loss: 0.6214 - policy_loss: 1.8884 - val_loss: 6.2967 - val_value_loss: 0.6139 - val_policy_loss: 1.9010\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2901 - value_loss: 0.6143 - policy_loss: 1.8874 - val_loss: 6.2938 - val_value_loss: 0.6097 - val_policy_loss: 1.8995\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2856 - value_loss: 0.6080 - policy_loss: 1.8848 - val_loss: 6.2914 - val_value_loss: 0.6063 - val_policy_loss: 1.8980\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2815 - value_loss: 0.6027 - policy_loss: 1.8817 - val_loss: 6.2891 - val_value_loss: 0.6031 - val_policy_loss: 1.8966\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2770 - value_loss: 0.5950 - policy_loss: 1.8806 - val_loss: 6.2868 - val_value_loss: 0.6000 - val_policy_loss: 1.8952\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2744 - value_loss: 0.5922 - policy_loss: 1.8782 - val_loss: 6.2849 - val_value_loss: 0.5976 - val_policy_loss: 1.8938\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2724 - value_loss: 0.5893 - policy_loss: 1.8771 - val_loss: 6.2832 - val_value_loss: 0.5956 - val_policy_loss: 1.8925\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2679 - value_loss: 0.5833 - policy_loss: 1.8742 - val_loss: 6.2816 - val_value_loss: 0.5936 - val_policy_loss: 1.8912\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2659 - value_loss: 0.5805 - policy_loss: 1.8730 - val_loss: 6.2800 - val_value_loss: 0.5917 - val_policy_loss: 1.8899\n",
      "Saved model  tictactoe_lr_0_0002_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.0\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.3032 - value_loss: 0.6490 - policy_loss: 1.8791 - val_loss: 6.2871 - val_value_loss: 0.6370 - val_policy_loss: 1.8589\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2976 - value_loss: 0.6410 - policy_loss: 1.8759 - val_loss: 6.2842 - val_value_loss: 0.6329 - val_policy_loss: 1.8572\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2935 - value_loss: 0.6352 - policy_loss: 1.8735 - val_loss: 6.2815 - val_value_loss: 0.6291 - val_policy_loss: 1.8556\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2891 - value_loss: 0.6283 - policy_loss: 1.8716 - val_loss: 6.2797 - val_value_loss: 0.6272 - val_policy_loss: 1.8541\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2867 - value_loss: 0.6250 - policy_loss: 1.8703 - val_loss: 6.2773 - val_value_loss: 0.6240 - val_policy_loss: 1.8525\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2829 - value_loss: 0.6198 - policy_loss: 1.8678 - val_loss: 6.2760 - val_value_loss: 0.6227 - val_policy_loss: 1.8511\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2802 - value_loss: 0.6167 - policy_loss: 1.8657 - val_loss: 6.2740 - val_value_loss: 0.6203 - val_policy_loss: 1.8496\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2765 - value_loss: 0.6109 - policy_loss: 1.8639 - val_loss: 6.2721 - val_value_loss: 0.6180 - val_policy_loss: 1.8482\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2728 - value_loss: 0.6055 - policy_loss: 1.8620 - val_loss: 6.2709 - val_value_loss: 0.6170 - val_policy_loss: 1.8468\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2709 - value_loss: 0.6029 - policy_loss: 1.8608 - val_loss: 6.2689 - val_value_loss: 0.6144 - val_policy_loss: 1.8455\n",
      "Saved model  tictactoe_lr_0_0002_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.0\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.2824 - value_loss: 0.6259 - policy_loss: 1.8610 - val_loss: 6.2645 - val_value_loss: 0.6133 - val_policy_loss: 1.8378\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2799 - value_loss: 0.6211 - policy_loss: 1.8608 - val_loss: 6.2627 - val_value_loss: 0.6104 - val_policy_loss: 1.8370\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2764 - value_loss: 0.6162 - policy_loss: 1.8585 - val_loss: 6.2612 - val_value_loss: 0.6082 - val_policy_loss: 1.8363\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2753 - value_loss: 0.6140 - policy_loss: 1.8586 - val_loss: 6.2598 - val_value_loss: 0.6062 - val_policy_loss: 1.8356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2725 - value_loss: 0.6095 - policy_loss: 1.8575 - val_loss: 6.2586 - val_value_loss: 0.6044 - val_policy_loss: 1.8349\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2710 - value_loss: 0.6075 - policy_loss: 1.8565 - val_loss: 6.2574 - val_value_loss: 0.6028 - val_policy_loss: 1.8342\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2680 - value_loss: 0.6035 - policy_loss: 1.8547 - val_loss: 6.2563 - val_value_loss: 0.6012 - val_policy_loss: 1.8335\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2663 - value_loss: 0.6010 - policy_loss: 1.8537 - val_loss: 6.2552 - val_value_loss: 0.5997 - val_policy_loss: 1.8328\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2646 - value_loss: 0.5979 - policy_loss: 1.8535 - val_loss: 6.2542 - val_value_loss: 0.5983 - val_policy_loss: 1.8321\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2631 - value_loss: 0.5963 - policy_loss: 1.8520 - val_loss: 6.2532 - val_value_loss: 0.5970 - val_policy_loss: 1.8315\n",
      "Saved model  tictactoe_lr_0_0002_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.02\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2940 - value_loss: 0.6427 - policy_loss: 1.8674 - val_loss: 6.2879 - val_value_loss: 0.6624 - val_policy_loss: 1.8357\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2899 - value_loss: 0.6371 - policy_loss: 1.8649 - val_loss: 6.2858 - val_value_loss: 0.6586 - val_policy_loss: 1.8351\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2880 - value_loss: 0.6343 - policy_loss: 1.8640 - val_loss: 6.2841 - val_value_loss: 0.6559 - val_policy_loss: 1.8345\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2858 - value_loss: 0.6301 - policy_loss: 1.8637 - val_loss: 6.2826 - val_value_loss: 0.6536 - val_policy_loss: 1.8339\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2827 - value_loss: 0.6260 - policy_loss: 1.8616 - val_loss: 6.2815 - val_value_loss: 0.6520 - val_policy_loss: 1.8333\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2794 - value_loss: 0.6207 - policy_loss: 1.8604 - val_loss: 6.2803 - val_value_loss: 0.6502 - val_policy_loss: 1.8327\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2774 - value_loss: 0.6179 - policy_loss: 1.8592 - val_loss: 6.2791 - val_value_loss: 0.6484 - val_policy_loss: 1.8321\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2758 - value_loss: 0.6157 - policy_loss: 1.8582 - val_loss: 6.2782 - val_value_loss: 0.6472 - val_policy_loss: 1.8315\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2730 - value_loss: 0.6105 - policy_loss: 1.8579 - val_loss: 6.2771 - val_value_loss: 0.6457 - val_policy_loss: 1.8309\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2726 - value_loss: 0.6103 - policy_loss: 1.8574 - val_loss: 6.2760 - val_value_loss: 0.6440 - val_policy_loss: 1.8303\n",
      "Saved model  tictactoe_lr_0_0002_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.81 - draw ratio 0.01\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.2862 - value_loss: 0.6397 - policy_loss: 1.8550 - val_loss: 6.2700 - val_value_loss: 0.6159 - val_policy_loss: 1.8464\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2833 - value_loss: 0.6355 - policy_loss: 1.8534 - val_loss: 6.2680 - val_value_loss: 0.6127 - val_policy_loss: 1.8456\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2798 - value_loss: 0.6301 - policy_loss: 1.8519 - val_loss: 6.2662 - val_value_loss: 0.6100 - val_policy_loss: 1.8449\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2783 - value_loss: 0.6277 - policy_loss: 1.8513 - val_loss: 6.2645 - val_value_loss: 0.6073 - val_policy_loss: 1.8441\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2757 - value_loss: 0.6240 - policy_loss: 1.8497 - val_loss: 6.2630 - val_value_loss: 0.6052 - val_policy_loss: 1.8433\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2743 - value_loss: 0.6218 - policy_loss: 1.8493 - val_loss: 6.2612 - val_value_loss: 0.6022 - val_policy_loss: 1.8426\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2717 - value_loss: 0.6175 - policy_loss: 1.8484 - val_loss: 6.2601 - val_value_loss: 0.6007 - val_policy_loss: 1.8418\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2711 - value_loss: 0.6170 - policy_loss: 1.8476 - val_loss: 6.2586 - val_value_loss: 0.5986 - val_policy_loss: 1.8411\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2676 - value_loss: 0.6111 - policy_loss: 1.8465 - val_loss: 6.2571 - val_value_loss: 0.5963 - val_policy_loss: 1.8404\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2650 - value_loss: 0.6073 - policy_loss: 1.8452 - val_loss: 6.2557 - val_value_loss: 0.5942 - val_policy_loss: 1.8397\n",
      "Saved model  tictactoe_lr_0_0002_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.01\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2429 - value_loss: 0.5840 - policy_loss: 1.8243 - val_loss: 6.2624 - val_value_loss: 0.6187 - val_policy_loss: 1.8285\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2392 - value_loss: 0.5778 - policy_loss: 1.8232 - val_loss: 6.2607 - val_value_loss: 0.6161 - val_policy_loss: 1.8277\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2363 - value_loss: 0.5732 - policy_loss: 1.8218 - val_loss: 6.2596 - val_value_loss: 0.6147 - val_policy_loss: 1.8269\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2349 - value_loss: 0.5707 - policy_loss: 1.8217 - val_loss: 6.2587 - val_value_loss: 0.6137 - val_policy_loss: 1.8262\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2331 - value_loss: 0.5686 - policy_loss: 1.8202 - val_loss: 6.2578 - val_value_loss: 0.6127 - val_policy_loss: 1.8255\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2308 - value_loss: 0.5657 - policy_loss: 1.8185 - val_loss: 6.2571 - val_value_loss: 0.6121 - val_policy_loss: 1.8247\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2293 - value_loss: 0.5636 - policy_loss: 1.8175 - val_loss: 6.2564 - val_value_loss: 0.6115 - val_policy_loss: 1.8240\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2284 - value_loss: 0.5621 - policy_loss: 1.8173 - val_loss: 6.2558 - val_value_loss: 0.6109 - val_policy_loss: 1.8233\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2255 - value_loss: 0.5578 - policy_loss: 1.8159 - val_loss: 6.2552 - val_value_loss: 0.6105 - val_policy_loss: 1.8226\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2243 - value_loss: 0.5566 - policy_loss: 1.8147 - val_loss: 6.2546 - val_value_loss: 0.6100 - val_policy_loss: 1.8219\n",
      "Saved model  tictactoe_lr_0_0002_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.0\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2807 - value_loss: 0.6541 - policy_loss: 1.8299 - val_loss: 6.2795 - val_value_loss: 0.6595 - val_policy_loss: 1.8222\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2793 - value_loss: 0.6511 - policy_loss: 1.8302 - val_loss: 6.2785 - val_value_loss: 0.6582 - val_policy_loss: 1.8215\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2755 - value_loss: 0.6461 - policy_loss: 1.8277 - val_loss: 6.2776 - val_value_loss: 0.6572 - val_policy_loss: 1.8208\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2744 - value_loss: 0.6430 - policy_loss: 1.8285 - val_loss: 6.2769 - val_value_loss: 0.6564 - val_policy_loss: 1.8201\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2725 - value_loss: 0.6398 - policy_loss: 1.8279 - val_loss: 6.2761 - val_value_loss: 0.6555 - val_policy_loss: 1.8194\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2691 - value_loss: 0.6356 - policy_loss: 1.8253 - val_loss: 6.2754 - val_value_loss: 0.6548 - val_policy_loss: 1.8187\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2693 - value_loss: 0.6361 - policy_loss: 1.8253 - val_loss: 6.2747 - val_value_loss: 0.6541 - val_policy_loss: 1.8180\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2682 - value_loss: 0.6344 - policy_loss: 1.8248 - val_loss: 6.2740 - val_value_loss: 0.6534 - val_policy_loss: 1.8174\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2652 - value_loss: 0.6294 - policy_loss: 1.8237 - val_loss: 6.2733 - val_value_loss: 0.6527 - val_policy_loss: 1.8167\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2630 - value_loss: 0.6263 - policy_loss: 1.8225 - val_loss: 6.2727 - val_value_loss: 0.6520 - val_policy_loss: 1.8161\n",
      "Saved model  tictactoe_lr_0_0002_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.01\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2937 - value_loss: 0.6871 - policy_loss: 1.8232 - val_loss: 6.2932 - val_value_loss: 0.6697 - val_policy_loss: 1.8395\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2932 - value_loss: 0.6855 - policy_loss: 1.8237 - val_loss: 6.2924 - val_value_loss: 0.6684 - val_policy_loss: 1.8392\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2917 - value_loss: 0.6833 - policy_loss: 1.8230 - val_loss: 6.2916 - val_value_loss: 0.6671 - val_policy_loss: 1.8389\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2894 - value_loss: 0.6794 - policy_loss: 1.8222 - val_loss: 6.2909 - val_value_loss: 0.6660 - val_policy_loss: 1.8386\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2883 - value_loss: 0.6771 - policy_loss: 1.8223 - val_loss: 6.2902 - val_value_loss: 0.6649 - val_policy_loss: 1.8383\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2866 - value_loss: 0.6742 - policy_loss: 1.8219 - val_loss: 6.2895 - val_value_loss: 0.6639 - val_policy_loss: 1.8380\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2854 - value_loss: 0.6730 - policy_loss: 1.8207 - val_loss: 6.2889 - val_value_loss: 0.6629 - val_policy_loss: 1.8377\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2851 - value_loss: 0.6712 - policy_loss: 1.8219 - val_loss: 6.2882 - val_value_loss: 0.6619 - val_policy_loss: 1.8375\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2836 - value_loss: 0.6702 - policy_loss: 1.8200 - val_loss: 6.2876 - val_value_loss: 0.6609 - val_policy_loss: 1.8372\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2813 - value_loss: 0.6660 - policy_loss: 1.8195 - val_loss: 6.2870 - val_value_loss: 0.6600 - val_policy_loss: 1.8369\n",
      "Saved model  tictactoe_lr_0_0002_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.02\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.2349 - value_loss: 0.5731 - policy_loss: 1.8195 - val_loss: 6.2417 - val_value_loss: 0.5625 - val_policy_loss: 1.8439\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2325 - value_loss: 0.5689 - policy_loss: 1.8191 - val_loss: 6.2404 - val_value_loss: 0.5601 - val_policy_loss: 1.8436\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2322 - value_loss: 0.5678 - policy_loss: 1.8195 - val_loss: 6.2394 - val_value_loss: 0.5585 - val_policy_loss: 1.8433\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2302 - value_loss: 0.5647 - policy_loss: 1.8186 - val_loss: 6.2386 - val_value_loss: 0.5572 - val_policy_loss: 1.8430\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2291 - value_loss: 0.5632 - policy_loss: 1.8178 - val_loss: 6.2380 - val_value_loss: 0.5561 - val_policy_loss: 1.8428\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2278 - value_loss: 0.5609 - policy_loss: 1.8176 - val_loss: 6.2373 - val_value_loss: 0.5551 - val_policy_loss: 1.8425\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2275 - value_loss: 0.5600 - policy_loss: 1.8178 - val_loss: 6.2368 - val_value_loss: 0.5542 - val_policy_loss: 1.8422\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2250 - value_loss: 0.5564 - policy_loss: 1.8165 - val_loss: 6.2363 - val_value_loss: 0.5535 - val_policy_loss: 1.8420\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2238 - value_loss: 0.5550 - policy_loss: 1.8155 - val_loss: 6.2358 - val_value_loss: 0.5528 - val_policy_loss: 1.8417\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2241 - value_loss: 0.5547 - policy_loss: 1.8165 - val_loss: 6.2353 - val_value_loss: 0.5521 - val_policy_loss: 1.8415\n",
      "Saved model  tictactoe_lr_0_0002_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.01\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.2468 - value_loss: 0.5772 - policy_loss: 1.8394 - val_loss: 6.2230 - val_value_loss: 0.5491 - val_policy_loss: 1.8198\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2462 - value_loss: 0.5758 - policy_loss: 1.8396 - val_loss: 6.2228 - val_value_loss: 0.5491 - val_policy_loss: 1.8194\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2451 - value_loss: 0.5740 - policy_loss: 1.8393 - val_loss: 6.2226 - val_value_loss: 0.5491 - val_policy_loss: 1.8191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2443 - value_loss: 0.5732 - policy_loss: 1.8383 - val_loss: 6.2224 - val_value_loss: 0.5491 - val_policy_loss: 1.8187\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2441 - value_loss: 0.5732 - policy_loss: 1.8380 - val_loss: 6.2222 - val_value_loss: 0.5490 - val_policy_loss: 1.8184\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2415 - value_loss: 0.5688 - policy_loss: 1.8373 - val_loss: 6.2220 - val_value_loss: 0.5490 - val_policy_loss: 1.8180\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2407 - value_loss: 0.5672 - policy_loss: 1.8371 - val_loss: 6.2218 - val_value_loss: 0.5490 - val_policy_loss: 1.8177\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2398 - value_loss: 0.5664 - policy_loss: 1.8363 - val_loss: 6.2216 - val_value_loss: 0.5489 - val_policy_loss: 1.8174\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2390 - value_loss: 0.5648 - policy_loss: 1.8362 - val_loss: 6.2214 - val_value_loss: 0.5488 - val_policy_loss: 1.8171\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2393 - value_loss: 0.5644 - policy_loss: 1.8373 - val_loss: 6.2212 - val_value_loss: 0.5487 - val_policy_loss: 1.8167\n",
      "Saved model  tictactoe_lr_0_0002_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.02\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.2801 - value_loss: 0.6518 - policy_loss: 1.8315 - val_loss: 6.2470 - val_value_loss: 0.5768 - val_policy_loss: 1.8402\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2772 - value_loss: 0.6463 - policy_loss: 1.8313 - val_loss: 6.2462 - val_value_loss: 0.5755 - val_policy_loss: 1.8400\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2765 - value_loss: 0.6453 - policy_loss: 1.8308 - val_loss: 6.2456 - val_value_loss: 0.5746 - val_policy_loss: 1.8398\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2758 - value_loss: 0.6444 - policy_loss: 1.8303 - val_loss: 6.2451 - val_value_loss: 0.5738 - val_policy_loss: 1.8396\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2737 - value_loss: 0.6408 - policy_loss: 1.8297 - val_loss: 6.2447 - val_value_loss: 0.5731 - val_policy_loss: 1.8394\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2724 - value_loss: 0.6387 - policy_loss: 1.8292 - val_loss: 6.2443 - val_value_loss: 0.5725 - val_policy_loss: 1.8392\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.2720 - value_loss: 0.6369 - policy_loss: 1.8302 - val_loss: 6.2439 - val_value_loss: 0.5719 - val_policy_loss: 1.8390\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.2702 - value_loss: 0.6344 - policy_loss: 1.8291 - val_loss: 6.2435 - val_value_loss: 0.5714 - val_policy_loss: 1.8388\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2695 - value_loss: 0.6331 - policy_loss: 1.8291 - val_loss: 6.2431 - val_value_loss: 0.5708 - val_policy_loss: 1.8386\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.2680 - value_loss: 0.6303 - policy_loss: 1.8288 - val_loss: 6.2428 - val_value_loss: 0.5704 - val_policy_loss: 1.8384\n",
      "Saved model  tictactoe_lr_0_0002_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.01\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.2760 - value_loss: 0.6394 - policy_loss: 1.8358 - val_loss: 6.2785 - val_value_loss: 0.6405 - val_policy_loss: 1.8398\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2729 - value_loss: 0.6348 - policy_loss: 1.8342 - val_loss: 6.2779 - val_value_loss: 0.6395 - val_policy_loss: 1.8394\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2719 - value_loss: 0.6326 - policy_loss: 1.8344 - val_loss: 6.2773 - val_value_loss: 0.6388 - val_policy_loss: 1.8390\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2702 - value_loss: 0.6299 - policy_loss: 1.8336 - val_loss: 6.2768 - val_value_loss: 0.6381 - val_policy_loss: 1.8386\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2696 - value_loss: 0.6283 - policy_loss: 1.8342 - val_loss: 6.2763 - val_value_loss: 0.6375 - val_policy_loss: 1.8382\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2687 - value_loss: 0.6276 - policy_loss: 1.8329 - val_loss: 6.2758 - val_value_loss: 0.6369 - val_policy_loss: 1.8379\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2658 - value_loss: 0.6234 - policy_loss: 1.8314 - val_loss: 6.2753 - val_value_loss: 0.6363 - val_policy_loss: 1.8375\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2664 - value_loss: 0.6239 - policy_loss: 1.8320 - val_loss: 6.2749 - val_value_loss: 0.6358 - val_policy_loss: 1.8371\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2632 - value_loss: 0.6188 - policy_loss: 1.8308 - val_loss: 6.2745 - val_value_loss: 0.6353 - val_policy_loss: 1.8368\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2637 - value_loss: 0.6193 - policy_loss: 1.8314 - val_loss: 6.2741 - val_value_loss: 0.6349 - val_policy_loss: 1.8365\n",
      "Saved model  tictactoe_lr_0_0002_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.0\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.2787 - value_loss: 0.6497 - policy_loss: 1.8309 - val_loss: 6.2749 - val_value_loss: 0.6478 - val_policy_loss: 1.8251\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2778 - value_loss: 0.6475 - policy_loss: 1.8314 - val_loss: 6.2746 - val_value_loss: 0.6477 - val_policy_loss: 1.8248\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2772 - value_loss: 0.6470 - policy_loss: 1.8307 - val_loss: 6.2744 - val_value_loss: 0.6474 - val_policy_loss: 1.8245\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2764 - value_loss: 0.6449 - policy_loss: 1.8311 - val_loss: 6.2741 - val_value_loss: 0.6472 - val_policy_loss: 1.8243\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2753 - value_loss: 0.6429 - policy_loss: 1.8309 - val_loss: 6.2739 - val_value_loss: 0.6471 - val_policy_loss: 1.8240\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2761 - value_loss: 0.6440 - policy_loss: 1.8315 - val_loss: 6.2737 - val_value_loss: 0.6469 - val_policy_loss: 1.8238\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2756 - value_loss: 0.6441 - policy_loss: 1.8304 - val_loss: 6.2735 - val_value_loss: 0.6467 - val_policy_loss: 1.8235\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2742 - value_loss: 0.6417 - policy_loss: 1.8300 - val_loss: 6.2733 - val_value_loss: 0.6465 - val_policy_loss: 1.8233\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2727 - value_loss: 0.6393 - policy_loss: 1.8293 - val_loss: 6.2731 - val_value_loss: 0.6464 - val_policy_loss: 1.8231\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2741 - value_loss: 0.6412 - policy_loss: 1.8303 - val_loss: 6.2729 - val_value_loss: 0.6462 - val_policy_loss: 1.8229\n",
      "Saved model  tictactoe_lr_0_0002_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.72 - draw ratio 0.02\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2386 - value_loss: 0.5805 - policy_loss: 1.8200 - val_loss: 6.2352 - val_value_loss: 0.5642 - val_policy_loss: 1.8295\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2363 - value_loss: 0.5767 - policy_loss: 1.8193 - val_loss: 6.2348 - val_value_loss: 0.5634 - val_policy_loss: 1.8294\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2356 - value_loss: 0.5755 - policy_loss: 1.8189 - val_loss: 6.2343 - val_value_loss: 0.5626 - val_policy_loss: 1.8292\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2349 - value_loss: 0.5739 - policy_loss: 1.8192 - val_loss: 6.2339 - val_value_loss: 0.5619 - val_policy_loss: 1.8291\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2342 - value_loss: 0.5729 - policy_loss: 1.8188 - val_loss: 6.2335 - val_value_loss: 0.5613 - val_policy_loss: 1.8290\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2338 - value_loss: 0.5727 - policy_loss: 1.8181 - val_loss: 6.2331 - val_value_loss: 0.5606 - val_policy_loss: 1.8289\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2318 - value_loss: 0.5688 - policy_loss: 1.8180 - val_loss: 6.2327 - val_value_loss: 0.5600 - val_policy_loss: 1.8288\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2324 - value_loss: 0.5695 - policy_loss: 1.8186 - val_loss: 6.2324 - val_value_loss: 0.5595 - val_policy_loss: 1.8287\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2314 - value_loss: 0.5668 - policy_loss: 1.8192 - val_loss: 6.2321 - val_value_loss: 0.5590 - val_policy_loss: 1.8285\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2294 - value_loss: 0.5650 - policy_loss: 1.8171 - val_loss: 6.2318 - val_value_loss: 0.5584 - val_policy_loss: 1.8284\n",
      "Saved model  tictactoe_lr_0_0002_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.81 - draw ratio 0.01\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2700 - value_loss: 0.6380 - policy_loss: 1.8253 - val_loss: 6.2425 - val_value_loss: 0.5909 - val_policy_loss: 1.8173\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2691 - value_loss: 0.6365 - policy_loss: 1.8251 - val_loss: 6.2421 - val_value_loss: 0.5904 - val_policy_loss: 1.8172\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2679 - value_loss: 0.6344 - policy_loss: 1.8247 - val_loss: 6.2418 - val_value_loss: 0.5899 - val_policy_loss: 1.8171\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2665 - value_loss: 0.6317 - policy_loss: 1.8247 - val_loss: 6.2415 - val_value_loss: 0.5894 - val_policy_loss: 1.8170\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2667 - value_loss: 0.6320 - policy_loss: 1.8248 - val_loss: 6.2412 - val_value_loss: 0.5889 - val_policy_loss: 1.8169\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2656 - value_loss: 0.6305 - policy_loss: 1.8239 - val_loss: 6.2409 - val_value_loss: 0.5883 - val_policy_loss: 1.8168\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2652 - value_loss: 0.6302 - policy_loss: 1.8235 - val_loss: 6.2406 - val_value_loss: 0.5878 - val_policy_loss: 1.8167\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2635 - value_loss: 0.6272 - policy_loss: 1.8230 - val_loss: 6.2402 - val_value_loss: 0.5872 - val_policy_loss: 1.8166\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2633 - value_loss: 0.6269 - policy_loss: 1.8231 - val_loss: 6.2399 - val_value_loss: 0.5867 - val_policy_loss: 1.8165\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2636 - value_loss: 0.6269 - policy_loss: 1.8236 - val_loss: 6.2396 - val_value_loss: 0.5862 - val_policy_loss: 1.8164\n",
      "Saved model  tictactoe_lr_0_0002_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.03\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2963 - value_loss: 0.6929 - policy_loss: 1.8229 - val_loss: 6.2823 - val_value_loss: 0.6827 - val_policy_loss: 1.8051\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2967 - value_loss: 0.6941 - policy_loss: 1.8226 - val_loss: 6.2819 - val_value_loss: 0.6821 - val_policy_loss: 1.8050\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2943 - value_loss: 0.6902 - policy_loss: 1.8218 - val_loss: 6.2815 - val_value_loss: 0.6815 - val_policy_loss: 1.8049\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2934 - value_loss: 0.6883 - policy_loss: 1.8218 - val_loss: 6.2812 - val_value_loss: 0.6810 - val_policy_loss: 1.8048\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2938 - value_loss: 0.6891 - policy_loss: 1.8219 - val_loss: 6.2809 - val_value_loss: 0.6805 - val_policy_loss: 1.8047\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2929 - value_loss: 0.6874 - policy_loss: 1.8217 - val_loss: 6.2806 - val_value_loss: 0.6800 - val_policy_loss: 1.8046\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2915 - value_loss: 0.6850 - policy_loss: 1.8214 - val_loss: 6.2803 - val_value_loss: 0.6796 - val_policy_loss: 1.8045\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2923 - value_loss: 0.6865 - policy_loss: 1.8215 - val_loss: 6.2801 - val_value_loss: 0.6791 - val_policy_loss: 1.8043\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2907 - value_loss: 0.6833 - policy_loss: 1.8215 - val_loss: 6.2798 - val_value_loss: 0.6788 - val_policy_loss: 1.8042\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2899 - value_loss: 0.6826 - policy_loss: 1.8205 - val_loss: 6.2796 - val_value_loss: 0.6784 - val_policy_loss: 1.8041\n",
      "Saved model  tictactoe_lr_0_0002_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.0\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2804 - value_loss: 0.6662 - policy_loss: 1.8179 - val_loss: 6.2886 - val_value_loss: 0.6746 - val_policy_loss: 1.8259\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2797 - value_loss: 0.6662 - policy_loss: 1.8166 - val_loss: 6.2878 - val_value_loss: 0.6730 - val_policy_loss: 1.8259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2784 - value_loss: 0.6631 - policy_loss: 1.8171 - val_loss: 6.2871 - val_value_loss: 0.6717 - val_policy_loss: 1.8259\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2777 - value_loss: 0.6621 - policy_loss: 1.8167 - val_loss: 6.2865 - val_value_loss: 0.6705 - val_policy_loss: 1.8259\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2766 - value_loss: 0.6598 - policy_loss: 1.8167 - val_loss: 6.2860 - val_value_loss: 0.6695 - val_policy_loss: 1.8258\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2758 - value_loss: 0.6589 - policy_loss: 1.8162 - val_loss: 6.2854 - val_value_loss: 0.6685 - val_policy_loss: 1.8258\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2736 - value_loss: 0.6554 - policy_loss: 1.8152 - val_loss: 6.2849 - val_value_loss: 0.6675 - val_policy_loss: 1.8258\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2732 - value_loss: 0.6541 - policy_loss: 1.8157 - val_loss: 6.2845 - val_value_loss: 0.6666 - val_policy_loss: 1.8257\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2725 - value_loss: 0.6527 - policy_loss: 1.8158 - val_loss: 6.2840 - val_value_loss: 0.6657 - val_policy_loss: 1.8257\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2725 - value_loss: 0.6538 - policy_loss: 1.8146 - val_loss: 6.2835 - val_value_loss: 0.6649 - val_policy_loss: 1.8256\n",
      "Saved model  tictactoe_lr_0_0002_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.02\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.2892 - value_loss: 0.6815 - policy_loss: 1.8203 - val_loss: 6.2889 - val_value_loss: 0.6935 - val_policy_loss: 1.8077\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2886 - value_loss: 0.6807 - policy_loss: 1.8200 - val_loss: 6.2884 - val_value_loss: 0.6928 - val_policy_loss: 1.8075\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2860 - value_loss: 0.6767 - policy_loss: 1.8188 - val_loss: 6.2880 - val_value_loss: 0.6921 - val_policy_loss: 1.8073\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2865 - value_loss: 0.6774 - policy_loss: 1.8190 - val_loss: 6.2876 - val_value_loss: 0.6915 - val_policy_loss: 1.8071\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2863 - value_loss: 0.6773 - policy_loss: 1.8187 - val_loss: 6.2872 - val_value_loss: 0.6908 - val_policy_loss: 1.8069\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2849 - value_loss: 0.6754 - policy_loss: 1.8179 - val_loss: 6.2868 - val_value_loss: 0.6902 - val_policy_loss: 1.8068\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2857 - value_loss: 0.6758 - policy_loss: 1.8190 - val_loss: 6.2864 - val_value_loss: 0.6895 - val_policy_loss: 1.8066\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2843 - value_loss: 0.6737 - policy_loss: 1.8184 - val_loss: 6.2860 - val_value_loss: 0.6889 - val_policy_loss: 1.8065\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2839 - value_loss: 0.6724 - policy_loss: 1.8187 - val_loss: 6.2856 - val_value_loss: 0.6883 - val_policy_loss: 1.8063\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2839 - value_loss: 0.6730 - policy_loss: 1.8182 - val_loss: 6.2852 - val_value_loss: 0.6877 - val_policy_loss: 1.8062\n",
      "Saved model  tictactoe_lr_0_0002_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.03\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2655 - value_loss: 0.6305 - policy_loss: 1.8239 - val_loss: 6.2469 - val_value_loss: 0.5938 - val_policy_loss: 1.8234\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2662 - value_loss: 0.6298 - policy_loss: 1.8259 - val_loss: 6.2467 - val_value_loss: 0.5936 - val_policy_loss: 1.8233\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2651 - value_loss: 0.6290 - policy_loss: 1.8246 - val_loss: 6.2466 - val_value_loss: 0.5933 - val_policy_loss: 1.8232\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2653 - value_loss: 0.6298 - policy_loss: 1.8242 - val_loss: 6.2464 - val_value_loss: 0.5932 - val_policy_loss: 1.8231\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2649 - value_loss: 0.6283 - policy_loss: 1.8249 - val_loss: 6.2463 - val_value_loss: 0.5930 - val_policy_loss: 1.8230\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2642 - value_loss: 0.6278 - policy_loss: 1.8240 - val_loss: 6.2461 - val_value_loss: 0.5928 - val_policy_loss: 1.8229\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2640 - value_loss: 0.6276 - policy_loss: 1.8238 - val_loss: 6.2460 - val_value_loss: 0.5926 - val_policy_loss: 1.8228\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2630 - value_loss: 0.6268 - policy_loss: 1.8227 - val_loss: 6.2459 - val_value_loss: 0.5925 - val_policy_loss: 1.8228\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2632 - value_loss: 0.6264 - policy_loss: 1.8234 - val_loss: 6.2458 - val_value_loss: 0.5923 - val_policy_loss: 1.8227\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2636 - value_loss: 0.6265 - policy_loss: 1.8241 - val_loss: 6.2457 - val_value_loss: 0.5922 - val_policy_loss: 1.8226\n",
      "Saved model  tictactoe_lr_0_0002_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.01\n",
      "iteration 27 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.2398 - value_loss: 0.5815 - policy_loss: 1.8216 - val_loss: 6.2426 - val_value_loss: 0.5752 - val_policy_loss: 1.8334\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2387 - value_loss: 0.5792 - policy_loss: 1.8216 - val_loss: 6.2423 - val_value_loss: 0.5748 - val_policy_loss: 1.8334\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2392 - value_loss: 0.5802 - policy_loss: 1.8216 - val_loss: 6.2421 - val_value_loss: 0.5744 - val_policy_loss: 1.8333\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2375 - value_loss: 0.5775 - policy_loss: 1.8209 - val_loss: 6.2419 - val_value_loss: 0.5741 - val_policy_loss: 1.8332\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2371 - value_loss: 0.5771 - policy_loss: 1.8205 - val_loss: 6.2417 - val_value_loss: 0.5738 - val_policy_loss: 1.8332\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2383 - value_loss: 0.5774 - policy_loss: 1.8226 - val_loss: 6.2416 - val_value_loss: 0.5735 - val_policy_loss: 1.8331\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2364 - value_loss: 0.5756 - policy_loss: 1.8208 - val_loss: 6.2414 - val_value_loss: 0.5733 - val_policy_loss: 1.8330\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2357 - value_loss: 0.5748 - policy_loss: 1.8200 - val_loss: 6.2413 - val_value_loss: 0.5731 - val_policy_loss: 1.8330\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2350 - value_loss: 0.5734 - policy_loss: 1.8200 - val_loss: 6.2411 - val_value_loss: 0.5728 - val_policy_loss: 1.8329\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2353 - value_loss: 0.5738 - policy_loss: 1.8203 - val_loss: 6.2410 - val_value_loss: 0.5726 - val_policy_loss: 1.8329\n",
      "Saved model  tictactoe_lr_0_0002_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.01\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2554 - value_loss: 0.6321 - policy_loss: 1.8022 - val_loss: 6.2594 - val_value_loss: 0.6486 - val_policy_loss: 1.7937\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2556 - value_loss: 0.6317 - policy_loss: 1.8030 - val_loss: 6.2591 - val_value_loss: 0.6480 - val_policy_loss: 1.7936\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2539 - value_loss: 0.6294 - policy_loss: 1.8018 - val_loss: 6.2588 - val_value_loss: 0.6475 - val_policy_loss: 1.7936\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2554 - value_loss: 0.6316 - policy_loss: 1.8028 - val_loss: 6.2585 - val_value_loss: 0.6469 - val_policy_loss: 1.7935\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2541 - value_loss: 0.6300 - policy_loss: 1.8016 - val_loss: 6.2582 - val_value_loss: 0.6465 - val_policy_loss: 1.7934\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2527 - value_loss: 0.6278 - policy_loss: 1.8011 - val_loss: 6.2580 - val_value_loss: 0.6461 - val_policy_loss: 1.7934\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2544 - value_loss: 0.6307 - policy_loss: 1.8015 - val_loss: 6.2578 - val_value_loss: 0.6457 - val_policy_loss: 1.7933\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2533 - value_loss: 0.6283 - policy_loss: 1.8018 - val_loss: 6.2576 - val_value_loss: 0.6453 - val_policy_loss: 1.7933\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2533 - value_loss: 0.6281 - policy_loss: 1.8020 - val_loss: 6.2574 - val_value_loss: 0.6450 - val_policy_loss: 1.7932\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2514 - value_loss: 0.6264 - policy_loss: 1.7999 - val_loss: 6.2572 - val_value_loss: 0.6447 - val_policy_loss: 1.7932\n",
      "Saved model  tictactoe_lr_0_0002_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.01\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2543 - value_loss: 0.6170 - policy_loss: 1.8151 - val_loss: 6.2405 - val_value_loss: 0.6000 - val_policy_loss: 1.8045\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2540 - value_loss: 0.6163 - policy_loss: 1.8151 - val_loss: 6.2401 - val_value_loss: 0.5994 - val_policy_loss: 1.8044\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2545 - value_loss: 0.6172 - policy_loss: 1.8152 - val_loss: 6.2398 - val_value_loss: 0.5988 - val_policy_loss: 1.8042\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2538 - value_loss: 0.6162 - policy_loss: 1.8149 - val_loss: 6.2395 - val_value_loss: 0.5983 - val_policy_loss: 1.8041\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2528 - value_loss: 0.6140 - policy_loss: 1.8150 - val_loss: 6.2392 - val_value_loss: 0.5979 - val_policy_loss: 1.8040\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2523 - value_loss: 0.6141 - policy_loss: 1.8141 - val_loss: 6.2389 - val_value_loss: 0.5974 - val_policy_loss: 1.8039\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2537 - value_loss: 0.6160 - policy_loss: 1.8150 - val_loss: 6.2387 - val_value_loss: 0.5970 - val_policy_loss: 1.8038\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2528 - value_loss: 0.6144 - policy_loss: 1.8147 - val_loss: 6.2384 - val_value_loss: 0.5966 - val_policy_loss: 1.8037\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2523 - value_loss: 0.6137 - policy_loss: 1.8144 - val_loss: 6.2382 - val_value_loss: 0.5962 - val_policy_loss: 1.8036\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2515 - value_loss: 0.6122 - policy_loss: 1.8143 - val_loss: 6.2380 - val_value_loss: 0.5959 - val_policy_loss: 1.8036\n",
      "Saved model  tictactoe_lr_0_0002_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.0\n"
     ]
    }
   ],
   "source": [
    "wins_4, draws_4 = test_pipeline.run(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - Learning rate 0.002\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "losses_4 = np.ones(30) - wins_4 - draws_4\n",
    "# no_loss = np.zeros(50) + wins +draws\n",
    "\n",
    "plt.plot(x, wins_4, label=\"win ratio\")\n",
    "plt.plot(x, draws_4, label=\"draw ratio\")\n",
    "#plt.plot(x, no_loss, label=\"no loss ratio\")\n",
    "plt.plot(x, losses_4, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins_4 = [0.75, 0.77, 0.79, 0.66, 0.79, 0.78, 0.83, 0.8, 0.85, 0.8, 0.85, 0.81, 0.82, 0.78, 0.85, 0.85, 0.83, 0.87, 0.79, 0.83, 0.72, 0.81, 0.87, 0.84, 0.85, 0.76, 0.82, 0.88, 0.83, 0.84]\n",
      "draws_4 = [0.05, 0.04, 0.01, 0.05, 0.03, 0.01, 0.0, 0.0, 0.0, 0.0, 0.02, 0.01, 0.01, 0.0, 0.01, 0.02, 0.01, 0.02, 0.01, 0.0, 0.02, 0.01, 0.03, 0.0, 0.02, 0.03, 0.01, 0.01, 0.01, 0.0]\n",
      "losses_4 = [0.2  0.19 0.2  0.29 0.18 0.21 0.17 0.2  0.15 0.2  0.13 0.18 0.17 0.22\n",
      " 0.14 0.13 0.16 0.11 0.2  0.17 0.26 0.18 0.1  0.16 0.13 0.21 0.17 0.11\n",
      " 0.16 0.16]\n"
     ]
    }
   ],
   "source": [
    "print(\"wins_4 =\", wins_4)\n",
    "print(\"draws_4 =\",draws_4)\n",
    "print(\"losses_4 =\",losses_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(data, window_size):\n",
    "    return np.convolve(data, np.ones((window_size,))/window_size, mode='valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wins_1 = [0.75, 0.82, 0.84, 0.74, 0.76, 0.77, 0.78, 0.74, 0.71, 0.77, 0.7, 0.79, 0.78, 0.73, 0.71, 0.77, 0.71, 0.68, 0.78, 0.76, 0.7, 0.8, 0.82, 0.73, 0.74, 0.76, 0.67, 0.78, 0.66, 0.65]\n",
    "draws_1 = [0.02, 0.02, 0.0, 0.01, 0.01, 0.03, 0.0, 0.0, 0.03, 0.01, 0.0, 0.01, 0.0, 0.01, 0.01, 0.01, 0.02, 0.04, 0.03, 0.02, 0.03, 0.02, 0.0, 0.03, 0.02, 0.04, 0.05, 0.04, 0.06, 0.04]\n",
    "losses_1 = np.ones(30) - wins_1 - draws_1\n",
    "\n",
    "wins_2 = [0.8, 0.66, 0.6, 0.68, 0.69, 0.78, 0.73, 0.62, 0.79, 0.76, 0.73, 0.71, 0.77, 0.7, 0.66, 0.76, 0.69, 0.77, 0.7, 0.88, 0.79, 0.82, 0.7, 0.64, 0.71, 0.66, 0.66, 0.71, 0.8, 0.76]\n",
    "draws_2 = [0.01, 0.02, 0.1, 0.04, 0.02, 0.03, 0.04, 0.08, 0.05, 0.03, 0.03, 0.06, 0.01, 0.03, 0.02, 0.04, 0.02, 0.02, 0.02, 0.02, 0.01, 0.03, 0.03, 0.06, 0.09, 0.04, 0.05, 0.03, 0.03, 0.04]\n",
    "losses_2 = np.ones(30) - wins_2 - draws_2\n",
    "\n",
    "wins_3 = [0.7, 0.67, 0.78, 0.66, 0.71, 0.75, 0.77, 0.77, 0.82, 0.84, 0.78, 0.81, 0.86, 0.87, 0.87, 0.78, 0.78, 0.78, 0.78, 0.84, 0.88, 0.8, 0.8, 0.82, 0.79, 0.77, 0.79, 0.83, 0.77, 0.75]\n",
    "draws_3 = [0.06, 0.09, 0.07, 0.08, 0.08, 0.03, 0.05, 0.01, 0.01, 0.02, 0.03, 0.03, 0.02, 0.01, 0.01, 0.0, 0.03, 0.03, 0.03, 0.02, 0.01, 0.0, 0.0, 0.01, 0.0, 0.02, 0.03, 0.01, 0.03, 0.04]\n",
    "losses_3 = np.ones(30) - wins_3 - draws_3\n",
    "\n",
    "wins_4 = [0.75, 0.77, 0.79, 0.66, 0.79, 0.78, 0.83, 0.8, 0.85, 0.8, 0.85, 0.81, 0.82, 0.78, 0.85, 0.85, 0.83, 0.87, 0.79, 0.83, 0.72, 0.81, 0.87, 0.84, 0.85, 0.76, 0.82, 0.88, 0.83, 0.84]\n",
    "draws_4 = [0.05, 0.04, 0.01, 0.05, 0.03, 0.01, 0.0, 0.0, 0.0, 0.0, 0.02, 0.01, 0.01, 0.0, 0.01, 0.02, 0.01, 0.02, 0.01, 0.0, 0.02, 0.01, 0.03, 0.0, 0.02, 0.03, 0.01, 0.01, 0.01, 0.0]\n",
    "losses_4 = np.ones(30) - wins_4 -draws_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_size = 1\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "\n",
    "plt.title(\"Evaluation - Win ratio\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"win ratio\")\n",
    "\n",
    "x = np.arange(30 - window_size + 1)\n",
    "\n",
    "plt.plot(x, smooth(wins_1, window_size), label=\"learning rate 0.2\")\n",
    "plt.plot(x, smooth(wins_2, window_size), label=\"learning rate 0.02\")\n",
    "plt.plot(x, smooth(wins_3, window_size), label=\"learning rate 0.002\")\n",
    "plt.plot(x, smooth(wins_4, window_size), label=\"learning rate 0.0002\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "(300,)\n",
      "(300,)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "train_loss_1 = pd.read_csv(\"tictactoe_exp_lr/run_tictactoe_lr_0_2-tag-loss.csv\")\n",
    "train_loss_1 = train_loss_1['Value'].values[:300]\n",
    "\n",
    "train_loss_2 = pd.read_csv(\"tictactoe_exp_lr/run_tictactoe_lr_0_02-tag-loss.csv\")\n",
    "train_loss_2 = train_loss_2['Value'].values\n",
    "\n",
    "train_loss_3 = pd.read_csv(\"tictactoe_exp_lr/run_tictactoe_lr_0_002-tag-loss.csv\")\n",
    "train_loss_3 = train_loss_3['Value'].values\n",
    "\n",
    "train_loss_4 = pd.read_csv(\"tictactoe_exp_lr/run_tictactoe_lr_0_0002-tag-loss.csv\")\n",
    "train_loss_4 = train_loss_4['Value'].values\n",
    "\n",
    "# length \n",
    "print(train_loss_1.shape)\n",
    "print(train_loss_2.shape)\n",
    "print(train_loss_3.shape)\n",
    "print(train_loss_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_size = 10\n",
    "first_iteration = 0\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "\n",
    "plt.title(\"Evaluation - Training loss\")\n",
    "\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "x = np.arange(300-window_size+1 - first_iteration)+first_iteration\n",
    "\n",
    "#plt.plot(x, smooth(train_loss_1[first_iteration:],window_size), label=\"learning rate 0.2\")\n",
    "plt.plot(x, smooth(train_loss_2[first_iteration:],window_size), label=\"learning rate 0.02\")\n",
    "plt.plot(x, smooth(train_loss_3[first_iteration:],window_size), label=\"learning rate 0.002\")\n",
    "plt.plot(x, smooth(train_loss_4[first_iteration:],window_size), label=\"learning rate 0.0002\")\n",
    "\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "(300,)\n",
      "(300,)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "val_loss_1 = pd.read_csv(\"tictactoe_exp_lr/run_tictactoe_lr_0_2-tag-val_loss.csv\")\n",
    "val_loss_1 = val_loss_1['Value'].values[:300]\n",
    "\n",
    "val_loss_2 = pd.read_csv(\"tictactoe_exp_lr/run_tictactoe_lr_0_02-tag-val_loss.csv\")\n",
    "val_loss_2 = val_loss_2['Value'].values\n",
    "\n",
    "val_loss_3 = pd.read_csv(\"tictactoe_exp_lr/run_tictactoe_lr_0_002-tag-val_loss.csv\")\n",
    "val_loss_3 = val_loss_3['Value'].values\n",
    "\n",
    "val_loss_4 = pd.read_csv(\"tictactoe_exp_lr/run_tictactoe_lr_0_0002-tag-val_loss.csv\")\n",
    "val_loss_4 = val_loss_4['Value'].values\n",
    "\n",
    "# length \n",
    "print(val_loss_1.shape)\n",
    "print(val_loss_2.shape)\n",
    "print(val_loss_3.shape)\n",
    "print(val_loss_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_size = 1\n",
    "first_iteration = 0\n",
    "last_iteration = 300\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "plt.title(\"Evaluation - Validation loss\")\n",
    "\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "x = np.arange(300 - window_size + 1 - first_iteration -(300-last_iteration)) + first_iteration\n",
    "\n",
    "#plt.plot(x, smooth(val_loss_1[first_iteration:last_iteration],window_size), label=\"learning rate 0.2\")\n",
    "plt.plot(x, smooth(val_loss_2[first_iteration:last_iteration],window_size), label=\"learning rate 0.02\")\n",
    "plt.plot(x, smooth(val_loss_3[first_iteration:last_iteration],window_size), label=\"learning rate 0.002\")\n",
    "plt.plot(x, smooth(val_loss_4[first_iteration:last_iteration],window_size), label=\"learning rate 0.0002\")\n",
    "\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play against agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate: 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_lr_0_2_29\n"
     ]
    }
   ],
   "source": [
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "last_model_0_2 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_lr_0_2\"\n",
    ")\n",
    "last_model_0_2.load(29)\n",
    "last_agent_0_2 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=last_model_0_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 0 | 0\n",
      " 1 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "-0.092552975\n",
      "[0.132 0.121 0.128 0.    0.128 0.12  0.126 0.118 0.127]\n",
      "value: -0.09255297482013702\n",
      "policy:\n",
      " 0.13237212598323822 | 0.12084122002124786 | 0.12785330414772034\n",
      " 0.0 | 0.1277981549501419 | 0.12044928967952728\n",
      " 0.12600380182266235 | 0.1180933266878128 | 0.12658880650997162\n",
      "===========\n",
      "choose from [1 1 1 0 1 1 1 1 1] :4\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 1 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.5874475\n",
      "[0.144 0.139 0.145 0.    0.    0.136 0.138 0.136 0.162]\n",
      "value: 0.5874475240707397\n",
      "policy:\n",
      " 0.14365708827972412 | 0.13927528262138367 | 0.14547210931777954\n",
      " 0.0 | 0.0 | 0.13636574149131775\n",
      " 0.13765200972557068 | 0.13604804873466492 | 0.16152970492839813\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 1 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.5550063\n",
      "[0.    0.145 0.198 0.    0.    0.141 0.174 0.178 0.164]\n",
      "value: 0.5550063252449036\n",
      "policy:\n",
      " 0.0 | 0.14508111774921417 | 0.19786252081394196\n",
      " 0.0 | 0.0 | 0.14059507846832275\n",
      " 0.17393073439598083 | 0.17818507552146912 | 0.16434547305107117\n",
      "===========\n",
      "choose from [0 1 1 0 0 1 1 1 1] :6\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 1 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "0.7288759\n",
      "[0.    0.139 0.3   0.    0.    0.177 0.    0.135 0.249]\n",
      "value: 0.7288758754730225\n",
      "policy:\n",
      " 0.0 | 0.1390814483165741 | 0.29965248703956604\n",
      " 0.0 | 0.0 | 0.17691132426261902\n",
      " 0.0 | 0.1352691948413849 | 0.24908559024333954\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 1\n",
      " 1 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "0.54328656\n",
      "[0.    0.345 0.    0.    0.    0.172 0.    0.194 0.288]\n",
      "value: 0.5432865619659424\n",
      "policy:\n",
      " 0.0 | 0.3449200987815857 | 0.0\n",
      " 0.0 | 0.0 | 0.1724902242422104\n",
      " 0.0 | 0.19442041218280792 | 0.2881692945957184\n",
      "===========\n",
      "choose from [0 1 0 0 0 1 0 1 1] :1\n",
      "===========\n",
      " 1 | 2 | 1\n",
      " 1 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "0.4742858\n",
      "[0.    0.    0.    0.    0.    0.438 0.    0.262 0.3  ]\n",
      "value: 0.4742858111858368\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.4382736384868622\n",
      " 0.0 | 0.2616117000579834 | 0.3001146614551544\n",
      "===========\n",
      "===========\n",
      " 1 | 2 | 1\n",
      " 1 | 2 | 1\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "-0.9898523\n",
      "[0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 9.995e-01 4.600e-04]\n",
      "value: -0.9898523092269897\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.9995400309562683 | 0.00045999709982424974\n",
      "===========\n",
      "choose from [0 0 0 0 0 0 0 1 1] :7\n",
      "===========\n",
      " 1 | 2 | 1\n",
      " 1 | 2 | 1\n",
      " 2 | 2 | 0\n",
      "-----------\n",
      "-0.79255646\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "value: -0.7925564646720886\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 1.0\n",
      "===========\n",
      "Player -1 won the game after 8 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(last_agent_0_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_lr_0_2_2\n"
     ]
    }
   ],
   "source": [
    "best_version = np.argmax(wins_1)\n",
    "\n",
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "best_model_0_2 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_lr_0_2\"\n",
    ")\n",
    "best_model_0_2.load(best_version)\n",
    "best_agent_0_2 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=best_model_0_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 1 | 0\n",
      "-----------\n",
      "-0.01686379\n",
      "[0.157 0.142 0.153 0.117 0.089 0.112 0.143 0.    0.088]\n",
      "value: -0.016863789409399033\n",
      "policy:\n",
      " 0.15659697353839874 | 0.14220961928367615 | 0.15307332575321198\n",
      " 0.11735028028488159 | 0.08880799263715744 | 0.11153189837932587\n",
      " 0.14264127612113953 | 0.0 | 0.08778861165046692\n",
      "===========\n",
      "choose from [1 1 1 1 1 1 1 0 1] :4\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 1 | 0\n",
      "-----------\n",
      "0.35282496\n",
      "[0.142 0.139 0.14  0.137 0.    0.108 0.221 0.    0.113]\n",
      "value: 0.35282495617866516\n",
      "policy:\n",
      " 0.14236223697662354 | 0.13912415504455566 | 0.13955415785312653\n",
      " 0.13705547153949738 | 0.0 | 0.10802163928747177\n",
      " 0.22134587168693542 | 0.0 | 0.11253654211759567\n",
      "===========\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 1 | 1 | 0\n",
      "-----------\n",
      "0.2028839\n",
      "[0.229 0.179 0.167 0.221 0.    0.119 0.    0.    0.084]\n",
      "value: 0.20288389921188354\n",
      "policy:\n",
      " 0.22940543293952942 | 0.17900031805038452 | 0.16657552123069763\n",
      " 0.22144398093223572 | 0.0 | 0.11911413073539734\n",
      " 0.0 | 0.0 | 0.08446060121059418\n",
      "===========\n",
      "choose from [1 1 1 1 0 1 0 0 1] :8\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 1 | 1 | 2\n",
      "-----------\n",
      "0.13463782\n",
      "[0.242 0.218 0.226 0.203 0.    0.111 0.    0.    0.   ]\n",
      "value: 0.13463781774044037\n",
      "policy:\n",
      " 0.24195167422294617 | 0.21812453866004944 | 0.22564314305782318\n",
      " 0.20349326729774475 | 0.0 | 0.11078743636608124\n",
      " 0.0 | 0.0 | 0.0\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 1 | 1 | 2\n",
      "-----------\n",
      "0.15641677\n",
      "[0.    0.212 0.336 0.228 0.    0.225 0.    0.    0.   ]\n",
      "value: 0.15641677379608154\n",
      "policy:\n",
      " 0.0 | 0.21168620884418488 | 0.33599716424942017\n",
      " 0.22776992619037628 | 0.0 | 0.22454673051834106\n",
      " 0.0 | 0.0 | 0.0\n",
      "===========\n",
      "choose from [0 1 1 1 0 1 0 0 0] :3\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 2 | 2 | 0\n",
      " 1 | 1 | 2\n",
      "-----------\n",
      "-0.1520787\n",
      "[0.    0.405 0.52  0.    0.    0.075 0.    0.    0.   ]\n",
      "value: -0.15207870304584503\n",
      "policy:\n",
      " 0.0 | 0.404909610748291 | 0.5196768641471863\n",
      " 0.0 | 0.0 | 0.0754135400056839\n",
      " 0.0 | 0.0 | 0.0\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 1\n",
      " 2 | 2 | 0\n",
      " 1 | 1 | 2\n",
      "-----------\n",
      "-0.19874384\n",
      "[0.    0.166 0.    0.    0.    0.834 0.    0.    0.   ]\n",
      "value: -0.19874383509159088\n",
      "policy:\n",
      " 0.0 | 0.165902242064476 | 0.0\n",
      " 0.0 | 0.0 | 0.8340977430343628\n",
      " 0.0 | 0.0 | 0.0\n",
      "===========\n",
      "choose from [0 1 0 0 0 1 0 0 0] :5\n",
      "===========\n",
      " 1 | 0 | 1\n",
      " 2 | 2 | 2\n",
      " 1 | 1 | 2\n",
      "-----------\n",
      "-0.44066295\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "value: -0.4406629502773285\n",
      "policy:\n",
      " 0.0 | 1.0 | 0.0\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.0\n",
      "===========\n",
      "Player -1 won the game after 8 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(best_agent_0_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_lr_0_02_29\n"
     ]
    }
   ],
   "source": [
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "last_model_0_02 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_lr_0_02\"\n",
    ")\n",
    "last_model_0_02.load(29)\n",
    "last_agent_0_02 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=last_model_0_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 1 | 0\n",
      "-----------\n",
      "0.2034065\n",
      "[0.128 0.13  0.13  0.117 0.128 0.124 0.117 0.    0.126]\n",
      "value: 0.20340649783611298\n",
      "policy:\n",
      " 0.12753771245479584 | 0.12993218004703522 | 0.1303442120552063\n",
      " 0.11725719273090363 | 0.12755239009857178 | 0.12413354963064194\n",
      " 0.11747501790523529 | 0.0 | 0.125767782330513\n",
      "===========\n",
      "choose from [1 1 1 1 1 1 1 0 1] :4\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 1 | 0\n",
      "-----------\n",
      "-0.9993197\n",
      "[0.14  0.146 0.142 0.145 0.    0.146 0.139 0.    0.142]\n",
      "value: -0.9993196725845337\n",
      "policy:\n",
      " 0.13992546498775482 | 0.145741805434227 | 0.14180661737918854\n",
      " 0.14511631429195404 | 0.0 | 0.14606274664402008\n",
      " 0.13937383890151978 | 0.0 | 0.14197322726249695\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 1 | 0\n",
      "-----------\n",
      "-0.9346763\n",
      "[0.161 0.    0.142 0.205 0.    0.19  0.147 0.    0.154]\n",
      "value: -0.9346762895584106\n",
      "policy:\n",
      " 0.16104483604431152 | 0.0 | 0.14168789982795715\n",
      " 0.20546987652778625 | 0.0 | 0.1900305151939392\n",
      " 0.14744074642658234 | 0.0 | 0.15432609617710114\n",
      "===========\n",
      "choose from [1 0 1 1 0 1 1 0 1] :0\n",
      "===========\n",
      " 2 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 1 | 0\n",
      "-----------\n",
      "-0.9999891\n",
      "[0.    0.    0.218 0.158 0.    0.234 0.191 0.    0.198]\n",
      "value: -0.9999890923500061\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.21833501756191254\n",
      " 0.1581793874502182 | 0.0 | 0.2337612807750702\n",
      " 0.19124464690685272 | 0.0 | 0.19847966730594635\n",
      "===========\n",
      "===========\n",
      " 2 | 1 | 0\n",
      " 0 | 2 | 1\n",
      " 0 | 1 | 0\n",
      "-----------\n",
      "-0.9562858\n",
      "[0.    0.    0.004 0.002 0.    0.    0.008 0.    0.986]\n",
      "value: -0.9562857747077942\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.004326766822487116\n",
      " 0.0020436658523976803 | 0.0 | 0.0\n",
      " 0.007676552049815655 | 0.0 | 0.9859529733657837\n",
      "===========\n",
      "choose from [0 0 1 1 0 0 1 0 1] :8\n",
      "===========\n",
      " 2 | 1 | 0\n",
      " 0 | 2 | 1\n",
      " 0 | 1 | 2\n",
      "-----------\n",
      "-0.9999699\n",
      "[0.    0.    0.454 0.196 0.    0.    0.35  0.    0.   ]\n",
      "value: -0.9999698996543884\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.453878253698349\n",
      " 0.19595062732696533 | 0.0 | 0.0\n",
      " 0.35017111897468567 | 0.0 | 0.0\n",
      "===========\n",
      "Player -1 won the game after 6 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(last_agent_0_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_lr_0_02_19\n"
     ]
    }
   ],
   "source": [
    "best_version = np.argmax(wins_2)\n",
    "\n",
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "best_model_0_02 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_lr_0_02\"\n",
    ")\n",
    "best_model_0_02.load(best_version)\n",
    "best_agent_0_02 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=best_model_0_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.21825084\n",
      "[0.124 0.    0.117 0.116 0.132 0.126 0.129 0.132 0.124]\n",
      "value: 0.2182508409023285\n",
      "policy:\n",
      " 0.12448519468307495 | 0.0 | 0.1166791319847107\n",
      " 0.11619044840335846 | 0.13207566738128662 | 0.12577731907367706\n",
      " 0.12878252565860748 | 0.131577268242836 | 0.12443237751722336\n",
      "===========\n",
      "choose from [1 0 1 1 1 1 1 1 1] :4\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "-0.9996773\n",
      "[0.155 0.    0.144 0.149 0.    0.137 0.133 0.15  0.132]\n",
      "value: -0.999677300453186\n",
      "policy:\n",
      " 0.155099019408226 | 0.0 | 0.14383193850517273\n",
      " 0.14926689863204956 | 0.0 | 0.13705851137638092\n",
      " 0.13301467895507812 | 0.14950118958950043 | 0.13222776353359222\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.50591993\n",
      "[0.    0.    0.137 0.189 0.    0.138 0.161 0.187 0.187]\n",
      "value: 0.5059199333190918\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.1370673030614853\n",
      " 0.1893438696861267 | 0.0 | 0.13817830383777618\n",
      " 0.16118060052394867 | 0.187216117978096 | 0.18701377511024475\n",
      "===========\n",
      "choose from [0 0 1 1 0 1 1 1 1] :2\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "-0.9999455\n",
      "[0.    0.    0.    0.255 0.    0.151 0.213 0.25  0.132]\n",
      "value: -0.9999455213546753\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.25486746430397034 | 0.0 | 0.1507628709077835\n",
      " 0.21288235485553741 | 0.24959439039230347 | 0.13189299404621124\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 1 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "-0.89030844\n",
      "[0.    0.    0.    0.    0.    0.002 0.992 0.002 0.005]\n",
      "value: -0.8903084397315979\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.0018647137330844998\n",
      " 0.9918856620788574 | 0.0017174282111227512 | 0.004532205406576395\n",
      "===========\n",
      "choose from [0 0 0 0 0 1 1 1 1] :6\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 1 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "-0.99999696\n",
      "[0.    0.    0.    0.    0.    0.162 0.    0.388 0.45 ]\n",
      "value: -0.9999969601631165\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.16154226660728455\n",
      " 0.0 | 0.38841819763183594 | 0.4500395357608795\n",
      "===========\n",
      "Player -1 won the game after 6 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(best_agent_0_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Learning rate 0.002\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_lr_0_002_29\n"
     ]
    }
   ],
   "source": [
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "last_model_0_002 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_lr_0_002\"\n",
    ")\n",
    "last_model_0_002.load(29)\n",
    "last_agent_0_002 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=last_model_0_002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 1\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.3067093\n",
      "[0.119 0.121 0.126 0.126 0.143 0.    0.122 0.117 0.126]\n",
      "value: 0.30670928955078125\n",
      "policy:\n",
      " 0.11889251321554184 | 0.12100300192832947 | 0.12592630088329315\n",
      " 0.1261391043663025 | 0.14288966357707977 | 0.0\n",
      " 0.12218474596738815 | 0.11659008264541626 | 0.12637457251548767\n",
      "===========\n",
      "choose from [1 1 1 1 1 0 1 1 1] :4\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 1\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "-0.15143882\n",
      "[0.146 0.151 0.166 0.12  0.    0.    0.12  0.134 0.163]\n",
      "value: -0.15143881738185883\n",
      "policy:\n",
      " 0.1461571753025055 | 0.1506337672472 | 0.16582757234573364\n",
      " 0.11971481144428253 | 0.0 | 0.0\n",
      " 0.12043415009975433 | 0.13438628613948822 | 0.16284620761871338\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 0 | 2 | 1\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "-0.12113561\n",
      "[0.    0.136 0.245 0.125 0.    0.    0.188 0.174 0.133]\n",
      "value: -0.12113560736179352\n",
      "policy:\n",
      " 0.0 | 0.13643606007099152 | 0.24457809329032898\n",
      " 0.12454771250486374 | 0.0 | 0.0\n",
      " 0.1876029521226883 | 0.17355559766292572 | 0.13327959179878235\n",
      "===========\n",
      "choose from [0 1 1 1 0 0 1 1 1] :2\n",
      "===========\n",
      " 1 | 0 | 2\n",
      " 0 | 2 | 1\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.5649933\n",
      "[0.    0.179 0.    0.295 0.    0.    0.285 0.082 0.159]\n",
      "value: 0.5649933218955994\n",
      "policy:\n",
      " 0.0 | 0.1786465346813202 | 0.0\n",
      " 0.29520347714424133 | 0.0 | 0.0\n",
      " 0.2847195565700531 | 0.08245569467544556 | 0.1589747816324234\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 2\n",
      " 1 | 2 | 1\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "-0.9192118\n",
      "[0.    0.073 0.    0.    0.    0.    0.838 0.046 0.043]\n",
      "value: -0.9192118048667908\n",
      "policy:\n",
      " 0.0 | 0.07312552630901337 | 0.0\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.8381617069244385 | 0.04554767161607742 | 0.043165095150470734\n",
      "===========\n",
      "choose from [0 1 0 0 0 0 1 1 1] :6\n",
      "===========\n",
      " 1 | 0 | 2\n",
      " 1 | 2 | 1\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "-0.3358869\n",
      "[0.    0.303 0.    0.    0.    0.    0.    0.235 0.462]\n",
      "value: -0.3358868956565857\n",
      "policy:\n",
      " 0.0 | 0.30263563990592957 | 0.0\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.23536653816699982 | 0.4619978368282318\n",
      "===========\n",
      "Player -1 won the game after 6 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(last_agent_0_002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_lr_0_002_20\n"
     ]
    }
   ],
   "source": [
    "best_version = np.argmax(wins_3)\n",
    "\n",
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "best_model_0_002 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_lr_0_002\"\n",
    ")\n",
    "best_model_0_002.load(best_version)\n",
    "best_agent_0_002 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=best_model_0_002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.18894832\n",
      "[0.12  0.    0.122 0.125 0.137 0.124 0.124 0.129 0.12 ]\n",
      "value: 0.18894831836223602\n",
      "policy:\n",
      " 0.11962060630321503 | 0.0 | 0.12186503410339355\n",
      " 0.12541380524635315 | 0.13661648333072662 | 0.12374608218669891\n",
      " 0.1238662376999855 | 0.12857550382614136 | 0.12029623985290527\n",
      "===========\n",
      "choose from [1 0 1 1 1 1 1 1 1] :0\n",
      "===========\n",
      " 2 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.0513978\n",
      "[0.    0.    0.137 0.146 0.154 0.146 0.12  0.162 0.133]\n",
      "value: 0.05139780044555664\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.13738007843494415\n",
      " 0.14620456099510193 | 0.15428867936134338 | 0.14638656377792358\n",
      " 0.12042072415351868 | 0.16224907338619232 | 0.13307031989097595\n",
      "===========\n",
      "===========\n",
      " 2 | 1 | 0\n",
      " 1 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.30599442\n",
      "[0.    0.    0.125 0.    0.258 0.153 0.115 0.148 0.201]\n",
      "value: 0.3059944212436676\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.12498369812965393\n",
      " 0.0 | 0.2575860321521759 | 0.15349158644676208\n",
      " 0.11483828723430634 | 0.14785084128379822 | 0.20124951004981995\n",
      "===========\n",
      "choose from [0 0 1 0 1 1 1 1 1] :4\n",
      "===========\n",
      " 2 | 1 | 0\n",
      " 1 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.6765139\n",
      "[0.    0.    0.181 0.    0.    0.251 0.196 0.177 0.195]\n",
      "value: 0.6765139102935791\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.18057528138160706\n",
      " 0.0 | 0.0 | 0.2508574426174164\n",
      " 0.1957293301820755 | 0.17741382122039795 | 0.19542409479618073\n",
      "===========\n",
      "===========\n",
      " 2 | 1 | 0\n",
      " 1 | 2 | 1\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "-0.7573442\n",
      "[0.    0.    0.054 0.    0.    0.    0.079 0.029 0.838]\n",
      "value: -0.7573441863059998\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.05386526137590408\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0792028084397316 | 0.028807809576392174 | 0.8381240963935852\n",
      "===========\n",
      "choose from [0 0 1 0 0 0 1 1 1] :8\n",
      "===========\n",
      " 2 | 1 | 0\n",
      " 1 | 2 | 1\n",
      " 0 | 0 | 2\n",
      "-----------\n",
      "0.0036120112\n",
      "[0.    0.    0.455 0.    0.    0.    0.321 0.224 0.   ]\n",
      "value: 0.003612011205404997\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.4554179310798645\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.3210550844669342 | 0.2235269993543625 | 0.0\n",
      "===========\n",
      "Player -1 won the game after 6 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(best_agent_0_002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_lr_0_0002_29\n"
     ]
    }
   ],
   "source": [
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "last_model_0_0002 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_lr_0_0002\"\n",
    ")\n",
    "last_model_0_0002.load(29)\n",
    "last_agent_0_0002 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=last_model_0_0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.37847984\n",
      "[0.118 0.    0.12  0.127 0.141 0.123 0.13  0.112 0.13 ]\n",
      "value: 0.37847983837127686\n",
      "policy:\n",
      " 0.11751061677932739 | 0.0 | 0.12036557495594025\n",
      " 0.12700878083705902 | 0.14060549437999725 | 0.1227807104587555\n",
      " 0.13023239374160767 | 0.11191745847463608 | 0.12957900762557983\n",
      "===========\n",
      "choose from [1 0 1 1 1 1 1 1 1] :4\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "-0.2869664\n",
      "[0.242 0.    0.166 0.117 0.    0.125 0.092 0.173 0.086]\n",
      "value: -0.2869664132595062\n",
      "policy:\n",
      " 0.24194589257240295 | 0.0 | 0.16600653529167175\n",
      " 0.1165558472275734 | 0.0 | 0.1253194659948349\n",
      " 0.09165647625923157 | 0.17275278270244598 | 0.08576305210590363\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.8492265\n",
      "[0.    0.    0.204 0.245 0.    0.137 0.292 0.075 0.048]\n",
      "value: 0.8492264747619629\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.20373155176639557\n",
      " 0.24514541029930115 | 0.0 | 0.1368740350008011\n",
      " 0.2915874719619751 | 0.07486338913440704 | 0.04779815301299095\n",
      "===========\n",
      "choose from [0 0 1 1 0 1 1 1 1] :2\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.24669363\n",
      "[0.    0.    0.    0.217 0.    0.149 0.25  0.201 0.184]\n",
      "value: 0.24669362604618073\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.21664899587631226 | 0.0 | 0.1491871178150177\n",
      " 0.24961218237876892 | 0.20064440369606018 | 0.18390730023384094\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 2 | 0\n",
      " 1 | 0 | 0\n",
      "-----------\n",
      "0.31401497\n",
      "[0.    0.    0.    0.103 0.    0.607 0.    0.103 0.187]\n",
      "value: 0.3140149712562561\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.10325335711240768 | 0.0 | 0.6069076657295227\n",
      " 0.0 | 0.10327242314815521 | 0.1865665167570114\n",
      "===========\n",
      "choose from [0 0 0 1 0 1 0 1 1] :3\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 2 | 2 | 0\n",
      " 1 | 0 | 0\n",
      "-----------\n",
      "-0.7273296\n",
      "[0.    0.    0.    0.    0.    0.076 0.    0.588 0.336]\n",
      "value: -0.7273296117782593\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.07602883130311966\n",
      " 0.0 | 0.5877930521965027 | 0.33617809414863586\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 2 | 2 | 0\n",
      " 1 | 1 | 0\n",
      "-----------\n",
      "-0.46471557\n",
      "[0.    0.    0.    0.    0.    0.931 0.    0.    0.069]\n",
      "value: -0.4647155702114105\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.930583119392395\n",
      " 0.0 | 0.0 | 0.0694168284535408\n",
      "===========\n",
      "choose from [0 0 0 0 0 1 0 0 1] :5\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 2 | 2 | 2\n",
      " 1 | 1 | 0\n",
      "-----------\n",
      "-0.7668644\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "value: -0.7668644189834595\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 1.0\n",
      "===========\n",
      "Player -1 won the game after 8 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(last_agent_0_0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_lr_0_0002_27\n"
     ]
    }
   ],
   "source": [
    "best_version = np.argmax(wins_4)\n",
    "\n",
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "best_model_0_0002 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_lr_0_0002\"\n",
    ")\n",
    "best_model_0_0002.load(best_version)\n",
    "best_agent_0_0002 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=best_model_0_0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.32971698\n",
      "[0.115 0.    0.118 0.129 0.138 0.125 0.13  0.114 0.132]\n",
      "value: 0.3297169804573059\n",
      "policy:\n",
      " 0.11475159227848053 | 0.0 | 0.11784227192401886\n",
      " 0.12882934510707855 | 0.13752275705337524 | 0.12518244981765747\n",
      " 0.12980562448501587 | 0.11423487961292267 | 0.13183104991912842\n",
      "===========\n",
      "choose from [1 0 1 1 1 1 1 1 1] :4\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "-0.30895224\n",
      "[0.237 0.    0.17  0.117 0.    0.123 0.092 0.174 0.088]\n",
      "value: -0.3089522421360016\n",
      "policy:\n",
      " 0.23746846616268158 | 0.0 | 0.16951853036880493\n",
      " 0.11710184812545776 | 0.0 | 0.12319333106279373\n",
      " 0.09155654162168503 | 0.1736159324645996 | 0.08754531294107437\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.84630734\n",
      "[0.    0.    0.2   0.251 0.    0.14  0.287 0.075 0.048]\n",
      "value: 0.8463073372840881\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.19987259805202484\n",
      " 0.25094860792160034 | 0.0 | 0.1398068219423294\n",
      " 0.2867220938205719 | 0.07452985644340515 | 0.04811999946832657\n",
      "===========\n",
      "choose from [0 0 1 1 0 1 1 1 1] :2\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.25359443\n",
      "[0.    0.    0.    0.219 0.    0.145 0.246 0.2   0.19 ]\n",
      "value: 0.25359442830085754\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.21948105096817017 | 0.0 | 0.1446012705564499\n",
      " 0.24620556831359863 | 0.19979949295520782 | 0.18991266191005707\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 1 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "-0.5241996\n",
      "[0.    0.    0.    0.    0.    0.209 0.408 0.137 0.246]\n",
      "value: -0.5241996049880981\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.20863358676433563\n",
      " 0.40823376178741455 | 0.1373894363641739 | 0.2457432597875595\n",
      "===========\n",
      "choose from [0 0 0 0 0 1 1 1 1] :6\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 1 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "-0.22747563\n",
      "[0.    0.    0.    0.    0.    0.262 0.    0.357 0.38 ]\n",
      "value: -0.2274756282567978\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.2622460126876831\n",
      " 0.0 | 0.3573232591152191 | 0.38043078780174255\n",
      "===========\n",
      "Player -1 won the game after 6 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(best_agent_0_0002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last(1) vs best(2)\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 1 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 2 | 0 | 0\n",
      " 1 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 2 | 0 | 0\n",
      " 1 | 1 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 2 | 2 | 0\n",
      " 1 | 1 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 2 | 2 | 0\n",
      " 1 | 1 | 1\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "last(2) vs best(1)\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 1 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 2 | 2 | 0\n",
      " 1 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 2 | 2 | 0\n",
      " 1 | 1 | 1\n",
      "===========\n",
      "result -  last_0_2: 0 best_0_2: 0\n"
     ]
    }
   ],
   "source": [
    "# best vs last 0_2\n",
    "print(\"last(1) vs best(2)\")\n",
    "winner_a = agent_vs_agent(last_agent_0_2, best_agent_0_2, player=1)    \n",
    "print(\"last(2) vs best(1)\")\n",
    "winner_b = agent_vs_agent(best_agent_0_2, last_agent_0_2, player=1)\n",
    "\n",
    "print(\"result -  last_0_2: {} best_0_2: {}\" .format(winner_a - winner_b, winner_b - winner_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last(1) vs best(2)\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 2 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 2 | 0\n",
      " 2 | 0 | 0\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 2 | 0\n",
      " 2 | 1 | 0\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 2 | 0\n",
      " 2 | 1 | 2\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 2 | 0\n",
      " 2 | 1 | 2\n",
      " 0 | 1 | 1\n",
      "===========\n",
      "last(2) vs best(1)\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 2\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 1\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 2\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 1\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 2\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 1\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 2\n",
      "===========\n",
      "result -  last_0_02: 0 best_0_02: 0\n"
     ]
    }
   ],
   "source": [
    "# best vs last 0_02\n",
    "print(\"last(1) vs best(2)\")\n",
    "winner_a = agent_vs_agent(last_agent_0_02, best_agent_0_02, player=1)    \n",
    "print(\"last(2) vs best(1)\")\n",
    "winner_b = agent_vs_agent(best_agent_0_02, last_agent_0_02, player=1)\n",
    "\n",
    "print(\"result -  last_0_02: {} best_0_02: {}\" .format(winner_a - winner_b, winner_b - winner_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last(1) vs best(2)\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 1\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 1\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 0 | 2 | 1\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 2\n",
      " 0 | 2 | 1\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 2\n",
      " 1 | 2 | 1\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 2\n",
      " 1 | 2 | 1\n",
      " 2 | 0 | 0\n",
      "===========\n",
      "last(2) vs best(1)\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 2 | 2 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 1\n",
      " 0 | 0 | 0\n",
      " 2 | 2 | 0\n",
      "===========\n",
      "result -  last_0_002: -2 best_0_002: 2\n"
     ]
    }
   ],
   "source": [
    "# best vs last 0_002\n",
    "print(\"last(1) vs best(2)\")\n",
    "winner_a = agent_vs_agent(last_agent_0_002, best_agent_0_002, player=1)    \n",
    "print(\"last(2) vs best(1)\")\n",
    "winner_b = agent_vs_agent(best_agent_0_002, last_agent_0_002, player=1)\n",
    "\n",
    "print(\"result -  last_0_002: {} best_0_002: {}\" .format(winner_a - winner_b, winner_b - winner_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last(1) vs best(2)\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 2 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 1\n",
      " 2 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "last(2) vs best(1)\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 1\n",
      " 0 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "===========\n",
      "result -  last_0_0002: 0 best_0_0002: 0\n"
     ]
    }
   ],
   "source": [
    "# best vs last 0_0002\n",
    "print(\"last(1) vs best(2)\")\n",
    "winner_a = agent_vs_agent(last_agent_0_0002, best_agent_0_0002, player=1)    \n",
    "print(\"last(2) vs best(1)\")\n",
    "winner_b = agent_vs_agent(best_agent_0_0002, last_agent_0_0002, player=1)\n",
    "\n",
    "print(\"result -  last_0_0002: {} best_0_0002: {}\" .format(winner_a - winner_b, winner_b - winner_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_agent_0_2(1) vs best_agent_0_02(2)\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      " 1 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 2 | 2\n",
      " 0 | 0 | 0\n",
      " 1 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 2 | 2\n",
      " 0 | 0 | 0\n",
      " 1 | 1 | 1\n",
      "===========\n",
      "best_agent_0_2(2) vs best_agent_0_02(1)\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 2\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 1 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 1 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "===========\n",
      "result -  best_agent_0_2: 2 best_agent_0_02: -2\n"
     ]
    }
   ],
   "source": [
    "# best_agent_0_2 vs best_agent_0_02\n",
    "print(\"best_agent_0_2(1) vs best_agent_0_02(2)\")\n",
    "winner_a = agent_vs_agent(best_agent_0_2, best_agent_0_02, player=1)    \n",
    "print(\"best_agent_0_2(2) vs best_agent_0_02(1)\")\n",
    "winner_b = agent_vs_agent(best_agent_0_02, last_agent_0_2, player=1)\n",
    "\n",
    "print(\"result -  best_agent_0_2: {} best_agent_0_02: {}\" .format(winner_a - winner_b, winner_b - winner_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_agent_0_2(1) vs best_agent_0_002(2)\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 1 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 1 | 1 | 2\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 1 | 1 | 2\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 0 | 2 | 2\n",
      " 1 | 1 | 2\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 1 | 2 | 2\n",
      " 1 | 1 | 2\n",
      "===========\n",
      "best_agent_0_2(2) vs best_agent_0_002(1)\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 2\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 2\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 2\n",
      " 0 | 1 | 2\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 2\n",
      " 0 | 1 | 2\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "result -  best_agent_0_2: 0 best_agent_0_002: 0\n"
     ]
    }
   ],
   "source": [
    "# best_agent_0_2 vs best_agent_0_002\n",
    "print(\"best_agent_0_2(1) vs best_agent_0_002(2)\")\n",
    "winner_a = agent_vs_agent(best_agent_0_2, best_agent_0_002, player=1)    \n",
    "print(\"best_agent_0_2(2) vs best_agent_0_002(1)\")\n",
    "winner_b = agent_vs_agent(best_agent_0_002, last_agent_0_2, player=1)\n",
    "\n",
    "print(\"result -  best_agent_0_2: {} best_agent_0_002: {}\" .format(winner_a - winner_b, winner_b - winner_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_agent_0_2(1) vs best_agent_0_0002(2)\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 1 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 2 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 1 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 2 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 1 | 1 | 1\n",
      "===========\n",
      "best_agent_0_2(2) vs best_agent_0_0002(1)\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 2\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 2\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 2\n",
      " 0 | 1 | 2\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 2\n",
      " 0 | 1 | 2\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "result -  best_agent_0_2: 0 best_agent_0_0002: 0\n"
     ]
    }
   ],
   "source": [
    "# best_agent_0_2 vs best_agent_0_0002\n",
    "print(\"best_agent_0_2(1) vs best_agent_0_0002(2)\")\n",
    "winner_a = agent_vs_agent(best_agent_0_2, best_agent_0_0002, player=1)    \n",
    "print(\"best_agent_0_2(2) vs best_agent_0_0002(1)\")\n",
    "winner_b = agent_vs_agent(best_agent_0_0002, last_agent_0_2, player=1)\n",
    "\n",
    "print(\"result -  best_agent_0_2: {} best_agent_0_0002: {}\" .format(winner_a - winner_b, winner_b - winner_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
