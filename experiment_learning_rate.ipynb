{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: TicTacToe - Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from pipeline import Pipeline, agent_vs_player, agent_vs_agent\n",
    "import memory\n",
    "import model\n",
    "import agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every 5 iterations the learning rate will be decreased to (learning rate)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learning rate 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCTS = {\n",
    "    'c_puct': 1.0,\n",
    "    'dir_alpha': 0.6,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 10,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 10\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 0,\n",
    "    'show_games': False\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.2,\n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 512,\n",
    "    'num_filters_value': 512,\n",
    "    'num_filters_tower': 512,\n",
    "    'num_residual_blocks': 3,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 512\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"tictactoe_lr_0_2\", \"TicTacToe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5000, 3, 3, 3)\n",
      "model_y_outcomes: (5000,)\n",
      "model_y_probabilities: (5000, 9)\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 16.2961 - value_loss: 1.8824 - policy_loss: 20.5502 - val_loss: 33.5617 - val_value_loss: 2.0560 - val_policy_loss: 54.8915\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 1s 172us/step - loss: 12.5458 - value_loss: 2.1520 - policy_loss: 12.7830 - val_loss: 8.3320 - val_value_loss: 2.0560 - val_policy_loss: 4.4839\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 1s 171us/step - loss: 8.3846 - value_loss: 2.1520 - policy_loss: 4.5207 - val_loss: 7.5944 - val_value_loss: 2.0560 - val_policy_loss: 3.0737\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 1s 171us/step - loss: 7.2967 - value_loss: 2.1519 - policy_loss: 2.4097 - val_loss: 7.2844 - val_value_loss: 2.0560 - val_policy_loss: 2.5176\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 1s 172us/step - loss: 7.1589 - value_loss: 2.1519 - policy_loss: 2.1979 - val_loss: 7.1570 - val_value_loss: 2.0560 - val_policy_loss: 2.3263\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 1s 171us/step - loss: 7.1428 - value_loss: 2.1519 - policy_loss: 2.2289 - val_loss: 7.0418 - val_value_loss: 2.0560 - val_policy_loss: 2.1589\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 1s 171us/step - loss: 7.0752 - value_loss: 2.1519 - policy_loss: 2.1565 - val_loss: 6.9916 - val_value_loss: 2.0560 - val_policy_loss: 2.1210\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 1s 172us/step - loss: 7.0408 - value_loss: 2.1519 - policy_loss: 2.1501 - val_loss: 6.9397 - val_value_loss: 2.0559 - val_policy_loss: 2.0791\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 1s 172us/step - loss: 6.9936 - value_loss: 2.1518 - policy_loss: 2.1175 - val_loss: 6.8923 - val_value_loss: 2.0559 - val_policy_loss: 2.0461\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 1s 171us/step - loss: 6.9087 - value_loss: 2.1518 - policy_loss: 2.0092 - val_loss: 6.8332 - val_value_loss: 2.0559 - val_policy_loss: 1.9892\n",
      "Saved model  tictactoe_lr_0_2_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.01\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.9008 - value_loss: 2.2182 - policy_loss: 1.9886 - val_loss: 6.8316 - val_value_loss: 2.1716 - val_policy_loss: 1.9310\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.8555 - value_loss: 2.2126 - policy_loss: 1.9641 - val_loss: 6.6534 - val_value_loss: 1.8060 - val_policy_loss: 2.0005\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.4319 - value_loss: 1.4061 - policy_loss: 1.9837 - val_loss: 6.3387 - val_value_loss: 1.3082 - val_policy_loss: 1.9290\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2604 - value_loss: 1.1592 - policy_loss: 1.9474 - val_loss: 6.2441 - val_value_loss: 1.1374 - val_policy_loss: 1.9698\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0939 - value_loss: 0.9372 - policy_loss: 1.8957 - val_loss: 6.0950 - val_value_loss: 0.9495 - val_policy_loss: 1.9190\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1085 - value_loss: 0.9929 - policy_loss: 1.9221 - val_loss: 6.1388 - val_value_loss: 1.0501 - val_policy_loss: 1.9523\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0188 - value_loss: 0.8843 - policy_loss: 1.9038 - val_loss: 6.0584 - val_value_loss: 0.9530 - val_policy_loss: 1.9471\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0501 - value_loss: 0.9004 - policy_loss: 2.0080 - val_loss: 6.1778 - val_value_loss: 1.0627 - val_policy_loss: 2.1336\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9554 - value_loss: 0.8489 - policy_loss: 1.9280 - val_loss: 5.9891 - val_value_loss: 0.9731 - val_policy_loss: 1.9036\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.8810 - value_loss: 0.8307 - policy_loss: 1.8550 - val_loss: 5.9194 - val_value_loss: 0.9202 - val_policy_loss: 1.8746\n",
      "Saved model  tictactoe_lr_0_2_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.0\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.8576 - value_loss: 0.8486 - policy_loss: 1.8476 - val_loss: 5.8423 - val_value_loss: 0.8711 - val_policy_loss: 1.8266\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.7987 - value_loss: 0.8151 - policy_loss: 1.8202 - val_loss: 5.7912 - val_value_loss: 0.8369 - val_policy_loss: 1.8152\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.7707 - value_loss: 0.7890 - policy_loss: 1.8467 - val_loss: 5.7396 - val_value_loss: 0.8162 - val_policy_loss: 1.7890\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.6966 - value_loss: 0.7577 - policy_loss: 1.7860 - val_loss: 5.7125 - val_value_loss: 0.8098 - val_policy_loss: 1.7973\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.6850 - value_loss: 0.7918 - policy_loss: 1.7842 - val_loss: 5.7022 - val_value_loss: 0.8204 - val_policy_loss: 1.8214\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.6134 - value_loss: 0.7278 - policy_loss: 1.7604 - val_loss: 5.6519 - val_value_loss: 0.8038 - val_policy_loss: 1.7925\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.6049 - value_loss: 0.7241 - policy_loss: 1.8023 - val_loss: 5.6244 - val_value_loss: 0.7849 - val_policy_loss: 1.8111\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.5602 - value_loss: 0.7421 - policy_loss: 1.7493 - val_loss: 5.5918 - val_value_loss: 0.8203 - val_policy_loss: 1.7648\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.5054 - value_loss: 0.6844 - policy_loss: 1.7516 - val_loss: 5.5662 - val_value_loss: 0.7938 - val_policy_loss: 1.7942\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.4967 - value_loss: 0.7043 - policy_loss: 1.7683 - val_loss: 5.5160 - val_value_loss: 0.7944 - val_policy_loss: 1.7469\n",
      "Saved model  tictactoe_lr_0_2_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.02\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.4962 - value_loss: 0.7919 - policy_loss: 1.7332 - val_loss: 5.5056 - val_value_loss: 0.8551 - val_policy_loss: 1.7188\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.4377 - value_loss: 0.7404 - policy_loss: 1.7210 - val_loss: 5.5416 - val_value_loss: 0.9172 - val_policy_loss: 1.7817\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 5.4173 - value_loss: 0.7052 - policy_loss: 1.7681 - val_loss: 5.4712 - val_value_loss: 0.9010 - val_policy_loss: 1.7097\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.3619 - value_loss: 0.7275 - policy_loss: 1.6874 - val_loss: 5.4333 - val_value_loss: 0.8467 - val_policy_loss: 1.7403\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.3151 - value_loss: 0.6286 - policy_loss: 1.7449 - val_loss: 5.4194 - val_value_loss: 0.8364 - val_policy_loss: 1.7749\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.2961 - value_loss: 0.6594 - policy_loss: 1.7278 - val_loss: 5.3440 - val_value_loss: 0.8229 - val_policy_loss: 1.6892\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.2360 - value_loss: 0.6165 - policy_loss: 1.7019 - val_loss: 5.3645 - val_value_loss: 0.8571 - val_policy_loss: 1.7473\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.2124 - value_loss: 0.6264 - policy_loss: 1.6960 - val_loss: 5.3488 - val_value_loss: 0.8911 - val_policy_loss: 1.7327\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.1652 - value_loss: 0.6007 - policy_loss: 1.6780 - val_loss: 5.2843 - val_value_loss: 0.7904 - val_policy_loss: 1.7550\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.1564 - value_loss: 0.6347 - policy_loss: 1.6769 - val_loss: 5.2338 - val_value_loss: 0.7914 - val_policy_loss: 1.7033\n",
      "Saved model  tictactoe_lr_0_2_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.9 - draw ratio 0.0\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.1459 - value_loss: 0.6811 - policy_loss: 1.6599 - val_loss: 5.2209 - val_value_loss: 0.8031 - val_policy_loss: 1.7161\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.1030 - value_loss: 0.6426 - policy_loss: 1.6628 - val_loss: 5.1878 - val_value_loss: 0.8202 - val_policy_loss: 1.6828\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.0528 - value_loss: 0.6179 - policy_loss: 1.6367 - val_loss: 5.1635 - val_value_loss: 0.8041 - val_policy_loss: 1.6997\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.0324 - value_loss: 0.6003 - policy_loss: 1.6628 - val_loss: 5.0978 - val_value_loss: 0.7303 - val_policy_loss: 1.6913\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.9729 - value_loss: 0.5549 - policy_loss: 1.6384 - val_loss: 5.0998 - val_value_loss: 0.7590 - val_policy_loss: 1.7155\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.9432 - value_loss: 0.5439 - policy_loss: 1.6388 - val_loss: 5.1044 - val_value_loss: 0.7934 - val_policy_loss: 1.7392\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.9270 - value_loss: 0.5377 - policy_loss: 1.6612 - val_loss: 5.0246 - val_value_loss: 0.7338 - val_policy_loss: 1.6875\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.8744 - value_loss: 0.5282 - policy_loss: 1.6138 - val_loss: 5.0038 - val_value_loss: 0.7479 - val_policy_loss: 1.6799\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.8478 - value_loss: 0.5137 - policy_loss: 1.6231 - val_loss: 4.9690 - val_value_loss: 0.7230 - val_policy_loss: 1.6831\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.8171 - value_loss: 0.5098 - policy_loss: 1.6134 - val_loss: 4.9224 - val_value_loss: 0.6936 - val_policy_loss: 1.6669\n",
      "Saved model  tictactoe_lr_0_2_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.0\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 4.8747 - value_loss: 0.6724 - policy_loss: 1.6033 - val_loss: 4.9098 - val_value_loss: 0.7189 - val_policy_loss: 1.6404\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.8261 - value_loss: 0.6061 - policy_loss: 1.5961 - val_loss: 4.8850 - val_value_loss: 0.6958 - val_policy_loss: 1.6376\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.8003 - value_loss: 0.5802 - policy_loss: 1.5941 - val_loss: 4.8670 - val_value_loss: 0.6846 - val_policy_loss: 1.6362\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.7805 - value_loss: 0.5663 - policy_loss: 1.5919 - val_loss: 4.8845 - val_value_loss: 0.7435 - val_policy_loss: 1.6360\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.7629 - value_loss: 0.5566 - policy_loss: 1.5899 - val_loss: 4.8483 - val_value_loss: 0.6980 - val_policy_loss: 1.6324\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.7432 - value_loss: 0.5420 - policy_loss: 1.5886 - val_loss: 4.8264 - val_value_loss: 0.6788 - val_policy_loss: 1.6312\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.7262 - value_loss: 0.5325 - policy_loss: 1.5873 - val_loss: 4.7993 - val_value_loss: 0.6505 - val_policy_loss: 1.6285\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.7133 - value_loss: 0.5311 - policy_loss: 1.5862 - val_loss: 4.7887 - val_value_loss: 0.6540 - val_policy_loss: 1.6270\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.6999 - value_loss: 0.5277 - policy_loss: 1.5859 - val_loss: 4.7725 - val_value_loss: 0.6476 - val_policy_loss: 1.6244\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.6848 - value_loss: 0.5221 - policy_loss: 1.5845 - val_loss: 4.7559 - val_value_loss: 0.6366 - val_policy_loss: 1.6252\n",
      "Saved model  tictactoe_lr_0_2_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.75 - draw ratio 0.02\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 4.7322 - value_loss: 0.6233 - policy_loss: 1.6012 - val_loss: 4.7356 - val_value_loss: 0.6590 - val_policy_loss: 1.5853\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.6902 - value_loss: 0.5650 - policy_loss: 1.5987 - val_loss: 4.7217 - val_value_loss: 0.6540 - val_policy_loss: 1.5854\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.6659 - value_loss: 0.5391 - policy_loss: 1.5989 - val_loss: 4.7088 - val_value_loss: 0.6553 - val_policy_loss: 1.5813\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.6464 - value_loss: 0.5250 - policy_loss: 1.5967 - val_loss: 4.6890 - val_value_loss: 0.6378 - val_policy_loss: 1.5819\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.6332 - value_loss: 0.5228 - policy_loss: 1.5951 - val_loss: 4.7001 - val_value_loss: 0.6835 - val_policy_loss: 1.5811\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.6170 - value_loss: 0.5128 - policy_loss: 1.5955 - val_loss: 4.6657 - val_value_loss: 0.6399 - val_policy_loss: 1.5784\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.6003 - value_loss: 0.5040 - policy_loss: 1.5935 - val_loss: 4.6579 - val_value_loss: 0.6478 - val_policy_loss: 1.5777\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.5903 - value_loss: 0.5065 - policy_loss: 1.5936 - val_loss: 4.6534 - val_value_loss: 0.6641 - val_policy_loss: 1.5749\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.5779 - value_loss: 0.5038 - policy_loss: 1.5941 - val_loss: 4.6264 - val_value_loss: 0.6285 - val_policy_loss: 1.5788\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.5645 - value_loss: 0.5004 - policy_loss: 1.5931 - val_loss: 4.6152 - val_value_loss: 0.6346 - val_policy_loss: 1.5727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_lr_0_2_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.77 - draw ratio 0.02\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 4.6460 - value_loss: 0.6924 - policy_loss: 1.5864 - val_loss: 4.6388 - val_value_loss: 0.6849 - val_policy_loss: 1.5922\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.5927 - value_loss: 0.6105 - policy_loss: 1.5840 - val_loss: 4.6232 - val_value_loss: 0.6752 - val_policy_loss: 1.5928\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.5663 - value_loss: 0.5821 - policy_loss: 1.5818 - val_loss: 4.6085 - val_value_loss: 0.6692 - val_policy_loss: 1.5916\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.5473 - value_loss: 0.5669 - policy_loss: 1.5811 - val_loss: 4.6020 - val_value_loss: 0.6788 - val_policy_loss: 1.5911\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.5341 - value_loss: 0.5624 - policy_loss: 1.5812 - val_loss: 4.5864 - val_value_loss: 0.6714 - val_policy_loss: 1.5893\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.5219 - value_loss: 0.5604 - policy_loss: 1.5809 - val_loss: 4.5781 - val_value_loss: 0.6769 - val_policy_loss: 1.5892\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.5054 - value_loss: 0.5508 - policy_loss: 1.5795 - val_loss: 4.5649 - val_value_loss: 0.6713 - val_policy_loss: 1.5901\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.4915 - value_loss: 0.5456 - policy_loss: 1.5787 - val_loss: 4.5562 - val_value_loss: 0.6774 - val_policy_loss: 1.5886\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.4793 - value_loss: 0.5426 - policy_loss: 1.5791 - val_loss: 4.5455 - val_value_loss: 0.6757 - val_policy_loss: 1.5907\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.4668 - value_loss: 0.5400 - policy_loss: 1.5784 - val_loss: 4.5392 - val_value_loss: 0.6884 - val_policy_loss: 1.5870\n",
      "Saved model  tictactoe_lr_0_2_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.01\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 4.4937 - value_loss: 0.6042 - policy_loss: 1.5897 - val_loss: 4.5361 - val_value_loss: 0.6594 - val_policy_loss: 1.6316\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.4544 - value_loss: 0.5482 - policy_loss: 1.5888 - val_loss: 4.4941 - val_value_loss: 0.6042 - val_policy_loss: 1.6243\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.4276 - value_loss: 0.5209 - policy_loss: 1.5838 - val_loss: 4.4884 - val_value_loss: 0.6136 - val_policy_loss: 1.6249\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.4154 - value_loss: 0.5100 - policy_loss: 1.5918 - val_loss: 4.4636 - val_value_loss: 0.5809 - val_policy_loss: 1.6294\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.3964 - value_loss: 0.4986 - policy_loss: 1.5866 - val_loss: 4.4524 - val_value_loss: 0.5855 - val_policy_loss: 1.6237\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.3888 - value_loss: 0.5055 - policy_loss: 1.5858 - val_loss: 4.4398 - val_value_loss: 0.5746 - val_policy_loss: 1.6307\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.3795 - value_loss: 0.5027 - policy_loss: 1.5913 - val_loss: 4.4313 - val_value_loss: 0.5811 - val_policy_loss: 1.6284\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.3575 - value_loss: 0.4864 - policy_loss: 1.5848 - val_loss: 4.4154 - val_value_loss: 0.5771 - val_policy_loss: 1.6218\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.3449 - value_loss: 0.4829 - policy_loss: 1.5841 - val_loss: 4.4059 - val_value_loss: 0.5719 - val_policy_loss: 1.6291\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.3360 - value_loss: 0.4847 - policy_loss: 1.5856 - val_loss: 4.4002 - val_value_loss: 0.5874 - val_policy_loss: 1.6231\n",
      "Saved model  tictactoe_lr_0_2_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.03\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 4.3697 - value_loss: 0.5700 - policy_loss: 1.5887 - val_loss: 4.3347 - val_value_loss: 0.5154 - val_policy_loss: 1.5850\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.3272 - value_loss: 0.5077 - policy_loss: 1.5870 - val_loss: 4.3128 - val_value_loss: 0.4910 - val_policy_loss: 1.5865\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.3006 - value_loss: 0.4738 - policy_loss: 1.5885 - val_loss: 4.2981 - val_value_loss: 0.4860 - val_policy_loss: 1.5830\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2829 - value_loss: 0.4609 - policy_loss: 1.5867 - val_loss: 4.2925 - val_value_loss: 0.4930 - val_policy_loss: 1.5855\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2706 - value_loss: 0.4568 - policy_loss: 1.5869 - val_loss: 4.2798 - val_value_loss: 0.4899 - val_policy_loss: 1.5837\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2560 - value_loss: 0.4478 - policy_loss: 1.5875 - val_loss: 4.2686 - val_value_loss: 0.4870 - val_policy_loss: 1.5850\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2408 - value_loss: 0.4405 - policy_loss: 1.5848 - val_loss: 4.2740 - val_value_loss: 0.5188 - val_policy_loss: 1.5844\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.2281 - value_loss: 0.4400 - policy_loss: 1.5805 - val_loss: 4.2533 - val_value_loss: 0.5025 - val_policy_loss: 1.5798\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2145 - value_loss: 0.4355 - policy_loss: 1.5782 - val_loss: 4.2366 - val_value_loss: 0.4896 - val_policy_loss: 1.5797\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.2045 - value_loss: 0.4355 - policy_loss: 1.5787 - val_loss: 4.2288 - val_value_loss: 0.4929 - val_policy_loss: 1.5811\n",
      "Saved model  tictactoe_lr_0_2_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.81 - draw ratio 0.03\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 4.3104 - value_loss: 0.6529 - policy_loss: 1.5889 - val_loss: 4.3140 - val_value_loss: 0.6676 - val_policy_loss: 1.5871\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2730 - value_loss: 0.5895 - policy_loss: 1.5877 - val_loss: 4.2965 - val_value_loss: 0.6448 - val_policy_loss: 1.5852\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2562 - value_loss: 0.5666 - policy_loss: 1.5872 - val_loss: 4.2966 - val_value_loss: 0.6552 - val_policy_loss: 1.5850\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2430 - value_loss: 0.5509 - policy_loss: 1.5865 - val_loss: 4.2934 - val_value_loss: 0.6588 - val_policy_loss: 1.5851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2328 - value_loss: 0.5409 - policy_loss: 1.5863 - val_loss: 4.2797 - val_value_loss: 0.6418 - val_policy_loss: 1.5847\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.2237 - value_loss: 0.5335 - policy_loss: 1.5856 - val_loss: 4.2733 - val_value_loss: 0.6393 - val_policy_loss: 1.5846\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2161 - value_loss: 0.5289 - policy_loss: 1.5850 - val_loss: 4.2594 - val_value_loss: 0.6224 - val_policy_loss: 1.5838\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2077 - value_loss: 0.5228 - policy_loss: 1.5845 - val_loss: 4.2571 - val_value_loss: 0.6279 - val_policy_loss: 1.5838\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2006 - value_loss: 0.5183 - policy_loss: 1.5847 - val_loss: 4.2537 - val_value_loss: 0.6313 - val_policy_loss: 1.5835\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.1951 - value_loss: 0.5178 - policy_loss: 1.5842 - val_loss: 4.2485 - val_value_loss: 0.6312 - val_policy_loss: 1.5831\n",
      "Saved model  tictactoe_lr_0_2_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.72 - draw ratio 0.04\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 4.2913 - value_loss: 0.7081 - policy_loss: 1.5962 - val_loss: 4.2739 - val_value_loss: 0.6916 - val_policy_loss: 1.5837\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2585 - value_loss: 0.6539 - policy_loss: 1.5950 - val_loss: 4.2551 - val_value_loss: 0.6649 - val_policy_loss: 1.5827\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2381 - value_loss: 0.6234 - policy_loss: 1.5945 - val_loss: 4.2489 - val_value_loss: 0.6630 - val_policy_loss: 1.5822\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.2230 - value_loss: 0.6039 - policy_loss: 1.5940 - val_loss: 4.2453 - val_value_loss: 0.6660 - val_policy_loss: 1.5819\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.2135 - value_loss: 0.5951 - policy_loss: 1.5935 - val_loss: 4.2306 - val_value_loss: 0.6465 - val_policy_loss: 1.5819\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.2038 - value_loss: 0.5861 - policy_loss: 1.5930 - val_loss: 4.2438 - val_value_loss: 0.6832 - val_policy_loss: 1.5815\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.1952 - value_loss: 0.5788 - policy_loss: 1.5931 - val_loss: 4.2234 - val_value_loss: 0.6518 - val_policy_loss: 1.5819\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.1876 - value_loss: 0.5743 - policy_loss: 1.5923 - val_loss: 4.2171 - val_value_loss: 0.6503 - val_policy_loss: 1.5808\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.1813 - value_loss: 0.5717 - policy_loss: 1.5921 - val_loss: 4.2091 - val_value_loss: 0.6443 - val_policy_loss: 1.5808\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.1753 - value_loss: 0.5689 - policy_loss: 1.5928 - val_loss: 4.2044 - val_value_loss: 0.6448 - val_policy_loss: 1.5806\n",
      "Saved model  tictactoe_lr_0_2_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.0\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 4.2062 - value_loss: 0.6492 - policy_loss: 1.5841 - val_loss: 4.1643 - val_value_loss: 0.6042 - val_policy_loss: 1.5510\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.1730 - value_loss: 0.5935 - policy_loss: 1.5834 - val_loss: 4.1547 - val_value_loss: 0.5949 - val_policy_loss: 1.5509\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.1576 - value_loss: 0.5729 - policy_loss: 1.5829 - val_loss: 4.1495 - val_value_loss: 0.5939 - val_policy_loss: 1.5512\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.1458 - value_loss: 0.5602 - policy_loss: 1.5819 - val_loss: 4.1420 - val_value_loss: 0.5898 - val_policy_loss: 1.5501\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.1368 - value_loss: 0.5522 - policy_loss: 1.5816 - val_loss: 4.1388 - val_value_loss: 0.5932 - val_policy_loss: 1.5502\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.1289 - value_loss: 0.5468 - policy_loss: 1.5811 - val_loss: 4.1330 - val_value_loss: 0.5910 - val_policy_loss: 1.5505\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.1207 - value_loss: 0.5404 - policy_loss: 1.5808 - val_loss: 4.1292 - val_value_loss: 0.5934 - val_policy_loss: 1.5502\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.1130 - value_loss: 0.5349 - policy_loss: 1.5807 - val_loss: 4.1244 - val_value_loss: 0.5944 - val_policy_loss: 1.5494\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.1074 - value_loss: 0.5334 - policy_loss: 1.5806 - val_loss: 4.1201 - val_value_loss: 0.5957 - val_policy_loss: 1.5491\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.1010 - value_loss: 0.5308 - policy_loss: 1.5802 - val_loss: 4.1156 - val_value_loss: 0.5961 - val_policy_loss: 1.5496\n",
      "Saved model  tictactoe_lr_0_2_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.05\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 4.1393 - value_loss: 0.6176 - policy_loss: 1.5797 - val_loss: 4.1259 - val_value_loss: 0.6061 - val_policy_loss: 1.5698\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.1070 - value_loss: 0.5639 - policy_loss: 1.5785 - val_loss: 4.1148 - val_value_loss: 0.5945 - val_policy_loss: 1.5689\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 4.0882 - value_loss: 0.5369 - policy_loss: 1.5776 - val_loss: 4.1059 - val_value_loss: 0.5856 - val_policy_loss: 1.5696\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.0754 - value_loss: 0.5214 - policy_loss: 1.5770 - val_loss: 4.0988 - val_value_loss: 0.5819 - val_policy_loss: 1.5688\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.0649 - value_loss: 0.5106 - policy_loss: 1.5765 - val_loss: 4.0917 - val_value_loss: 0.5770 - val_policy_loss: 1.5692\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.0591 - value_loss: 0.5085 - policy_loss: 1.5766 - val_loss: 4.0863 - val_value_loss: 0.5765 - val_policy_loss: 1.5685\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.0488 - value_loss: 0.4980 - policy_loss: 1.5761 - val_loss: 4.0813 - val_value_loss: 0.5761 - val_policy_loss: 1.5685\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.0415 - value_loss: 0.4933 - policy_loss: 1.5759 - val_loss: 4.0745 - val_value_loss: 0.5726 - val_policy_loss: 1.5679\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.0355 - value_loss: 0.4911 - policy_loss: 1.5757 - val_loss: 4.0700 - val_value_loss: 0.5730 - val_policy_loss: 1.5681\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.0296 - value_loss: 0.4889 - policy_loss: 1.5756 - val_loss: 4.0657 - val_value_loss: 0.5734 - val_policy_loss: 1.5685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_lr_0_2_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.72 - draw ratio 0.05\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 4.0914 - value_loss: 0.6110 - policy_loss: 1.5866 - val_loss: 4.0521 - val_value_loss: 0.5638 - val_policy_loss: 1.5605\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.0580 - value_loss: 0.5553 - policy_loss: 1.5850 - val_loss: 4.0410 - val_value_loss: 0.5512 - val_policy_loss: 1.5605\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.0438 - value_loss: 0.5373 - policy_loss: 1.5841 - val_loss: 4.0379 - val_value_loss: 0.5539 - val_policy_loss: 1.5610\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.0304 - value_loss: 0.5210 - policy_loss: 1.5832 - val_loss: 4.0295 - val_value_loss: 0.5458 - val_policy_loss: 1.5618\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.0230 - value_loss: 0.5156 - policy_loss: 1.5830 - val_loss: 4.0219 - val_value_loss: 0.5410 - val_policy_loss: 1.5609\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.0149 - value_loss: 0.5099 - policy_loss: 1.5820 - val_loss: 4.0189 - val_value_loss: 0.5454 - val_policy_loss: 1.5597\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.0081 - value_loss: 0.5056 - policy_loss: 1.5823 - val_loss: 4.0160 - val_value_loss: 0.5482 - val_policy_loss: 1.5607\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 4.0028 - value_loss: 0.5049 - policy_loss: 1.5817 - val_loss: 4.0192 - val_value_loss: 0.5645 - val_policy_loss: 1.5603\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9964 - value_loss: 0.5016 - policy_loss: 1.5817 - val_loss: 4.0065 - val_value_loss: 0.5484 - val_policy_loss: 1.5603\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9905 - value_loss: 0.4995 - policy_loss: 1.5813 - val_loss: 4.0049 - val_value_loss: 0.5549 - val_policy_loss: 1.5602\n",
      "Saved model  tictactoe_lr_0_2_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.73 - draw ratio 0.04\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 4.0093 - value_loss: 0.5564 - policy_loss: 1.5694 - val_loss: 3.9926 - val_value_loss: 0.5094 - val_policy_loss: 1.5856\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9905 - value_loss: 0.5242 - policy_loss: 1.5686 - val_loss: 3.9874 - val_value_loss: 0.5043 - val_policy_loss: 1.5851\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9791 - value_loss: 0.5066 - policy_loss: 1.5682 - val_loss: 3.9834 - val_value_loss: 0.5012 - val_policy_loss: 1.5849\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9701 - value_loss: 0.4939 - policy_loss: 1.5676 - val_loss: 3.9807 - val_value_loss: 0.5005 - val_policy_loss: 1.5848\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.9631 - value_loss: 0.4851 - policy_loss: 1.5671 - val_loss: 3.9775 - val_value_loss: 0.4989 - val_policy_loss: 1.5847\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9573 - value_loss: 0.4784 - policy_loss: 1.5669 - val_loss: 3.9752 - val_value_loss: 0.4991 - val_policy_loss: 1.5846\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9528 - value_loss: 0.4741 - policy_loss: 1.5667 - val_loss: 3.9719 - val_value_loss: 0.4968 - val_policy_loss: 1.5850\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9472 - value_loss: 0.4679 - policy_loss: 1.5665 - val_loss: 3.9688 - val_value_loss: 0.4958 - val_policy_loss: 1.5846\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.9436 - value_loss: 0.4656 - policy_loss: 1.5662 - val_loss: 3.9663 - val_value_loss: 0.4954 - val_policy_loss: 1.5846\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9381 - value_loss: 0.4595 - policy_loss: 1.5661 - val_loss: 3.9639 - val_value_loss: 0.4953 - val_policy_loss: 1.5844\n",
      "Saved model  tictactoe_lr_0_2_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.02\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 3.9864 - value_loss: 0.5491 - policy_loss: 1.5778 - val_loss: 4.0364 - val_value_loss: 0.6215 - val_policy_loss: 1.6079\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9652 - value_loss: 0.5123 - policy_loss: 1.5769 - val_loss: 4.0319 - val_value_loss: 0.6172 - val_policy_loss: 1.6078\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9536 - value_loss: 0.4943 - policy_loss: 1.5764 - val_loss: 4.0274 - val_value_loss: 0.6132 - val_policy_loss: 1.6076\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9444 - value_loss: 0.4809 - policy_loss: 1.5760 - val_loss: 4.0213 - val_value_loss: 0.6059 - val_policy_loss: 1.6073\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.9369 - value_loss: 0.4709 - policy_loss: 1.5755 - val_loss: 4.0182 - val_value_loss: 0.6047 - val_policy_loss: 1.6070\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9311 - value_loss: 0.4641 - policy_loss: 1.5755 - val_loss: 4.0157 - val_value_loss: 0.6043 - val_policy_loss: 1.6071\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9242 - value_loss: 0.4554 - policy_loss: 1.5750 - val_loss: 4.0122 - val_value_loss: 0.6018 - val_policy_loss: 1.6072\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9210 - value_loss: 0.4537 - policy_loss: 1.5750 - val_loss: 4.0123 - val_value_loss: 0.6068 - val_policy_loss: 1.6071\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9153 - value_loss: 0.4474 - policy_loss: 1.5746 - val_loss: 4.0100 - val_value_loss: 0.6070 - val_policy_loss: 1.6068\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9118 - value_loss: 0.4449 - policy_loss: 1.5745 - val_loss: 4.0068 - val_value_loss: 0.6052 - val_policy_loss: 1.6068\n",
      "Saved model  tictactoe_lr_0_2_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.66 - draw ratio 0.03\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 4.0255 - value_loss: 0.6763 - policy_loss: 1.5752 - val_loss: 3.9811 - val_value_loss: 0.6155 - val_policy_loss: 1.5498\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 4.0008 - value_loss: 0.6326 - policy_loss: 1.5743 - val_loss: 3.9729 - val_value_loss: 0.6039 - val_policy_loss: 1.5496\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9885 - value_loss: 0.6127 - policy_loss: 1.5741 - val_loss: 3.9683 - val_value_loss: 0.5993 - val_policy_loss: 1.5497\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9771 - value_loss: 0.5951 - policy_loss: 1.5735 - val_loss: 3.9617 - val_value_loss: 0.5909 - val_policy_loss: 1.5495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9685 - value_loss: 0.5826 - policy_loss: 1.5733 - val_loss: 3.9605 - val_value_loss: 0.5926 - val_policy_loss: 1.5500\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.9615 - value_loss: 0.5736 - policy_loss: 1.5730 - val_loss: 3.9547 - val_value_loss: 0.5861 - val_policy_loss: 1.5496\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.9546 - value_loss: 0.5644 - policy_loss: 1.5729 - val_loss: 3.9510 - val_value_loss: 0.5831 - val_policy_loss: 1.5498\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.9486 - value_loss: 0.5577 - policy_loss: 1.5723 - val_loss: 3.9479 - val_value_loss: 0.5815 - val_policy_loss: 1.5496\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9446 - value_loss: 0.5540 - policy_loss: 1.5726 - val_loss: 3.9483 - val_value_loss: 0.5864 - val_policy_loss: 1.5500\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9400 - value_loss: 0.5496 - policy_loss: 1.5722 - val_loss: 3.9442 - val_value_loss: 0.5834 - val_policy_loss: 1.5496\n",
      "Saved model  tictactoe_lr_0_2_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.03\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 3.9934 - value_loss: 0.6542 - policy_loss: 1.5792 - val_loss: 3.9684 - val_value_loss: 0.6126 - val_policy_loss: 1.5733\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9697 - value_loss: 0.6124 - policy_loss: 1.5783 - val_loss: 3.9649 - val_value_loss: 0.6106 - val_policy_loss: 1.5729\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9542 - value_loss: 0.5868 - policy_loss: 1.5774 - val_loss: 3.9647 - val_value_loss: 0.6147 - val_policy_loss: 1.5730\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9443 - value_loss: 0.5717 - policy_loss: 1.5771 - val_loss: 3.9619 - val_value_loss: 0.6138 - val_policy_loss: 1.5729\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9356 - value_loss: 0.5593 - policy_loss: 1.5768 - val_loss: 3.9594 - val_value_loss: 0.6132 - val_policy_loss: 1.5730\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9285 - value_loss: 0.5498 - policy_loss: 1.5766 - val_loss: 3.9573 - val_value_loss: 0.6135 - val_policy_loss: 1.5731\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9228 - value_loss: 0.5437 - policy_loss: 1.5760 - val_loss: 3.9575 - val_value_loss: 0.6182 - val_policy_loss: 1.5734\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.9174 - value_loss: 0.5375 - policy_loss: 1.5758 - val_loss: 3.9559 - val_value_loss: 0.6197 - val_policy_loss: 1.5731\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9133 - value_loss: 0.5339 - policy_loss: 1.5758 - val_loss: 3.9530 - val_value_loss: 0.6187 - val_policy_loss: 1.5730\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.9077 - value_loss: 0.5276 - policy_loss: 1.5755 - val_loss: 3.9501 - val_value_loss: 0.6174 - val_policy_loss: 1.5730\n",
      "Saved model  tictactoe_lr_0_2_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.71 - draw ratio 0.09\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 3.9285 - value_loss: 0.5816 - policy_loss: 1.5676 - val_loss: 3.9400 - val_value_loss: 0.5855 - val_policy_loss: 1.5892\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9004 - value_loss: 0.5314 - policy_loss: 1.5661 - val_loss: 3.9337 - val_value_loss: 0.5778 - val_policy_loss: 1.5889\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8868 - value_loss: 0.5087 - policy_loss: 1.5661 - val_loss: 3.9301 - val_value_loss: 0.5750 - val_policy_loss: 1.5891\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8779 - value_loss: 0.4962 - policy_loss: 1.5653 - val_loss: 3.9241 - val_value_loss: 0.5676 - val_policy_loss: 1.5889\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8705 - value_loss: 0.4864 - policy_loss: 1.5650 - val_loss: 3.9215 - val_value_loss: 0.5672 - val_policy_loss: 1.5888\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8641 - value_loss: 0.4783 - policy_loss: 1.5647 - val_loss: 3.9200 - val_value_loss: 0.5683 - val_policy_loss: 1.5892\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8596 - value_loss: 0.4740 - policy_loss: 1.5646 - val_loss: 3.9172 - val_value_loss: 0.5674 - val_policy_loss: 1.5889\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8553 - value_loss: 0.4699 - policy_loss: 1.5647 - val_loss: 3.9147 - val_value_loss: 0.5671 - val_policy_loss: 1.5888\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8537 - value_loss: 0.4715 - policy_loss: 1.5642 - val_loss: 3.9116 - val_value_loss: 0.5656 - val_policy_loss: 1.5886\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8467 - value_loss: 0.4624 - policy_loss: 1.5639 - val_loss: 3.9110 - val_value_loss: 0.5690 - val_policy_loss: 1.5885\n",
      "Saved model  tictactoe_lr_0_2_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.03\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 3.9043 - value_loss: 0.5750 - policy_loss: 1.5702 - val_loss: 3.9197 - val_value_loss: 0.5850 - val_policy_loss: 1.5921\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8907 - value_loss: 0.5507 - policy_loss: 1.5694 - val_loss: 3.9173 - val_value_loss: 0.5825 - val_policy_loss: 1.5920\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8808 - value_loss: 0.5335 - policy_loss: 1.5691 - val_loss: 3.9157 - val_value_loss: 0.5814 - val_policy_loss: 1.5923\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8737 - value_loss: 0.5218 - policy_loss: 1.5689 - val_loss: 3.9147 - val_value_loss: 0.5817 - val_policy_loss: 1.5923\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8687 - value_loss: 0.5145 - policy_loss: 1.5684 - val_loss: 3.9139 - val_value_loss: 0.5825 - val_policy_loss: 1.5922\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8639 - value_loss: 0.5073 - policy_loss: 1.5683 - val_loss: 3.9135 - val_value_loss: 0.5837 - val_policy_loss: 1.5924\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8595 - value_loss: 0.5008 - policy_loss: 1.5682 - val_loss: 3.9125 - val_value_loss: 0.5841 - val_policy_loss: 1.5923\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8558 - value_loss: 0.4959 - policy_loss: 1.5680 - val_loss: 3.9117 - val_value_loss: 0.5845 - val_policy_loss: 1.5925\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8529 - value_loss: 0.4926 - policy_loss: 1.5678 - val_loss: 3.9110 - val_value_loss: 0.5853 - val_policy_loss: 1.5924\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8498 - value_loss: 0.4889 - policy_loss: 1.5675 - val_loss: 3.9099 - val_value_loss: 0.5853 - val_policy_loss: 1.5925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_lr_0_2_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.07\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 3.9195 - value_loss: 0.6267 - policy_loss: 1.5713 - val_loss: 3.9181 - val_value_loss: 0.6274 - val_policy_loss: 1.5692\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9032 - value_loss: 0.5969 - policy_loss: 1.5708 - val_loss: 3.9134 - val_value_loss: 0.6204 - val_policy_loss: 1.5690\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8934 - value_loss: 0.5795 - policy_loss: 1.5708 - val_loss: 3.9096 - val_value_loss: 0.6154 - val_policy_loss: 1.5687\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8849 - value_loss: 0.5657 - policy_loss: 1.5700 - val_loss: 3.9084 - val_value_loss: 0.6151 - val_policy_loss: 1.5688\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8794 - value_loss: 0.5569 - policy_loss: 1.5699 - val_loss: 3.9055 - val_value_loss: 0.6118 - val_policy_loss: 1.5686\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8748 - value_loss: 0.5502 - policy_loss: 1.5696 - val_loss: 3.9034 - val_value_loss: 0.6095 - val_policy_loss: 1.5689\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8703 - value_loss: 0.5435 - policy_loss: 1.5696 - val_loss: 3.9023 - val_value_loss: 0.6099 - val_policy_loss: 1.5685\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8667 - value_loss: 0.5389 - policy_loss: 1.5693 - val_loss: 3.9017 - val_value_loss: 0.6111 - val_policy_loss: 1.5684\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8640 - value_loss: 0.5358 - policy_loss: 1.5691 - val_loss: 3.8998 - val_value_loss: 0.6095 - val_policy_loss: 1.5684\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8618 - value_loss: 0.5338 - policy_loss: 1.5691 - val_loss: 3.8983 - val_value_loss: 0.6091 - val_policy_loss: 1.5680\n",
      "Saved model  tictactoe_lr_0_2_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.67 - draw ratio 0.1\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 3.9139 - value_loss: 0.6288 - policy_loss: 1.5804 - val_loss: 3.9299 - val_value_loss: 0.6409 - val_policy_loss: 1.6016\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.9024 - value_loss: 0.6089 - policy_loss: 1.5795 - val_loss: 3.9275 - val_value_loss: 0.6385 - val_policy_loss: 1.6015\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8925 - value_loss: 0.5920 - policy_loss: 1.5789 - val_loss: 3.9257 - val_value_loss: 0.6373 - val_policy_loss: 1.6014\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8863 - value_loss: 0.5821 - policy_loss: 1.5789 - val_loss: 3.9248 - val_value_loss: 0.6378 - val_policy_loss: 1.6013\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8811 - value_loss: 0.5742 - policy_loss: 1.5784 - val_loss: 3.9233 - val_value_loss: 0.6370 - val_policy_loss: 1.6013\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8768 - value_loss: 0.5679 - policy_loss: 1.5783 - val_loss: 3.9224 - val_value_loss: 0.6376 - val_policy_loss: 1.6012\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8734 - value_loss: 0.5637 - policy_loss: 1.5781 - val_loss: 3.9232 - val_value_loss: 0.6416 - val_policy_loss: 1.6011\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8701 - value_loss: 0.5597 - policy_loss: 1.5778 - val_loss: 3.9214 - val_value_loss: 0.6401 - val_policy_loss: 1.6011\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8676 - value_loss: 0.5568 - policy_loss: 1.5778 - val_loss: 3.9216 - val_value_loss: 0.6428 - val_policy_loss: 1.6011\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8645 - value_loss: 0.5532 - policy_loss: 1.5775 - val_loss: 3.9194 - val_value_loss: 0.6408 - val_policy_loss: 1.6010\n",
      "Saved model  tictactoe_lr_0_2_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.71 - draw ratio 0.05\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 3.8984 - value_loss: 0.5843 - policy_loss: 1.6164 - val_loss: 3.8472 - val_value_loss: 0.5692 - val_policy_loss: 1.5304\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8816 - value_loss: 0.5536 - policy_loss: 1.6157 - val_loss: 3.8436 - val_value_loss: 0.5641 - val_policy_loss: 1.5305\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8721 - value_loss: 0.5374 - policy_loss: 1.6152 - val_loss: 3.8420 - val_value_loss: 0.5631 - val_policy_loss: 1.5306\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8662 - value_loss: 0.5277 - policy_loss: 1.6152 - val_loss: 3.8383 - val_value_loss: 0.5580 - val_policy_loss: 1.5304\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8596 - value_loss: 0.5170 - policy_loss: 1.6150 - val_loss: 3.8358 - val_value_loss: 0.5553 - val_policy_loss: 1.5304\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8542 - value_loss: 0.5088 - policy_loss: 1.6146 - val_loss: 3.8336 - val_value_loss: 0.5532 - val_policy_loss: 1.5303\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8501 - value_loss: 0.5031 - policy_loss: 1.6144 - val_loss: 3.8323 - val_value_loss: 0.5529 - val_policy_loss: 1.5303\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8472 - value_loss: 0.4995 - policy_loss: 1.6145 - val_loss: 3.8309 - val_value_loss: 0.5524 - val_policy_loss: 1.5303\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8444 - value_loss: 0.4964 - policy_loss: 1.6142 - val_loss: 3.8299 - val_value_loss: 0.5527 - val_policy_loss: 1.5301\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8420 - value_loss: 0.4938 - policy_loss: 1.6142 - val_loss: 3.8282 - val_value_loss: 0.5517 - val_policy_loss: 1.5300\n",
      "Saved model  tictactoe_lr_0_2_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.73 - draw ratio 0.08\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 3.8982 - value_loss: 0.6444 - policy_loss: 1.5781 - val_loss: 3.8775 - val_value_loss: 0.6409 - val_policy_loss: 1.5416\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8793 - value_loss: 0.6098 - policy_loss: 1.5771 - val_loss: 3.8696 - val_value_loss: 0.6274 - val_policy_loss: 1.5414\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8672 - value_loss: 0.5881 - policy_loss: 1.5769 - val_loss: 3.8657 - val_value_loss: 0.6218 - val_policy_loss: 1.5415\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8564 - value_loss: 0.5692 - policy_loss: 1.5765 - val_loss: 3.8627 - val_value_loss: 0.6183 - val_policy_loss: 1.5413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8492 - value_loss: 0.5574 - policy_loss: 1.5761 - val_loss: 3.8611 - val_value_loss: 0.6169 - val_policy_loss: 1.5417\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8429 - value_loss: 0.5471 - policy_loss: 1.5761 - val_loss: 3.8588 - val_value_loss: 0.6147 - val_policy_loss: 1.5414\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8386 - value_loss: 0.5409 - policy_loss: 1.5758 - val_loss: 3.8564 - val_value_loss: 0.6123 - val_policy_loss: 1.5412\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8342 - value_loss: 0.5344 - policy_loss: 1.5757 - val_loss: 3.8549 - val_value_loss: 0.6115 - val_policy_loss: 1.5414\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8304 - value_loss: 0.5292 - policy_loss: 1.5756 - val_loss: 3.8526 - val_value_loss: 0.6092 - val_policy_loss: 1.5412\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8271 - value_loss: 0.5247 - policy_loss: 1.5756 - val_loss: 3.8510 - val_value_loss: 0.6082 - val_policy_loss: 1.5412\n",
      "Saved model  tictactoe_lr_0_2_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.67 - draw ratio 0.09\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 3.8997 - value_loss: 0.6536 - policy_loss: 1.5938 - val_loss: 3.8901 - val_value_loss: 0.6269 - val_policy_loss: 1.6019\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8889 - value_loss: 0.6335 - policy_loss: 1.5933 - val_loss: 3.8875 - val_value_loss: 0.6228 - val_policy_loss: 1.6019\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8805 - value_loss: 0.6180 - policy_loss: 1.5932 - val_loss: 3.8863 - val_value_loss: 0.6215 - val_policy_loss: 1.6019\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8741 - value_loss: 0.6067 - policy_loss: 1.5928 - val_loss: 3.8848 - val_value_loss: 0.6196 - val_policy_loss: 1.6019\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8690 - value_loss: 0.5974 - policy_loss: 1.5928 - val_loss: 3.8837 - val_value_loss: 0.6185 - val_policy_loss: 1.6018\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8645 - value_loss: 0.5897 - policy_loss: 1.5927 - val_loss: 3.8830 - val_value_loss: 0.6183 - val_policy_loss: 1.6018\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8607 - value_loss: 0.5834 - policy_loss: 1.5924 - val_loss: 3.8823 - val_value_loss: 0.6181 - val_policy_loss: 1.6017\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8573 - value_loss: 0.5777 - policy_loss: 1.5925 - val_loss: 3.8813 - val_value_loss: 0.6173 - val_policy_loss: 1.6016\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8545 - value_loss: 0.5734 - policy_loss: 1.5924 - val_loss: 3.8810 - val_value_loss: 0.6179 - val_policy_loss: 1.6016\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8516 - value_loss: 0.5688 - policy_loss: 1.5922 - val_loss: 3.8806 - val_value_loss: 0.6182 - val_policy_loss: 1.6016\n",
      "Saved model  tictactoe_lr_0_2_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.77 - draw ratio 0.02\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 3.8696 - value_loss: 0.6043 - policy_loss: 1.5938 - val_loss: 3.8799 - val_value_loss: 0.6008 - val_policy_loss: 1.6186\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8583 - value_loss: 0.5835 - policy_loss: 1.5932 - val_loss: 3.8765 - val_value_loss: 0.5951 - val_policy_loss: 1.6187\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8503 - value_loss: 0.5686 - policy_loss: 1.5931 - val_loss: 3.8741 - val_value_loss: 0.5913 - val_policy_loss: 1.6187\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8440 - value_loss: 0.5574 - policy_loss: 1.5930 - val_loss: 3.8722 - val_value_loss: 0.5887 - val_policy_loss: 1.6186\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8386 - value_loss: 0.5478 - policy_loss: 1.5928 - val_loss: 3.8707 - val_value_loss: 0.5869 - val_policy_loss: 1.6186\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8345 - value_loss: 0.5409 - policy_loss: 1.5927 - val_loss: 3.8694 - val_value_loss: 0.5854 - val_policy_loss: 1.6186\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8299 - value_loss: 0.5327 - policy_loss: 1.5926 - val_loss: 3.8683 - val_value_loss: 0.5843 - val_policy_loss: 1.6186\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8263 - value_loss: 0.5270 - policy_loss: 1.5924 - val_loss: 3.8674 - val_value_loss: 0.5836 - val_policy_loss: 1.6185\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8226 - value_loss: 0.5207 - policy_loss: 1.5923 - val_loss: 3.8665 - val_value_loss: 0.5830 - val_policy_loss: 1.6185\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8192 - value_loss: 0.5151 - policy_loss: 1.5922 - val_loss: 3.8656 - val_value_loss: 0.5823 - val_policy_loss: 1.6185\n",
      "Saved model  tictactoe_lr_0_2_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.63 - draw ratio 0.09\n",
      "iteration 27 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 3.9044 - value_loss: 0.6831 - policy_loss: 1.5957 - val_loss: 3.8797 - val_value_loss: 0.6660 - val_policy_loss: 1.5640\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8936 - value_loss: 0.6630 - policy_loss: 1.5953 - val_loss: 3.8757 - val_value_loss: 0.6592 - val_policy_loss: 1.5639\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8849 - value_loss: 0.6470 - policy_loss: 1.5951 - val_loss: 3.8732 - val_value_loss: 0.6554 - val_policy_loss: 1.5638\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8784 - value_loss: 0.6351 - policy_loss: 1.5951 - val_loss: 3.8712 - val_value_loss: 0.6525 - val_policy_loss: 1.5638\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8731 - value_loss: 0.6257 - policy_loss: 1.5949 - val_loss: 3.8694 - val_value_loss: 0.6501 - val_policy_loss: 1.5638\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8704 - value_loss: 0.6215 - policy_loss: 1.5948 - val_loss: 3.8682 - val_value_loss: 0.6489 - val_policy_loss: 1.5637\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8649 - value_loss: 0.6117 - policy_loss: 1.5947 - val_loss: 3.8668 - val_value_loss: 0.6473 - val_policy_loss: 1.5636\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8610 - value_loss: 0.6050 - policy_loss: 1.5948 - val_loss: 3.8661 - val_value_loss: 0.6469 - val_policy_loss: 1.5637\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8579 - value_loss: 0.6003 - policy_loss: 1.5944 - val_loss: 3.8648 - val_value_loss: 0.6455 - val_policy_loss: 1.5636\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8556 - value_loss: 0.5966 - policy_loss: 1.5946 - val_loss: 3.8641 - val_value_loss: 0.6451 - val_policy_loss: 1.5636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_lr_0_2_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.65 - draw ratio 0.09\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 3.9041 - value_loss: 0.6950 - policy_loss: 1.5943 - val_loss: 3.8676 - val_value_loss: 0.6590 - val_policy_loss: 1.5579\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8944 - value_loss: 0.6770 - policy_loss: 1.5939 - val_loss: 3.8640 - val_value_loss: 0.6529 - val_policy_loss: 1.5579\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8881 - value_loss: 0.6657 - policy_loss: 1.5937 - val_loss: 3.8618 - val_value_loss: 0.6495 - val_policy_loss: 1.5579\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8834 - value_loss: 0.6575 - policy_loss: 1.5937 - val_loss: 3.8599 - val_value_loss: 0.6469 - val_policy_loss: 1.5579\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8790 - value_loss: 0.6499 - policy_loss: 1.5936 - val_loss: 3.8584 - val_value_loss: 0.6451 - val_policy_loss: 1.5578\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8753 - value_loss: 0.6439 - policy_loss: 1.5933 - val_loss: 3.8571 - val_value_loss: 0.6436 - val_policy_loss: 1.5578\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8709 - value_loss: 0.6363 - policy_loss: 1.5931 - val_loss: 3.8564 - val_value_loss: 0.6434 - val_policy_loss: 1.5578\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8678 - value_loss: 0.6315 - policy_loss: 1.5929 - val_loss: 3.8558 - val_value_loss: 0.6433 - val_policy_loss: 1.5577\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8655 - value_loss: 0.6279 - policy_loss: 1.5929 - val_loss: 3.8552 - val_value_loss: 0.6432 - val_policy_loss: 1.5577\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8631 - value_loss: 0.6243 - policy_loss: 1.5929 - val_loss: 3.8546 - val_value_loss: 0.6432 - val_policy_loss: 1.5576\n",
      "Saved model  tictactoe_lr_0_2_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.56 - draw ratio 0.05\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_2_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 3.8600 - value_loss: 0.6348 - policy_loss: 1.5774 - val_loss: 3.8548 - val_value_loss: 0.6580 - val_policy_loss: 1.5444\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8506 - value_loss: 0.6173 - policy_loss: 1.5770 - val_loss: 3.8505 - val_value_loss: 0.6504 - val_policy_loss: 1.5444\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8444 - value_loss: 0.6064 - policy_loss: 1.5767 - val_loss: 3.8476 - val_value_loss: 0.6457 - val_policy_loss: 1.5444\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8391 - value_loss: 0.5971 - policy_loss: 1.5765 - val_loss: 3.8447 - val_value_loss: 0.6410 - val_policy_loss: 1.5444\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8334 - value_loss: 0.5870 - policy_loss: 1.5762 - val_loss: 3.8428 - val_value_loss: 0.6383 - val_policy_loss: 1.5444\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8299 - value_loss: 0.5812 - policy_loss: 1.5762 - val_loss: 3.8409 - val_value_loss: 0.6355 - val_policy_loss: 1.5444\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 3.8268 - value_loss: 0.5761 - policy_loss: 1.5762 - val_loss: 3.8392 - val_value_loss: 0.6333 - val_policy_loss: 1.5445\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8239 - value_loss: 0.5715 - policy_loss: 1.5761 - val_loss: 3.8372 - val_value_loss: 0.6303 - val_policy_loss: 1.5445\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8215 - value_loss: 0.5680 - policy_loss: 1.5760 - val_loss: 3.8364 - val_value_loss: 0.6298 - val_policy_loss: 1.5444\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 3.8182 - value_loss: 0.5625 - policy_loss: 1.5758 - val_loss: 3.8353 - val_value_loss: 0.6288 - val_policy_loss: 1.5444\n",
      "Saved model  tictactoe_lr_0_2_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.65 - draw ratio 0.08\n"
     ]
    }
   ],
   "source": [
    "wins_1, draws_1 = test_pipeline.run(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - learning rate 0.2\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "losses_1 = np.ones(30) - wins_1 - draws_1\n",
    "# no_loss = np.zeros(50) + wins +draws\n",
    "\n",
    "plt.plot(x, wins_1, label=\"win ratio\")\n",
    "plt.plot(x, draws_1, label=\"draw ratio\")\n",
    "#plt.plot(x, no_loss, label=\"no loss ratio\")\n",
    "plt.plot(x, losses_1, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins_1 = [0.7, 0.79, 0.84, 0.9, 0.83, 0.75, 0.77, 0.8, 0.86, 0.81, 0.72, 0.85, 0.76, 0.72, 0.73, 0.74, 0.66, 0.78, 0.71, 0.78, 0.74, 0.67, 0.71, 0.73, 0.67, 0.77, 0.63, 0.65, 0.56, 0.65]\n",
      "draws_1 = [0.01, 0.0, 0.02, 0.0, 0.0, 0.02, 0.02, 0.01, 0.03, 0.03, 0.04, 0.0, 0.05, 0.05, 0.04, 0.02, 0.03, 0.03, 0.09, 0.03, 0.07, 0.1, 0.05, 0.08, 0.09, 0.02, 0.09, 0.09, 0.05, 0.08]\n",
      "losses_1 = [0.29 0.21 0.14 0.1  0.17 0.23 0.21 0.19 0.11 0.16 0.24 0.15 0.19 0.23\n",
      " 0.23 0.24 0.31 0.19 0.2  0.19 0.19 0.23 0.24 0.19 0.24 0.21 0.28 0.26\n",
      " 0.39 0.27]\n"
     ]
    }
   ],
   "source": [
    "print(\"wins_1 =\", wins_1)\n",
    "print(\"draws_1 =\", draws_1)\n",
    "print(\"losses_1 =\", losses_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learning rate 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCTS = {\n",
    "    'c_puct': 1.0,\n",
    "    'dir_alpha': 0.6,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 10,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 10\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 0,\n",
    "    'show_games': False\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.02,\n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 512,\n",
    "    'num_filters_value': 512,\n",
    "    'num_filters_tower': 512,\n",
    "    'num_residual_blocks': 3,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 512\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"tictactoe_lr_0_02\", \"TicTacToe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (4928, 3, 3, 3)\n",
      "model_y_outcomes: (4928,)\n",
      "model_y_probabilities: (4928, 9)\n",
      "Train on 3942 samples, validate on 986 samples\n",
      "Epoch 1/10\n",
      "3942/3942 [==============================] - 5s 1ms/step - loss: 7.4229 - value_loss: 1.4613 - policy_loss: 3.3020 - val_loss: 7.3672 - val_value_loss: 0.9624 - val_policy_loss: 3.6932\n",
      "Epoch 2/10\n",
      "3942/3942 [==============================] - 1s 174us/step - loss: 6.7429 - value_loss: 0.9173 - policy_loss: 2.4924 - val_loss: 6.6433 - val_value_loss: 0.9558 - val_policy_loss: 2.2583\n",
      "Epoch 3/10\n",
      "3942/3942 [==============================] - 1s 175us/step - loss: 6.4907 - value_loss: 0.8651 - policy_loss: 2.0466 - val_loss: 6.5399 - val_value_loss: 0.9490 - val_policy_loss: 2.0647\n",
      "Epoch 4/10\n",
      "3942/3942 [==============================] - 1s 176us/step - loss: 6.3721 - value_loss: 0.8135 - policy_loss: 1.8674 - val_loss: 6.4815 - val_value_loss: 0.9743 - val_policy_loss: 1.9288\n",
      "Epoch 5/10\n",
      "3942/3942 [==============================] - 1s 174us/step - loss: 6.3645 - value_loss: 0.8335 - policy_loss: 1.8385 - val_loss: 6.5067 - val_value_loss: 1.0151 - val_policy_loss: 1.9448\n",
      "Epoch 6/10\n",
      "3942/3942 [==============================] - 1s 173us/step - loss: 6.3298 - value_loss: 0.8001 - policy_loss: 1.8088 - val_loss: 6.4353 - val_value_loss: 0.9252 - val_policy_loss: 1.8983\n",
      "Epoch 7/10\n",
      "3942/3942 [==============================] - 1s 173us/step - loss: 6.3021 - value_loss: 0.7809 - policy_loss: 1.7790 - val_loss: 6.4144 - val_value_loss: 0.9801 - val_policy_loss: 1.8082\n",
      "Epoch 8/10\n",
      "3942/3942 [==============================] - 1s 174us/step - loss: 6.2426 - value_loss: 0.7372 - policy_loss: 1.7100 - val_loss: 6.3754 - val_value_loss: 0.9228 - val_policy_loss: 1.7939\n",
      "Epoch 9/10\n",
      "3942/3942 [==============================] - 1s 176us/step - loss: 6.2211 - value_loss: 0.7210 - policy_loss: 1.6897 - val_loss: 6.3592 - val_value_loss: 0.9186 - val_policy_loss: 1.7719\n",
      "Epoch 10/10\n",
      "3942/3942 [==============================] - 1s 176us/step - loss: 6.2255 - value_loss: 0.7349 - policy_loss: 1.6909 - val_loss: 6.3667 - val_value_loss: 0.9454 - val_policy_loss: 1.7665\n",
      "Saved model  tictactoe_lr_0_02_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.01\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 6.2817 - value_loss: 0.8534 - policy_loss: 1.6913 - val_loss: 6.2966 - val_value_loss: 0.8798 - val_policy_loss: 1.6984\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2390 - value_loss: 0.8100 - policy_loss: 1.6558 - val_loss: 6.2460 - val_value_loss: 0.7779 - val_policy_loss: 1.7054\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2225 - value_loss: 0.7810 - policy_loss: 1.6580 - val_loss: 6.2617 - val_value_loss: 0.7944 - val_policy_loss: 1.7266\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2024 - value_loss: 0.7617 - policy_loss: 1.6435 - val_loss: 6.2111 - val_value_loss: 0.7671 - val_policy_loss: 1.6591\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1797 - value_loss: 0.7534 - policy_loss: 1.6128 - val_loss: 6.2026 - val_value_loss: 0.7601 - val_policy_loss: 1.6556\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1741 - value_loss: 0.7481 - policy_loss: 1.6133 - val_loss: 6.2026 - val_value_loss: 0.7683 - val_policy_loss: 1.6536\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1665 - value_loss: 0.7470 - policy_loss: 1.6056 - val_loss: 6.1949 - val_value_loss: 0.7591 - val_policy_loss: 1.6539\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1617 - value_loss: 0.7453 - policy_loss: 1.6040 - val_loss: 6.1867 - val_value_loss: 0.7554 - val_policy_loss: 1.6476\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1639 - value_loss: 0.7489 - policy_loss: 1.6113 - val_loss: 6.1868 - val_value_loss: 0.7568 - val_policy_loss: 1.6527\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1558 - value_loss: 0.7487 - policy_loss: 1.6015 - val_loss: 6.1841 - val_value_loss: 0.7606 - val_policy_loss: 1.6499\n",
      "Saved model  tictactoe_lr_0_02_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.66 - draw ratio 0.02\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.2665 - value_loss: 0.9335 - policy_loss: 1.6445 - val_loss: 6.2370 - val_value_loss: 0.8968 - val_policy_loss: 1.6258\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2212 - value_loss: 0.8609 - policy_loss: 1.6328 - val_loss: 6.2377 - val_value_loss: 0.8806 - val_policy_loss: 1.6497\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2043 - value_loss: 0.8378 - policy_loss: 1.6285 - val_loss: 6.2144 - val_value_loss: 0.8717 - val_policy_loss: 1.6183\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1783 - value_loss: 0.8046 - policy_loss: 1.6159 - val_loss: 6.2130 - val_value_loss: 0.8747 - val_policy_loss: 1.6188\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1738 - value_loss: 0.8021 - policy_loss: 1.6159 - val_loss: 6.2000 - val_value_loss: 0.8602 - val_policy_loss: 1.6137\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1704 - value_loss: 0.8075 - policy_loss: 1.6100 - val_loss: 6.1970 - val_value_loss: 0.8639 - val_policy_loss: 1.6104\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1575 - value_loss: 0.7921 - policy_loss: 1.6059 - val_loss: 6.1946 - val_value_loss: 0.8751 - val_policy_loss: 1.6006\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1576 - value_loss: 0.8056 - policy_loss: 1.5989 - val_loss: 6.1827 - val_value_loss: 0.8562 - val_policy_loss: 1.6020\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1508 - value_loss: 0.7882 - policy_loss: 1.6091 - val_loss: 6.1829 - val_value_loss: 0.8549 - val_policy_loss: 1.6100\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1463 - value_loss: 0.7888 - policy_loss: 1.6057 - val_loss: 6.1781 - val_value_loss: 0.8604 - val_policy_loss: 1.6012\n",
      "Saved model  tictactoe_lr_0_02_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.6 - draw ratio 0.1\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2280 - value_loss: 0.9264 - policy_loss: 1.6379 - val_loss: 6.2447 - val_value_loss: 0.9536 - val_policy_loss: 1.6475\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2142 - value_loss: 0.9008 - policy_loss: 1.6421 - val_loss: 6.2393 - val_value_loss: 0.9495 - val_policy_loss: 1.6472\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1885 - value_loss: 0.8650 - policy_loss: 1.6328 - val_loss: 6.2290 - val_value_loss: 0.9441 - val_policy_loss: 1.6383\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1713 - value_loss: 0.8527 - policy_loss: 1.6170 - val_loss: 6.2209 - val_value_loss: 0.9429 - val_policy_loss: 1.6296\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1691 - value_loss: 0.8518 - policy_loss: 1.6200 - val_loss: 6.2143 - val_value_loss: 0.9352 - val_policy_loss: 1.6303\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1556 - value_loss: 0.8430 - policy_loss: 1.6080 - val_loss: 6.2076 - val_value_loss: 0.9386 - val_policy_loss: 1.6199\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1528 - value_loss: 0.8403 - policy_loss: 1.6113 - val_loss: 6.2091 - val_value_loss: 0.9408 - val_policy_loss: 1.6269\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1485 - value_loss: 0.8430 - policy_loss: 1.6063 - val_loss: 6.2034 - val_value_loss: 0.9433 - val_policy_loss: 1.6195\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1475 - value_loss: 0.8482 - policy_loss: 1.6053 - val_loss: 6.2032 - val_value_loss: 0.9399 - val_policy_loss: 1.6287\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1423 - value_loss: 0.8423 - policy_loss: 1.6072 - val_loss: 6.2022 - val_value_loss: 0.9513 - val_policy_loss: 1.6214\n",
      "Saved model  tictactoe_lr_0_02_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.68 - draw ratio 0.04\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1653 - value_loss: 0.8946 - policy_loss: 1.6071 - val_loss: 6.1533 - val_value_loss: 0.8845 - val_policy_loss: 1.5967\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1404 - value_loss: 0.8620 - policy_loss: 1.5962 - val_loss: 6.1456 - val_value_loss: 0.8731 - val_policy_loss: 1.5990\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1293 - value_loss: 0.8534 - policy_loss: 1.5889 - val_loss: 6.1347 - val_value_loss: 0.8637 - val_policy_loss: 1.5928\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1193 - value_loss: 0.8412 - policy_loss: 1.5873 - val_loss: 6.1332 - val_value_loss: 0.8636 - val_policy_loss: 1.5963\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1169 - value_loss: 0.8434 - policy_loss: 1.5865 - val_loss: 6.1348 - val_value_loss: 0.8783 - val_policy_loss: 1.5910\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1126 - value_loss: 0.8428 - policy_loss: 1.5849 - val_loss: 6.1246 - val_value_loss: 0.8641 - val_policy_loss: 1.5911\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1072 - value_loss: 0.8367 - policy_loss: 1.5863 - val_loss: 6.1267 - val_value_loss: 0.8757 - val_policy_loss: 1.5899\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1018 - value_loss: 0.8378 - policy_loss: 1.5808 - val_loss: 6.1216 - val_value_loss: 0.8707 - val_policy_loss: 1.5910\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0980 - value_loss: 0.8361 - policy_loss: 1.5810 - val_loss: 6.1130 - val_value_loss: 0.8670 - val_policy_loss: 1.5838\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0958 - value_loss: 0.8373 - policy_loss: 1.5818 - val_loss: 6.1149 - val_value_loss: 0.8714 - val_policy_loss: 1.5893\n",
      "Saved model  tictactoe_lr_0_02_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.69 - draw ratio 0.02\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1278 - value_loss: 0.8949 - policy_loss: 1.5930 - val_loss: 6.1674 - val_value_loss: 0.9625 - val_policy_loss: 1.6064\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1104 - value_loss: 0.8676 - policy_loss: 1.5887 - val_loss: 6.1629 - val_value_loss: 0.9573 - val_policy_loss: 1.6058\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1015 - value_loss: 0.8553 - policy_loss: 1.5863 - val_loss: 6.1577 - val_value_loss: 0.9505 - val_policy_loss: 1.6052\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0943 - value_loss: 0.8454 - policy_loss: 1.5850 - val_loss: 6.1570 - val_value_loss: 0.9535 - val_policy_loss: 1.6040\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0906 - value_loss: 0.8420 - policy_loss: 1.5840 - val_loss: 6.1544 - val_value_loss: 0.9513 - val_policy_loss: 1.6040\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0848 - value_loss: 0.8349 - policy_loss: 1.5827 - val_loss: 6.1560 - val_value_loss: 0.9565 - val_policy_loss: 1.6051\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0821 - value_loss: 0.8333 - policy_loss: 1.5819 - val_loss: 6.1523 - val_value_loss: 0.9541 - val_policy_loss: 1.6033\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0797 - value_loss: 0.8324 - policy_loss: 1.5812 - val_loss: 6.1512 - val_value_loss: 0.9547 - val_policy_loss: 1.6036\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0756 - value_loss: 0.8280 - policy_loss: 1.5806 - val_loss: 6.1530 - val_value_loss: 0.9621 - val_policy_loss: 1.6029\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0742 - value_loss: 0.8290 - policy_loss: 1.5798 - val_loss: 6.1491 - val_value_loss: 0.9578 - val_policy_loss: 1.6025\n",
      "Saved model  tictactoe_lr_0_02_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.03\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9962 - value_loss: 0.6763 - policy_loss: 1.5796 - val_loss: 6.0200 - val_value_loss: 0.7200 - val_policy_loss: 1.5851\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9828 - value_loss: 0.6559 - policy_loss: 1.5762 - val_loss: 6.0151 - val_value_loss: 0.7152 - val_policy_loss: 1.5834\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9737 - value_loss: 0.6432 - policy_loss: 1.5738 - val_loss: 6.0131 - val_value_loss: 0.7144 - val_policy_loss: 1.5833\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9682 - value_loss: 0.6366 - policy_loss: 1.5727 - val_loss: 6.0115 - val_value_loss: 0.7149 - val_policy_loss: 1.5826\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9652 - value_loss: 0.6347 - policy_loss: 1.5716 - val_loss: 6.0089 - val_value_loss: 0.7132 - val_policy_loss: 1.5823\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9621 - value_loss: 0.6321 - policy_loss: 1.5711 - val_loss: 6.0085 - val_value_loss: 0.7154 - val_policy_loss: 1.5823\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.9591 - value_loss: 0.6301 - policy_loss: 1.5701 - val_loss: 6.0074 - val_value_loss: 0.7159 - val_policy_loss: 1.5827\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9581 - value_loss: 0.6316 - policy_loss: 1.5698 - val_loss: 6.0053 - val_value_loss: 0.7160 - val_policy_loss: 1.5816\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9539 - value_loss: 0.6270 - policy_loss: 1.5692 - val_loss: 6.0033 - val_value_loss: 0.7156 - val_policy_loss: 1.5810\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9518 - value_loss: 0.6253 - policy_loss: 1.5696 - val_loss: 6.0019 - val_value_loss: 0.7159 - val_policy_loss: 1.5811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_lr_0_02_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.73 - draw ratio 0.04\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0405 - value_loss: 0.7785 - policy_loss: 1.5971 - val_loss: 5.9787 - val_value_loss: 0.6456 - val_policy_loss: 1.6081\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0244 - value_loss: 0.7524 - policy_loss: 1.5940 - val_loss: 5.9757 - val_value_loss: 0.6432 - val_policy_loss: 1.6076\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0154 - value_loss: 0.7389 - policy_loss: 1.5926 - val_loss: 5.9729 - val_value_loss: 0.6417 - val_policy_loss: 1.6065\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0076 - value_loss: 0.7282 - policy_loss: 1.5909 - val_loss: 5.9701 - val_value_loss: 0.6396 - val_policy_loss: 1.6062\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0019 - value_loss: 0.7210 - policy_loss: 1.5898 - val_loss: 5.9696 - val_value_loss: 0.6418 - val_policy_loss: 1.6060\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9977 - value_loss: 0.7159 - policy_loss: 1.5895 - val_loss: 5.9674 - val_value_loss: 0.6406 - val_policy_loss: 1.6059\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9942 - value_loss: 0.7129 - policy_loss: 1.5885 - val_loss: 5.9662 - val_value_loss: 0.6417 - val_policy_loss: 1.6055\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9925 - value_loss: 0.7135 - policy_loss: 1.5877 - val_loss: 5.9651 - val_value_loss: 0.6422 - val_policy_loss: 1.6058\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9892 - value_loss: 0.7103 - policy_loss: 1.5875 - val_loss: 5.9622 - val_value_loss: 0.6403 - val_policy_loss: 1.6052\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9879 - value_loss: 0.7108 - policy_loss: 1.5874 - val_loss: 5.9613 - val_value_loss: 0.6418 - val_policy_loss: 1.6050\n",
      "Saved model  tictactoe_lr_0_02_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.62 - draw ratio 0.08\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.0525 - value_loss: 0.8485 - policy_loss: 1.5819 - val_loss: 6.0307 - val_value_loss: 0.8319 - val_policy_loss: 1.5568\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0354 - value_loss: 0.8205 - policy_loss: 1.5789 - val_loss: 6.0272 - val_value_loss: 0.8285 - val_policy_loss: 1.5563\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0270 - value_loss: 0.8076 - policy_loss: 1.5780 - val_loss: 6.0231 - val_value_loss: 0.8243 - val_policy_loss: 1.5553\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0202 - value_loss: 0.7992 - policy_loss: 1.5759 - val_loss: 6.0244 - val_value_loss: 0.8299 - val_policy_loss: 1.5555\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0172 - value_loss: 0.7971 - policy_loss: 1.5752 - val_loss: 6.0214 - val_value_loss: 0.8272 - val_policy_loss: 1.5551\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0137 - value_loss: 0.7942 - policy_loss: 1.5742 - val_loss: 6.0215 - val_value_loss: 0.8304 - val_policy_loss: 1.5553\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0107 - value_loss: 0.7919 - policy_loss: 1.5735 - val_loss: 6.0195 - val_value_loss: 0.8300 - val_policy_loss: 1.5547\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0074 - value_loss: 0.7886 - policy_loss: 1.5732 - val_loss: 6.0186 - val_value_loss: 0.8315 - val_policy_loss: 1.5544\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0055 - value_loss: 0.7881 - policy_loss: 1.5730 - val_loss: 6.0173 - val_value_loss: 0.8323 - val_policy_loss: 1.5542\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0045 - value_loss: 0.7897 - policy_loss: 1.5726 - val_loss: 6.0163 - val_value_loss: 0.8330 - val_policy_loss: 1.5547\n",
      "Saved model  tictactoe_lr_0_02_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.05\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0806 - value_loss: 0.9229 - policy_loss: 1.5946 - val_loss: 6.0216 - val_value_loss: 0.8004 - val_policy_loss: 1.6008\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0590 - value_loss: 0.8854 - policy_loss: 1.5921 - val_loss: 6.0193 - val_value_loss: 0.8000 - val_policy_loss: 1.5997\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0469 - value_loss: 0.8660 - policy_loss: 1.5902 - val_loss: 6.0165 - val_value_loss: 0.7970 - val_policy_loss: 1.6002\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0405 - value_loss: 0.8575 - policy_loss: 1.5891 - val_loss: 6.0150 - val_value_loss: 0.7979 - val_policy_loss: 1.5995\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0365 - value_loss: 0.8528 - policy_loss: 1.5887 - val_loss: 6.0131 - val_value_loss: 0.7971 - val_policy_loss: 1.5994\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0330 - value_loss: 0.8500 - policy_loss: 1.5877 - val_loss: 6.0141 - val_value_loss: 0.8022 - val_policy_loss: 1.5995\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0297 - value_loss: 0.8470 - policy_loss: 1.5871 - val_loss: 6.0144 - val_value_loss: 0.8068 - val_policy_loss: 1.5986\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0257 - value_loss: 0.8422 - policy_loss: 1.5870 - val_loss: 6.0141 - val_value_loss: 0.8087 - val_policy_loss: 1.5990\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0249 - value_loss: 0.8437 - policy_loss: 1.5871 - val_loss: 6.0120 - val_value_loss: 0.8076 - val_policy_loss: 1.5990\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0218 - value_loss: 0.8416 - policy_loss: 1.5861 - val_loss: 6.0116 - val_value_loss: 0.8100 - val_policy_loss: 1.5989\n",
      "Saved model  tictactoe_lr_0_02_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.03\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.0577 - value_loss: 0.8965 - policy_loss: 1.6053 - val_loss: 5.9860 - val_value_loss: 0.7936 - val_policy_loss: 1.5657\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0428 - value_loss: 0.8701 - policy_loss: 1.6034 - val_loss: 5.9830 - val_value_loss: 0.7902 - val_policy_loss: 1.5646\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0345 - value_loss: 0.8559 - policy_loss: 1.6027 - val_loss: 5.9814 - val_value_loss: 0.7883 - val_policy_loss: 1.5648\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0275 - value_loss: 0.8453 - policy_loss: 1.6007 - val_loss: 5.9811 - val_value_loss: 0.7893 - val_policy_loss: 1.5649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0245 - value_loss: 0.8412 - policy_loss: 1.6004 - val_loss: 5.9808 - val_value_loss: 0.7905 - val_policy_loss: 1.5646\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0213 - value_loss: 0.8373 - policy_loss: 1.5995 - val_loss: 5.9804 - val_value_loss: 0.7918 - val_policy_loss: 1.5640\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0184 - value_loss: 0.8335 - policy_loss: 1.5990 - val_loss: 5.9806 - val_value_loss: 0.7935 - val_policy_loss: 1.5642\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0164 - value_loss: 0.8318 - policy_loss: 1.5983 - val_loss: 5.9809 - val_value_loss: 0.7956 - val_policy_loss: 1.5643\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0146 - value_loss: 0.8300 - policy_loss: 1.5980 - val_loss: 5.9804 - val_value_loss: 0.7965 - val_policy_loss: 1.5639\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0126 - value_loss: 0.8273 - policy_loss: 1.5981 - val_loss: 5.9806 - val_value_loss: 0.7982 - val_policy_loss: 1.5642\n",
      "Saved model  tictactoe_lr_0_02_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.73 - draw ratio 0.03\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0976 - value_loss: 1.0056 - policy_loss: 1.5914 - val_loss: 6.0536 - val_value_loss: 0.9043 - val_policy_loss: 1.6057\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0824 - value_loss: 0.9790 - policy_loss: 1.5891 - val_loss: 6.0487 - val_value_loss: 0.8964 - val_policy_loss: 1.6052\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0733 - value_loss: 0.9631 - policy_loss: 1.5884 - val_loss: 6.0451 - val_value_loss: 0.8909 - val_policy_loss: 1.6050\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0679 - value_loss: 0.9550 - policy_loss: 1.5872 - val_loss: 6.0430 - val_value_loss: 0.8883 - val_policy_loss: 1.6049\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0642 - value_loss: 0.9496 - policy_loss: 1.5866 - val_loss: 6.0409 - val_value_loss: 0.8856 - val_policy_loss: 1.6049\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0610 - value_loss: 0.9450 - policy_loss: 1.5865 - val_loss: 6.0398 - val_value_loss: 0.8852 - val_policy_loss: 1.6047\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0575 - value_loss: 0.9400 - policy_loss: 1.5859 - val_loss: 6.0384 - val_value_loss: 0.8842 - val_policy_loss: 1.6044\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0559 - value_loss: 0.9389 - policy_loss: 1.5854 - val_loss: 6.0372 - val_value_loss: 0.8834 - val_policy_loss: 1.6044\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0532 - value_loss: 0.9353 - policy_loss: 1.5851 - val_loss: 6.0368 - val_value_loss: 0.8842 - val_policy_loss: 1.6043\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0503 - value_loss: 0.9316 - policy_loss: 1.5846 - val_loss: 6.0345 - val_value_loss: 0.8815 - val_policy_loss: 1.6040\n",
      "Saved model  tictactoe_lr_0_02_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.71 - draw ratio 0.06\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0102 - value_loss: 0.8711 - policy_loss: 1.5664 - val_loss: 6.0641 - val_value_loss: 0.9495 - val_policy_loss: 1.5967\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9990 - value_loss: 0.8522 - policy_loss: 1.5644 - val_loss: 6.0586 - val_value_loss: 0.9405 - val_policy_loss: 1.5963\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9918 - value_loss: 0.8402 - policy_loss: 1.5635 - val_loss: 6.0549 - val_value_loss: 0.9347 - val_policy_loss: 1.5961\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9865 - value_loss: 0.8320 - policy_loss: 1.5627 - val_loss: 6.0514 - val_value_loss: 0.9298 - val_policy_loss: 1.5955\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9815 - value_loss: 0.8244 - policy_loss: 1.5618 - val_loss: 6.0502 - val_value_loss: 0.9290 - val_policy_loss: 1.5955\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9786 - value_loss: 0.8209 - policy_loss: 1.5611 - val_loss: 6.0473 - val_value_loss: 0.9251 - val_policy_loss: 1.5952\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9764 - value_loss: 0.8183 - policy_loss: 1.5607 - val_loss: 6.0461 - val_value_loss: 0.9239 - val_policy_loss: 1.5953\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9743 - value_loss: 0.8163 - policy_loss: 1.5601 - val_loss: 6.0447 - val_value_loss: 0.9226 - val_policy_loss: 1.5955\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9729 - value_loss: 0.8150 - policy_loss: 1.5600 - val_loss: 6.0431 - val_value_loss: 0.9216 - val_policy_loss: 1.5949\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9708 - value_loss: 0.8129 - policy_loss: 1.5596 - val_loss: 6.0418 - val_value_loss: 0.9207 - val_policy_loss: 1.5947\n",
      "Saved model  tictactoe_lr_0_02_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.77 - draw ratio 0.01\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.9785 - value_loss: 0.8272 - policy_loss: 1.5622 - val_loss: 5.9831 - val_value_loss: 0.8321 - val_policy_loss: 1.5673\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9674 - value_loss: 0.8083 - policy_loss: 1.5604 - val_loss: 5.9789 - val_value_loss: 0.8255 - val_policy_loss: 1.5671\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9603 - value_loss: 0.7962 - policy_loss: 1.5599 - val_loss: 5.9769 - val_value_loss: 0.8228 - val_policy_loss: 1.5673\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9559 - value_loss: 0.7897 - policy_loss: 1.5591 - val_loss: 5.9754 - val_value_loss: 0.8215 - val_policy_loss: 1.5671\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9517 - value_loss: 0.7833 - policy_loss: 1.5586 - val_loss: 5.9732 - val_value_loss: 0.8186 - val_policy_loss: 1.5671\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9489 - value_loss: 0.7798 - policy_loss: 1.5580 - val_loss: 5.9711 - val_value_loss: 0.8161 - val_policy_loss: 1.5670\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9474 - value_loss: 0.7788 - policy_loss: 1.5575 - val_loss: 5.9695 - val_value_loss: 0.8142 - val_policy_loss: 1.5671\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9449 - value_loss: 0.7757 - policy_loss: 1.5572 - val_loss: 5.9687 - val_value_loss: 0.8142 - val_policy_loss: 1.5671\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9429 - value_loss: 0.7736 - policy_loss: 1.5568 - val_loss: 5.9683 - val_value_loss: 0.8151 - val_policy_loss: 1.5669\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9413 - value_loss: 0.7723 - policy_loss: 1.5564 - val_loss: 5.9670 - val_value_loss: 0.8144 - val_policy_loss: 1.5667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_lr_0_02_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.03\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.0093 - value_loss: 0.8775 - policy_loss: 1.5887 - val_loss: 5.9936 - val_value_loss: 0.8685 - val_policy_loss: 1.5672\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9966 - value_loss: 0.8551 - policy_loss: 1.5872 - val_loss: 5.9901 - val_value_loss: 0.8627 - val_policy_loss: 1.5676\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9906 - value_loss: 0.8459 - policy_loss: 1.5861 - val_loss: 5.9888 - val_value_loss: 0.8622 - val_policy_loss: 1.5669\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9868 - value_loss: 0.8402 - policy_loss: 1.5856 - val_loss: 5.9879 - val_value_loss: 0.8617 - val_policy_loss: 1.5671\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9837 - value_loss: 0.8360 - policy_loss: 1.5851 - val_loss: 5.9855 - val_value_loss: 0.8587 - val_policy_loss: 1.5669\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9808 - value_loss: 0.8321 - policy_loss: 1.5849 - val_loss: 5.9854 - val_value_loss: 0.8603 - val_policy_loss: 1.5667\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9791 - value_loss: 0.8309 - policy_loss: 1.5841 - val_loss: 5.9841 - val_value_loss: 0.8597 - val_policy_loss: 1.5661\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9780 - value_loss: 0.8300 - policy_loss: 1.5844 - val_loss: 5.9824 - val_value_loss: 0.8581 - val_policy_loss: 1.5660\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9748 - value_loss: 0.8257 - policy_loss: 1.5837 - val_loss: 5.9813 - val_value_loss: 0.8571 - val_policy_loss: 1.5663\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9734 - value_loss: 0.8247 - policy_loss: 1.5834 - val_loss: 5.9803 - val_value_loss: 0.8572 - val_policy_loss: 1.5657\n",
      "Saved model  tictactoe_lr_0_02_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.66 - draw ratio 0.02\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9891 - value_loss: 0.8773 - policy_loss: 1.5635 - val_loss: 5.9266 - val_value_loss: 0.7579 - val_policy_loss: 1.5582\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9817 - value_loss: 0.8644 - policy_loss: 1.5623 - val_loss: 5.9247 - val_value_loss: 0.7552 - val_policy_loss: 1.5580\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9771 - value_loss: 0.8568 - policy_loss: 1.5615 - val_loss: 5.9226 - val_value_loss: 0.7521 - val_policy_loss: 1.5577\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9733 - value_loss: 0.8507 - policy_loss: 1.5608 - val_loss: 5.9211 - val_value_loss: 0.7498 - val_policy_loss: 1.5576\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9703 - value_loss: 0.8458 - policy_loss: 1.5605 - val_loss: 5.9203 - val_value_loss: 0.7491 - val_policy_loss: 1.5575\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9679 - value_loss: 0.8420 - policy_loss: 1.5601 - val_loss: 5.9190 - val_value_loss: 0.7475 - val_policy_loss: 1.5574\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9659 - value_loss: 0.8389 - policy_loss: 1.5600 - val_loss: 5.9184 - val_value_loss: 0.7471 - val_policy_loss: 1.5574\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9639 - value_loss: 0.8361 - policy_loss: 1.5597 - val_loss: 5.9178 - val_value_loss: 0.7467 - val_policy_loss: 1.5572\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9621 - value_loss: 0.8337 - policy_loss: 1.5592 - val_loss: 5.9175 - val_value_loss: 0.7469 - val_policy_loss: 1.5571\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9605 - value_loss: 0.8312 - policy_loss: 1.5593 - val_loss: 5.9168 - val_value_loss: 0.7464 - val_policy_loss: 1.5571\n",
      "Saved model  tictactoe_lr_0_02_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.04\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.9971 - value_loss: 0.8692 - policy_loss: 1.5952 - val_loss: 5.9606 - val_value_loss: 0.8172 - val_policy_loss: 1.5745\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9886 - value_loss: 0.8539 - policy_loss: 1.5944 - val_loss: 5.9574 - val_value_loss: 0.8118 - val_policy_loss: 1.5743\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9822 - value_loss: 0.8426 - policy_loss: 1.5936 - val_loss: 5.9550 - val_value_loss: 0.8080 - val_policy_loss: 1.5742\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9772 - value_loss: 0.8340 - policy_loss: 1.5929 - val_loss: 5.9533 - val_value_loss: 0.8055 - val_policy_loss: 1.5741\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9730 - value_loss: 0.8266 - policy_loss: 1.5926 - val_loss: 5.9516 - val_value_loss: 0.8030 - val_policy_loss: 1.5739\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9689 - value_loss: 0.8197 - policy_loss: 1.5920 - val_loss: 5.9493 - val_value_loss: 0.7992 - val_policy_loss: 1.5739\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9621 - value_loss: 0.8070 - policy_loss: 1.5919 - val_loss: 5.9352 - val_value_loss: 0.7714 - val_policy_loss: 1.5741\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9425 - value_loss: 0.7687 - policy_loss: 1.5918 - val_loss: 5.9231 - val_value_loss: 0.7481 - val_policy_loss: 1.5741\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9381 - value_loss: 0.7609 - policy_loss: 1.5916 - val_loss: 5.9200 - val_value_loss: 0.7427 - val_policy_loss: 1.5741\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9370 - value_loss: 0.7592 - policy_loss: 1.5918 - val_loss: 5.9196 - val_value_loss: 0.7428 - val_policy_loss: 1.5739\n",
      "Saved model  tictactoe_lr_0_02_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.69 - draw ratio 0.02\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9744 - value_loss: 0.8314 - policy_loss: 1.5952 - val_loss: 5.9792 - val_value_loss: 0.8532 - val_policy_loss: 1.5835\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9697 - value_loss: 0.8239 - policy_loss: 1.5941 - val_loss: 5.9851 - val_value_loss: 0.8661 - val_policy_loss: 1.5832\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9632 - value_loss: 0.8125 - policy_loss: 1.5933 - val_loss: 5.9789 - val_value_loss: 0.8544 - val_policy_loss: 1.5831\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9611 - value_loss: 0.8091 - policy_loss: 1.5931 - val_loss: 5.9729 - val_value_loss: 0.8436 - val_policy_loss: 1.5827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9575 - value_loss: 0.8033 - policy_loss: 1.5926 - val_loss: 5.9763 - val_value_loss: 0.8514 - val_policy_loss: 1.5826\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9581 - value_loss: 0.8055 - policy_loss: 1.5923 - val_loss: 5.9720 - val_value_loss: 0.8434 - val_policy_loss: 1.5826\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9553 - value_loss: 0.8010 - policy_loss: 1.5921 - val_loss: 5.9756 - val_value_loss: 0.8515 - val_policy_loss: 1.5825\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9509 - value_loss: 0.7935 - policy_loss: 1.5915 - val_loss: 5.9757 - val_value_loss: 0.8526 - val_policy_loss: 1.5823\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9505 - value_loss: 0.7933 - policy_loss: 1.5917 - val_loss: 5.9836 - val_value_loss: 0.8693 - val_policy_loss: 1.5822\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9486 - value_loss: 0.7904 - policy_loss: 1.5914 - val_loss: 5.9719 - val_value_loss: 0.8469 - val_policy_loss: 1.5821\n",
      "Saved model  tictactoe_lr_0_02_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.77 - draw ratio 0.02\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 5.9128 - value_loss: 0.7553 - policy_loss: 1.5558 - val_loss: 5.9280 - val_value_loss: 0.7895 - val_policy_loss: 1.5524\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9043 - value_loss: 0.7404 - policy_loss: 1.5544 - val_loss: 5.9242 - val_value_loss: 0.7829 - val_policy_loss: 1.5520\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9003 - value_loss: 0.7340 - policy_loss: 1.5535 - val_loss: 5.9225 - val_value_loss: 0.7805 - val_policy_loss: 1.5519\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.8984 - value_loss: 0.7314 - policy_loss: 1.5531 - val_loss: 5.9207 - val_value_loss: 0.7779 - val_policy_loss: 1.5517\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.8942 - value_loss: 0.7247 - policy_loss: 1.5522 - val_loss: 5.9188 - val_value_loss: 0.7750 - val_policy_loss: 1.5514\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.8921 - value_loss: 0.7215 - policy_loss: 1.5520 - val_loss: 5.9184 - val_value_loss: 0.7751 - val_policy_loss: 1.5514\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.8901 - value_loss: 0.7187 - policy_loss: 1.5515 - val_loss: 5.9179 - val_value_loss: 0.7749 - val_policy_loss: 1.5513\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.8879 - value_loss: 0.7154 - policy_loss: 1.5511 - val_loss: 5.9160 - val_value_loss: 0.7720 - val_policy_loss: 1.5512\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.8876 - value_loss: 0.7158 - policy_loss: 1.5509 - val_loss: 5.9155 - val_value_loss: 0.7717 - val_policy_loss: 1.5512\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.8852 - value_loss: 0.7120 - policy_loss: 1.5506 - val_loss: 5.9152 - val_value_loss: 0.7720 - val_policy_loss: 1.5511\n",
      "Saved model  tictactoe_lr_0_02_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.02\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9062 - value_loss: 0.7315 - policy_loss: 1.5739 - val_loss: 5.8863 - val_value_loss: 0.7126 - val_policy_loss: 1.5534\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9005 - value_loss: 0.7221 - policy_loss: 1.5728 - val_loss: 5.8839 - val_value_loss: 0.7088 - val_policy_loss: 1.5532\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.8963 - value_loss: 0.7149 - policy_loss: 1.5723 - val_loss: 5.8819 - val_value_loss: 0.7055 - val_policy_loss: 1.5532\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.8939 - value_loss: 0.7116 - policy_loss: 1.5715 - val_loss: 5.8824 - val_value_loss: 0.7074 - val_policy_loss: 1.5531\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.8905 - value_loss: 0.7058 - policy_loss: 1.5712 - val_loss: 5.8804 - val_value_loss: 0.7043 - val_policy_loss: 1.5530\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.8882 - value_loss: 0.7023 - policy_loss: 1.5709 - val_loss: 5.8798 - val_value_loss: 0.7040 - val_policy_loss: 1.5528\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.8864 - value_loss: 0.6999 - policy_loss: 1.5704 - val_loss: 5.8791 - val_value_loss: 0.7034 - val_policy_loss: 1.5527\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.8841 - value_loss: 0.6963 - policy_loss: 1.5702 - val_loss: 5.8795 - val_value_loss: 0.7050 - val_policy_loss: 1.5528\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.8841 - value_loss: 0.6975 - policy_loss: 1.5697 - val_loss: 5.8783 - val_value_loss: 0.7034 - val_policy_loss: 1.5526\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.8817 - value_loss: 0.6936 - policy_loss: 1.5697 - val_loss: 5.8771 - val_value_loss: 0.7019 - val_policy_loss: 1.5527\n",
      "Saved model  tictactoe_lr_0_02_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.02\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.9516 - value_loss: 0.8163 - policy_loss: 1.5874 - val_loss: 5.9613 - val_value_loss: 0.8282 - val_policy_loss: 1.5951\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9472 - value_loss: 0.8088 - policy_loss: 1.5864 - val_loss: 5.9601 - val_value_loss: 0.8264 - val_policy_loss: 1.5949\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9420 - value_loss: 0.7993 - policy_loss: 1.5858 - val_loss: 5.9581 - val_value_loss: 0.8228 - val_policy_loss: 1.5947\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9388 - value_loss: 0.7936 - policy_loss: 1.5856 - val_loss: 5.9578 - val_value_loss: 0.8228 - val_policy_loss: 1.5946\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9357 - value_loss: 0.7878 - policy_loss: 1.5856 - val_loss: 5.9559 - val_value_loss: 0.8195 - val_policy_loss: 1.5945\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9322 - value_loss: 0.7818 - policy_loss: 1.5850 - val_loss: 5.9557 - val_value_loss: 0.8194 - val_policy_loss: 1.5945\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9303 - value_loss: 0.7785 - policy_loss: 1.5848 - val_loss: 5.9551 - val_value_loss: 0.8188 - val_policy_loss: 1.5944\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9283 - value_loss: 0.7751 - policy_loss: 1.5845 - val_loss: 5.9563 - val_value_loss: 0.8215 - val_policy_loss: 1.5943\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9265 - value_loss: 0.7723 - policy_loss: 1.5843 - val_loss: 5.9566 - val_value_loss: 0.8225 - val_policy_loss: 1.5943\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9248 - value_loss: 0.7695 - policy_loss: 1.5840 - val_loss: 5.9557 - val_value_loss: 0.8212 - val_policy_loss: 1.5943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_lr_0_02_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.01\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.9722 - value_loss: 0.8466 - policy_loss: 1.6021 - val_loss: 5.9809 - val_value_loss: 0.8795 - val_policy_loss: 1.5867\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9670 - value_loss: 0.8374 - policy_loss: 1.6012 - val_loss: 5.9815 - val_value_loss: 0.8813 - val_policy_loss: 1.5865\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9637 - value_loss: 0.8313 - policy_loss: 1.6011 - val_loss: 5.9792 - val_value_loss: 0.8773 - val_policy_loss: 1.5863\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9607 - value_loss: 0.8264 - policy_loss: 1.6004 - val_loss: 5.9789 - val_value_loss: 0.8772 - val_policy_loss: 1.5862\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9578 - value_loss: 0.8215 - policy_loss: 1.5999 - val_loss: 5.9787 - val_value_loss: 0.8773 - val_policy_loss: 1.5861\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9561 - value_loss: 0.8183 - policy_loss: 1.6000 - val_loss: 5.9786 - val_value_loss: 0.8774 - val_policy_loss: 1.5860\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9538 - value_loss: 0.8147 - policy_loss: 1.5995 - val_loss: 5.9784 - val_value_loss: 0.8775 - val_policy_loss: 1.5860\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9531 - value_loss: 0.8139 - policy_loss: 1.5993 - val_loss: 5.9795 - val_value_loss: 0.8801 - val_policy_loss: 1.5860\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9506 - value_loss: 0.8094 - policy_loss: 1.5991 - val_loss: 5.9787 - val_value_loss: 0.8790 - val_policy_loss: 1.5859\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9498 - value_loss: 0.8082 - policy_loss: 1.5990 - val_loss: 5.9780 - val_value_loss: 0.8781 - val_policy_loss: 1.5858\n",
      "Saved model  tictactoe_lr_0_02_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.03\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9766 - value_loss: 0.8852 - policy_loss: 1.5760 - val_loss: 5.9757 - val_value_loss: 0.8919 - val_policy_loss: 1.5679\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9711 - value_loss: 0.8751 - policy_loss: 1.5755 - val_loss: 5.9742 - val_value_loss: 0.8891 - val_policy_loss: 1.5678\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9681 - value_loss: 0.8696 - policy_loss: 1.5754 - val_loss: 5.9728 - val_value_loss: 0.8869 - val_policy_loss: 1.5677\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9642 - value_loss: 0.8629 - policy_loss: 1.5747 - val_loss: 5.9720 - val_value_loss: 0.8858 - val_policy_loss: 1.5677\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9613 - value_loss: 0.8577 - policy_loss: 1.5745 - val_loss: 5.9711 - val_value_loss: 0.8843 - val_policy_loss: 1.5676\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9600 - value_loss: 0.8557 - policy_loss: 1.5742 - val_loss: 5.9704 - val_value_loss: 0.8835 - val_policy_loss: 1.5675\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9574 - value_loss: 0.8512 - policy_loss: 1.5739 - val_loss: 5.9702 - val_value_loss: 0.8834 - val_policy_loss: 1.5675\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9554 - value_loss: 0.8476 - policy_loss: 1.5740 - val_loss: 5.9695 - val_value_loss: 0.8824 - val_policy_loss: 1.5675\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9541 - value_loss: 0.8454 - policy_loss: 1.5739 - val_loss: 5.9691 - val_value_loss: 0.8821 - val_policy_loss: 1.5675\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9525 - value_loss: 0.8426 - policy_loss: 1.5738 - val_loss: 5.9688 - val_value_loss: 0.8819 - val_policy_loss: 1.5674\n",
      "Saved model  tictactoe_lr_0_02_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.03\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9687 - value_loss: 0.8820 - policy_loss: 1.5673 - val_loss: 6.0079 - val_value_loss: 0.9484 - val_policy_loss: 1.5794\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9643 - value_loss: 0.8741 - policy_loss: 1.5667 - val_loss: 6.0081 - val_value_loss: 0.9493 - val_policy_loss: 1.5792\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9599 - value_loss: 0.8659 - policy_loss: 1.5665 - val_loss: 6.0051 - val_value_loss: 0.9439 - val_policy_loss: 1.5791\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9580 - value_loss: 0.8623 - policy_loss: 1.5667 - val_loss: 6.0085 - val_value_loss: 0.9513 - val_policy_loss: 1.5790\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9551 - value_loss: 0.8575 - policy_loss: 1.5660 - val_loss: 6.0072 - val_value_loss: 0.9492 - val_policy_loss: 1.5788\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 5.9520 - value_loss: 0.8520 - policy_loss: 1.5657 - val_loss: 6.0054 - val_value_loss: 0.9460 - val_policy_loss: 1.5787\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9501 - value_loss: 0.8489 - policy_loss: 1.5654 - val_loss: 6.0035 - val_value_loss: 0.9426 - val_policy_loss: 1.5786\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9489 - value_loss: 0.8466 - policy_loss: 1.5657 - val_loss: 6.0037 - val_value_loss: 0.9435 - val_policy_loss: 1.5786\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 5.9470 - value_loss: 0.8434 - policy_loss: 1.5655 - val_loss: 6.0035 - val_value_loss: 0.9436 - val_policy_loss: 1.5785\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9449 - value_loss: 0.8401 - policy_loss: 1.5649 - val_loss: 6.0040 - val_value_loss: 0.9449 - val_policy_loss: 1.5785\n",
      "Saved model  tictactoe_lr_0_02_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.64 - draw ratio 0.06\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 5.9938 - value_loss: 0.9216 - policy_loss: 1.5817 - val_loss: 5.9641 - val_value_loss: 0.8732 - val_policy_loss: 1.5707\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9885 - value_loss: 0.9116 - policy_loss: 1.5813 - val_loss: 5.9612 - val_value_loss: 0.8681 - val_policy_loss: 1.5706\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9849 - value_loss: 0.9052 - policy_loss: 1.5810 - val_loss: 5.9624 - val_value_loss: 0.8709 - val_policy_loss: 1.5705\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9810 - value_loss: 0.8979 - policy_loss: 1.5810 - val_loss: 5.9602 - val_value_loss: 0.8669 - val_policy_loss: 1.5704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9776 - value_loss: 0.8917 - policy_loss: 1.5807 - val_loss: 5.9635 - val_value_loss: 0.8741 - val_policy_loss: 1.5704\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9767 - value_loss: 0.8906 - policy_loss: 1.5803 - val_loss: 5.9615 - val_value_loss: 0.8705 - val_policy_loss: 1.5703\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9733 - value_loss: 0.8840 - policy_loss: 1.5805 - val_loss: 5.9585 - val_value_loss: 0.8649 - val_policy_loss: 1.5703\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9718 - value_loss: 0.8817 - policy_loss: 1.5803 - val_loss: 5.9566 - val_value_loss: 0.8614 - val_policy_loss: 1.5703\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9701 - value_loss: 0.8788 - policy_loss: 1.5799 - val_loss: 5.9570 - val_value_loss: 0.8625 - val_policy_loss: 1.5703\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9685 - value_loss: 0.8761 - policy_loss: 1.5798 - val_loss: 5.9575 - val_value_loss: 0.8640 - val_policy_loss: 1.5702\n",
      "Saved model  tictactoe_lr_0_02_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.71 - draw ratio 0.09\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.9333 - value_loss: 0.8025 - policy_loss: 1.5834 - val_loss: 5.9208 - val_value_loss: 0.8023 - val_policy_loss: 1.5587\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9301 - value_loss: 0.7968 - policy_loss: 1.5830 - val_loss: 5.9197 - val_value_loss: 0.8005 - val_policy_loss: 1.5586\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9279 - value_loss: 0.7926 - policy_loss: 1.5829 - val_loss: 5.9180 - val_value_loss: 0.7974 - val_policy_loss: 1.5585\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9264 - value_loss: 0.7902 - policy_loss: 1.5824 - val_loss: 5.9179 - val_value_loss: 0.7975 - val_policy_loss: 1.5584\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9247 - value_loss: 0.7872 - policy_loss: 1.5823 - val_loss: 5.9172 - val_value_loss: 0.7963 - val_policy_loss: 1.5583\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9232 - value_loss: 0.7846 - policy_loss: 1.5820 - val_loss: 5.9162 - val_value_loss: 0.7946 - val_policy_loss: 1.5582\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9220 - value_loss: 0.7824 - policy_loss: 1.5821 - val_loss: 5.9156 - val_value_loss: 0.7937 - val_policy_loss: 1.5581\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9200 - value_loss: 0.7785 - policy_loss: 1.5822 - val_loss: 5.9155 - val_value_loss: 0.7936 - val_policy_loss: 1.5581\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9193 - value_loss: 0.7774 - policy_loss: 1.5819 - val_loss: 5.9156 - val_value_loss: 0.7941 - val_policy_loss: 1.5580\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9175 - value_loss: 0.7746 - policy_loss: 1.5814 - val_loss: 5.9146 - val_value_loss: 0.7923 - val_policy_loss: 1.5580\n",
      "Saved model  tictactoe_lr_0_02_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.66 - draw ratio 0.04\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.9537 - value_loss: 0.8540 - policy_loss: 1.5747 - val_loss: 5.9622 - val_value_loss: 0.8311 - val_policy_loss: 1.6147\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9512 - value_loss: 0.8499 - policy_loss: 1.5739 - val_loss: 5.9620 - val_value_loss: 0.8311 - val_policy_loss: 1.6145\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9489 - value_loss: 0.8461 - policy_loss: 1.5734 - val_loss: 5.9617 - val_value_loss: 0.8308 - val_policy_loss: 1.6144\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9476 - value_loss: 0.8436 - policy_loss: 1.5733 - val_loss: 5.9614 - val_value_loss: 0.8305 - val_policy_loss: 1.6143\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9458 - value_loss: 0.8409 - policy_loss: 1.5727 - val_loss: 5.9610 - val_value_loss: 0.8300 - val_policy_loss: 1.6142\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9443 - value_loss: 0.8383 - policy_loss: 1.5725 - val_loss: 5.9610 - val_value_loss: 0.8302 - val_policy_loss: 1.6141\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9430 - value_loss: 0.8356 - policy_loss: 1.5727 - val_loss: 5.9605 - val_value_loss: 0.8295 - val_policy_loss: 1.6140\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9421 - value_loss: 0.8344 - policy_loss: 1.5723 - val_loss: 5.9606 - val_value_loss: 0.8298 - val_policy_loss: 1.6140\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9410 - value_loss: 0.8325 - policy_loss: 1.5723 - val_loss: 5.9602 - val_value_loss: 0.8294 - val_policy_loss: 1.6139\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9394 - value_loss: 0.8296 - policy_loss: 1.5722 - val_loss: 5.9601 - val_value_loss: 0.8293 - val_policy_loss: 1.6139\n",
      "Saved model  tictactoe_lr_0_02_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.66 - draw ratio 0.05\n",
      "iteration 27 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 5.9560 - value_loss: 0.8615 - policy_loss: 1.5736 - val_loss: 5.9827 - val_value_loss: 0.8704 - val_policy_loss: 1.6182\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9535 - value_loss: 0.8573 - policy_loss: 1.5731 - val_loss: 5.9812 - val_value_loss: 0.8677 - val_policy_loss: 1.6181\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9516 - value_loss: 0.8534 - policy_loss: 1.5732 - val_loss: 5.9805 - val_value_loss: 0.8666 - val_policy_loss: 1.6180\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9499 - value_loss: 0.8507 - policy_loss: 1.5728 - val_loss: 5.9795 - val_value_loss: 0.8648 - val_policy_loss: 1.6180\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9483 - value_loss: 0.8477 - policy_loss: 1.5728 - val_loss: 5.9788 - val_value_loss: 0.8637 - val_policy_loss: 1.6179\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9469 - value_loss: 0.8453 - policy_loss: 1.5727 - val_loss: 5.9785 - val_value_loss: 0.8633 - val_policy_loss: 1.6178\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9454 - value_loss: 0.8427 - policy_loss: 1.5723 - val_loss: 5.9780 - val_value_loss: 0.8626 - val_policy_loss: 1.6177\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9440 - value_loss: 0.8402 - policy_loss: 1.5722 - val_loss: 5.9777 - val_value_loss: 0.8623 - val_policy_loss: 1.6177\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9430 - value_loss: 0.8383 - policy_loss: 1.5723 - val_loss: 5.9773 - val_value_loss: 0.8618 - val_policy_loss: 1.6176\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 5.9422 - value_loss: 0.8372 - policy_loss: 1.5719 - val_loss: 5.9766 - val_value_loss: 0.8606 - val_policy_loss: 1.6176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_lr_0_02_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.71 - draw ratio 0.03\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.9411 - value_loss: 0.8155 - policy_loss: 1.5917 - val_loss: 5.9060 - val_value_loss: 0.7563 - val_policy_loss: 1.5808\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9385 - value_loss: 0.8109 - policy_loss: 1.5914 - val_loss: 5.9046 - val_value_loss: 0.7537 - val_policy_loss: 1.5808\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9367 - value_loss: 0.8076 - policy_loss: 1.5912 - val_loss: 5.9042 - val_value_loss: 0.7531 - val_policy_loss: 1.5808\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9349 - value_loss: 0.8043 - policy_loss: 1.5910 - val_loss: 5.9036 - val_value_loss: 0.7520 - val_policy_loss: 1.5808\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9333 - value_loss: 0.8015 - policy_loss: 1.5909 - val_loss: 5.9022 - val_value_loss: 0.7495 - val_policy_loss: 1.5807\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9320 - value_loss: 0.7995 - policy_loss: 1.5906 - val_loss: 5.9022 - val_value_loss: 0.7497 - val_policy_loss: 1.5807\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9307 - value_loss: 0.7970 - policy_loss: 1.5906 - val_loss: 5.9008 - val_value_loss: 0.7473 - val_policy_loss: 1.5806\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9295 - value_loss: 0.7950 - policy_loss: 1.5904 - val_loss: 5.9011 - val_value_loss: 0.7481 - val_policy_loss: 1.5806\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9285 - value_loss: 0.7929 - policy_loss: 1.5907 - val_loss: 5.9007 - val_value_loss: 0.7475 - val_policy_loss: 1.5806\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9271 - value_loss: 0.7908 - policy_loss: 1.5901 - val_loss: 5.9010 - val_value_loss: 0.7484 - val_policy_loss: 1.5805\n",
      "Saved model  tictactoe_lr_0_02_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.03\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_02_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 5.9598 - value_loss: 0.8357 - policy_loss: 1.6108 - val_loss: 5.9674 - val_value_loss: 0.8792 - val_policy_loss: 1.5827\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9575 - value_loss: 0.8315 - policy_loss: 1.6106 - val_loss: 5.9666 - val_value_loss: 0.8777 - val_policy_loss: 1.5826\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9555 - value_loss: 0.8278 - policy_loss: 1.6104 - val_loss: 5.9654 - val_value_loss: 0.8756 - val_policy_loss: 1.5825\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9535 - value_loss: 0.8245 - policy_loss: 1.6100 - val_loss: 5.9647 - val_value_loss: 0.8745 - val_policy_loss: 1.5825\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9521 - value_loss: 0.8220 - policy_loss: 1.6099 - val_loss: 5.9632 - val_value_loss: 0.8717 - val_policy_loss: 1.5824\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9501 - value_loss: 0.8182 - policy_loss: 1.6099 - val_loss: 5.9623 - val_value_loss: 0.8701 - val_policy_loss: 1.5824\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9485 - value_loss: 0.8155 - policy_loss: 1.6096 - val_loss: 5.9613 - val_value_loss: 0.8683 - val_policy_loss: 1.5824\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9476 - value_loss: 0.8140 - policy_loss: 1.6095 - val_loss: 5.9604 - val_value_loss: 0.8668 - val_policy_loss: 1.5824\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 5.9469 - value_loss: 0.8125 - policy_loss: 1.6096 - val_loss: 5.9599 - val_value_loss: 0.8659 - val_policy_loss: 1.5823\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 5.9459 - value_loss: 0.8106 - policy_loss: 1.6099 - val_loss: 5.9595 - val_value_loss: 0.8653 - val_policy_loss: 1.5823\n",
      "Saved model  tictactoe_lr_0_02_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.04\n"
     ]
    }
   ],
   "source": [
    "wins_2, draws_2 = test_pipeline.run(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - learning rate 0.02\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "losses_2 = np.ones(30) - wins_2 - draws_2\n",
    "# no_loss = np.zeros(50) + wins +draws\n",
    "\n",
    "plt.plot(x, wins_2, label=\"win ratio\")\n",
    "plt.plot(x, draws_2, label=\"draw ratio\")\n",
    "#plt.plot(x, no_loss, label=\"no loss ratio\")\n",
    "plt.plot(x, losses_2, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins_2 = [0.8, 0.66, 0.6, 0.68, 0.69, 0.78, 0.73, 0.62, 0.79, 0.76, 0.73, 0.71, 0.77, 0.7, 0.66, 0.76, 0.69, 0.77, 0.7, 0.88, 0.79, 0.82, 0.7, 0.64, 0.71, 0.66, 0.66, 0.71, 0.8, 0.76]\n",
      "draws_2 = [0.01, 0.02, 0.1, 0.04, 0.02, 0.03, 0.04, 0.08, 0.05, 0.03, 0.03, 0.06, 0.01, 0.03, 0.02, 0.04, 0.02, 0.02, 0.02, 0.02, 0.01, 0.03, 0.03, 0.06, 0.09, 0.04, 0.05, 0.03, 0.03, 0.04]\n",
      "losses_2 = [0.19 0.32 0.3  0.28 0.29 0.19 0.23 0.3  0.16 0.21 0.24 0.23 0.22 0.27\n",
      " 0.32 0.2  0.29 0.21 0.28 0.1  0.2  0.15 0.27 0.3  0.2  0.3  0.29 0.26\n",
      " 0.17 0.2 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"wins_2 =\",wins_2)\n",
    "print(\"draws_2 =\",draws_2)\n",
    "print(\"losses_2 =\",losses_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learning rate 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCTS = {\n",
    "    'c_puct': 1.0,\n",
    "    'dir_alpha': 0.6,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 10,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 10\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 0,\n",
    "    'show_games': False\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.002,\n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 512,\n",
    "    'num_filters_value': 512,\n",
    "    'num_filters_tower': 512,\n",
    "    'num_residual_blocks': 3,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 512\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"tictactoe_lr_0_002\", \"TicTacToe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5056, 3, 3, 3)\n",
      "model_y_outcomes: (5056,)\n",
      "model_y_probabilities: (5056, 9)\n",
      "Train on 4044 samples, validate on 1012 samples\n",
      "Epoch 1/10\n",
      "4044/4044 [==============================] - 5s 1ms/step - loss: 6.6496 - value_loss: 0.8509 - policy_loss: 2.3654 - val_loss: 6.8887 - val_value_loss: 1.4779 - val_policy_loss: 2.2170\n",
      "Epoch 2/10\n",
      "4044/4044 [==============================] - 1s 174us/step - loss: 6.4779 - value_loss: 0.7282 - policy_loss: 2.1453 - val_loss: 6.7463 - val_value_loss: 1.2840 - val_policy_loss: 2.1266\n",
      "Epoch 3/10\n",
      "4044/4044 [==============================] - 1s 174us/step - loss: 6.3940 - value_loss: 0.6515 - policy_loss: 2.0548 - val_loss: 6.6695 - val_value_loss: 1.1934 - val_policy_loss: 2.0643\n",
      "Epoch 4/10\n",
      "4044/4044 [==============================] - 1s 173us/step - loss: 6.3459 - value_loss: 0.6200 - policy_loss: 1.9908 - val_loss: 6.6509 - val_value_loss: 1.2026 - val_policy_loss: 2.0186\n",
      "Epoch 5/10\n",
      "4044/4044 [==============================] - 1s 173us/step - loss: 6.2971 - value_loss: 0.5720 - policy_loss: 1.9418 - val_loss: 6.6079 - val_value_loss: 1.1540 - val_policy_loss: 1.9819\n",
      "Epoch 6/10\n",
      "4044/4044 [==============================] - 1s 173us/step - loss: 6.2691 - value_loss: 0.5544 - policy_loss: 1.9041 - val_loss: 6.5272 - val_value_loss: 1.0198 - val_policy_loss: 1.9552\n",
      "Epoch 7/10\n",
      "4044/4044 [==============================] - 1s 173us/step - loss: 6.2318 - value_loss: 0.5102 - policy_loss: 1.8744 - val_loss: 6.6110 - val_value_loss: 1.2119 - val_policy_loss: 1.9314\n",
      "Epoch 8/10\n",
      "4044/4044 [==============================] - 1s 173us/step - loss: 6.2277 - value_loss: 0.5280 - policy_loss: 1.8490 - val_loss: 6.5168 - val_value_loss: 1.0462 - val_policy_loss: 1.9094\n",
      "Epoch 9/10\n",
      "4044/4044 [==============================] - 1s 173us/step - loss: 6.2047 - value_loss: 0.5042 - policy_loss: 1.8273 - val_loss: 6.5284 - val_value_loss: 1.0870 - val_policy_loss: 1.8924\n",
      "Epoch 10/10\n",
      "4044/4044 [==============================] - 1s 173us/step - loss: 6.1930 - value_loss: 0.4994 - policy_loss: 1.8094 - val_loss: 6.4574 - val_value_loss: 0.9605 - val_policy_loss: 1.8776\n",
      "Saved model  tictactoe_lr_0_002_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.06\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2608 - value_loss: 0.6303 - policy_loss: 1.8148 - val_loss: 6.2241 - val_value_loss: 0.5705 - val_policy_loss: 1.8016\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2056 - value_loss: 0.5452 - policy_loss: 1.7902 - val_loss: 6.2370 - val_value_loss: 0.6096 - val_policy_loss: 1.7888\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1949 - value_loss: 0.5432 - policy_loss: 1.7713 - val_loss: 6.2124 - val_value_loss: 0.5720 - val_policy_loss: 1.7780\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1696 - value_loss: 0.5094 - policy_loss: 1.7551 - val_loss: 6.2252 - val_value_loss: 0.6070 - val_policy_loss: 1.7692\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1746 - value_loss: 0.5343 - policy_loss: 1.7410 - val_loss: 6.2021 - val_value_loss: 0.5700 - val_policy_loss: 1.7606\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1538 - value_loss: 0.5057 - policy_loss: 1.7286 - val_loss: 6.1957 - val_value_loss: 0.5658 - val_policy_loss: 1.7526\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1337 - value_loss: 0.4766 - policy_loss: 1.7181 - val_loss: 6.1766 - val_value_loss: 0.5353 - val_policy_loss: 1.7455\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1186 - value_loss: 0.4557 - policy_loss: 1.7093 - val_loss: 6.2113 - val_value_loss: 0.6103 - val_policy_loss: 1.7406\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1220 - value_loss: 0.4711 - policy_loss: 1.7015 - val_loss: 6.1614 - val_value_loss: 0.5180 - val_policy_loss: 1.7339\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1168 - value_loss: 0.4686 - policy_loss: 1.6943 - val_loss: 6.1769 - val_value_loss: 0.5546 - val_policy_loss: 1.7287\n",
      "Saved model  tictactoe_lr_0_002_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.03\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1999 - value_loss: 0.6159 - policy_loss: 1.7138 - val_loss: 6.2156 - val_value_loss: 0.6161 - val_policy_loss: 1.7454\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1587 - value_loss: 0.5506 - policy_loss: 1.6973 - val_loss: 6.1945 - val_value_loss: 0.5837 - val_policy_loss: 1.7363\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1500 - value_loss: 0.5441 - policy_loss: 1.6870 - val_loss: 6.1971 - val_value_loss: 0.5970 - val_policy_loss: 1.7287\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1264 - value_loss: 0.5084 - policy_loss: 1.6762 - val_loss: 6.1724 - val_value_loss: 0.5548 - val_policy_loss: 1.7221\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1042 - value_loss: 0.4727 - policy_loss: 1.6681 - val_loss: 6.1835 - val_value_loss: 0.5832 - val_policy_loss: 1.7166\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1009 - value_loss: 0.4759 - policy_loss: 1.6591 - val_loss: 6.1738 - val_value_loss: 0.5693 - val_policy_loss: 1.7118\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0964 - value_loss: 0.4736 - policy_loss: 1.6528 - val_loss: 6.1827 - val_value_loss: 0.5925 - val_policy_loss: 1.7070\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0856 - value_loss: 0.4587 - policy_loss: 1.6469 - val_loss: 6.1607 - val_value_loss: 0.5537 - val_policy_loss: 1.7024\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0690 - value_loss: 0.4313 - policy_loss: 1.6417 - val_loss: 6.1730 - val_value_loss: 0.5832 - val_policy_loss: 1.6982\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0801 - value_loss: 0.4597 - policy_loss: 1.6362 - val_loss: 6.1738 - val_value_loss: 0.5886 - val_policy_loss: 1.6949\n",
      "Saved model  tictactoe_lr_0_002_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.07\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2012 - value_loss: 0.6581 - policy_loss: 1.6806 - val_loss: 6.2004 - val_value_loss: 0.6480 - val_policy_loss: 1.6894\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1607 - value_loss: 0.5872 - policy_loss: 1.6711 - val_loss: 6.1939 - val_value_loss: 0.6396 - val_policy_loss: 1.6854\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1478 - value_loss: 0.5708 - policy_loss: 1.6624 - val_loss: 6.1954 - val_value_loss: 0.6473 - val_policy_loss: 1.6814\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1418 - value_loss: 0.5652 - policy_loss: 1.6566 - val_loss: 6.2524 - val_value_loss: 0.7650 - val_policy_loss: 1.6783\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1455 - value_loss: 0.5792 - policy_loss: 1.6507 - val_loss: 6.2056 - val_value_loss: 0.6754 - val_policy_loss: 1.6751\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1211 - value_loss: 0.5354 - policy_loss: 1.6463 - val_loss: 6.1740 - val_value_loss: 0.6162 - val_policy_loss: 1.6716\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0983 - value_loss: 0.4957 - policy_loss: 1.6410 - val_loss: 6.1769 - val_value_loss: 0.6257 - val_policy_loss: 1.6686\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0894 - value_loss: 0.4820 - policy_loss: 1.6375 - val_loss: 6.1755 - val_value_loss: 0.6255 - val_policy_loss: 1.6666\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0860 - value_loss: 0.4794 - policy_loss: 1.6339 - val_loss: 6.1778 - val_value_loss: 0.6337 - val_policy_loss: 1.6636\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0955 - value_loss: 0.5025 - policy_loss: 1.6304 - val_loss: 6.2089 - val_value_loss: 0.6986 - val_policy_loss: 1.6615\n",
      "Saved model  tictactoe_lr_0_002_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.89 - draw ratio 0.0\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1904 - value_loss: 0.6467 - policy_loss: 1.6768 - val_loss: 6.1429 - val_value_loss: 0.5731 - val_policy_loss: 1.6556\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1523 - value_loss: 0.5795 - policy_loss: 1.6684 - val_loss: 6.1471 - val_value_loss: 0.5851 - val_policy_loss: 1.6528\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1362 - value_loss: 0.5536 - policy_loss: 1.6626 - val_loss: 6.1517 - val_value_loss: 0.5970 - val_policy_loss: 1.6508\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1209 - value_loss: 0.5277 - policy_loss: 1.6587 - val_loss: 6.1504 - val_value_loss: 0.5968 - val_policy_loss: 1.6489\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1035 - value_loss: 0.4986 - policy_loss: 1.6537 - val_loss: 6.1350 - val_value_loss: 0.5697 - val_policy_loss: 1.6459\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0929 - value_loss: 0.4815 - policy_loss: 1.6501 - val_loss: 6.1274 - val_value_loss: 0.5571 - val_policy_loss: 1.6440\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0859 - value_loss: 0.4720 - policy_loss: 1.6463 - val_loss: 6.1158 - val_value_loss: 0.5365 - val_policy_loss: 1.6420\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0761 - value_loss: 0.4549 - policy_loss: 1.6444 - val_loss: 6.1136 - val_value_loss: 0.5342 - val_policy_loss: 1.6404\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0799 - value_loss: 0.4671 - policy_loss: 1.6406 - val_loss: 6.1198 - val_value_loss: 0.5493 - val_policy_loss: 1.6384\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0685 - value_loss: 0.4469 - policy_loss: 1.6385 - val_loss: 6.1177 - val_value_loss: 0.5473 - val_policy_loss: 1.6369\n",
      "Saved model  tictactoe_lr_0_002_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.03\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1722 - value_loss: 0.6376 - policy_loss: 1.6557 - val_loss: 6.1631 - val_value_loss: 0.6318 - val_policy_loss: 1.6436\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1471 - value_loss: 0.5915 - policy_loss: 1.6520 - val_loss: 6.1502 - val_value_loss: 0.6084 - val_policy_loss: 1.6413\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1332 - value_loss: 0.5667 - policy_loss: 1.6493 - val_loss: 6.1492 - val_value_loss: 0.6085 - val_policy_loss: 1.6397\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1217 - value_loss: 0.5463 - policy_loss: 1.6469 - val_loss: 6.1401 - val_value_loss: 0.5916 - val_policy_loss: 1.6385\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1129 - value_loss: 0.5319 - policy_loss: 1.6442 - val_loss: 6.1416 - val_value_loss: 0.5961 - val_policy_loss: 1.6374\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1064 - value_loss: 0.5214 - policy_loss: 1.6419 - val_loss: 6.1388 - val_value_loss: 0.5921 - val_policy_loss: 1.6360\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1011 - value_loss: 0.5128 - policy_loss: 1.6403 - val_loss: 6.1394 - val_value_loss: 0.5947 - val_policy_loss: 1.6350\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0973 - value_loss: 0.5070 - policy_loss: 1.6387 - val_loss: 6.1388 - val_value_loss: 0.5947 - val_policy_loss: 1.6342\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0951 - value_loss: 0.5045 - policy_loss: 1.6371 - val_loss: 6.1372 - val_value_loss: 0.5929 - val_policy_loss: 1.6332\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0917 - value_loss: 0.4999 - policy_loss: 1.6353 - val_loss: 6.1350 - val_value_loss: 0.5900 - val_policy_loss: 1.6320\n",
      "Saved model  tictactoe_lr_0_002_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.04\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1389 - value_loss: 0.5994 - policy_loss: 1.6305 - val_loss: 6.1807 - val_value_loss: 0.6382 - val_policy_loss: 1.6755\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1193 - value_loss: 0.5616 - policy_loss: 1.6294 - val_loss: 6.1774 - val_value_loss: 0.6326 - val_policy_loss: 1.6749\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1051 - value_loss: 0.5369 - policy_loss: 1.6261 - val_loss: 6.1748 - val_value_loss: 0.6286 - val_policy_loss: 1.6739\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0972 - value_loss: 0.5236 - policy_loss: 1.6239 - val_loss: 6.1760 - val_value_loss: 0.6319 - val_policy_loss: 1.6732\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0909 - value_loss: 0.5128 - policy_loss: 1.6224 - val_loss: 6.1709 - val_value_loss: 0.6228 - val_policy_loss: 1.6725\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0838 - value_loss: 0.5004 - policy_loss: 1.6209 - val_loss: 6.1694 - val_value_loss: 0.6210 - val_policy_loss: 1.6717\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0788 - value_loss: 0.4914 - policy_loss: 1.6201 - val_loss: 6.1693 - val_value_loss: 0.6217 - val_policy_loss: 1.6711\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0760 - value_loss: 0.4879 - policy_loss: 1.6185 - val_loss: 6.1668 - val_value_loss: 0.6177 - val_policy_loss: 1.6704\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0719 - value_loss: 0.4815 - policy_loss: 1.6169 - val_loss: 6.1667 - val_value_loss: 0.6184 - val_policy_loss: 1.6699\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0688 - value_loss: 0.4768 - policy_loss: 1.6158 - val_loss: 6.1657 - val_value_loss: 0.6173 - val_policy_loss: 1.6693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_lr_0_002_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.03\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1061 - value_loss: 0.5271 - policy_loss: 1.6405 - val_loss: 6.1272 - val_value_loss: 0.5659 - val_policy_loss: 1.6441\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0899 - value_loss: 0.4974 - policy_loss: 1.6379 - val_loss: 6.1257 - val_value_loss: 0.5643 - val_policy_loss: 1.6429\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0768 - value_loss: 0.4740 - policy_loss: 1.6355 - val_loss: 6.1189 - val_value_loss: 0.5520 - val_policy_loss: 1.6419\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0688 - value_loss: 0.4595 - policy_loss: 1.6343 - val_loss: 6.1185 - val_value_loss: 0.5521 - val_policy_loss: 1.6413\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0631 - value_loss: 0.4503 - policy_loss: 1.6325 - val_loss: 6.1167 - val_value_loss: 0.5497 - val_policy_loss: 1.6405\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0584 - value_loss: 0.4426 - policy_loss: 1.6310 - val_loss: 6.1186 - val_value_loss: 0.5545 - val_policy_loss: 1.6398\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0550 - value_loss: 0.4370 - policy_loss: 1.6303 - val_loss: 6.1174 - val_value_loss: 0.5532 - val_policy_loss: 1.6389\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0508 - value_loss: 0.4303 - policy_loss: 1.6287 - val_loss: 6.1120 - val_value_loss: 0.5436 - val_policy_loss: 1.6381\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0473 - value_loss: 0.4255 - policy_loss: 1.6269 - val_loss: 6.1147 - val_value_loss: 0.5499 - val_policy_loss: 1.6375\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0474 - value_loss: 0.4262 - policy_loss: 1.6268 - val_loss: 6.1094 - val_value_loss: 0.5401 - val_policy_loss: 1.6369\n",
      "Saved model  tictactoe_lr_0_002_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.03\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1010 - value_loss: 0.5447 - policy_loss: 1.6158 - val_loss: 6.1001 - val_value_loss: 0.5283 - val_policy_loss: 1.6305\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0823 - value_loss: 0.5105 - policy_loss: 1.6130 - val_loss: 6.0923 - val_value_loss: 0.5135 - val_policy_loss: 1.6300\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0694 - value_loss: 0.4864 - policy_loss: 1.6115 - val_loss: 6.0883 - val_value_loss: 0.5066 - val_policy_loss: 1.6293\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0625 - value_loss: 0.4741 - policy_loss: 1.6103 - val_loss: 6.0855 - val_value_loss: 0.5019 - val_policy_loss: 1.6288\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0550 - value_loss: 0.4609 - policy_loss: 1.6089 - val_loss: 6.0852 - val_value_loss: 0.5019 - val_policy_loss: 1.6283\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0511 - value_loss: 0.4545 - policy_loss: 1.6078 - val_loss: 6.0881 - val_value_loss: 0.5088 - val_policy_loss: 1.6277\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0469 - value_loss: 0.4482 - policy_loss: 1.6061 - val_loss: 6.0854 - val_value_loss: 0.5041 - val_policy_loss: 1.6272\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0446 - value_loss: 0.4451 - policy_loss: 1.6049 - val_loss: 6.0847 - val_value_loss: 0.5036 - val_policy_loss: 1.6267\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0403 - value_loss: 0.4373 - policy_loss: 1.6042 - val_loss: 6.0854 - val_value_loss: 0.5058 - val_policy_loss: 1.6262\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0396 - value_loss: 0.4375 - policy_loss: 1.6031 - val_loss: 6.0842 - val_value_loss: 0.5042 - val_policy_loss: 1.6256\n",
      "Saved model  tictactoe_lr_0_002_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.01\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0888 - value_loss: 0.5140 - policy_loss: 1.6253 - val_loss: 6.1201 - val_value_loss: 0.5412 - val_policy_loss: 1.6609\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0679 - value_loss: 0.4746 - policy_loss: 1.6232 - val_loss: 6.1255 - val_value_loss: 0.5537 - val_policy_loss: 1.6595\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0551 - value_loss: 0.4511 - policy_loss: 1.6215 - val_loss: 6.1152 - val_value_loss: 0.5342 - val_policy_loss: 1.6586\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0481 - value_loss: 0.4391 - policy_loss: 1.6197 - val_loss: 6.1143 - val_value_loss: 0.5338 - val_policy_loss: 1.6577\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0429 - value_loss: 0.4301 - policy_loss: 1.6186 - val_loss: 6.1115 - val_value_loss: 0.5290 - val_policy_loss: 1.6570\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0380 - value_loss: 0.4213 - policy_loss: 1.6179 - val_loss: 6.1104 - val_value_loss: 0.5278 - val_policy_loss: 1.6564\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0328 - value_loss: 0.4128 - policy_loss: 1.6163 - val_loss: 6.1048 - val_value_loss: 0.5175 - val_policy_loss: 1.6558\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0315 - value_loss: 0.4116 - policy_loss: 1.6154 - val_loss: 6.1072 - val_value_loss: 0.5232 - val_policy_loss: 1.6554\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0288 - value_loss: 0.4067 - policy_loss: 1.6150 - val_loss: 6.1056 - val_value_loss: 0.5211 - val_policy_loss: 1.6546\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0270 - value_loss: 0.4049 - policy_loss: 1.6137 - val_loss: 6.1047 - val_value_loss: 0.5200 - val_policy_loss: 1.6541\n",
      "Saved model  tictactoe_lr_0_002_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.0\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1024 - value_loss: 0.5407 - policy_loss: 1.6289 - val_loss: 6.0968 - val_value_loss: 0.5116 - val_policy_loss: 1.6468\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0907 - value_loss: 0.5190 - policy_loss: 1.6273 - val_loss: 6.0934 - val_value_loss: 0.5054 - val_policy_loss: 1.6464\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0848 - value_loss: 0.5082 - policy_loss: 1.6265 - val_loss: 6.0905 - val_value_loss: 0.5001 - val_policy_loss: 1.6460\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0794 - value_loss: 0.4980 - policy_loss: 1.6260 - val_loss: 6.0877 - val_value_loss: 0.4952 - val_policy_loss: 1.6456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0735 - value_loss: 0.4871 - policy_loss: 1.6254 - val_loss: 6.0861 - val_value_loss: 0.4924 - val_policy_loss: 1.6453\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0700 - value_loss: 0.4810 - policy_loss: 1.6245 - val_loss: 6.0850 - val_value_loss: 0.4908 - val_policy_loss: 1.6449\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0660 - value_loss: 0.4740 - policy_loss: 1.6238 - val_loss: 6.0838 - val_value_loss: 0.4887 - val_policy_loss: 1.6446\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0634 - value_loss: 0.4690 - policy_loss: 1.6237 - val_loss: 6.0835 - val_value_loss: 0.4886 - val_policy_loss: 1.6443\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0598 - value_loss: 0.4630 - policy_loss: 1.6226 - val_loss: 6.0819 - val_value_loss: 0.4859 - val_policy_loss: 1.6440\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0580 - value_loss: 0.4604 - policy_loss: 1.6217 - val_loss: 6.0817 - val_value_loss: 0.4859 - val_policy_loss: 1.6438\n",
      "Saved model  tictactoe_lr_0_002_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.01\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 6.1202 - value_loss: 0.5902 - policy_loss: 1.6165 - val_loss: 6.1257 - val_value_loss: 0.5596 - val_policy_loss: 1.6583\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1072 - value_loss: 0.5655 - policy_loss: 1.6155 - val_loss: 6.1225 - val_value_loss: 0.5540 - val_policy_loss: 1.6577\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0961 - value_loss: 0.5442 - policy_loss: 1.6147 - val_loss: 6.1208 - val_value_loss: 0.5512 - val_policy_loss: 1.6572\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0888 - value_loss: 0.5306 - policy_loss: 1.6139 - val_loss: 6.1207 - val_value_loss: 0.5514 - val_policy_loss: 1.6569\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0821 - value_loss: 0.5185 - policy_loss: 1.6127 - val_loss: 6.1208 - val_value_loss: 0.5521 - val_policy_loss: 1.6565\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0774 - value_loss: 0.5102 - policy_loss: 1.6119 - val_loss: 6.1200 - val_value_loss: 0.5511 - val_policy_loss: 1.6562\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.0737 - value_loss: 0.5034 - policy_loss: 1.6112 - val_loss: 6.1208 - val_value_loss: 0.5531 - val_policy_loss: 1.6559\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0705 - value_loss: 0.4976 - policy_loss: 1.6109 - val_loss: 6.1208 - val_value_loss: 0.5536 - val_policy_loss: 1.6557\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0694 - value_loss: 0.4964 - policy_loss: 1.6101 - val_loss: 6.1193 - val_value_loss: 0.5511 - val_policy_loss: 1.6553\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0658 - value_loss: 0.4901 - policy_loss: 1.6093 - val_loss: 6.1217 - val_value_loss: 0.5563 - val_policy_loss: 1.6551\n",
      "Saved model  tictactoe_lr_0_002_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.89 - draw ratio 0.01\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1126 - value_loss: 0.5821 - policy_loss: 1.6111 - val_loss: 6.1642 - val_value_loss: 0.6393 - val_policy_loss: 1.6572\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0962 - value_loss: 0.5510 - policy_loss: 1.6096 - val_loss: 6.1598 - val_value_loss: 0.6309 - val_policy_loss: 1.6568\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0862 - value_loss: 0.5319 - policy_loss: 1.6088 - val_loss: 6.1553 - val_value_loss: 0.6223 - val_policy_loss: 1.6566\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0813 - value_loss: 0.5233 - policy_loss: 1.6078 - val_loss: 6.1552 - val_value_loss: 0.6225 - val_policy_loss: 1.6564\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0741 - value_loss: 0.5098 - policy_loss: 1.6071 - val_loss: 6.1523 - val_value_loss: 0.6171 - val_policy_loss: 1.6562\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0695 - value_loss: 0.5014 - policy_loss: 1.6065 - val_loss: 6.1511 - val_value_loss: 0.6151 - val_policy_loss: 1.6560\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0656 - value_loss: 0.4941 - policy_loss: 1.6059 - val_loss: 6.1504 - val_value_loss: 0.6140 - val_policy_loss: 1.6558\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0620 - value_loss: 0.4877 - policy_loss: 1.6053 - val_loss: 6.1506 - val_value_loss: 0.6147 - val_policy_loss: 1.6556\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0585 - value_loss: 0.4823 - policy_loss: 1.6040 - val_loss: 6.1497 - val_value_loss: 0.6135 - val_policy_loss: 1.6553\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0574 - value_loss: 0.4806 - policy_loss: 1.6037 - val_loss: 6.1479 - val_value_loss: 0.6102 - val_policy_loss: 1.6551\n",
      "Saved model  tictactoe_lr_0_002_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.03\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1082 - value_loss: 0.5711 - policy_loss: 1.6150 - val_loss: 6.1217 - val_value_loss: 0.5777 - val_policy_loss: 1.6355\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0942 - value_loss: 0.5447 - policy_loss: 1.6135 - val_loss: 6.1180 - val_value_loss: 0.5710 - val_policy_loss: 1.6349\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0863 - value_loss: 0.5302 - policy_loss: 1.6123 - val_loss: 6.1157 - val_value_loss: 0.5672 - val_policy_loss: 1.6343\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0807 - value_loss: 0.5198 - policy_loss: 1.6117 - val_loss: 6.1156 - val_value_loss: 0.5675 - val_policy_loss: 1.6337\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0755 - value_loss: 0.5101 - policy_loss: 1.6111 - val_loss: 6.1160 - val_value_loss: 0.5690 - val_policy_loss: 1.6333\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0714 - value_loss: 0.5033 - policy_loss: 1.6100 - val_loss: 6.1130 - val_value_loss: 0.5636 - val_policy_loss: 1.6329\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0690 - value_loss: 0.4988 - policy_loss: 1.6098 - val_loss: 6.1130 - val_value_loss: 0.5641 - val_policy_loss: 1.6326\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0647 - value_loss: 0.4917 - policy_loss: 1.6083 - val_loss: 6.1119 - val_value_loss: 0.5623 - val_policy_loss: 1.6322\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0624 - value_loss: 0.4875 - policy_loss: 1.6081 - val_loss: 6.1113 - val_value_loss: 0.5618 - val_policy_loss: 1.6318\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0598 - value_loss: 0.4829 - policy_loss: 1.6078 - val_loss: 6.1105 - val_value_loss: 0.5607 - val_policy_loss: 1.6314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_lr_0_002_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.01\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1017 - value_loss: 0.5482 - policy_loss: 1.6264 - val_loss: 6.1074 - val_value_loss: 0.5679 - val_policy_loss: 1.6182\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0926 - value_loss: 0.5314 - policy_loss: 1.6252 - val_loss: 6.1047 - val_value_loss: 0.5632 - val_policy_loss: 1.6176\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0871 - value_loss: 0.5204 - policy_loss: 1.6253 - val_loss: 6.1021 - val_value_loss: 0.5587 - val_policy_loss: 1.6171\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0813 - value_loss: 0.5103 - policy_loss: 1.6239 - val_loss: 6.0999 - val_value_loss: 0.5548 - val_policy_loss: 1.6167\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0781 - value_loss: 0.5054 - policy_loss: 1.6226 - val_loss: 6.1015 - val_value_loss: 0.5585 - val_policy_loss: 1.6163\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0749 - value_loss: 0.4989 - policy_loss: 1.6230 - val_loss: 6.0988 - val_value_loss: 0.5538 - val_policy_loss: 1.6159\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0705 - value_loss: 0.4912 - policy_loss: 1.6220 - val_loss: 6.0971 - val_value_loss: 0.5508 - val_policy_loss: 1.6156\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0681 - value_loss: 0.4866 - policy_loss: 1.6218 - val_loss: 6.0977 - val_value_loss: 0.5526 - val_policy_loss: 1.6152\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0662 - value_loss: 0.4836 - policy_loss: 1.6212 - val_loss: 6.0983 - val_value_loss: 0.5542 - val_policy_loss: 1.6149\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0640 - value_loss: 0.4801 - policy_loss: 1.6206 - val_loss: 6.0969 - val_value_loss: 0.5520 - val_policy_loss: 1.6146\n",
      "Saved model  tictactoe_lr_0_002_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.0\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1294 - value_loss: 0.6270 - policy_loss: 1.6045 - val_loss: 6.0956 - val_value_loss: 0.5695 - val_policy_loss: 1.5944\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1175 - value_loss: 0.6039 - policy_loss: 1.6040 - val_loss: 6.0926 - val_value_loss: 0.5639 - val_policy_loss: 1.5942\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1100 - value_loss: 0.5898 - policy_loss: 1.6032 - val_loss: 6.0902 - val_value_loss: 0.5593 - val_policy_loss: 1.5941\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1045 - value_loss: 0.5786 - policy_loss: 1.6034 - val_loss: 6.0906 - val_value_loss: 0.5603 - val_policy_loss: 1.5939\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0996 - value_loss: 0.5696 - policy_loss: 1.6026 - val_loss: 6.0871 - val_value_loss: 0.5534 - val_policy_loss: 1.5938\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0958 - value_loss: 0.5629 - policy_loss: 1.6019 - val_loss: 6.0873 - val_value_loss: 0.5541 - val_policy_loss: 1.5937\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0920 - value_loss: 0.5558 - policy_loss: 1.6015 - val_loss: 6.0841 - val_value_loss: 0.5479 - val_policy_loss: 1.5936\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0902 - value_loss: 0.5517 - policy_loss: 1.6020 - val_loss: 6.0826 - val_value_loss: 0.5451 - val_policy_loss: 1.5935\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0870 - value_loss: 0.5463 - policy_loss: 1.6011 - val_loss: 6.0811 - val_value_loss: 0.5423 - val_policy_loss: 1.5934\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0855 - value_loss: 0.5432 - policy_loss: 1.6011 - val_loss: 6.0812 - val_value_loss: 0.5426 - val_policy_loss: 1.5933\n",
      "Saved model  tictactoe_lr_0_002_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.01\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0935 - value_loss: 0.5571 - policy_loss: 1.6034 - val_loss: 6.0866 - val_value_loss: 0.5473 - val_policy_loss: 1.5995\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.0863 - value_loss: 0.5437 - policy_loss: 1.6026 - val_loss: 6.0837 - val_value_loss: 0.5418 - val_policy_loss: 1.5993\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 168us/step - loss: 6.0809 - value_loss: 0.5335 - policy_loss: 1.6019 - val_loss: 6.0824 - val_value_loss: 0.5393 - val_policy_loss: 1.5991\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.0777 - value_loss: 0.5273 - policy_loss: 1.6019 - val_loss: 6.0816 - val_value_loss: 0.5380 - val_policy_loss: 1.5990\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.0738 - value_loss: 0.5204 - policy_loss: 1.6011 - val_loss: 6.0810 - val_value_loss: 0.5370 - val_policy_loss: 1.5989\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 169us/step - loss: 6.0709 - value_loss: 0.5149 - policy_loss: 1.6008 - val_loss: 6.0799 - val_value_loss: 0.5350 - val_policy_loss: 1.5987\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0677 - value_loss: 0.5094 - policy_loss: 1.6001 - val_loss: 6.0813 - val_value_loss: 0.5380 - val_policy_loss: 1.5986\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0655 - value_loss: 0.5047 - policy_loss: 1.6004 - val_loss: 6.0809 - val_value_loss: 0.5375 - val_policy_loss: 1.5985\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0637 - value_loss: 0.5012 - policy_loss: 1.6004 - val_loss: 6.0790 - val_value_loss: 0.5339 - val_policy_loss: 1.5984\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0605 - value_loss: 0.4963 - policy_loss: 1.5989 - val_loss: 6.0802 - val_value_loss: 0.5364 - val_policy_loss: 1.5983\n",
      "Saved model  tictactoe_lr_0_002_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.01\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0922 - value_loss: 0.5492 - policy_loss: 1.6095 - val_loss: 6.1206 - val_value_loss: 0.5798 - val_policy_loss: 1.6359\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0859 - value_loss: 0.5371 - policy_loss: 1.6091 - val_loss: 6.1184 - val_value_loss: 0.5757 - val_policy_loss: 1.6356\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0810 - value_loss: 0.5279 - policy_loss: 1.6087 - val_loss: 6.1170 - val_value_loss: 0.5731 - val_policy_loss: 1.6354\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0773 - value_loss: 0.5204 - policy_loss: 1.6087 - val_loss: 6.1164 - val_value_loss: 0.5721 - val_policy_loss: 1.6352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0731 - value_loss: 0.5132 - policy_loss: 1.6076 - val_loss: 6.1158 - val_value_loss: 0.5713 - val_policy_loss: 1.6350\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0704 - value_loss: 0.5076 - policy_loss: 1.6079 - val_loss: 6.1152 - val_value_loss: 0.5702 - val_policy_loss: 1.6349\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0677 - value_loss: 0.5028 - policy_loss: 1.6075 - val_loss: 6.1148 - val_value_loss: 0.5696 - val_policy_loss: 1.6347\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0660 - value_loss: 0.4997 - policy_loss: 1.6073 - val_loss: 6.1144 - val_value_loss: 0.5691 - val_policy_loss: 1.6346\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0626 - value_loss: 0.4937 - policy_loss: 1.6066 - val_loss: 6.1143 - val_value_loss: 0.5690 - val_policy_loss: 1.6345\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0618 - value_loss: 0.4922 - policy_loss: 1.6065 - val_loss: 6.1144 - val_value_loss: 0.5694 - val_policy_loss: 1.6344\n",
      "Saved model  tictactoe_lr_0_002_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.02\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1044 - value_loss: 0.5715 - policy_loss: 1.6124 - val_loss: 6.1300 - val_value_loss: 0.5981 - val_policy_loss: 1.6370\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0967 - value_loss: 0.5572 - policy_loss: 1.6114 - val_loss: 6.1271 - val_value_loss: 0.5928 - val_policy_loss: 1.6368\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0923 - value_loss: 0.5488 - policy_loss: 1.6111 - val_loss: 6.1248 - val_value_loss: 0.5884 - val_policy_loss: 1.6366\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0870 - value_loss: 0.5390 - policy_loss: 1.6105 - val_loss: 6.1237 - val_value_loss: 0.5863 - val_policy_loss: 1.6365\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0836 - value_loss: 0.5324 - policy_loss: 1.6102 - val_loss: 6.1217 - val_value_loss: 0.5826 - val_policy_loss: 1.6363\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0807 - value_loss: 0.5266 - policy_loss: 1.6103 - val_loss: 6.1206 - val_value_loss: 0.5805 - val_policy_loss: 1.6362\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0764 - value_loss: 0.5190 - policy_loss: 1.6095 - val_loss: 6.1202 - val_value_loss: 0.5799 - val_policy_loss: 1.6361\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0745 - value_loss: 0.5153 - policy_loss: 1.6095 - val_loss: 6.1190 - val_value_loss: 0.5777 - val_policy_loss: 1.6359\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0721 - value_loss: 0.5101 - policy_loss: 1.6099 - val_loss: 6.1189 - val_value_loss: 0.5777 - val_policy_loss: 1.6358\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0708 - value_loss: 0.5078 - policy_loss: 1.6096 - val_loss: 6.1188 - val_value_loss: 0.5777 - val_policy_loss: 1.6357\n",
      "Saved model  tictactoe_lr_0_002_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.9 - draw ratio 0.03\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1297 - value_loss: 0.6051 - policy_loss: 1.6302 - val_loss: 6.1058 - val_value_loss: 0.5936 - val_policy_loss: 1.5939\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1219 - value_loss: 0.5899 - policy_loss: 1.6298 - val_loss: 6.1028 - val_value_loss: 0.5880 - val_policy_loss: 1.5936\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1178 - value_loss: 0.5818 - policy_loss: 1.6299 - val_loss: 6.1007 - val_value_loss: 0.5842 - val_policy_loss: 1.5934\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1118 - value_loss: 0.5705 - policy_loss: 1.6293 - val_loss: 6.0990 - val_value_loss: 0.5811 - val_policy_loss: 1.5932\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1089 - value_loss: 0.5653 - policy_loss: 1.6289 - val_loss: 6.0970 - val_value_loss: 0.5772 - val_policy_loss: 1.5931\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1052 - value_loss: 0.5589 - policy_loss: 1.6279 - val_loss: 6.0964 - val_value_loss: 0.5763 - val_policy_loss: 1.5929\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1023 - value_loss: 0.5531 - policy_loss: 1.6280 - val_loss: 6.0949 - val_value_loss: 0.5734 - val_policy_loss: 1.5927\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0994 - value_loss: 0.5477 - policy_loss: 1.6276 - val_loss: 6.0938 - val_value_loss: 0.5716 - val_policy_loss: 1.5926\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0984 - value_loss: 0.5461 - policy_loss: 1.6273 - val_loss: 6.0928 - val_value_loss: 0.5698 - val_policy_loss: 1.5925\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0948 - value_loss: 0.5391 - policy_loss: 1.6272 - val_loss: 6.0919 - val_value_loss: 0.5682 - val_policy_loss: 1.5923\n",
      "Saved model  tictactoe_lr_0_002_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.92 - draw ratio 0.01\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1289 - value_loss: 0.6233 - policy_loss: 1.6112 - val_loss: 6.1139 - val_value_loss: 0.5993 - val_policy_loss: 1.6053\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1243 - value_loss: 0.6145 - policy_loss: 1.6109 - val_loss: 6.1131 - val_value_loss: 0.5977 - val_policy_loss: 1.6052\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1215 - value_loss: 0.6095 - policy_loss: 1.6103 - val_loss: 6.1116 - val_value_loss: 0.5949 - val_policy_loss: 1.6051\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1177 - value_loss: 0.6020 - policy_loss: 1.6102 - val_loss: 6.1104 - val_value_loss: 0.5926 - val_policy_loss: 1.6050\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1146 - value_loss: 0.5962 - policy_loss: 1.6099 - val_loss: 6.1102 - val_value_loss: 0.5924 - val_policy_loss: 1.6049\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1118 - value_loss: 0.5910 - policy_loss: 1.6096 - val_loss: 6.1097 - val_value_loss: 0.5916 - val_policy_loss: 1.6048\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1096 - value_loss: 0.5866 - policy_loss: 1.6094 - val_loss: 6.1090 - val_value_loss: 0.5902 - val_policy_loss: 1.6048\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1080 - value_loss: 0.5832 - policy_loss: 1.6098 - val_loss: 6.1087 - val_value_loss: 0.5897 - val_policy_loss: 1.6047\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1047 - value_loss: 0.5773 - policy_loss: 1.6091 - val_loss: 6.1083 - val_value_loss: 0.5889 - val_policy_loss: 1.6047\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1036 - value_loss: 0.5754 - policy_loss: 1.6089 - val_loss: 6.1077 - val_value_loss: 0.5878 - val_policy_loss: 1.6046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_lr_0_002_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.89 - draw ratio 0.01\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1403 - value_loss: 0.6262 - policy_loss: 1.6316 - val_loss: 6.1194 - val_value_loss: 0.6057 - val_policy_loss: 1.6103\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1349 - value_loss: 0.6160 - policy_loss: 1.6311 - val_loss: 6.1172 - val_value_loss: 0.6015 - val_policy_loss: 1.6102\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1312 - value_loss: 0.6079 - policy_loss: 1.6316 - val_loss: 6.1157 - val_value_loss: 0.5985 - val_policy_loss: 1.6101\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1285 - value_loss: 0.6033 - policy_loss: 1.6309 - val_loss: 6.1146 - val_value_loss: 0.5965 - val_policy_loss: 1.6100\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1259 - value_loss: 0.5985 - policy_loss: 1.6307 - val_loss: 6.1136 - val_value_loss: 0.5945 - val_policy_loss: 1.6100\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1234 - value_loss: 0.5934 - policy_loss: 1.6307 - val_loss: 6.1129 - val_value_loss: 0.5932 - val_policy_loss: 1.6099\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1212 - value_loss: 0.5897 - policy_loss: 1.6301 - val_loss: 6.1121 - val_value_loss: 0.5918 - val_policy_loss: 1.6099\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1191 - value_loss: 0.5855 - policy_loss: 1.6300 - val_loss: 6.1117 - val_value_loss: 0.5909 - val_policy_loss: 1.6098\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1170 - value_loss: 0.5816 - policy_loss: 1.6299 - val_loss: 6.1112 - val_value_loss: 0.5901 - val_policy_loss: 1.6098\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1153 - value_loss: 0.5787 - policy_loss: 1.6294 - val_loss: 6.1108 - val_value_loss: 0.5893 - val_policy_loss: 1.6097\n",
      "Saved model  tictactoe_lr_0_002_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.94 - draw ratio 0.01\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1120 - value_loss: 0.6016 - policy_loss: 1.5999 - val_loss: 6.1084 - val_value_loss: 0.5596 - val_policy_loss: 1.6347\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1086 - value_loss: 0.5947 - policy_loss: 1.6000 - val_loss: 6.1070 - val_value_loss: 0.5570 - val_policy_loss: 1.6346\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1046 - value_loss: 0.5874 - policy_loss: 1.5994 - val_loss: 6.1061 - val_value_loss: 0.5552 - val_policy_loss: 1.6346\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1021 - value_loss: 0.5830 - policy_loss: 1.5989 - val_loss: 6.1054 - val_value_loss: 0.5538 - val_policy_loss: 1.6346\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0994 - value_loss: 0.5772 - policy_loss: 1.5993 - val_loss: 6.1048 - val_value_loss: 0.5527 - val_policy_loss: 1.6345\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0961 - value_loss: 0.5713 - policy_loss: 1.5985 - val_loss: 6.1043 - val_value_loss: 0.5517 - val_policy_loss: 1.6345\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0935 - value_loss: 0.5664 - policy_loss: 1.5983 - val_loss: 6.1038 - val_value_loss: 0.5508 - val_policy_loss: 1.6345\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0923 - value_loss: 0.5640 - policy_loss: 1.5983 - val_loss: 6.1037 - val_value_loss: 0.5508 - val_policy_loss: 1.6345\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0898 - value_loss: 0.5593 - policy_loss: 1.5982 - val_loss: 6.1031 - val_value_loss: 0.5495 - val_policy_loss: 1.6345\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0879 - value_loss: 0.5561 - policy_loss: 1.5977 - val_loss: 6.1025 - val_value_loss: 0.5485 - val_policy_loss: 1.6344\n",
      "Saved model  tictactoe_lr_0_002_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.92 - draw ratio 0.0\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1193 - value_loss: 0.6115 - policy_loss: 1.6050 - val_loss: 6.1268 - val_value_loss: 0.6116 - val_policy_loss: 1.6199\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1153 - value_loss: 0.6037 - policy_loss: 1.6048 - val_loss: 6.1246 - val_value_loss: 0.6073 - val_policy_loss: 1.6198\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1111 - value_loss: 0.5958 - policy_loss: 1.6043 - val_loss: 6.1236 - val_value_loss: 0.6056 - val_policy_loss: 1.6197\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1070 - value_loss: 0.5878 - policy_loss: 1.6042 - val_loss: 6.1228 - val_value_loss: 0.6039 - val_policy_loss: 1.6197\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1039 - value_loss: 0.5821 - policy_loss: 1.6037 - val_loss: 6.1216 - val_value_loss: 0.6018 - val_policy_loss: 1.6196\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1006 - value_loss: 0.5757 - policy_loss: 1.6037 - val_loss: 6.1212 - val_value_loss: 0.6009 - val_policy_loss: 1.6196\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0984 - value_loss: 0.5711 - policy_loss: 1.6038 - val_loss: 6.1202 - val_value_loss: 0.5990 - val_policy_loss: 1.6195\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0960 - value_loss: 0.5661 - policy_loss: 1.6042 - val_loss: 6.1198 - val_value_loss: 0.5983 - val_policy_loss: 1.6195\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0935 - value_loss: 0.5618 - policy_loss: 1.6033 - val_loss: 6.1193 - val_value_loss: 0.5973 - val_policy_loss: 1.6195\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0916 - value_loss: 0.5581 - policy_loss: 1.6033 - val_loss: 6.1186 - val_value_loss: 0.5960 - val_policy_loss: 1.6195\n",
      "Saved model  tictactoe_lr_0_002_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.81 - draw ratio 0.04\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1273 - value_loss: 0.6117 - policy_loss: 1.6212 - val_loss: 6.1063 - val_value_loss: 0.5920 - val_policy_loss: 1.5991\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1234 - value_loss: 0.6045 - policy_loss: 1.6207 - val_loss: 6.1055 - val_value_loss: 0.5904 - val_policy_loss: 1.5989\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1200 - value_loss: 0.5981 - policy_loss: 1.6202 - val_loss: 6.1042 - val_value_loss: 0.5881 - val_policy_loss: 1.5988\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1175 - value_loss: 0.5928 - policy_loss: 1.6205 - val_loss: 6.1031 - val_value_loss: 0.5859 - val_policy_loss: 1.5987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1139 - value_loss: 0.5866 - policy_loss: 1.6197 - val_loss: 6.1024 - val_value_loss: 0.5848 - val_policy_loss: 1.5986\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1118 - value_loss: 0.5820 - policy_loss: 1.6200 - val_loss: 6.1029 - val_value_loss: 0.5859 - val_policy_loss: 1.5985\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1103 - value_loss: 0.5793 - policy_loss: 1.6199 - val_loss: 6.1028 - val_value_loss: 0.5857 - val_policy_loss: 1.5984\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1072 - value_loss: 0.5735 - policy_loss: 1.6196 - val_loss: 6.1023 - val_value_loss: 0.5848 - val_policy_loss: 1.5983\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1068 - value_loss: 0.5726 - policy_loss: 1.6196 - val_loss: 6.1019 - val_value_loss: 0.5842 - val_policy_loss: 1.5982\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1054 - value_loss: 0.5703 - policy_loss: 1.6191 - val_loss: 6.1014 - val_value_loss: 0.5834 - val_policy_loss: 1.5982\n",
      "Saved model  tictactoe_lr_0_002_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.03\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1346 - value_loss: 0.6241 - policy_loss: 1.6238 - val_loss: 6.1346 - val_value_loss: 0.6098 - val_policy_loss: 1.6380\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1299 - value_loss: 0.6152 - policy_loss: 1.6233 - val_loss: 6.1328 - val_value_loss: 0.6063 - val_policy_loss: 1.6379\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1278 - value_loss: 0.6108 - policy_loss: 1.6235 - val_loss: 6.1314 - val_value_loss: 0.6037 - val_policy_loss: 1.6379\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1260 - value_loss: 0.6075 - policy_loss: 1.6232 - val_loss: 6.1303 - val_value_loss: 0.6015 - val_policy_loss: 1.6378\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1229 - value_loss: 0.6013 - policy_loss: 1.6234 - val_loss: 6.1292 - val_value_loss: 0.5995 - val_policy_loss: 1.6377\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1214 - value_loss: 0.5989 - policy_loss: 1.6228 - val_loss: 6.1285 - val_value_loss: 0.5981 - val_policy_loss: 1.6377\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1198 - value_loss: 0.5952 - policy_loss: 1.6232 - val_loss: 6.1279 - val_value_loss: 0.5970 - val_policy_loss: 1.6376\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1184 - value_loss: 0.5924 - policy_loss: 1.6231 - val_loss: 6.1272 - val_value_loss: 0.5956 - val_policy_loss: 1.6376\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1158 - value_loss: 0.5881 - policy_loss: 1.6224 - val_loss: 6.1266 - val_value_loss: 0.5946 - val_policy_loss: 1.6375\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1140 - value_loss: 0.5844 - policy_loss: 1.6224 - val_loss: 6.1260 - val_value_loss: 0.5935 - val_policy_loss: 1.6375\n",
      "Saved model  tictactoe_lr_0_002_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.01\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1027 - value_loss: 0.5832 - policy_loss: 1.6012 - val_loss: 6.1277 - val_value_loss: 0.6097 - val_policy_loss: 1.6246\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0996 - value_loss: 0.5774 - policy_loss: 1.6008 - val_loss: 6.1257 - val_value_loss: 0.6058 - val_policy_loss: 1.6246\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0965 - value_loss: 0.5716 - policy_loss: 1.6004 - val_loss: 6.1242 - val_value_loss: 0.6028 - val_policy_loss: 1.6246\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0937 - value_loss: 0.5661 - policy_loss: 1.6002 - val_loss: 6.1229 - val_value_loss: 0.6003 - val_policy_loss: 1.6246\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0913 - value_loss: 0.5616 - policy_loss: 1.6001 - val_loss: 6.1219 - val_value_loss: 0.5981 - val_policy_loss: 1.6246\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0904 - value_loss: 0.5593 - policy_loss: 1.6004 - val_loss: 6.1208 - val_value_loss: 0.5961 - val_policy_loss: 1.6246\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0878 - value_loss: 0.5547 - policy_loss: 1.6000 - val_loss: 6.1201 - val_value_loss: 0.5947 - val_policy_loss: 1.6246\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0878 - value_loss: 0.5538 - policy_loss: 1.6009 - val_loss: 6.1194 - val_value_loss: 0.5932 - val_policy_loss: 1.6246\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0851 - value_loss: 0.5499 - policy_loss: 1.5995 - val_loss: 6.1187 - val_value_loss: 0.5919 - val_policy_loss: 1.6246\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0839 - value_loss: 0.5472 - policy_loss: 1.5998 - val_loss: 6.1181 - val_value_loss: 0.5908 - val_policy_loss: 1.6246\n",
      "Saved model  tictactoe_lr_0_002_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.0\n",
      "iteration 27 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1155 - value_loss: 0.5795 - policy_loss: 1.6305 - val_loss: 6.1114 - val_value_loss: 0.5714 - val_policy_loss: 1.6306\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1124 - value_loss: 0.5731 - policy_loss: 1.6309 - val_loss: 6.1104 - val_value_loss: 0.5694 - val_policy_loss: 1.6306\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1108 - value_loss: 0.5703 - policy_loss: 1.6304 - val_loss: 6.1097 - val_value_loss: 0.5681 - val_policy_loss: 1.6305\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1079 - value_loss: 0.5648 - policy_loss: 1.6302 - val_loss: 6.1090 - val_value_loss: 0.5667 - val_policy_loss: 1.6305\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1074 - value_loss: 0.5633 - policy_loss: 1.6306 - val_loss: 6.1084 - val_value_loss: 0.5655 - val_policy_loss: 1.6305\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1053 - value_loss: 0.5595 - policy_loss: 1.6303 - val_loss: 6.1078 - val_value_loss: 0.5643 - val_policy_loss: 1.6305\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1033 - value_loss: 0.5557 - policy_loss: 1.6300 - val_loss: 6.1073 - val_value_loss: 0.5634 - val_policy_loss: 1.6305\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1020 - value_loss: 0.5535 - policy_loss: 1.6297 - val_loss: 6.1070 - val_value_loss: 0.5628 - val_policy_loss: 1.6304\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1008 - value_loss: 0.5511 - policy_loss: 1.6298 - val_loss: 6.1065 - val_value_loss: 0.5618 - val_policy_loss: 1.6304\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0990 - value_loss: 0.5475 - policy_loss: 1.6298 - val_loss: 6.1061 - val_value_loss: 0.5610 - val_policy_loss: 1.6304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_lr_0_002_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.0\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0844 - value_loss: 0.5248 - policy_loss: 1.6233 - val_loss: 6.0627 - val_value_loss: 0.4943 - val_policy_loss: 1.6103\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0775 - value_loss: 0.5108 - policy_loss: 1.6236 - val_loss: 6.0591 - val_value_loss: 0.4872 - val_policy_loss: 1.6103\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0742 - value_loss: 0.5041 - policy_loss: 1.6236 - val_loss: 6.0568 - val_value_loss: 0.4828 - val_policy_loss: 1.6102\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0712 - value_loss: 0.4984 - policy_loss: 1.6233 - val_loss: 6.0552 - val_value_loss: 0.4796 - val_policy_loss: 1.6102\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0692 - value_loss: 0.4946 - policy_loss: 1.6231 - val_loss: 6.0540 - val_value_loss: 0.4773 - val_policy_loss: 1.6101\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0670 - value_loss: 0.4905 - policy_loss: 1.6230 - val_loss: 6.0530 - val_value_loss: 0.4754 - val_policy_loss: 1.6100\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0661 - value_loss: 0.4884 - policy_loss: 1.6232 - val_loss: 6.0521 - val_value_loss: 0.4737 - val_policy_loss: 1.6100\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0651 - value_loss: 0.4862 - policy_loss: 1.6234 - val_loss: 6.0514 - val_value_loss: 0.4723 - val_policy_loss: 1.6099\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0630 - value_loss: 0.4824 - policy_loss: 1.6230 - val_loss: 6.0507 - val_value_loss: 0.4710 - val_policy_loss: 1.6099\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0627 - value_loss: 0.4817 - policy_loss: 1.6232 - val_loss: 6.0501 - val_value_loss: 0.4698 - val_policy_loss: 1.6098\n",
      "Saved model  tictactoe_lr_0_002_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.93 - draw ratio 0.02\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_002_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.0920 - value_loss: 0.5394 - policy_loss: 1.6241 - val_loss: 6.0602 - val_value_loss: 0.4852 - val_policy_loss: 1.6146\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0898 - value_loss: 0.5354 - policy_loss: 1.6237 - val_loss: 6.0585 - val_value_loss: 0.4819 - val_policy_loss: 1.6146\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0872 - value_loss: 0.5301 - policy_loss: 1.6238 - val_loss: 6.0572 - val_value_loss: 0.4794 - val_policy_loss: 1.6146\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0853 - value_loss: 0.5261 - policy_loss: 1.6241 - val_loss: 6.0562 - val_value_loss: 0.4774 - val_policy_loss: 1.6145\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0831 - value_loss: 0.5218 - policy_loss: 1.6240 - val_loss: 6.0553 - val_value_loss: 0.4757 - val_policy_loss: 1.6145\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0804 - value_loss: 0.5172 - policy_loss: 1.6232 - val_loss: 6.0545 - val_value_loss: 0.4742 - val_policy_loss: 1.6145\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0789 - value_loss: 0.5143 - policy_loss: 1.6231 - val_loss: 6.0538 - val_value_loss: 0.4728 - val_policy_loss: 1.6144\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0775 - value_loss: 0.5116 - policy_loss: 1.6230 - val_loss: 6.0531 - val_value_loss: 0.4715 - val_policy_loss: 1.6144\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0761 - value_loss: 0.5091 - policy_loss: 1.6228 - val_loss: 6.0526 - val_value_loss: 0.4705 - val_policy_loss: 1.6144\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0750 - value_loss: 0.5067 - policy_loss: 1.6229 - val_loss: 6.0521 - val_value_loss: 0.4695 - val_policy_loss: 1.6143\n",
      "Saved model  tictactoe_lr_0_002_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.02\n"
     ]
    }
   ],
   "source": [
    "wins_3, draws_3 = test_pipeline.run(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - Learning rate 0.002\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "losses_3 = np.ones(30) - wins_3 - draws_3\n",
    "# no_loss = np.zeros(50) + wins +draws\n",
    "\n",
    "plt.plot(x, wins_3, label=\"win ratio\")\n",
    "plt.plot(x, draws_3, label=\"draw ratio\")\n",
    "#plt.plot(x, no_loss, label=\"no loss ratio\")\n",
    "plt.plot(x, losses_3, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins_3 = [0.7, 0.67, 0.78, 0.66, 0.71, 0.75, 0.77, 0.77, 0.82, 0.84, 0.78, 0.81, 0.86, 0.87, 0.87, 0.78, 0.78, 0.78, 0.78, 0.84, 0.88, 0.8, 0.8, 0.82, 0.79, 0.77, 0.79, 0.83, 0.77, 0.75]\n",
      "draws_3 = [0.06, 0.09, 0.07, 0.08, 0.08, 0.03, 0.05, 0.01, 0.01, 0.02, 0.03, 0.03, 0.02, 0.01, 0.01, 0.0, 0.03, 0.03, 0.03, 0.02, 0.01, 0.0, 0.0, 0.01, 0.0, 0.02, 0.03, 0.01, 0.03, 0.04]\n",
      "losses_3 = [0.24 0.24 0.15 0.26 0.21 0.22 0.18 0.22 0.17 0.14 0.19 0.16 0.12 0.12\n",
      " 0.12 0.22 0.19 0.19 0.19 0.14 0.11 0.2  0.2  0.17 0.21 0.21 0.18 0.16\n",
      " 0.2  0.21]\n"
     ]
    }
   ],
   "source": [
    "print(\"wins_3 =\", wins_3)\n",
    "print(\"draws_3 =\",draws_3)\n",
    "print(\"losses_3 =\",losses_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCTS = {\n",
    "    'c_puct': 1.0,\n",
    "    'dir_alpha': 0.6,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 10,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 10\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 0,\n",
    "    'show_games': False\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.0002,\n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 512,\n",
    "    'num_filters_value': 512,\n",
    "    'num_filters_tower': 512,\n",
    "    'num_residual_blocks': 3,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 512\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"tictactoe_lr_0_0002\", \"TicTacToe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (4960, 3, 3, 3)\n",
      "model_y_outcomes: (4960,)\n",
      "model_y_probabilities: (4960, 9)\n",
      "Train on 3968 samples, validate on 992 samples\n",
      "Epoch 1/10\n",
      "3968/3968 [==============================] - 4s 1ms/step - loss: 6.8130 - value_loss: 1.0097 - policy_loss: 2.5334 - val_loss: 6.7064 - val_value_loss: 0.7914 - val_policy_loss: 2.5386\n",
      "Epoch 2/10\n",
      "3968/3968 [==============================] - 1s 173us/step - loss: 6.7198 - value_loss: 0.8973 - policy_loss: 2.4595 - val_loss: 6.6420 - val_value_loss: 0.7278 - val_policy_loss: 2.4736\n",
      "Epoch 3/10\n",
      "3968/3968 [==============================] - 1s 173us/step - loss: 6.6703 - value_loss: 0.8514 - policy_loss: 2.4065 - val_loss: 6.6030 - val_value_loss: 0.6973 - val_policy_loss: 2.4261\n",
      "Epoch 4/10\n",
      "3968/3968 [==============================] - 1s 173us/step - loss: 6.6336 - value_loss: 0.8161 - policy_loss: 2.3685 - val_loss: 6.5771 - val_value_loss: 0.6820 - val_policy_loss: 2.3895\n",
      "Epoch 5/10\n",
      "3968/3968 [==============================] - 1s 174us/step - loss: 6.6038 - value_loss: 0.7874 - policy_loss: 2.3377 - val_loss: 6.5540 - val_value_loss: 0.6657 - val_policy_loss: 2.3598\n",
      "Epoch 6/10\n",
      "3968/3968 [==============================] - 1s 174us/step - loss: 6.5811 - value_loss: 0.7677 - policy_loss: 2.3121 - val_loss: 6.5358 - val_value_loss: 0.6543 - val_policy_loss: 2.3348\n",
      "Epoch 7/10\n",
      "3968/3968 [==============================] - 1s 174us/step - loss: 6.5588 - value_loss: 0.7458 - policy_loss: 2.2895 - val_loss: 6.5156 - val_value_loss: 0.6354 - val_policy_loss: 2.3135\n",
      "Epoch 8/10\n",
      "3968/3968 [==============================] - 1s 174us/step - loss: 6.5394 - value_loss: 0.7273 - policy_loss: 2.2692 - val_loss: 6.5056 - val_value_loss: 0.6343 - val_policy_loss: 2.2945\n",
      "Epoch 9/10\n",
      "3968/3968 [==============================] - 1s 174us/step - loss: 6.5267 - value_loss: 0.7198 - policy_loss: 2.2514 - val_loss: 6.4944 - val_value_loss: 0.6290 - val_policy_loss: 2.2775\n",
      "Epoch 10/10\n",
      "3968/3968 [==============================] - 1s 175us/step - loss: 6.5090 - value_loss: 0.7015 - policy_loss: 2.2343 - val_loss: 6.4809 - val_value_loss: 0.6175 - val_policy_loss: 2.2622\n",
      "Saved model  tictactoe_lr_0_0002_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.75 - draw ratio 0.05\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.4910 - value_loss: 0.6831 - policy_loss: 2.2168 - val_loss: 6.4896 - val_value_loss: 0.6838 - val_policy_loss: 2.2134\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.4754 - value_loss: 0.6679 - policy_loss: 2.2008 - val_loss: 6.4774 - val_value_loss: 0.6728 - val_policy_loss: 2.1999\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.4617 - value_loss: 0.6539 - policy_loss: 2.1875 - val_loss: 6.4672 - val_value_loss: 0.6653 - val_policy_loss: 2.1872\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.4494 - value_loss: 0.6426 - policy_loss: 2.1743 - val_loss: 6.4590 - val_value_loss: 0.6609 - val_policy_loss: 2.1753\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.4366 - value_loss: 0.6312 - policy_loss: 2.1600 - val_loss: 6.4514 - val_value_loss: 0.6570 - val_policy_loss: 2.1639\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.4248 - value_loss: 0.6190 - policy_loss: 2.1488 - val_loss: 6.4428 - val_value_loss: 0.6508 - val_policy_loss: 2.1530\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.4146 - value_loss: 0.6104 - policy_loss: 2.1370 - val_loss: 6.4372 - val_value_loss: 0.6500 - val_policy_loss: 2.1426\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.4048 - value_loss: 0.6026 - policy_loss: 2.1254 - val_loss: 6.4293 - val_value_loss: 0.6443 - val_policy_loss: 2.1326\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.3966 - value_loss: 0.5968 - policy_loss: 2.1148 - val_loss: 6.4227 - val_value_loss: 0.6408 - val_policy_loss: 2.1231\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.3895 - value_loss: 0.5912 - policy_loss: 2.1062 - val_loss: 6.4178 - val_value_loss: 0.6401 - val_policy_loss: 2.1139\n",
      "Saved model  tictactoe_lr_0_0002_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.77 - draw ratio 0.04\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.4749 - value_loss: 0.7524 - policy_loss: 2.1158 - val_loss: 6.4509 - val_value_loss: 0.7163 - val_policy_loss: 2.1042\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.4613 - value_loss: 0.7366 - policy_loss: 2.1047 - val_loss: 6.4440 - val_value_loss: 0.7107 - val_policy_loss: 2.0959\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.4484 - value_loss: 0.7207 - policy_loss: 2.0948 - val_loss: 6.4383 - val_value_loss: 0.7071 - val_policy_loss: 2.0881\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.4378 - value_loss: 0.7100 - policy_loss: 2.0842 - val_loss: 6.4315 - val_value_loss: 0.7015 - val_policy_loss: 2.0804\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.4261 - value_loss: 0.6951 - policy_loss: 2.0758 - val_loss: 6.4257 - val_value_loss: 0.6973 - val_policy_loss: 2.0730\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.4179 - value_loss: 0.6872 - policy_loss: 2.0675 - val_loss: 6.4201 - val_value_loss: 0.6932 - val_policy_loss: 2.0659\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.4096 - value_loss: 0.6795 - policy_loss: 2.0585 - val_loss: 6.4155 - val_value_loss: 0.6911 - val_policy_loss: 2.0588\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.4014 - value_loss: 0.6708 - policy_loss: 2.0509 - val_loss: 6.4091 - val_value_loss: 0.6850 - val_policy_loss: 2.0521\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.3928 - value_loss: 0.6622 - policy_loss: 2.0424 - val_loss: 6.4056 - val_value_loss: 0.6845 - val_policy_loss: 2.0457\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.3852 - value_loss: 0.6546 - policy_loss: 2.0349 - val_loss: 6.3992 - val_value_loss: 0.6781 - val_policy_loss: 2.0393\n",
      "Saved model  tictactoe_lr_0_0002_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.01\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.4115 - value_loss: 0.7030 - policy_loss: 2.0391 - val_loss: 6.4323 - val_value_loss: 0.7475 - val_policy_loss: 2.0363\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.3970 - value_loss: 0.6830 - policy_loss: 2.0303 - val_loss: 6.4260 - val_value_loss: 0.7413 - val_policy_loss: 2.0299\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3878 - value_loss: 0.6714 - policy_loss: 2.0236 - val_loss: 6.4202 - val_value_loss: 0.7360 - val_policy_loss: 2.0237\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3778 - value_loss: 0.6603 - policy_loss: 2.0146 - val_loss: 6.4146 - val_value_loss: 0.7307 - val_policy_loss: 2.0178\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3693 - value_loss: 0.6500 - policy_loss: 2.0080 - val_loss: 6.4119 - val_value_loss: 0.7313 - val_policy_loss: 2.0120\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3610 - value_loss: 0.6406 - policy_loss: 2.0008 - val_loss: 6.4059 - val_value_loss: 0.7249 - val_policy_loss: 2.0065\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3546 - value_loss: 0.6343 - policy_loss: 1.9944 - val_loss: 6.4006 - val_value_loss: 0.7196 - val_policy_loss: 2.0011\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3467 - value_loss: 0.6248 - policy_loss: 1.9882 - val_loss: 6.3975 - val_value_loss: 0.7187 - val_policy_loss: 1.9960\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.3407 - value_loss: 0.6197 - policy_loss: 1.9813 - val_loss: 6.3937 - val_value_loss: 0.7162 - val_policy_loss: 1.9910\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3345 - value_loss: 0.6132 - policy_loss: 1.9755 - val_loss: 6.3907 - val_value_loss: 0.7151 - val_policy_loss: 1.9861\n",
      "Saved model  tictactoe_lr_0_0002_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.66 - draw ratio 0.05\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.3720 - value_loss: 0.6724 - policy_loss: 1.9913 - val_loss: 6.3492 - val_value_loss: 0.6426 - val_policy_loss: 1.9756\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.3613 - value_loss: 0.6576 - policy_loss: 1.9847 - val_loss: 6.3440 - val_value_loss: 0.6375 - val_policy_loss: 1.9705\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3531 - value_loss: 0.6465 - policy_loss: 1.9796 - val_loss: 6.3401 - val_value_loss: 0.6346 - val_policy_loss: 1.9656\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3447 - value_loss: 0.6366 - policy_loss: 1.9728 - val_loss: 6.3364 - val_value_loss: 0.6319 - val_policy_loss: 1.9609\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.3381 - value_loss: 0.6288 - policy_loss: 1.9675 - val_loss: 6.3351 - val_value_loss: 0.6338 - val_policy_loss: 1.9564\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3304 - value_loss: 0.6200 - policy_loss: 1.9609 - val_loss: 6.3307 - val_value_loss: 0.6296 - val_policy_loss: 1.9521\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3248 - value_loss: 0.6144 - policy_loss: 1.9554 - val_loss: 6.3282 - val_value_loss: 0.6286 - val_policy_loss: 1.9479\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3184 - value_loss: 0.6068 - policy_loss: 1.9502 - val_loss: 6.3250 - val_value_loss: 0.6264 - val_policy_loss: 1.9439\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3117 - value_loss: 0.5996 - policy_loss: 1.9442 - val_loss: 6.3228 - val_value_loss: 0.6260 - val_policy_loss: 1.9399\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3064 - value_loss: 0.5936 - policy_loss: 1.9396 - val_loss: 6.3209 - val_value_loss: 0.6261 - val_policy_loss: 1.9361\n",
      "Saved model  tictactoe_lr_0_0002_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.03\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.3178 - value_loss: 0.6146 - policy_loss: 1.9415 - val_loss: 6.3281 - val_value_loss: 0.6363 - val_policy_loss: 1.9403\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3102 - value_loss: 0.6031 - policy_loss: 1.9377 - val_loss: 6.3258 - val_value_loss: 0.6344 - val_policy_loss: 1.9377\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3055 - value_loss: 0.5968 - policy_loss: 1.9346 - val_loss: 6.3237 - val_value_loss: 0.6326 - val_policy_loss: 1.9352\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3003 - value_loss: 0.5898 - policy_loss: 1.9314 - val_loss: 6.3219 - val_value_loss: 0.6316 - val_policy_loss: 1.9328\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2965 - value_loss: 0.5848 - policy_loss: 1.9287 - val_loss: 6.3202 - val_value_loss: 0.6305 - val_policy_loss: 1.9305\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2931 - value_loss: 0.5812 - policy_loss: 1.9255 - val_loss: 6.3186 - val_value_loss: 0.6295 - val_policy_loss: 1.9283\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2899 - value_loss: 0.5762 - policy_loss: 1.9243 - val_loss: 6.3170 - val_value_loss: 0.6285 - val_policy_loss: 1.9262\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2850 - value_loss: 0.5709 - policy_loss: 1.9197 - val_loss: 6.3158 - val_value_loss: 0.6283 - val_policy_loss: 1.9241\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2806 - value_loss: 0.5652 - policy_loss: 1.9168 - val_loss: 6.3143 - val_value_loss: 0.6274 - val_policy_loss: 1.9220\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2782 - value_loss: 0.5628 - policy_loss: 1.9144 - val_loss: 6.3131 - val_value_loss: 0.6269 - val_policy_loss: 1.9199\n",
      "Saved model  tictactoe_lr_0_0002_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.01\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.3302 - value_loss: 0.6650 - policy_loss: 1.9162 - val_loss: 6.3031 - val_value_loss: 0.6055 - val_policy_loss: 1.9214\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3231 - value_loss: 0.6542 - policy_loss: 1.9127 - val_loss: 6.2997 - val_value_loss: 0.6011 - val_policy_loss: 1.9192\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3177 - value_loss: 0.6457 - policy_loss: 1.9107 - val_loss: 6.2965 - val_value_loss: 0.5968 - val_policy_loss: 1.9170\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3130 - value_loss: 0.6386 - policy_loss: 1.9082 - val_loss: 6.2939 - val_value_loss: 0.5938 - val_policy_loss: 1.9149\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3079 - value_loss: 0.6310 - policy_loss: 1.9057 - val_loss: 6.2922 - val_value_loss: 0.5923 - val_policy_loss: 1.9129\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3056 - value_loss: 0.6283 - policy_loss: 1.9039 - val_loss: 6.2898 - val_value_loss: 0.5896 - val_policy_loss: 1.9109\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2997 - value_loss: 0.6202 - policy_loss: 1.9001 - val_loss: 6.2874 - val_value_loss: 0.5868 - val_policy_loss: 1.9089\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2956 - value_loss: 0.6135 - policy_loss: 1.8986 - val_loss: 6.2858 - val_value_loss: 0.5855 - val_policy_loss: 1.9070\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2917 - value_loss: 0.6088 - policy_loss: 1.8956 - val_loss: 6.2836 - val_value_loss: 0.5830 - val_policy_loss: 1.9051\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2882 - value_loss: 0.6044 - policy_loss: 1.8930 - val_loss: 6.2818 - val_value_loss: 0.5815 - val_policy_loss: 1.9033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_lr_0_0002_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.0\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.3463 - value_loss: 0.7037 - policy_loss: 1.9100 - val_loss: 6.3458 - val_value_loss: 0.7045 - val_policy_loss: 1.9082\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.3420 - value_loss: 0.6974 - policy_loss: 1.9076 - val_loss: 6.3434 - val_value_loss: 0.7013 - val_policy_loss: 1.9066\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.3375 - value_loss: 0.6907 - policy_loss: 1.9054 - val_loss: 6.3410 - val_value_loss: 0.6982 - val_policy_loss: 1.9050\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3335 - value_loss: 0.6841 - policy_loss: 1.9040 - val_loss: 6.3389 - val_value_loss: 0.6955 - val_policy_loss: 1.9035\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.3289 - value_loss: 0.6780 - policy_loss: 1.9010 - val_loss: 6.3367 - val_value_loss: 0.6926 - val_policy_loss: 1.9020\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.3246 - value_loss: 0.6715 - policy_loss: 1.8991 - val_loss: 6.3347 - val_value_loss: 0.6902 - val_policy_loss: 1.9005\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.3209 - value_loss: 0.6664 - policy_loss: 1.8967 - val_loss: 6.3326 - val_value_loss: 0.6873 - val_policy_loss: 1.8991\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.3173 - value_loss: 0.6610 - policy_loss: 1.8949 - val_loss: 6.3312 - val_value_loss: 0.6860 - val_policy_loss: 1.8976\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3135 - value_loss: 0.6559 - policy_loss: 1.8924 - val_loss: 6.3295 - val_value_loss: 0.6841 - val_policy_loss: 1.8963\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.3103 - value_loss: 0.6515 - policy_loss: 1.8906 - val_loss: 6.3276 - val_value_loss: 0.6817 - val_policy_loss: 1.8949\n",
      "Saved model  tictactoe_lr_0_0002_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.0\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.3005 - value_loss: 0.6315 - policy_loss: 1.8909 - val_loss: 6.3006 - val_value_loss: 0.6199 - val_policy_loss: 1.9026\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2942 - value_loss: 0.6214 - policy_loss: 1.8884 - val_loss: 6.2967 - val_value_loss: 0.6139 - val_policy_loss: 1.9010\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2901 - value_loss: 0.6143 - policy_loss: 1.8874 - val_loss: 6.2938 - val_value_loss: 0.6097 - val_policy_loss: 1.8995\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2856 - value_loss: 0.6080 - policy_loss: 1.8848 - val_loss: 6.2914 - val_value_loss: 0.6063 - val_policy_loss: 1.8980\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2815 - value_loss: 0.6027 - policy_loss: 1.8817 - val_loss: 6.2891 - val_value_loss: 0.6031 - val_policy_loss: 1.8966\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2770 - value_loss: 0.5950 - policy_loss: 1.8806 - val_loss: 6.2868 - val_value_loss: 0.6000 - val_policy_loss: 1.8952\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2744 - value_loss: 0.5922 - policy_loss: 1.8782 - val_loss: 6.2849 - val_value_loss: 0.5976 - val_policy_loss: 1.8938\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2724 - value_loss: 0.5893 - policy_loss: 1.8771 - val_loss: 6.2832 - val_value_loss: 0.5956 - val_policy_loss: 1.8925\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2679 - value_loss: 0.5833 - policy_loss: 1.8742 - val_loss: 6.2816 - val_value_loss: 0.5936 - val_policy_loss: 1.8912\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2659 - value_loss: 0.5805 - policy_loss: 1.8730 - val_loss: 6.2800 - val_value_loss: 0.5917 - val_policy_loss: 1.8899\n",
      "Saved model  tictactoe_lr_0_0002_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.0\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.3032 - value_loss: 0.6490 - policy_loss: 1.8791 - val_loss: 6.2871 - val_value_loss: 0.6370 - val_policy_loss: 1.8589\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2976 - value_loss: 0.6410 - policy_loss: 1.8759 - val_loss: 6.2842 - val_value_loss: 0.6329 - val_policy_loss: 1.8572\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2935 - value_loss: 0.6352 - policy_loss: 1.8735 - val_loss: 6.2815 - val_value_loss: 0.6291 - val_policy_loss: 1.8556\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2891 - value_loss: 0.6283 - policy_loss: 1.8716 - val_loss: 6.2797 - val_value_loss: 0.6272 - val_policy_loss: 1.8541\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2867 - value_loss: 0.6250 - policy_loss: 1.8703 - val_loss: 6.2773 - val_value_loss: 0.6240 - val_policy_loss: 1.8525\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2829 - value_loss: 0.6198 - policy_loss: 1.8678 - val_loss: 6.2760 - val_value_loss: 0.6227 - val_policy_loss: 1.8511\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2802 - value_loss: 0.6167 - policy_loss: 1.8657 - val_loss: 6.2740 - val_value_loss: 0.6203 - val_policy_loss: 1.8496\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2765 - value_loss: 0.6109 - policy_loss: 1.8639 - val_loss: 6.2721 - val_value_loss: 0.6180 - val_policy_loss: 1.8482\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2728 - value_loss: 0.6055 - policy_loss: 1.8620 - val_loss: 6.2709 - val_value_loss: 0.6170 - val_policy_loss: 1.8468\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2709 - value_loss: 0.6029 - policy_loss: 1.8608 - val_loss: 6.2689 - val_value_loss: 0.6144 - val_policy_loss: 1.8455\n",
      "Saved model  tictactoe_lr_0_0002_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.0\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.2824 - value_loss: 0.6259 - policy_loss: 1.8610 - val_loss: 6.2645 - val_value_loss: 0.6133 - val_policy_loss: 1.8378\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2799 - value_loss: 0.6211 - policy_loss: 1.8608 - val_loss: 6.2627 - val_value_loss: 0.6104 - val_policy_loss: 1.8370\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2764 - value_loss: 0.6162 - policy_loss: 1.8585 - val_loss: 6.2612 - val_value_loss: 0.6082 - val_policy_loss: 1.8363\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2753 - value_loss: 0.6140 - policy_loss: 1.8586 - val_loss: 6.2598 - val_value_loss: 0.6062 - val_policy_loss: 1.8356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2725 - value_loss: 0.6095 - policy_loss: 1.8575 - val_loss: 6.2586 - val_value_loss: 0.6044 - val_policy_loss: 1.8349\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2710 - value_loss: 0.6075 - policy_loss: 1.8565 - val_loss: 6.2574 - val_value_loss: 0.6028 - val_policy_loss: 1.8342\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2680 - value_loss: 0.6035 - policy_loss: 1.8547 - val_loss: 6.2563 - val_value_loss: 0.6012 - val_policy_loss: 1.8335\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2663 - value_loss: 0.6010 - policy_loss: 1.8537 - val_loss: 6.2552 - val_value_loss: 0.5997 - val_policy_loss: 1.8328\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2646 - value_loss: 0.5979 - policy_loss: 1.8535 - val_loss: 6.2542 - val_value_loss: 0.5983 - val_policy_loss: 1.8321\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2631 - value_loss: 0.5963 - policy_loss: 1.8520 - val_loss: 6.2532 - val_value_loss: 0.5970 - val_policy_loss: 1.8315\n",
      "Saved model  tictactoe_lr_0_0002_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.02\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2940 - value_loss: 0.6427 - policy_loss: 1.8674 - val_loss: 6.2879 - val_value_loss: 0.6624 - val_policy_loss: 1.8357\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2899 - value_loss: 0.6371 - policy_loss: 1.8649 - val_loss: 6.2858 - val_value_loss: 0.6586 - val_policy_loss: 1.8351\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2880 - value_loss: 0.6343 - policy_loss: 1.8640 - val_loss: 6.2841 - val_value_loss: 0.6559 - val_policy_loss: 1.8345\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2858 - value_loss: 0.6301 - policy_loss: 1.8637 - val_loss: 6.2826 - val_value_loss: 0.6536 - val_policy_loss: 1.8339\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2827 - value_loss: 0.6260 - policy_loss: 1.8616 - val_loss: 6.2815 - val_value_loss: 0.6520 - val_policy_loss: 1.8333\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2794 - value_loss: 0.6207 - policy_loss: 1.8604 - val_loss: 6.2803 - val_value_loss: 0.6502 - val_policy_loss: 1.8327\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2774 - value_loss: 0.6179 - policy_loss: 1.8592 - val_loss: 6.2791 - val_value_loss: 0.6484 - val_policy_loss: 1.8321\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2758 - value_loss: 0.6157 - policy_loss: 1.8582 - val_loss: 6.2782 - val_value_loss: 0.6472 - val_policy_loss: 1.8315\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2730 - value_loss: 0.6105 - policy_loss: 1.8579 - val_loss: 6.2771 - val_value_loss: 0.6457 - val_policy_loss: 1.8309\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2726 - value_loss: 0.6103 - policy_loss: 1.8574 - val_loss: 6.2760 - val_value_loss: 0.6440 - val_policy_loss: 1.8303\n",
      "Saved model  tictactoe_lr_0_0002_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.81 - draw ratio 0.01\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.2862 - value_loss: 0.6397 - policy_loss: 1.8550 - val_loss: 6.2700 - val_value_loss: 0.6159 - val_policy_loss: 1.8464\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2833 - value_loss: 0.6355 - policy_loss: 1.8534 - val_loss: 6.2680 - val_value_loss: 0.6127 - val_policy_loss: 1.8456\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2798 - value_loss: 0.6301 - policy_loss: 1.8519 - val_loss: 6.2662 - val_value_loss: 0.6100 - val_policy_loss: 1.8449\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2783 - value_loss: 0.6277 - policy_loss: 1.8513 - val_loss: 6.2645 - val_value_loss: 0.6073 - val_policy_loss: 1.8441\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2757 - value_loss: 0.6240 - policy_loss: 1.8497 - val_loss: 6.2630 - val_value_loss: 0.6052 - val_policy_loss: 1.8433\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2743 - value_loss: 0.6218 - policy_loss: 1.8493 - val_loss: 6.2612 - val_value_loss: 0.6022 - val_policy_loss: 1.8426\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2717 - value_loss: 0.6175 - policy_loss: 1.8484 - val_loss: 6.2601 - val_value_loss: 0.6007 - val_policy_loss: 1.8418\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2711 - value_loss: 0.6170 - policy_loss: 1.8476 - val_loss: 6.2586 - val_value_loss: 0.5986 - val_policy_loss: 1.8411\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2676 - value_loss: 0.6111 - policy_loss: 1.8465 - val_loss: 6.2571 - val_value_loss: 0.5963 - val_policy_loss: 1.8404\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2650 - value_loss: 0.6073 - policy_loss: 1.8452 - val_loss: 6.2557 - val_value_loss: 0.5942 - val_policy_loss: 1.8397\n",
      "Saved model  tictactoe_lr_0_0002_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.01\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2429 - value_loss: 0.5840 - policy_loss: 1.8243 - val_loss: 6.2624 - val_value_loss: 0.6187 - val_policy_loss: 1.8285\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2392 - value_loss: 0.5778 - policy_loss: 1.8232 - val_loss: 6.2607 - val_value_loss: 0.6161 - val_policy_loss: 1.8277\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2363 - value_loss: 0.5732 - policy_loss: 1.8218 - val_loss: 6.2596 - val_value_loss: 0.6147 - val_policy_loss: 1.8269\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2349 - value_loss: 0.5707 - policy_loss: 1.8217 - val_loss: 6.2587 - val_value_loss: 0.6137 - val_policy_loss: 1.8262\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2331 - value_loss: 0.5686 - policy_loss: 1.8202 - val_loss: 6.2578 - val_value_loss: 0.6127 - val_policy_loss: 1.8255\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2308 - value_loss: 0.5657 - policy_loss: 1.8185 - val_loss: 6.2571 - val_value_loss: 0.6121 - val_policy_loss: 1.8247\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2293 - value_loss: 0.5636 - policy_loss: 1.8175 - val_loss: 6.2564 - val_value_loss: 0.6115 - val_policy_loss: 1.8240\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2284 - value_loss: 0.5621 - policy_loss: 1.8173 - val_loss: 6.2558 - val_value_loss: 0.6109 - val_policy_loss: 1.8233\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2255 - value_loss: 0.5578 - policy_loss: 1.8159 - val_loss: 6.2552 - val_value_loss: 0.6105 - val_policy_loss: 1.8226\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2243 - value_loss: 0.5566 - policy_loss: 1.8147 - val_loss: 6.2546 - val_value_loss: 0.6100 - val_policy_loss: 1.8219\n",
      "Saved model  tictactoe_lr_0_0002_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.0\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2807 - value_loss: 0.6541 - policy_loss: 1.8299 - val_loss: 6.2795 - val_value_loss: 0.6595 - val_policy_loss: 1.8222\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2793 - value_loss: 0.6511 - policy_loss: 1.8302 - val_loss: 6.2785 - val_value_loss: 0.6582 - val_policy_loss: 1.8215\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2755 - value_loss: 0.6461 - policy_loss: 1.8277 - val_loss: 6.2776 - val_value_loss: 0.6572 - val_policy_loss: 1.8208\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2744 - value_loss: 0.6430 - policy_loss: 1.8285 - val_loss: 6.2769 - val_value_loss: 0.6564 - val_policy_loss: 1.8201\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2725 - value_loss: 0.6398 - policy_loss: 1.8279 - val_loss: 6.2761 - val_value_loss: 0.6555 - val_policy_loss: 1.8194\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2691 - value_loss: 0.6356 - policy_loss: 1.8253 - val_loss: 6.2754 - val_value_loss: 0.6548 - val_policy_loss: 1.8187\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2693 - value_loss: 0.6361 - policy_loss: 1.8253 - val_loss: 6.2747 - val_value_loss: 0.6541 - val_policy_loss: 1.8180\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2682 - value_loss: 0.6344 - policy_loss: 1.8248 - val_loss: 6.2740 - val_value_loss: 0.6534 - val_policy_loss: 1.8174\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2652 - value_loss: 0.6294 - policy_loss: 1.8237 - val_loss: 6.2733 - val_value_loss: 0.6527 - val_policy_loss: 1.8167\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2630 - value_loss: 0.6263 - policy_loss: 1.8225 - val_loss: 6.2727 - val_value_loss: 0.6520 - val_policy_loss: 1.8161\n",
      "Saved model  tictactoe_lr_0_0002_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.01\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2937 - value_loss: 0.6871 - policy_loss: 1.8232 - val_loss: 6.2932 - val_value_loss: 0.6697 - val_policy_loss: 1.8395\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2932 - value_loss: 0.6855 - policy_loss: 1.8237 - val_loss: 6.2924 - val_value_loss: 0.6684 - val_policy_loss: 1.8392\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2917 - value_loss: 0.6833 - policy_loss: 1.8230 - val_loss: 6.2916 - val_value_loss: 0.6671 - val_policy_loss: 1.8389\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2894 - value_loss: 0.6794 - policy_loss: 1.8222 - val_loss: 6.2909 - val_value_loss: 0.6660 - val_policy_loss: 1.8386\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2883 - value_loss: 0.6771 - policy_loss: 1.8223 - val_loss: 6.2902 - val_value_loss: 0.6649 - val_policy_loss: 1.8383\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2866 - value_loss: 0.6742 - policy_loss: 1.8219 - val_loss: 6.2895 - val_value_loss: 0.6639 - val_policy_loss: 1.8380\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2854 - value_loss: 0.6730 - policy_loss: 1.8207 - val_loss: 6.2889 - val_value_loss: 0.6629 - val_policy_loss: 1.8377\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2851 - value_loss: 0.6712 - policy_loss: 1.8219 - val_loss: 6.2882 - val_value_loss: 0.6619 - val_policy_loss: 1.8375\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2836 - value_loss: 0.6702 - policy_loss: 1.8200 - val_loss: 6.2876 - val_value_loss: 0.6609 - val_policy_loss: 1.8372\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2813 - value_loss: 0.6660 - policy_loss: 1.8195 - val_loss: 6.2870 - val_value_loss: 0.6600 - val_policy_loss: 1.8369\n",
      "Saved model  tictactoe_lr_0_0002_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.02\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.2349 - value_loss: 0.5731 - policy_loss: 1.8195 - val_loss: 6.2417 - val_value_loss: 0.5625 - val_policy_loss: 1.8439\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2325 - value_loss: 0.5689 - policy_loss: 1.8191 - val_loss: 6.2404 - val_value_loss: 0.5601 - val_policy_loss: 1.8436\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2322 - value_loss: 0.5678 - policy_loss: 1.8195 - val_loss: 6.2394 - val_value_loss: 0.5585 - val_policy_loss: 1.8433\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2302 - value_loss: 0.5647 - policy_loss: 1.8186 - val_loss: 6.2386 - val_value_loss: 0.5572 - val_policy_loss: 1.8430\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2291 - value_loss: 0.5632 - policy_loss: 1.8178 - val_loss: 6.2380 - val_value_loss: 0.5561 - val_policy_loss: 1.8428\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2278 - value_loss: 0.5609 - policy_loss: 1.8176 - val_loss: 6.2373 - val_value_loss: 0.5551 - val_policy_loss: 1.8425\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2275 - value_loss: 0.5600 - policy_loss: 1.8178 - val_loss: 6.2368 - val_value_loss: 0.5542 - val_policy_loss: 1.8422\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2250 - value_loss: 0.5564 - policy_loss: 1.8165 - val_loss: 6.2363 - val_value_loss: 0.5535 - val_policy_loss: 1.8420\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2238 - value_loss: 0.5550 - policy_loss: 1.8155 - val_loss: 6.2358 - val_value_loss: 0.5528 - val_policy_loss: 1.8417\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2241 - value_loss: 0.5547 - policy_loss: 1.8165 - val_loss: 6.2353 - val_value_loss: 0.5521 - val_policy_loss: 1.8415\n",
      "Saved model  tictactoe_lr_0_0002_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.01\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.2468 - value_loss: 0.5772 - policy_loss: 1.8394 - val_loss: 6.2230 - val_value_loss: 0.5491 - val_policy_loss: 1.8198\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2462 - value_loss: 0.5758 - policy_loss: 1.8396 - val_loss: 6.2228 - val_value_loss: 0.5491 - val_policy_loss: 1.8194\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2451 - value_loss: 0.5740 - policy_loss: 1.8393 - val_loss: 6.2226 - val_value_loss: 0.5491 - val_policy_loss: 1.8191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2443 - value_loss: 0.5732 - policy_loss: 1.8383 - val_loss: 6.2224 - val_value_loss: 0.5491 - val_policy_loss: 1.8187\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2441 - value_loss: 0.5732 - policy_loss: 1.8380 - val_loss: 6.2222 - val_value_loss: 0.5490 - val_policy_loss: 1.8184\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2415 - value_loss: 0.5688 - policy_loss: 1.8373 - val_loss: 6.2220 - val_value_loss: 0.5490 - val_policy_loss: 1.8180\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2407 - value_loss: 0.5672 - policy_loss: 1.8371 - val_loss: 6.2218 - val_value_loss: 0.5490 - val_policy_loss: 1.8177\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2398 - value_loss: 0.5664 - policy_loss: 1.8363 - val_loss: 6.2216 - val_value_loss: 0.5489 - val_policy_loss: 1.8174\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2390 - value_loss: 0.5648 - policy_loss: 1.8362 - val_loss: 6.2214 - val_value_loss: 0.5488 - val_policy_loss: 1.8171\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2393 - value_loss: 0.5644 - policy_loss: 1.8373 - val_loss: 6.2212 - val_value_loss: 0.5487 - val_policy_loss: 1.8167\n",
      "Saved model  tictactoe_lr_0_0002_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.02\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.2801 - value_loss: 0.6518 - policy_loss: 1.8315 - val_loss: 6.2470 - val_value_loss: 0.5768 - val_policy_loss: 1.8402\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2772 - value_loss: 0.6463 - policy_loss: 1.8313 - val_loss: 6.2462 - val_value_loss: 0.5755 - val_policy_loss: 1.8400\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2765 - value_loss: 0.6453 - policy_loss: 1.8308 - val_loss: 6.2456 - val_value_loss: 0.5746 - val_policy_loss: 1.8398\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2758 - value_loss: 0.6444 - policy_loss: 1.8303 - val_loss: 6.2451 - val_value_loss: 0.5738 - val_policy_loss: 1.8396\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2737 - value_loss: 0.6408 - policy_loss: 1.8297 - val_loss: 6.2447 - val_value_loss: 0.5731 - val_policy_loss: 1.8394\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2724 - value_loss: 0.6387 - policy_loss: 1.8292 - val_loss: 6.2443 - val_value_loss: 0.5725 - val_policy_loss: 1.8392\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.2720 - value_loss: 0.6369 - policy_loss: 1.8302 - val_loss: 6.2439 - val_value_loss: 0.5719 - val_policy_loss: 1.8390\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.2702 - value_loss: 0.6344 - policy_loss: 1.8291 - val_loss: 6.2435 - val_value_loss: 0.5714 - val_policy_loss: 1.8388\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2695 - value_loss: 0.6331 - policy_loss: 1.8291 - val_loss: 6.2431 - val_value_loss: 0.5708 - val_policy_loss: 1.8386\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.2680 - value_loss: 0.6303 - policy_loss: 1.8288 - val_loss: 6.2428 - val_value_loss: 0.5704 - val_policy_loss: 1.8384\n",
      "Saved model  tictactoe_lr_0_0002_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.01\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.2760 - value_loss: 0.6394 - policy_loss: 1.8358 - val_loss: 6.2785 - val_value_loss: 0.6405 - val_policy_loss: 1.8398\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2729 - value_loss: 0.6348 - policy_loss: 1.8342 - val_loss: 6.2779 - val_value_loss: 0.6395 - val_policy_loss: 1.8394\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2719 - value_loss: 0.6326 - policy_loss: 1.8344 - val_loss: 6.2773 - val_value_loss: 0.6388 - val_policy_loss: 1.8390\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2702 - value_loss: 0.6299 - policy_loss: 1.8336 - val_loss: 6.2768 - val_value_loss: 0.6381 - val_policy_loss: 1.8386\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2696 - value_loss: 0.6283 - policy_loss: 1.8342 - val_loss: 6.2763 - val_value_loss: 0.6375 - val_policy_loss: 1.8382\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2687 - value_loss: 0.6276 - policy_loss: 1.8329 - val_loss: 6.2758 - val_value_loss: 0.6369 - val_policy_loss: 1.8379\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2658 - value_loss: 0.6234 - policy_loss: 1.8314 - val_loss: 6.2753 - val_value_loss: 0.6363 - val_policy_loss: 1.8375\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2664 - value_loss: 0.6239 - policy_loss: 1.8320 - val_loss: 6.2749 - val_value_loss: 0.6358 - val_policy_loss: 1.8371\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2632 - value_loss: 0.6188 - policy_loss: 1.8308 - val_loss: 6.2745 - val_value_loss: 0.6353 - val_policy_loss: 1.8368\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2637 - value_loss: 0.6193 - policy_loss: 1.8314 - val_loss: 6.2741 - val_value_loss: 0.6349 - val_policy_loss: 1.8365\n",
      "Saved model  tictactoe_lr_0_0002_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.0\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.2787 - value_loss: 0.6497 - policy_loss: 1.8309 - val_loss: 6.2749 - val_value_loss: 0.6478 - val_policy_loss: 1.8251\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2778 - value_loss: 0.6475 - policy_loss: 1.8314 - val_loss: 6.2746 - val_value_loss: 0.6477 - val_policy_loss: 1.8248\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2772 - value_loss: 0.6470 - policy_loss: 1.8307 - val_loss: 6.2744 - val_value_loss: 0.6474 - val_policy_loss: 1.8245\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2764 - value_loss: 0.6449 - policy_loss: 1.8311 - val_loss: 6.2741 - val_value_loss: 0.6472 - val_policy_loss: 1.8243\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2753 - value_loss: 0.6429 - policy_loss: 1.8309 - val_loss: 6.2739 - val_value_loss: 0.6471 - val_policy_loss: 1.8240\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2761 - value_loss: 0.6440 - policy_loss: 1.8315 - val_loss: 6.2737 - val_value_loss: 0.6469 - val_policy_loss: 1.8238\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2756 - value_loss: 0.6441 - policy_loss: 1.8304 - val_loss: 6.2735 - val_value_loss: 0.6467 - val_policy_loss: 1.8235\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2742 - value_loss: 0.6417 - policy_loss: 1.8300 - val_loss: 6.2733 - val_value_loss: 0.6465 - val_policy_loss: 1.8233\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2727 - value_loss: 0.6393 - policy_loss: 1.8293 - val_loss: 6.2731 - val_value_loss: 0.6464 - val_policy_loss: 1.8231\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2741 - value_loss: 0.6412 - policy_loss: 1.8303 - val_loss: 6.2729 - val_value_loss: 0.6462 - val_policy_loss: 1.8229\n",
      "Saved model  tictactoe_lr_0_0002_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.72 - draw ratio 0.02\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2386 - value_loss: 0.5805 - policy_loss: 1.8200 - val_loss: 6.2352 - val_value_loss: 0.5642 - val_policy_loss: 1.8295\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2363 - value_loss: 0.5767 - policy_loss: 1.8193 - val_loss: 6.2348 - val_value_loss: 0.5634 - val_policy_loss: 1.8294\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2356 - value_loss: 0.5755 - policy_loss: 1.8189 - val_loss: 6.2343 - val_value_loss: 0.5626 - val_policy_loss: 1.8292\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2349 - value_loss: 0.5739 - policy_loss: 1.8192 - val_loss: 6.2339 - val_value_loss: 0.5619 - val_policy_loss: 1.8291\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2342 - value_loss: 0.5729 - policy_loss: 1.8188 - val_loss: 6.2335 - val_value_loss: 0.5613 - val_policy_loss: 1.8290\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2338 - value_loss: 0.5727 - policy_loss: 1.8181 - val_loss: 6.2331 - val_value_loss: 0.5606 - val_policy_loss: 1.8289\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2318 - value_loss: 0.5688 - policy_loss: 1.8180 - val_loss: 6.2327 - val_value_loss: 0.5600 - val_policy_loss: 1.8288\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2324 - value_loss: 0.5695 - policy_loss: 1.8186 - val_loss: 6.2324 - val_value_loss: 0.5595 - val_policy_loss: 1.8287\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2314 - value_loss: 0.5668 - policy_loss: 1.8192 - val_loss: 6.2321 - val_value_loss: 0.5590 - val_policy_loss: 1.8285\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2294 - value_loss: 0.5650 - policy_loss: 1.8171 - val_loss: 6.2318 - val_value_loss: 0.5584 - val_policy_loss: 1.8284\n",
      "Saved model  tictactoe_lr_0_0002_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.81 - draw ratio 0.01\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2700 - value_loss: 0.6380 - policy_loss: 1.8253 - val_loss: 6.2425 - val_value_loss: 0.5909 - val_policy_loss: 1.8173\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2691 - value_loss: 0.6365 - policy_loss: 1.8251 - val_loss: 6.2421 - val_value_loss: 0.5904 - val_policy_loss: 1.8172\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2679 - value_loss: 0.6344 - policy_loss: 1.8247 - val_loss: 6.2418 - val_value_loss: 0.5899 - val_policy_loss: 1.8171\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2665 - value_loss: 0.6317 - policy_loss: 1.8247 - val_loss: 6.2415 - val_value_loss: 0.5894 - val_policy_loss: 1.8170\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2667 - value_loss: 0.6320 - policy_loss: 1.8248 - val_loss: 6.2412 - val_value_loss: 0.5889 - val_policy_loss: 1.8169\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2656 - value_loss: 0.6305 - policy_loss: 1.8239 - val_loss: 6.2409 - val_value_loss: 0.5883 - val_policy_loss: 1.8168\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2652 - value_loss: 0.6302 - policy_loss: 1.8235 - val_loss: 6.2406 - val_value_loss: 0.5878 - val_policy_loss: 1.8167\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2635 - value_loss: 0.6272 - policy_loss: 1.8230 - val_loss: 6.2402 - val_value_loss: 0.5872 - val_policy_loss: 1.8166\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2633 - value_loss: 0.6269 - policy_loss: 1.8231 - val_loss: 6.2399 - val_value_loss: 0.5867 - val_policy_loss: 1.8165\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2636 - value_loss: 0.6269 - policy_loss: 1.8236 - val_loss: 6.2396 - val_value_loss: 0.5862 - val_policy_loss: 1.8164\n",
      "Saved model  tictactoe_lr_0_0002_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.03\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2963 - value_loss: 0.6929 - policy_loss: 1.8229 - val_loss: 6.2823 - val_value_loss: 0.6827 - val_policy_loss: 1.8051\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2967 - value_loss: 0.6941 - policy_loss: 1.8226 - val_loss: 6.2819 - val_value_loss: 0.6821 - val_policy_loss: 1.8050\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2943 - value_loss: 0.6902 - policy_loss: 1.8218 - val_loss: 6.2815 - val_value_loss: 0.6815 - val_policy_loss: 1.8049\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2934 - value_loss: 0.6883 - policy_loss: 1.8218 - val_loss: 6.2812 - val_value_loss: 0.6810 - val_policy_loss: 1.8048\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2938 - value_loss: 0.6891 - policy_loss: 1.8219 - val_loss: 6.2809 - val_value_loss: 0.6805 - val_policy_loss: 1.8047\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2929 - value_loss: 0.6874 - policy_loss: 1.8217 - val_loss: 6.2806 - val_value_loss: 0.6800 - val_policy_loss: 1.8046\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2915 - value_loss: 0.6850 - policy_loss: 1.8214 - val_loss: 6.2803 - val_value_loss: 0.6796 - val_policy_loss: 1.8045\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2923 - value_loss: 0.6865 - policy_loss: 1.8215 - val_loss: 6.2801 - val_value_loss: 0.6791 - val_policy_loss: 1.8043\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2907 - value_loss: 0.6833 - policy_loss: 1.8215 - val_loss: 6.2798 - val_value_loss: 0.6788 - val_policy_loss: 1.8042\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2899 - value_loss: 0.6826 - policy_loss: 1.8205 - val_loss: 6.2796 - val_value_loss: 0.6784 - val_policy_loss: 1.8041\n",
      "Saved model  tictactoe_lr_0_0002_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.0\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2804 - value_loss: 0.6662 - policy_loss: 1.8179 - val_loss: 6.2886 - val_value_loss: 0.6746 - val_policy_loss: 1.8259\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2797 - value_loss: 0.6662 - policy_loss: 1.8166 - val_loss: 6.2878 - val_value_loss: 0.6730 - val_policy_loss: 1.8259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2784 - value_loss: 0.6631 - policy_loss: 1.8171 - val_loss: 6.2871 - val_value_loss: 0.6717 - val_policy_loss: 1.8259\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2777 - value_loss: 0.6621 - policy_loss: 1.8167 - val_loss: 6.2865 - val_value_loss: 0.6705 - val_policy_loss: 1.8259\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2766 - value_loss: 0.6598 - policy_loss: 1.8167 - val_loss: 6.2860 - val_value_loss: 0.6695 - val_policy_loss: 1.8258\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2758 - value_loss: 0.6589 - policy_loss: 1.8162 - val_loss: 6.2854 - val_value_loss: 0.6685 - val_policy_loss: 1.8258\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2736 - value_loss: 0.6554 - policy_loss: 1.8152 - val_loss: 6.2849 - val_value_loss: 0.6675 - val_policy_loss: 1.8258\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2732 - value_loss: 0.6541 - policy_loss: 1.8157 - val_loss: 6.2845 - val_value_loss: 0.6666 - val_policy_loss: 1.8257\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2725 - value_loss: 0.6527 - policy_loss: 1.8158 - val_loss: 6.2840 - val_value_loss: 0.6657 - val_policy_loss: 1.8257\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2725 - value_loss: 0.6538 - policy_loss: 1.8146 - val_loss: 6.2835 - val_value_loss: 0.6649 - val_policy_loss: 1.8256\n",
      "Saved model  tictactoe_lr_0_0002_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.02\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.2892 - value_loss: 0.6815 - policy_loss: 1.8203 - val_loss: 6.2889 - val_value_loss: 0.6935 - val_policy_loss: 1.8077\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2886 - value_loss: 0.6807 - policy_loss: 1.8200 - val_loss: 6.2884 - val_value_loss: 0.6928 - val_policy_loss: 1.8075\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2860 - value_loss: 0.6767 - policy_loss: 1.8188 - val_loss: 6.2880 - val_value_loss: 0.6921 - val_policy_loss: 1.8073\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2865 - value_loss: 0.6774 - policy_loss: 1.8190 - val_loss: 6.2876 - val_value_loss: 0.6915 - val_policy_loss: 1.8071\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2863 - value_loss: 0.6773 - policy_loss: 1.8187 - val_loss: 6.2872 - val_value_loss: 0.6908 - val_policy_loss: 1.8069\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2849 - value_loss: 0.6754 - policy_loss: 1.8179 - val_loss: 6.2868 - val_value_loss: 0.6902 - val_policy_loss: 1.8068\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2857 - value_loss: 0.6758 - policy_loss: 1.8190 - val_loss: 6.2864 - val_value_loss: 0.6895 - val_policy_loss: 1.8066\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2843 - value_loss: 0.6737 - policy_loss: 1.8184 - val_loss: 6.2860 - val_value_loss: 0.6889 - val_policy_loss: 1.8065\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2839 - value_loss: 0.6724 - policy_loss: 1.8187 - val_loss: 6.2856 - val_value_loss: 0.6883 - val_policy_loss: 1.8063\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2839 - value_loss: 0.6730 - policy_loss: 1.8182 - val_loss: 6.2852 - val_value_loss: 0.6877 - val_policy_loss: 1.8062\n",
      "Saved model  tictactoe_lr_0_0002_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.03\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2655 - value_loss: 0.6305 - policy_loss: 1.8239 - val_loss: 6.2469 - val_value_loss: 0.5938 - val_policy_loss: 1.8234\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2662 - value_loss: 0.6298 - policy_loss: 1.8259 - val_loss: 6.2467 - val_value_loss: 0.5936 - val_policy_loss: 1.8233\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2651 - value_loss: 0.6290 - policy_loss: 1.8246 - val_loss: 6.2466 - val_value_loss: 0.5933 - val_policy_loss: 1.8232\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2653 - value_loss: 0.6298 - policy_loss: 1.8242 - val_loss: 6.2464 - val_value_loss: 0.5932 - val_policy_loss: 1.8231\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2649 - value_loss: 0.6283 - policy_loss: 1.8249 - val_loss: 6.2463 - val_value_loss: 0.5930 - val_policy_loss: 1.8230\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2642 - value_loss: 0.6278 - policy_loss: 1.8240 - val_loss: 6.2461 - val_value_loss: 0.5928 - val_policy_loss: 1.8229\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2640 - value_loss: 0.6276 - policy_loss: 1.8238 - val_loss: 6.2460 - val_value_loss: 0.5926 - val_policy_loss: 1.8228\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2630 - value_loss: 0.6268 - policy_loss: 1.8227 - val_loss: 6.2459 - val_value_loss: 0.5925 - val_policy_loss: 1.8228\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2632 - value_loss: 0.6264 - policy_loss: 1.8234 - val_loss: 6.2458 - val_value_loss: 0.5923 - val_policy_loss: 1.8227\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2636 - value_loss: 0.6265 - policy_loss: 1.8241 - val_loss: 6.2457 - val_value_loss: 0.5922 - val_policy_loss: 1.8226\n",
      "Saved model  tictactoe_lr_0_0002_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.01\n",
      "iteration 27 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.2398 - value_loss: 0.5815 - policy_loss: 1.8216 - val_loss: 6.2426 - val_value_loss: 0.5752 - val_policy_loss: 1.8334\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2387 - value_loss: 0.5792 - policy_loss: 1.8216 - val_loss: 6.2423 - val_value_loss: 0.5748 - val_policy_loss: 1.8334\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2392 - value_loss: 0.5802 - policy_loss: 1.8216 - val_loss: 6.2421 - val_value_loss: 0.5744 - val_policy_loss: 1.8333\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2375 - value_loss: 0.5775 - policy_loss: 1.8209 - val_loss: 6.2419 - val_value_loss: 0.5741 - val_policy_loss: 1.8332\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2371 - value_loss: 0.5771 - policy_loss: 1.8205 - val_loss: 6.2417 - val_value_loss: 0.5738 - val_policy_loss: 1.8332\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2383 - value_loss: 0.5774 - policy_loss: 1.8226 - val_loss: 6.2416 - val_value_loss: 0.5735 - val_policy_loss: 1.8331\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2364 - value_loss: 0.5756 - policy_loss: 1.8208 - val_loss: 6.2414 - val_value_loss: 0.5733 - val_policy_loss: 1.8330\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2357 - value_loss: 0.5748 - policy_loss: 1.8200 - val_loss: 6.2413 - val_value_loss: 0.5731 - val_policy_loss: 1.8330\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2350 - value_loss: 0.5734 - policy_loss: 1.8200 - val_loss: 6.2411 - val_value_loss: 0.5728 - val_policy_loss: 1.8329\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2353 - value_loss: 0.5738 - policy_loss: 1.8203 - val_loss: 6.2410 - val_value_loss: 0.5726 - val_policy_loss: 1.8329\n",
      "Saved model  tictactoe_lr_0_0002_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.01\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2554 - value_loss: 0.6321 - policy_loss: 1.8022 - val_loss: 6.2594 - val_value_loss: 0.6486 - val_policy_loss: 1.7937\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2556 - value_loss: 0.6317 - policy_loss: 1.8030 - val_loss: 6.2591 - val_value_loss: 0.6480 - val_policy_loss: 1.7936\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2539 - value_loss: 0.6294 - policy_loss: 1.8018 - val_loss: 6.2588 - val_value_loss: 0.6475 - val_policy_loss: 1.7936\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2554 - value_loss: 0.6316 - policy_loss: 1.8028 - val_loss: 6.2585 - val_value_loss: 0.6469 - val_policy_loss: 1.7935\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2541 - value_loss: 0.6300 - policy_loss: 1.8016 - val_loss: 6.2582 - val_value_loss: 0.6465 - val_policy_loss: 1.7934\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2527 - value_loss: 0.6278 - policy_loss: 1.8011 - val_loss: 6.2580 - val_value_loss: 0.6461 - val_policy_loss: 1.7934\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2544 - value_loss: 0.6307 - policy_loss: 1.8015 - val_loss: 6.2578 - val_value_loss: 0.6457 - val_policy_loss: 1.7933\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2533 - value_loss: 0.6283 - policy_loss: 1.8018 - val_loss: 6.2576 - val_value_loss: 0.6453 - val_policy_loss: 1.7933\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2533 - value_loss: 0.6281 - policy_loss: 1.8020 - val_loss: 6.2574 - val_value_loss: 0.6450 - val_policy_loss: 1.7932\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2514 - value_loss: 0.6264 - policy_loss: 1.7999 - val_loss: 6.2572 - val_value_loss: 0.6447 - val_policy_loss: 1.7932\n",
      "Saved model  tictactoe_lr_0_0002_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.01\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_tictactoe_lr_0_0002_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2543 - value_loss: 0.6170 - policy_loss: 1.8151 - val_loss: 6.2405 - val_value_loss: 0.6000 - val_policy_loss: 1.8045\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2540 - value_loss: 0.6163 - policy_loss: 1.8151 - val_loss: 6.2401 - val_value_loss: 0.5994 - val_policy_loss: 1.8044\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2545 - value_loss: 0.6172 - policy_loss: 1.8152 - val_loss: 6.2398 - val_value_loss: 0.5988 - val_policy_loss: 1.8042\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2538 - value_loss: 0.6162 - policy_loss: 1.8149 - val_loss: 6.2395 - val_value_loss: 0.5983 - val_policy_loss: 1.8041\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2528 - value_loss: 0.6140 - policy_loss: 1.8150 - val_loss: 6.2392 - val_value_loss: 0.5979 - val_policy_loss: 1.8040\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2523 - value_loss: 0.6141 - policy_loss: 1.8141 - val_loss: 6.2389 - val_value_loss: 0.5974 - val_policy_loss: 1.8039\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2537 - value_loss: 0.6160 - policy_loss: 1.8150 - val_loss: 6.2387 - val_value_loss: 0.5970 - val_policy_loss: 1.8038\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2528 - value_loss: 0.6144 - policy_loss: 1.8147 - val_loss: 6.2384 - val_value_loss: 0.5966 - val_policy_loss: 1.8037\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2523 - value_loss: 0.6137 - policy_loss: 1.8144 - val_loss: 6.2382 - val_value_loss: 0.5962 - val_policy_loss: 1.8036\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2515 - value_loss: 0.6122 - policy_loss: 1.8143 - val_loss: 6.2380 - val_value_loss: 0.5959 - val_policy_loss: 1.8036\n",
      "Saved model  tictactoe_lr_0_0002_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.0\n"
     ]
    }
   ],
   "source": [
    "wins_4, draws_4 = test_pipeline.run(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - Learning rate 0.002\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "losses_4 = np.ones(30) - wins_4 - draws_4\n",
    "# no_loss = np.zeros(50) + wins +draws\n",
    "\n",
    "plt.plot(x, wins_4, label=\"win ratio\")\n",
    "plt.plot(x, draws_4, label=\"draw ratio\")\n",
    "#plt.plot(x, no_loss, label=\"no loss ratio\")\n",
    "plt.plot(x, losses_4, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins_4 = [0.75, 0.77, 0.79, 0.66, 0.79, 0.78, 0.83, 0.8, 0.85, 0.8, 0.85, 0.81, 0.82, 0.78, 0.85, 0.85, 0.83, 0.87, 0.79, 0.83, 0.72, 0.81, 0.87, 0.84, 0.85, 0.76, 0.82, 0.88, 0.83, 0.84]\n",
      "draws_4 = [0.05, 0.04, 0.01, 0.05, 0.03, 0.01, 0.0, 0.0, 0.0, 0.0, 0.02, 0.01, 0.01, 0.0, 0.01, 0.02, 0.01, 0.02, 0.01, 0.0, 0.02, 0.01, 0.03, 0.0, 0.02, 0.03, 0.01, 0.01, 0.01, 0.0]\n",
      "losses_4 = [0.2  0.19 0.2  0.29 0.18 0.21 0.17 0.2  0.15 0.2  0.13 0.18 0.17 0.22\n",
      " 0.14 0.13 0.16 0.11 0.2  0.17 0.26 0.18 0.1  0.16 0.13 0.21 0.17 0.11\n",
      " 0.16 0.16]\n"
     ]
    }
   ],
   "source": [
    "print(\"wins_4 =\", wins_4)\n",
    "print(\"draws_4 =\",draws_4)\n",
    "print(\"losses_4 =\",losses_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(data, window_size):\n",
    "    return np.convolve(data, np.ones((window_size,))/window_size, mode='valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wins_1 = [0.75, 0.82, 0.84, 0.74, 0.76, 0.77, 0.78, 0.74, 0.71, 0.77, 0.7, 0.79, 0.78, 0.73, 0.71, 0.77, 0.71, 0.68, 0.78, 0.76, 0.7, 0.8, 0.82, 0.73, 0.74, 0.76, 0.67, 0.78, 0.66, 0.65]\n",
    "draws_1 = [0.02, 0.02, 0.0, 0.01, 0.01, 0.03, 0.0, 0.0, 0.03, 0.01, 0.0, 0.01, 0.0, 0.01, 0.01, 0.01, 0.02, 0.04, 0.03, 0.02, 0.03, 0.02, 0.0, 0.03, 0.02, 0.04, 0.05, 0.04, 0.06, 0.04]\n",
    "losses_1 = np.ones(30) - wins_1 - draws_1\n",
    "\n",
    "wins_2 = [0.8, 0.66, 0.6, 0.68, 0.69, 0.78, 0.73, 0.62, 0.79, 0.76, 0.73, 0.71, 0.77, 0.7, 0.66, 0.76, 0.69, 0.77, 0.7, 0.88, 0.79, 0.82, 0.7, 0.64, 0.71, 0.66, 0.66, 0.71, 0.8, 0.76]\n",
    "draws_2 = [0.01, 0.02, 0.1, 0.04, 0.02, 0.03, 0.04, 0.08, 0.05, 0.03, 0.03, 0.06, 0.01, 0.03, 0.02, 0.04, 0.02, 0.02, 0.02, 0.02, 0.01, 0.03, 0.03, 0.06, 0.09, 0.04, 0.05, 0.03, 0.03, 0.04]\n",
    "losses_2 = np.ones(30) - wins_2 - draws_2\n",
    "\n",
    "wins_3 = [0.7, 0.67, 0.78, 0.66, 0.71, 0.75, 0.77, 0.77, 0.82, 0.84, 0.78, 0.81, 0.86, 0.87, 0.87, 0.78, 0.78, 0.78, 0.78, 0.84, 0.88, 0.8, 0.8, 0.82, 0.79, 0.77, 0.79, 0.83, 0.77, 0.75]\n",
    "draws_3 = [0.06, 0.09, 0.07, 0.08, 0.08, 0.03, 0.05, 0.01, 0.01, 0.02, 0.03, 0.03, 0.02, 0.01, 0.01, 0.0, 0.03, 0.03, 0.03, 0.02, 0.01, 0.0, 0.0, 0.01, 0.0, 0.02, 0.03, 0.01, 0.03, 0.04]\n",
    "losses_3 = np.ones(30) - wins_3 - draws_3\n",
    "\n",
    "wins_4 = [0.75, 0.77, 0.79, 0.66, 0.79, 0.78, 0.83, 0.8, 0.85, 0.8, 0.85, 0.81, 0.82, 0.78, 0.85, 0.85, 0.83, 0.87, 0.79, 0.83, 0.72, 0.81, 0.87, 0.84, 0.85, 0.76, 0.82, 0.88, 0.83, 0.84]\n",
    "draws_4 = [0.05, 0.04, 0.01, 0.05, 0.03, 0.01, 0.0, 0.0, 0.0, 0.0, 0.02, 0.01, 0.01, 0.0, 0.01, 0.02, 0.01, 0.02, 0.01, 0.0, 0.02, 0.01, 0.03, 0.0, 0.02, 0.03, 0.01, 0.01, 0.01, 0.0]\n",
    "losses_4 = np.ones(30) - wins_4 -draws_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_size = 3\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "\n",
    "plt.title(\"Evaluation - Win ratio\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"win ratio\")\n",
    "\n",
    "x = np.arange(30 - window_size + 1)\n",
    "\n",
    "plt.plot(x, smooth(wins_1, window_size), label=\"learning rate 0.2\")\n",
    "plt.plot(x, smooth(wins_2, window_size), label=\"learning rate 0.02\")\n",
    "plt.plot(x, smooth(wins_3, window_size), label=\"learning rate 0.002\")\n",
    "plt.plot(x, smooth(wins_4, window_size), label=\"learning rate 0.0002\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "(300,)\n",
      "(300,)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "train_loss_1 = pd.read_csv(\"tictactoe_exp_lr/run_tictactoe_lr_0_2-tag-loss.csv\")\n",
    "train_loss_1 = train_loss_1['Value'].values[:300]\n",
    "\n",
    "train_loss_2 = pd.read_csv(\"tictactoe_exp_lr/run_tictactoe_lr_0_02-tag-loss.csv\")\n",
    "train_loss_2 = train_loss_2['Value'].values\n",
    "\n",
    "train_loss_3 = pd.read_csv(\"tictactoe_exp_lr/run_tictactoe_lr_0_002-tag-loss.csv\")\n",
    "train_loss_3 = train_loss_3['Value'].values\n",
    "\n",
    "train_loss_4 = pd.read_csv(\"tictactoe_exp_lr/run_tictactoe_lr_0_0002-tag-loss.csv\")\n",
    "train_loss_4 = train_loss_4['Value'].values\n",
    "\n",
    "# length \n",
    "print(train_loss_1.shape)\n",
    "print(train_loss_2.shape)\n",
    "print(train_loss_3.shape)\n",
    "print(train_loss_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_size = 10\n",
    "first_iteration = 0\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "\n",
    "plt.title(\"Evaluation - Training loss\")\n",
    "\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "x = np.arange(300-window_size+1 - first_iteration)+first_iteration\n",
    "\n",
    "#plt.plot(x, smooth(train_loss_1[first_iteration:],window_size), label=\"learning rate 0.2\")\n",
    "plt.plot(x, smooth(train_loss_2[first_iteration:],window_size), label=\"learning rate 0.02\")\n",
    "plt.plot(x, smooth(train_loss_3[first_iteration:],window_size), label=\"learning rate 0.002\")\n",
    "plt.plot(x, smooth(train_loss_4[first_iteration:],window_size), label=\"learning rate 0.0002\")\n",
    "\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "(300,)\n",
      "(300,)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "val_loss_1 = pd.read_csv(\"tictactoe_exp_lr/run_tictactoe_lr_0_2-tag-val_loss.csv\")\n",
    "val_loss_1 = val_loss_1['Value'].values[:300]\n",
    "\n",
    "val_loss_2 = pd.read_csv(\"tictactoe_exp_lr/run_tictactoe_lr_0_02-tag-val_loss.csv\")\n",
    "val_loss_2 = val_loss_2['Value'].values\n",
    "\n",
    "val_loss_3 = pd.read_csv(\"tictactoe_exp_lr/run_tictactoe_lr_0_002-tag-val_loss.csv\")\n",
    "val_loss_3 = val_loss_3['Value'].values\n",
    "\n",
    "val_loss_4 = pd.read_csv(\"tictactoe_exp_lr/run_tictactoe_lr_0_0002-tag-val_loss.csv\")\n",
    "val_loss_4 = val_loss_4['Value'].values\n",
    "\n",
    "# length \n",
    "print(val_loss_1.shape)\n",
    "print(val_loss_2.shape)\n",
    "print(val_loss_3.shape)\n",
    "print(val_loss_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_size = 1\n",
    "first_iteration = 0\n",
    "last_iteration = 300\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "plt.title(\"Evaluation - Validation loss\")\n",
    "\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "x = np.arange(300 - window_size + 1 - first_iteration -(300-last_iteration)) + first_iteration\n",
    "\n",
    "#plt.plot(x, smooth(val_loss_1[first_iteration:last_iteration],window_size), label=\"learning rate 0.2\")\n",
    "plt.plot(x, smooth(val_loss_2[first_iteration:last_iteration],window_size), label=\"learning rate 0.02\")\n",
    "plt.plot(x, smooth(val_loss_3[first_iteration:last_iteration],window_size), label=\"learning rate 0.002\")\n",
    "plt.plot(x, smooth(val_loss_4[first_iteration:last_iteration],window_size), label=\"learning rate 0.0002\")\n",
    "\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play against agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate: 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_lr_0_2_29\n"
     ]
    }
   ],
   "source": [
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "last_model_0_2 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_lr_0_2\"\n",
    ")\n",
    "last_model_0_2.load(29)\n",
    "last_agent_0_2 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=last_model_0_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 0 | 0\n",
      " 1 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "-0.092552975\n",
      "[0.132 0.121 0.128 0.    0.128 0.12  0.126 0.118 0.127]\n",
      "value: -0.09255297482013702\n",
      "policy:\n",
      " 0.13237212598323822 | 0.12084122002124786 | 0.12785330414772034\n",
      " 0.0 | 0.1277981549501419 | 0.12044928967952728\n",
      " 0.12600380182266235 | 0.1180933266878128 | 0.12658880650997162\n",
      "===========\n",
      "choose from [1 1 1 0 1 1 1 1 1] :4\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 1 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.5874475\n",
      "[0.144 0.139 0.145 0.    0.    0.136 0.138 0.136 0.162]\n",
      "value: 0.5874475240707397\n",
      "policy:\n",
      " 0.14365708827972412 | 0.13927528262138367 | 0.14547210931777954\n",
      " 0.0 | 0.0 | 0.13636574149131775\n",
      " 0.13765200972557068 | 0.13604804873466492 | 0.16152970492839813\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 1 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.5550063\n",
      "[0.    0.145 0.198 0.    0.    0.141 0.174 0.178 0.164]\n",
      "value: 0.5550063252449036\n",
      "policy:\n",
      " 0.0 | 0.14508111774921417 | 0.19786252081394196\n",
      " 0.0 | 0.0 | 0.14059507846832275\n",
      " 0.17393073439598083 | 0.17818507552146912 | 0.16434547305107117\n",
      "===========\n",
      "choose from [0 1 1 0 0 1 1 1 1] :6\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 1 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "0.7288759\n",
      "[0.    0.139 0.3   0.    0.    0.177 0.    0.135 0.249]\n",
      "value: 0.7288758754730225\n",
      "policy:\n",
      " 0.0 | 0.1390814483165741 | 0.29965248703956604\n",
      " 0.0 | 0.0 | 0.17691132426261902\n",
      " 0.0 | 0.1352691948413849 | 0.24908559024333954\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 1\n",
      " 1 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "0.54328656\n",
      "[0.    0.345 0.    0.    0.    0.172 0.    0.194 0.288]\n",
      "value: 0.5432865619659424\n",
      "policy:\n",
      " 0.0 | 0.3449200987815857 | 0.0\n",
      " 0.0 | 0.0 | 0.1724902242422104\n",
      " 0.0 | 0.19442041218280792 | 0.2881692945957184\n",
      "===========\n",
      "choose from [0 1 0 0 0 1 0 1 1] :1\n",
      "===========\n",
      " 1 | 2 | 1\n",
      " 1 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "0.4742858\n",
      "[0.    0.    0.    0.    0.    0.438 0.    0.262 0.3  ]\n",
      "value: 0.4742858111858368\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.4382736384868622\n",
      " 0.0 | 0.2616117000579834 | 0.3001146614551544\n",
      "===========\n",
      "===========\n",
      " 1 | 2 | 1\n",
      " 1 | 2 | 1\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "-0.9898523\n",
      "[0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 9.995e-01 4.600e-04]\n",
      "value: -0.9898523092269897\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.9995400309562683 | 0.00045999709982424974\n",
      "===========\n",
      "choose from [0 0 0 0 0 0 0 1 1] :7\n",
      "===========\n",
      " 1 | 2 | 1\n",
      " 1 | 2 | 1\n",
      " 2 | 2 | 0\n",
      "-----------\n",
      "-0.79255646\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "value: -0.7925564646720886\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 1.0\n",
      "===========\n",
      "Player -1 won the game after 8 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(last_agent_0_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_lr_0_2_2\n"
     ]
    }
   ],
   "source": [
    "best_version = np.argmax(wins_1)\n",
    "\n",
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "best_model_0_2 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_lr_0_2\"\n",
    ")\n",
    "best_model_0_2.load(best_version)\n",
    "best_agent_0_2 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=best_model_0_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 1 | 0\n",
      "-----------\n",
      "-0.01686379\n",
      "[0.157 0.142 0.153 0.117 0.089 0.112 0.143 0.    0.088]\n",
      "value: -0.016863789409399033\n",
      "policy:\n",
      " 0.15659697353839874 | 0.14220961928367615 | 0.15307332575321198\n",
      " 0.11735028028488159 | 0.08880799263715744 | 0.11153189837932587\n",
      " 0.14264127612113953 | 0.0 | 0.08778861165046692\n",
      "===========\n",
      "choose from [1 1 1 1 1 1 1 0 1] :4\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 1 | 0\n",
      "-----------\n",
      "0.35282496\n",
      "[0.142 0.139 0.14  0.137 0.    0.108 0.221 0.    0.113]\n",
      "value: 0.35282495617866516\n",
      "policy:\n",
      " 0.14236223697662354 | 0.13912415504455566 | 0.13955415785312653\n",
      " 0.13705547153949738 | 0.0 | 0.10802163928747177\n",
      " 0.22134587168693542 | 0.0 | 0.11253654211759567\n",
      "===========\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 1 | 1 | 0\n",
      "-----------\n",
      "0.2028839\n",
      "[0.229 0.179 0.167 0.221 0.    0.119 0.    0.    0.084]\n",
      "value: 0.20288389921188354\n",
      "policy:\n",
      " 0.22940543293952942 | 0.17900031805038452 | 0.16657552123069763\n",
      " 0.22144398093223572 | 0.0 | 0.11911413073539734\n",
      " 0.0 | 0.0 | 0.08446060121059418\n",
      "===========\n",
      "choose from [1 1 1 1 0 1 0 0 1] :8\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 1 | 1 | 2\n",
      "-----------\n",
      "0.13463782\n",
      "[0.242 0.218 0.226 0.203 0.    0.111 0.    0.    0.   ]\n",
      "value: 0.13463781774044037\n",
      "policy:\n",
      " 0.24195167422294617 | 0.21812453866004944 | 0.22564314305782318\n",
      " 0.20349326729774475 | 0.0 | 0.11078743636608124\n",
      " 0.0 | 0.0 | 0.0\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 1 | 1 | 2\n",
      "-----------\n",
      "0.15641677\n",
      "[0.    0.212 0.336 0.228 0.    0.225 0.    0.    0.   ]\n",
      "value: 0.15641677379608154\n",
      "policy:\n",
      " 0.0 | 0.21168620884418488 | 0.33599716424942017\n",
      " 0.22776992619037628 | 0.0 | 0.22454673051834106\n",
      " 0.0 | 0.0 | 0.0\n",
      "===========\n",
      "choose from [0 1 1 1 0 1 0 0 0] :3\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 2 | 2 | 0\n",
      " 1 | 1 | 2\n",
      "-----------\n",
      "-0.1520787\n",
      "[0.    0.405 0.52  0.    0.    0.075 0.    0.    0.   ]\n",
      "value: -0.15207870304584503\n",
      "policy:\n",
      " 0.0 | 0.404909610748291 | 0.5196768641471863\n",
      " 0.0 | 0.0 | 0.0754135400056839\n",
      " 0.0 | 0.0 | 0.0\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 1\n",
      " 2 | 2 | 0\n",
      " 1 | 1 | 2\n",
      "-----------\n",
      "-0.19874384\n",
      "[0.    0.166 0.    0.    0.    0.834 0.    0.    0.   ]\n",
      "value: -0.19874383509159088\n",
      "policy:\n",
      " 0.0 | 0.165902242064476 | 0.0\n",
      " 0.0 | 0.0 | 0.8340977430343628\n",
      " 0.0 | 0.0 | 0.0\n",
      "===========\n",
      "choose from [0 1 0 0 0 1 0 0 0] :5\n",
      "===========\n",
      " 1 | 0 | 1\n",
      " 2 | 2 | 2\n",
      " 1 | 1 | 2\n",
      "-----------\n",
      "-0.44066295\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "value: -0.4406629502773285\n",
      "policy:\n",
      " 0.0 | 1.0 | 0.0\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.0\n",
      "===========\n",
      "Player -1 won the game after 8 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(best_agent_0_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_lr_0_02_29\n"
     ]
    }
   ],
   "source": [
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "last_model_0_02 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_lr_0_02\"\n",
    ")\n",
    "last_model_0_02.load(29)\n",
    "last_agent_0_02 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=last_model_0_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 1 | 0\n",
      "-----------\n",
      "0.2034065\n",
      "[0.128 0.13  0.13  0.117 0.128 0.124 0.117 0.    0.126]\n",
      "value: 0.20340649783611298\n",
      "policy:\n",
      " 0.12753771245479584 | 0.12993218004703522 | 0.1303442120552063\n",
      " 0.11725719273090363 | 0.12755239009857178 | 0.12413354963064194\n",
      " 0.11747501790523529 | 0.0 | 0.125767782330513\n",
      "===========\n",
      "choose from [1 1 1 1 1 1 1 0 1] :4\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 1 | 0\n",
      "-----------\n",
      "-0.9993197\n",
      "[0.14  0.146 0.142 0.145 0.    0.146 0.139 0.    0.142]\n",
      "value: -0.9993196725845337\n",
      "policy:\n",
      " 0.13992546498775482 | 0.145741805434227 | 0.14180661737918854\n",
      " 0.14511631429195404 | 0.0 | 0.14606274664402008\n",
      " 0.13937383890151978 | 0.0 | 0.14197322726249695\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 1 | 0\n",
      "-----------\n",
      "-0.9346763\n",
      "[0.161 0.    0.142 0.205 0.    0.19  0.147 0.    0.154]\n",
      "value: -0.9346762895584106\n",
      "policy:\n",
      " 0.16104483604431152 | 0.0 | 0.14168789982795715\n",
      " 0.20546987652778625 | 0.0 | 0.1900305151939392\n",
      " 0.14744074642658234 | 0.0 | 0.15432609617710114\n",
      "===========\n",
      "choose from [1 0 1 1 0 1 1 0 1] :0\n",
      "===========\n",
      " 2 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 1 | 0\n",
      "-----------\n",
      "-0.9999891\n",
      "[0.    0.    0.218 0.158 0.    0.234 0.191 0.    0.198]\n",
      "value: -0.9999890923500061\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.21833501756191254\n",
      " 0.1581793874502182 | 0.0 | 0.2337612807750702\n",
      " 0.19124464690685272 | 0.0 | 0.19847966730594635\n",
      "===========\n",
      "===========\n",
      " 2 | 1 | 0\n",
      " 0 | 2 | 1\n",
      " 0 | 1 | 0\n",
      "-----------\n",
      "-0.9562858\n",
      "[0.    0.    0.004 0.002 0.    0.    0.008 0.    0.986]\n",
      "value: -0.9562857747077942\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.004326766822487116\n",
      " 0.0020436658523976803 | 0.0 | 0.0\n",
      " 0.007676552049815655 | 0.0 | 0.9859529733657837\n",
      "===========\n",
      "choose from [0 0 1 1 0 0 1 0 1] :8\n",
      "===========\n",
      " 2 | 1 | 0\n",
      " 0 | 2 | 1\n",
      " 0 | 1 | 2\n",
      "-----------\n",
      "-0.9999699\n",
      "[0.    0.    0.454 0.196 0.    0.    0.35  0.    0.   ]\n",
      "value: -0.9999698996543884\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.453878253698349\n",
      " 0.19595062732696533 | 0.0 | 0.0\n",
      " 0.35017111897468567 | 0.0 | 0.0\n",
      "===========\n",
      "Player -1 won the game after 6 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(last_agent_0_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_lr_0_02_19\n"
     ]
    }
   ],
   "source": [
    "best_version = np.argmax(wins_2)\n",
    "\n",
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "best_model_0_02 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_lr_0_02\"\n",
    ")\n",
    "best_model_0_02.load(best_version)\n",
    "best_agent_0_02 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=best_model_0_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.21825084\n",
      "[0.124 0.    0.117 0.116 0.132 0.126 0.129 0.132 0.124]\n",
      "value: 0.2182508409023285\n",
      "policy:\n",
      " 0.12448519468307495 | 0.0 | 0.1166791319847107\n",
      " 0.11619044840335846 | 0.13207566738128662 | 0.12577731907367706\n",
      " 0.12878252565860748 | 0.131577268242836 | 0.12443237751722336\n",
      "===========\n",
      "choose from [1 0 1 1 1 1 1 1 1] :4\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "-0.9996773\n",
      "[0.155 0.    0.144 0.149 0.    0.137 0.133 0.15  0.132]\n",
      "value: -0.999677300453186\n",
      "policy:\n",
      " 0.155099019408226 | 0.0 | 0.14383193850517273\n",
      " 0.14926689863204956 | 0.0 | 0.13705851137638092\n",
      " 0.13301467895507812 | 0.14950118958950043 | 0.13222776353359222\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.50591993\n",
      "[0.    0.    0.137 0.189 0.    0.138 0.161 0.187 0.187]\n",
      "value: 0.5059199333190918\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.1370673030614853\n",
      " 0.1893438696861267 | 0.0 | 0.13817830383777618\n",
      " 0.16118060052394867 | 0.187216117978096 | 0.18701377511024475\n",
      "===========\n",
      "choose from [0 0 1 1 0 1 1 1 1] :2\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "-0.9999455\n",
      "[0.    0.    0.    0.255 0.    0.151 0.213 0.25  0.132]\n",
      "value: -0.9999455213546753\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.25486746430397034 | 0.0 | 0.1507628709077835\n",
      " 0.21288235485553741 | 0.24959439039230347 | 0.13189299404621124\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 1 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "-0.89030844\n",
      "[0.    0.    0.    0.    0.    0.002 0.992 0.002 0.005]\n",
      "value: -0.8903084397315979\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.0018647137330844998\n",
      " 0.9918856620788574 | 0.0017174282111227512 | 0.004532205406576395\n",
      "===========\n",
      "choose from [0 0 0 0 0 1 1 1 1] :6\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 1 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "-0.99999696\n",
      "[0.    0.    0.    0.    0.    0.162 0.    0.388 0.45 ]\n",
      "value: -0.9999969601631165\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.16154226660728455\n",
      " 0.0 | 0.38841819763183594 | 0.4500395357608795\n",
      "===========\n",
      "Player -1 won the game after 6 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(best_agent_0_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Learning rate 0.002\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_lr_0_002_29\n"
     ]
    }
   ],
   "source": [
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "last_model_0_002 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_lr_0_002\"\n",
    ")\n",
    "last_model_0_002.load(29)\n",
    "last_agent_0_002 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=last_model_0_002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 1\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.3067093\n",
      "[0.119 0.121 0.126 0.126 0.143 0.    0.122 0.117 0.126]\n",
      "value: 0.30670928955078125\n",
      "policy:\n",
      " 0.11889251321554184 | 0.12100300192832947 | 0.12592630088329315\n",
      " 0.1261391043663025 | 0.14288966357707977 | 0.0\n",
      " 0.12218474596738815 | 0.11659008264541626 | 0.12637457251548767\n",
      "===========\n",
      "choose from [1 1 1 1 1 0 1 1 1] :4\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 1\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "-0.15143882\n",
      "[0.146 0.151 0.166 0.12  0.    0.    0.12  0.134 0.163]\n",
      "value: -0.15143881738185883\n",
      "policy:\n",
      " 0.1461571753025055 | 0.1506337672472 | 0.16582757234573364\n",
      " 0.11971481144428253 | 0.0 | 0.0\n",
      " 0.12043415009975433 | 0.13438628613948822 | 0.16284620761871338\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 0 | 2 | 1\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "-0.12113561\n",
      "[0.    0.136 0.245 0.125 0.    0.    0.188 0.174 0.133]\n",
      "value: -0.12113560736179352\n",
      "policy:\n",
      " 0.0 | 0.13643606007099152 | 0.24457809329032898\n",
      " 0.12454771250486374 | 0.0 | 0.0\n",
      " 0.1876029521226883 | 0.17355559766292572 | 0.13327959179878235\n",
      "===========\n",
      "choose from [0 1 1 1 0 0 1 1 1] :2\n",
      "===========\n",
      " 1 | 0 | 2\n",
      " 0 | 2 | 1\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.5649933\n",
      "[0.    0.179 0.    0.295 0.    0.    0.285 0.082 0.159]\n",
      "value: 0.5649933218955994\n",
      "policy:\n",
      " 0.0 | 0.1786465346813202 | 0.0\n",
      " 0.29520347714424133 | 0.0 | 0.0\n",
      " 0.2847195565700531 | 0.08245569467544556 | 0.1589747816324234\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 2\n",
      " 1 | 2 | 1\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "-0.9192118\n",
      "[0.    0.073 0.    0.    0.    0.    0.838 0.046 0.043]\n",
      "value: -0.9192118048667908\n",
      "policy:\n",
      " 0.0 | 0.07312552630901337 | 0.0\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.8381617069244385 | 0.04554767161607742 | 0.043165095150470734\n",
      "===========\n",
      "choose from [0 1 0 0 0 0 1 1 1] :6\n",
      "===========\n",
      " 1 | 0 | 2\n",
      " 1 | 2 | 1\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "-0.3358869\n",
      "[0.    0.303 0.    0.    0.    0.    0.    0.235 0.462]\n",
      "value: -0.3358868956565857\n",
      "policy:\n",
      " 0.0 | 0.30263563990592957 | 0.0\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.23536653816699982 | 0.4619978368282318\n",
      "===========\n",
      "Player -1 won the game after 6 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(last_agent_0_002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_lr_0_002_20\n"
     ]
    }
   ],
   "source": [
    "best_version = np.argmax(wins_3)\n",
    "\n",
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "best_model_0_002 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_lr_0_002\"\n",
    ")\n",
    "best_model_0_002.load(best_version)\n",
    "best_agent_0_002 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=best_model_0_002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.18894832\n",
      "[0.12  0.    0.122 0.125 0.137 0.124 0.124 0.129 0.12 ]\n",
      "value: 0.18894831836223602\n",
      "policy:\n",
      " 0.11962060630321503 | 0.0 | 0.12186503410339355\n",
      " 0.12541380524635315 | 0.13661648333072662 | 0.12374608218669891\n",
      " 0.1238662376999855 | 0.12857550382614136 | 0.12029623985290527\n",
      "===========\n",
      "choose from [1 0 1 1 1 1 1 1 1] :0\n",
      "===========\n",
      " 2 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.0513978\n",
      "[0.    0.    0.137 0.146 0.154 0.146 0.12  0.162 0.133]\n",
      "value: 0.05139780044555664\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.13738007843494415\n",
      " 0.14620456099510193 | 0.15428867936134338 | 0.14638656377792358\n",
      " 0.12042072415351868 | 0.16224907338619232 | 0.13307031989097595\n",
      "===========\n",
      "===========\n",
      " 2 | 1 | 0\n",
      " 1 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.30599442\n",
      "[0.    0.    0.125 0.    0.258 0.153 0.115 0.148 0.201]\n",
      "value: 0.3059944212436676\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.12498369812965393\n",
      " 0.0 | 0.2575860321521759 | 0.15349158644676208\n",
      " 0.11483828723430634 | 0.14785084128379822 | 0.20124951004981995\n",
      "===========\n",
      "choose from [0 0 1 0 1 1 1 1 1] :4\n",
      "===========\n",
      " 2 | 1 | 0\n",
      " 1 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.6765139\n",
      "[0.    0.    0.181 0.    0.    0.251 0.196 0.177 0.195]\n",
      "value: 0.6765139102935791\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.18057528138160706\n",
      " 0.0 | 0.0 | 0.2508574426174164\n",
      " 0.1957293301820755 | 0.17741382122039795 | 0.19542409479618073\n",
      "===========\n",
      "===========\n",
      " 2 | 1 | 0\n",
      " 1 | 2 | 1\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "-0.7573442\n",
      "[0.    0.    0.054 0.    0.    0.    0.079 0.029 0.838]\n",
      "value: -0.7573441863059998\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.05386526137590408\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0792028084397316 | 0.028807809576392174 | 0.8381240963935852\n",
      "===========\n",
      "choose from [0 0 1 0 0 0 1 1 1] :8\n",
      "===========\n",
      " 2 | 1 | 0\n",
      " 1 | 2 | 1\n",
      " 0 | 0 | 2\n",
      "-----------\n",
      "0.0036120112\n",
      "[0.    0.    0.455 0.    0.    0.    0.321 0.224 0.   ]\n",
      "value: 0.003612011205404997\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.4554179310798645\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.3210550844669342 | 0.2235269993543625 | 0.0\n",
      "===========\n",
      "Player -1 won the game after 6 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(best_agent_0_002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_lr_0_0002_29\n"
     ]
    }
   ],
   "source": [
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "last_model_0_0002 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_lr_0_0002\"\n",
    ")\n",
    "last_model_0_0002.load(29)\n",
    "last_agent_0_0002 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=last_model_0_0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.37847984\n",
      "[0.118 0.    0.12  0.127 0.141 0.123 0.13  0.112 0.13 ]\n",
      "value: 0.37847983837127686\n",
      "policy:\n",
      " 0.11751061677932739 | 0.0 | 0.12036557495594025\n",
      " 0.12700878083705902 | 0.14060549437999725 | 0.1227807104587555\n",
      " 0.13023239374160767 | 0.11191745847463608 | 0.12957900762557983\n",
      "===========\n",
      "choose from [1 0 1 1 1 1 1 1 1] :4\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "-0.2869664\n",
      "[0.242 0.    0.166 0.117 0.    0.125 0.092 0.173 0.086]\n",
      "value: -0.2869664132595062\n",
      "policy:\n",
      " 0.24194589257240295 | 0.0 | 0.16600653529167175\n",
      " 0.1165558472275734 | 0.0 | 0.1253194659948349\n",
      " 0.09165647625923157 | 0.17275278270244598 | 0.08576305210590363\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.8492265\n",
      "[0.    0.    0.204 0.245 0.    0.137 0.292 0.075 0.048]\n",
      "value: 0.8492264747619629\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.20373155176639557\n",
      " 0.24514541029930115 | 0.0 | 0.1368740350008011\n",
      " 0.2915874719619751 | 0.07486338913440704 | 0.04779815301299095\n",
      "===========\n",
      "choose from [0 0 1 1 0 1 1 1 1] :2\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.24669363\n",
      "[0.    0.    0.    0.217 0.    0.149 0.25  0.201 0.184]\n",
      "value: 0.24669362604618073\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.21664899587631226 | 0.0 | 0.1491871178150177\n",
      " 0.24961218237876892 | 0.20064440369606018 | 0.18390730023384094\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 2 | 0\n",
      " 1 | 0 | 0\n",
      "-----------\n",
      "0.31401497\n",
      "[0.    0.    0.    0.103 0.    0.607 0.    0.103 0.187]\n",
      "value: 0.3140149712562561\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.10325335711240768 | 0.0 | 0.6069076657295227\n",
      " 0.0 | 0.10327242314815521 | 0.1865665167570114\n",
      "===========\n",
      "choose from [0 0 0 1 0 1 0 1 1] :3\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 2 | 2 | 0\n",
      " 1 | 0 | 0\n",
      "-----------\n",
      "-0.7273296\n",
      "[0.    0.    0.    0.    0.    0.076 0.    0.588 0.336]\n",
      "value: -0.7273296117782593\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.07602883130311966\n",
      " 0.0 | 0.5877930521965027 | 0.33617809414863586\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 2 | 2 | 0\n",
      " 1 | 1 | 0\n",
      "-----------\n",
      "-0.46471557\n",
      "[0.    0.    0.    0.    0.    0.931 0.    0.    0.069]\n",
      "value: -0.4647155702114105\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.930583119392395\n",
      " 0.0 | 0.0 | 0.0694168284535408\n",
      "===========\n",
      "choose from [0 0 0 0 0 1 0 0 1] :5\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 2 | 2 | 2\n",
      " 1 | 1 | 0\n",
      "-----------\n",
      "-0.7668644\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "value: -0.7668644189834595\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 1.0\n",
      "===========\n",
      "Player -1 won the game after 8 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(last_agent_0_0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_lr_0_0002_27\n"
     ]
    }
   ],
   "source": [
    "best_version = np.argmax(wins_4)\n",
    "\n",
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "best_model_0_0002 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_lr_0_0002\"\n",
    ")\n",
    "best_model_0_0002.load(best_version)\n",
    "best_agent_0_0002 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=best_model_0_0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.32971698\n",
      "[0.115 0.    0.118 0.129 0.138 0.125 0.13  0.114 0.132]\n",
      "value: 0.3297169804573059\n",
      "policy:\n",
      " 0.11475159227848053 | 0.0 | 0.11784227192401886\n",
      " 0.12882934510707855 | 0.13752275705337524 | 0.12518244981765747\n",
      " 0.12980562448501587 | 0.11423487961292267 | 0.13183104991912842\n",
      "===========\n",
      "choose from [1 0 1 1 1 1 1 1 1] :4\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "-0.30895224\n",
      "[0.237 0.    0.17  0.117 0.    0.123 0.092 0.174 0.088]\n",
      "value: -0.3089522421360016\n",
      "policy:\n",
      " 0.23746846616268158 | 0.0 | 0.16951853036880493\n",
      " 0.11710184812545776 | 0.0 | 0.12319333106279373\n",
      " 0.09155654162168503 | 0.1736159324645996 | 0.08754531294107437\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.84630734\n",
      "[0.    0.    0.2   0.251 0.    0.14  0.287 0.075 0.048]\n",
      "value: 0.8463073372840881\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.19987259805202484\n",
      " 0.25094860792160034 | 0.0 | 0.1398068219423294\n",
      " 0.2867220938205719 | 0.07452985644340515 | 0.04811999946832657\n",
      "===========\n",
      "choose from [0 0 1 1 0 1 1 1 1] :2\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "0.25359443\n",
      "[0.    0.    0.    0.219 0.    0.145 0.246 0.2   0.19 ]\n",
      "value: 0.25359442830085754\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.21948105096817017 | 0.0 | 0.1446012705564499\n",
      " 0.24620556831359863 | 0.19979949295520782 | 0.18991266191005707\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 1 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "-0.5241996\n",
      "[0.    0.    0.    0.    0.    0.209 0.408 0.137 0.246]\n",
      "value: -0.5241996049880981\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.20863358676433563\n",
      " 0.40823376178741455 | 0.1373894363641739 | 0.2457432597875595\n",
      "===========\n",
      "choose from [0 0 0 0 0 1 1 1 1] :6\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 1 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "-0.22747563\n",
      "[0.    0.    0.    0.    0.    0.262 0.    0.357 0.38 ]\n",
      "value: -0.2274756282567978\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.2622460126876831\n",
      " 0.0 | 0.3573232591152191 | 0.38043078780174255\n",
      "===========\n",
      "Player -1 won the game after 6 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(best_agent_0_0002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last(1) vs best(2)\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 1 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 2 | 0 | 0\n",
      " 1 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 2 | 0 | 0\n",
      " 1 | 1 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 2 | 2 | 0\n",
      " 1 | 1 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 2 | 2 | 0\n",
      " 1 | 1 | 1\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "last(2) vs best(1)\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 1 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 2 | 2 | 0\n",
      " 1 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 2 | 2 | 0\n",
      " 1 | 1 | 1\n",
      "===========\n",
      "result -  last_0_2: 0 best_0_2: 0\n"
     ]
    }
   ],
   "source": [
    "# best vs last 0_2\n",
    "print(\"last(1) vs best(2)\")\n",
    "winner_a = agent_vs_agent(last_agent_0_2, best_agent_0_2, player=1)    \n",
    "print(\"last(2) vs best(1)\")\n",
    "winner_b = agent_vs_agent(best_agent_0_2, last_agent_0_2, player=1)\n",
    "\n",
    "print(\"result -  last_0_2: {} best_0_2: {}\" .format(winner_a - winner_b, winner_b - winner_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last(1) vs best(2)\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 2 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 2 | 0\n",
      " 2 | 0 | 0\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 2 | 0\n",
      " 2 | 1 | 0\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 2 | 0\n",
      " 2 | 1 | 2\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 2 | 0\n",
      " 2 | 1 | 2\n",
      " 0 | 1 | 1\n",
      "===========\n",
      "last(2) vs best(1)\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 2\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 1\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 2\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 1\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 2\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 1\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 2\n",
      "===========\n",
      "result -  last_0_02: 0 best_0_02: 0\n"
     ]
    }
   ],
   "source": [
    "# best vs last 0_02\n",
    "print(\"last(1) vs best(2)\")\n",
    "winner_a = agent_vs_agent(last_agent_0_02, best_agent_0_02, player=1)    \n",
    "print(\"last(2) vs best(1)\")\n",
    "winner_b = agent_vs_agent(best_agent_0_02, last_agent_0_02, player=1)\n",
    "\n",
    "print(\"result -  last_0_02: {} best_0_02: {}\" .format(winner_a - winner_b, winner_b - winner_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last(1) vs best(2)\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 1\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 1\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 0 | 2 | 1\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 2\n",
      " 0 | 2 | 1\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 2\n",
      " 1 | 2 | 1\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 2\n",
      " 1 | 2 | 1\n",
      " 2 | 0 | 0\n",
      "===========\n",
      "last(2) vs best(1)\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 2 | 2 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 1\n",
      " 0 | 0 | 0\n",
      " 2 | 2 | 0\n",
      "===========\n",
      "result -  last_0_002: -2 best_0_002: 2\n"
     ]
    }
   ],
   "source": [
    "# best vs last 0_002\n",
    "print(\"last(1) vs best(2)\")\n",
    "winner_a = agent_vs_agent(last_agent_0_002, best_agent_0_002, player=1)    \n",
    "print(\"last(2) vs best(1)\")\n",
    "winner_b = agent_vs_agent(best_agent_0_002, last_agent_0_002, player=1)\n",
    "\n",
    "print(\"result -  last_0_002: {} best_0_002: {}\" .format(winner_a - winner_b, winner_b - winner_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last(1) vs best(2)\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 2 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 1\n",
      " 2 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "last(2) vs best(1)\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 1\n",
      " 0 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "===========\n",
      "result -  last_0_0002: 0 best_0_0002: 0\n"
     ]
    }
   ],
   "source": [
    "# best vs last 0_0002\n",
    "print(\"last(1) vs best(2)\")\n",
    "winner_a = agent_vs_agent(last_agent_0_0002, best_agent_0_0002, player=1)    \n",
    "print(\"last(2) vs best(1)\")\n",
    "winner_b = agent_vs_agent(best_agent_0_0002, last_agent_0_0002, player=1)\n",
    "\n",
    "print(\"result -  last_0_0002: {} best_0_0002: {}\" .format(winner_a - winner_b, winner_b - winner_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_agent_0_2(1) vs best_agent_0_02(2)\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      " 1 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 2 | 2\n",
      " 0 | 0 | 0\n",
      " 1 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 2 | 2\n",
      " 0 | 0 | 0\n",
      " 1 | 1 | 1\n",
      "===========\n",
      "best_agent_0_2(2) vs best_agent_0_02(1)\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 2\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 1 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 1 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "===========\n",
      "result -  best_agent_0_2: 2 best_agent_0_02: -2\n"
     ]
    }
   ],
   "source": [
    "# best_agent_0_2 vs best_agent_0_02\n",
    "print(\"best_agent_0_2(1) vs best_agent_0_02(2)\")\n",
    "winner_a = agent_vs_agent(best_agent_0_2, best_agent_0_02, player=1)    \n",
    "print(\"best_agent_0_2(2) vs best_agent_0_02(1)\")\n",
    "winner_b = agent_vs_agent(best_agent_0_02, last_agent_0_2, player=1)\n",
    "\n",
    "print(\"result -  best_agent_0_2: {} best_agent_0_02: {}\" .format(winner_a - winner_b, winner_b - winner_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_agent_0_2(1) vs best_agent_0_002(2)\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 1 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 1 | 1 | 2\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 1 | 1 | 2\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 0 | 2 | 2\n",
      " 1 | 1 | 2\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 1 | 2 | 2\n",
      " 1 | 1 | 2\n",
      "===========\n",
      "best_agent_0_2(2) vs best_agent_0_002(1)\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 2\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 2\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 2\n",
      " 0 | 1 | 2\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 2\n",
      " 0 | 1 | 2\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "result -  best_agent_0_2: 0 best_agent_0_002: 0\n"
     ]
    }
   ],
   "source": [
    "# best_agent_0_2 vs best_agent_0_002\n",
    "print(\"best_agent_0_2(1) vs best_agent_0_002(2)\")\n",
    "winner_a = agent_vs_agent(best_agent_0_2, best_agent_0_002, player=1)    \n",
    "print(\"best_agent_0_2(2) vs best_agent_0_002(1)\")\n",
    "winner_b = agent_vs_agent(best_agent_0_002, last_agent_0_2, player=1)\n",
    "\n",
    "print(\"result -  best_agent_0_2: {} best_agent_0_002: {}\" .format(winner_a - winner_b, winner_b - winner_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_agent_0_2(1) vs best_agent_0_0002(2)\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 1 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 2 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 1 | 1 | 0\n",
      "===========\n",
      "===========\n",
      " 2 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 1 | 1 | 1\n",
      "===========\n",
      "best_agent_0_2(2) vs best_agent_0_0002(1)\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 2\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 2\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 2\n",
      " 0 | 1 | 2\n",
      " 0 | 0 | 0\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 2\n",
      " 0 | 1 | 2\n",
      " 0 | 1 | 0\n",
      "===========\n",
      "result -  best_agent_0_2: 0 best_agent_0_0002: 0\n"
     ]
    }
   ],
   "source": [
    "# best_agent_0_2 vs best_agent_0_0002\n",
    "print(\"best_agent_0_2(1) vs best_agent_0_0002(2)\")\n",
    "winner_a = agent_vs_agent(best_agent_0_2, best_agent_0_0002, player=1)    \n",
    "print(\"best_agent_0_2(2) vs best_agent_0_0002(1)\")\n",
    "winner_b = agent_vs_agent(best_agent_0_0002, last_agent_0_2, player=1)\n",
    "\n",
    "print(\"result -  best_agent_0_2: {} best_agent_0_0002: {}\" .format(winner_a - winner_b, winner_b - winner_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
