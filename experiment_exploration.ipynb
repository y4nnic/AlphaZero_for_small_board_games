{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: TicTacToe - $c_{puct}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from pipeline import Pipeline, agent_vs_player, agent_vs_agent\n",
    "import memory\n",
    "import model\n",
    "import agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $c_{puct}$ = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCTS = {\n",
    "    'c_puct': 1.0,\n",
    "    'dir_alpha': 0.6,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 10,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 10\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 0,\n",
    "    'show_games': False\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.002,\n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 512,\n",
    "    'num_filters_value': 512,\n",
    "    'num_filters_tower': 512,\n",
    "    'num_residual_blocks': 3,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 512\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"tictactoe_c_puct_1\", \"TicTacToe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (4880, 3, 3, 3)\n",
      "model_y_outcomes: (4880,)\n",
      "model_y_probabilities: (4880, 9)\n",
      "Train on 3904 samples, validate on 976 samples\n",
      "Epoch 1/10\n",
      "3904/3904 [==============================] - 4s 1ms/step - loss: 6.6742 - value_loss: 0.9351 - policy_loss: 2.3226 - val_loss: 6.5812 - val_value_loss: 0.8725 - val_policy_loss: 2.1996\n",
      "Epoch 2/10\n",
      "3904/3904 [==============================] - 1s 175us/step - loss: 6.4979 - value_loss: 0.7700 - policy_loss: 2.1359 - val_loss: 6.5390 - val_value_loss: 0.8824 - val_policy_loss: 2.1061\n",
      "Epoch 3/10\n",
      "3904/3904 [==============================] - 1s 175us/step - loss: 6.4085 - value_loss: 0.6807 - policy_loss: 2.0469 - val_loss: 6.4668 - val_value_loss: 0.8098 - val_policy_loss: 2.0349\n",
      "Epoch 4/10\n",
      "3904/3904 [==============================] - 1s 174us/step - loss: 6.3583 - value_loss: 0.6437 - policy_loss: 1.9843 - val_loss: 6.4592 - val_value_loss: 0.8385 - val_policy_loss: 1.9916\n",
      "Epoch 5/10\n",
      "3904/3904 [==============================] - 1s 174us/step - loss: 6.3139 - value_loss: 0.6027 - policy_loss: 1.9372 - val_loss: 6.4173 - val_value_loss: 0.7890 - val_policy_loss: 1.9579\n",
      "Epoch 6/10\n",
      "3904/3904 [==============================] - 1s 176us/step - loss: 6.3084 - value_loss: 0.6272 - policy_loss: 1.9022 - val_loss: 6.4697 - val_value_loss: 0.9255 - val_policy_loss: 1.9268\n",
      "Epoch 7/10\n",
      "3904/3904 [==============================] - 1s 175us/step - loss: 6.2719 - value_loss: 0.5833 - policy_loss: 1.8737 - val_loss: 6.4422 - val_value_loss: 0.8934 - val_policy_loss: 1.9046\n",
      "Epoch 8/10\n",
      "3904/3904 [==============================] - 1s 174us/step - loss: 6.2374 - value_loss: 0.5405 - policy_loss: 1.8482 - val_loss: 6.3634 - val_value_loss: 0.7598 - val_policy_loss: 1.8813\n",
      "Epoch 9/10\n",
      "3904/3904 [==============================] - 1s 175us/step - loss: 6.2406 - value_loss: 0.5675 - policy_loss: 1.8282 - val_loss: 6.3936 - val_value_loss: 0.8371 - val_policy_loss: 1.8651\n",
      "Epoch 10/10\n",
      "3904/3904 [==============================] - 1s 174us/step - loss: 6.2147 - value_loss: 0.5320 - policy_loss: 1.8126 - val_loss: 6.3452 - val_value_loss: 0.7549 - val_policy_loss: 1.8511\n",
      "Saved model  tictactoe_c_puct_1_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.02\n",
      "Number of seen trajectories: 100\n",
      "Number of unique trajectories: 99\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.2715 - value_loss: 0.6577 - policy_loss: 1.8010 - val_loss: 6.2925 - val_value_loss: 0.6952 - val_policy_loss: 1.8059\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2278 - value_loss: 0.5965 - policy_loss: 1.7756 - val_loss: 6.3412 - val_value_loss: 0.8060 - val_policy_loss: 1.7933\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2368 - value_loss: 0.6339 - policy_loss: 1.7568 - val_loss: 6.2730 - val_value_loss: 0.6830 - val_policy_loss: 1.7805\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1831 - value_loss: 0.5435 - policy_loss: 1.7405 - val_loss: 6.2531 - val_value_loss: 0.6527 - val_policy_loss: 1.7717\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1560 - value_loss: 0.5021 - policy_loss: 1.7282 - val_loss: 6.2297 - val_value_loss: 0.6144 - val_policy_loss: 1.7639\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1565 - value_loss: 0.5161 - policy_loss: 1.7159 - val_loss: 6.2292 - val_value_loss: 0.6226 - val_policy_loss: 1.7551\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1433 - value_loss: 0.5004 - policy_loss: 1.7059 - val_loss: 6.2352 - val_value_loss: 0.6423 - val_policy_loss: 1.7480\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1390 - value_loss: 0.5006 - policy_loss: 1.6977 - val_loss: 6.2200 - val_value_loss: 0.6186 - val_policy_loss: 1.7421\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1370 - value_loss: 0.5053 - policy_loss: 1.6896 - val_loss: 6.2164 - val_value_loss: 0.6177 - val_policy_loss: 1.7365\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1236 - value_loss: 0.4854 - policy_loss: 1.6835 - val_loss: 6.2220 - val_value_loss: 0.6351 - val_policy_loss: 1.7309\n",
      "Saved model  tictactoe_c_puct_1_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.72 - draw ratio 0.01\n",
      "Number of seen trajectories: 200\n",
      "Number of unique trajectories: 197\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2440 - value_loss: 0.6809 - policy_loss: 1.7294 - val_loss: 6.2404 - val_value_loss: 0.6714 - val_policy_loss: 1.7320\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2055 - value_loss: 0.6191 - policy_loss: 1.7148 - val_loss: 6.2169 - val_value_loss: 0.6319 - val_policy_loss: 1.7251\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1979 - value_loss: 0.6162 - policy_loss: 1.7032 - val_loss: 6.2385 - val_value_loss: 0.6811 - val_policy_loss: 1.7197\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1721 - value_loss: 0.5733 - policy_loss: 1.6950 - val_loss: 6.2266 - val_value_loss: 0.6641 - val_policy_loss: 1.7135\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1692 - value_loss: 0.5761 - policy_loss: 1.6872 - val_loss: 6.1943 - val_value_loss: 0.6052 - val_policy_loss: 1.7084\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1472 - value_loss: 0.5398 - policy_loss: 1.6801 - val_loss: 6.1936 - val_value_loss: 0.6083 - val_policy_loss: 1.7046\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1293 - value_loss: 0.5105 - policy_loss: 1.6743 - val_loss: 6.1941 - val_value_loss: 0.6139 - val_policy_loss: 1.7006\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1262 - value_loss: 0.5105 - policy_loss: 1.6686 - val_loss: 6.1889 - val_value_loss: 0.6076 - val_policy_loss: 1.6971\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1316 - value_loss: 0.5259 - policy_loss: 1.6645 - val_loss: 6.1862 - val_value_loss: 0.6070 - val_policy_loss: 1.6931\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1221 - value_loss: 0.5114 - policy_loss: 1.6608 - val_loss: 6.1973 - val_value_loss: 0.6317 - val_policy_loss: 1.6912\n",
      "Saved model  tictactoe_c_puct_1_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.0\n",
      "Number of seen trajectories: 300\n",
      "Number of unique trajectories: 291\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 180us/step - loss: 6.1722 - value_loss: 0.5844 - policy_loss: 1.6886 - val_loss: 6.1703 - val_value_loss: 0.5980 - val_policy_loss: 1.6715\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1376 - value_loss: 0.5247 - policy_loss: 1.6797 - val_loss: 6.1853 - val_value_loss: 0.6332 - val_policy_loss: 1.6669\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1249 - value_loss: 0.5067 - policy_loss: 1.6731 - val_loss: 6.1558 - val_value_loss: 0.5798 - val_policy_loss: 1.6620\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1116 - value_loss: 0.4872 - policy_loss: 1.6666 - val_loss: 6.1589 - val_value_loss: 0.5902 - val_policy_loss: 1.6584\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1063 - value_loss: 0.4822 - policy_loss: 1.6615 - val_loss: 6.1541 - val_value_loss: 0.5837 - val_policy_loss: 1.6560\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1052 - value_loss: 0.4849 - policy_loss: 1.6572 - val_loss: 6.1681 - val_value_loss: 0.6152 - val_policy_loss: 1.6532\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0982 - value_loss: 0.4748 - policy_loss: 1.6541 - val_loss: 6.1512 - val_value_loss: 0.5847 - val_policy_loss: 1.6505\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0927 - value_loss: 0.4680 - policy_loss: 1.6504 - val_loss: 6.1415 - val_value_loss: 0.5687 - val_policy_loss: 1.6479\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0853 - value_loss: 0.4571 - policy_loss: 1.6472 - val_loss: 6.1327 - val_value_loss: 0.5543 - val_policy_loss: 1.6452\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0879 - value_loss: 0.4649 - policy_loss: 1.6453 - val_loss: 6.1521 - val_value_loss: 0.5953 - val_policy_loss: 1.6435\n",
      "Saved model  tictactoe_c_puct_1_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.0\n",
      "Number of seen trajectories: 400\n",
      "Number of unique trajectories: 386\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1787 - value_loss: 0.6182 - policy_loss: 1.6741 - val_loss: 6.1865 - val_value_loss: 0.6027 - val_policy_loss: 1.7056\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1518 - value_loss: 0.5719 - policy_loss: 1.6674 - val_loss: 6.1748 - val_value_loss: 0.5832 - val_policy_loss: 1.7024\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1311 - value_loss: 0.5360 - policy_loss: 1.6626 - val_loss: 6.1723 - val_value_loss: 0.5815 - val_policy_loss: 1.6998\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1227 - value_loss: 0.5235 - policy_loss: 1.6588 - val_loss: 6.1673 - val_value_loss: 0.5746 - val_policy_loss: 1.6973\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1222 - value_loss: 0.5276 - policy_loss: 1.6543 - val_loss: 6.1689 - val_value_loss: 0.5797 - val_policy_loss: 1.6960\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1089 - value_loss: 0.5048 - policy_loss: 1.6513 - val_loss: 6.1707 - val_value_loss: 0.5866 - val_policy_loss: 1.6935\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0974 - value_loss: 0.4854 - policy_loss: 1.6482 - val_loss: 6.1621 - val_value_loss: 0.5716 - val_policy_loss: 1.6918\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0921 - value_loss: 0.4786 - policy_loss: 1.6450 - val_loss: 6.1687 - val_value_loss: 0.5871 - val_policy_loss: 1.6901\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0945 - value_loss: 0.4866 - policy_loss: 1.6425 - val_loss: 6.1569 - val_value_loss: 0.5658 - val_policy_loss: 1.6885\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0827 - value_loss: 0.4663 - policy_loss: 1.6399 - val_loss: 6.1596 - val_value_loss: 0.5731 - val_policy_loss: 1.6873\n",
      "Saved model  tictactoe_c_puct_1_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.01\n",
      "Number of seen trajectories: 500\n",
      "Number of unique trajectories: 480\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1721 - value_loss: 0.6323 - policy_loss: 1.6533 - val_loss: 6.1463 - val_value_loss: 0.5996 - val_policy_loss: 1.6344\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1508 - value_loss: 0.5927 - policy_loss: 1.6505 - val_loss: 6.1399 - val_value_loss: 0.5886 - val_policy_loss: 1.6330\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1349 - value_loss: 0.5632 - policy_loss: 1.6484 - val_loss: 6.1379 - val_value_loss: 0.5858 - val_policy_loss: 1.6321\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1272 - value_loss: 0.5502 - policy_loss: 1.6464 - val_loss: 6.1338 - val_value_loss: 0.5787 - val_policy_loss: 1.6313\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1180 - value_loss: 0.5339 - policy_loss: 1.6446 - val_loss: 6.1365 - val_value_loss: 0.5855 - val_policy_loss: 1.6302\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1110 - value_loss: 0.5220 - policy_loss: 1.6430 - val_loss: 6.1312 - val_value_loss: 0.5761 - val_policy_loss: 1.6294\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1072 - value_loss: 0.5164 - policy_loss: 1.6413 - val_loss: 6.1306 - val_value_loss: 0.5762 - val_policy_loss: 1.6284\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1012 - value_loss: 0.5063 - policy_loss: 1.6396 - val_loss: 6.1314 - val_value_loss: 0.5789 - val_policy_loss: 1.6276\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0985 - value_loss: 0.5028 - policy_loss: 1.6381 - val_loss: 6.1299 - val_value_loss: 0.5771 - val_policy_loss: 1.6267\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0933 - value_loss: 0.4945 - policy_loss: 1.6362 - val_loss: 6.1300 - val_value_loss: 0.5784 - val_policy_loss: 1.6259\n",
      "Saved model  tictactoe_c_puct_1_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.01\n",
      "Number of seen trajectories: 600\n",
      "Number of unique trajectories: 570\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1960 - value_loss: 0.6848 - policy_loss: 1.6516 - val_loss: 6.1690 - val_value_loss: 0.6628 - val_policy_loss: 1.6198\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1736 - value_loss: 0.6443 - policy_loss: 1.6478 - val_loss: 6.1643 - val_value_loss: 0.6547 - val_policy_loss: 1.6188\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1602 - value_loss: 0.6197 - policy_loss: 1.6457 - val_loss: 6.1663 - val_value_loss: 0.6599 - val_policy_loss: 1.6181\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1469 - value_loss: 0.5953 - policy_loss: 1.6439 - val_loss: 6.1618 - val_value_loss: 0.6519 - val_policy_loss: 1.6173\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1410 - value_loss: 0.5850 - policy_loss: 1.6427 - val_loss: 6.1558 - val_value_loss: 0.6408 - val_policy_loss: 1.6168\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1334 - value_loss: 0.5725 - policy_loss: 1.6403 - val_loss: 6.1545 - val_value_loss: 0.6394 - val_policy_loss: 1.6159\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1295 - value_loss: 0.5664 - policy_loss: 1.6391 - val_loss: 6.1528 - val_value_loss: 0.6373 - val_policy_loss: 1.6148\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1236 - value_loss: 0.5565 - policy_loss: 1.6374 - val_loss: 6.1515 - val_value_loss: 0.6357 - val_policy_loss: 1.6141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1203 - value_loss: 0.5511 - policy_loss: 1.6365 - val_loss: 6.1507 - val_value_loss: 0.6349 - val_policy_loss: 1.6136\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1175 - value_loss: 0.5475 - policy_loss: 1.6350 - val_loss: 6.1485 - val_value_loss: 0.6319 - val_policy_loss: 1.6126\n",
      "Saved model  tictactoe_c_puct_1_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.0\n",
      "Number of seen trajectories: 700\n",
      "Number of unique trajectories: 659\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1404 - value_loss: 0.5932 - policy_loss: 1.6353 - val_loss: 6.1348 - val_value_loss: 0.5989 - val_policy_loss: 1.6184\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1211 - value_loss: 0.5577 - policy_loss: 1.6325 - val_loss: 6.1407 - val_value_loss: 0.6124 - val_policy_loss: 1.6172\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1088 - value_loss: 0.5354 - policy_loss: 1.6304 - val_loss: 6.1286 - val_value_loss: 0.5893 - val_policy_loss: 1.6164\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1017 - value_loss: 0.5235 - policy_loss: 1.6284 - val_loss: 6.1284 - val_value_loss: 0.5901 - val_policy_loss: 1.6156\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0943 - value_loss: 0.5104 - policy_loss: 1.6272 - val_loss: 6.1257 - val_value_loss: 0.5860 - val_policy_loss: 1.6146\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0910 - value_loss: 0.5037 - policy_loss: 1.6275 - val_loss: 6.1264 - val_value_loss: 0.5883 - val_policy_loss: 1.6139\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0876 - value_loss: 0.5002 - policy_loss: 1.6246 - val_loss: 6.1308 - val_value_loss: 0.5979 - val_policy_loss: 1.6134\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0845 - value_loss: 0.4949 - policy_loss: 1.6240 - val_loss: 6.1272 - val_value_loss: 0.5921 - val_policy_loss: 1.6124\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0827 - value_loss: 0.4938 - policy_loss: 1.6218 - val_loss: 6.1262 - val_value_loss: 0.5908 - val_policy_loss: 1.6120\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0772 - value_loss: 0.4838 - policy_loss: 1.6212 - val_loss: 6.1266 - val_value_loss: 0.5926 - val_policy_loss: 1.6113\n",
      "Saved model  tictactoe_c_puct_1_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.0\n",
      "Number of seen trajectories: 800\n",
      "Number of unique trajectories: 753\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1233 - value_loss: 0.5483 - policy_loss: 1.6492 - val_loss: 6.1225 - val_value_loss: 0.5637 - val_policy_loss: 1.6323\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1014 - value_loss: 0.5072 - policy_loss: 1.6467 - val_loss: 6.1169 - val_value_loss: 0.5538 - val_policy_loss: 1.6314\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0897 - value_loss: 0.4859 - policy_loss: 1.6450 - val_loss: 6.1106 - val_value_loss: 0.5421 - val_policy_loss: 1.6309\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0834 - value_loss: 0.4743 - policy_loss: 1.6443 - val_loss: 6.1087 - val_value_loss: 0.5391 - val_policy_loss: 1.6304\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0761 - value_loss: 0.4618 - policy_loss: 1.6426 - val_loss: 6.1063 - val_value_loss: 0.5352 - val_policy_loss: 1.6297\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0728 - value_loss: 0.4564 - policy_loss: 1.6416 - val_loss: 6.1035 - val_value_loss: 0.5305 - val_policy_loss: 1.6292\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0681 - value_loss: 0.4484 - policy_loss: 1.6406 - val_loss: 6.1057 - val_value_loss: 0.5357 - val_policy_loss: 1.6287\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0656 - value_loss: 0.4451 - policy_loss: 1.6392 - val_loss: 6.1029 - val_value_loss: 0.5309 - val_policy_loss: 1.6282\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0631 - value_loss: 0.4411 - policy_loss: 1.6384 - val_loss: 6.1020 - val_value_loss: 0.5301 - val_policy_loss: 1.6276\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0591 - value_loss: 0.4341 - policy_loss: 1.6378 - val_loss: 6.1034 - val_value_loss: 0.5338 - val_policy_loss: 1.6270\n",
      "Saved model  tictactoe_c_puct_1_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.01\n",
      "Number of seen trajectories: 900\n",
      "Number of unique trajectories: 838\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1449 - value_loss: 0.5967 - policy_loss: 1.6472 - val_loss: 6.1469 - val_value_loss: 0.6196 - val_policy_loss: 1.6283\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1286 - value_loss: 0.5664 - policy_loss: 1.6451 - val_loss: 6.1446 - val_value_loss: 0.6166 - val_policy_loss: 1.6272\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1186 - value_loss: 0.5480 - policy_loss: 1.6439 - val_loss: 6.1493 - val_value_loss: 0.6269 - val_policy_loss: 1.6266\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1078 - value_loss: 0.5286 - policy_loss: 1.6421 - val_loss: 6.1403 - val_value_loss: 0.6101 - val_policy_loss: 1.6258\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1013 - value_loss: 0.5171 - policy_loss: 1.6409 - val_loss: 6.1417 - val_value_loss: 0.6139 - val_policy_loss: 1.6251\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0973 - value_loss: 0.5102 - policy_loss: 1.6400 - val_loss: 6.1467 - val_value_loss: 0.6246 - val_policy_loss: 1.6246\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0933 - value_loss: 0.5032 - policy_loss: 1.6393 - val_loss: 6.1408 - val_value_loss: 0.6137 - val_policy_loss: 1.6241\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0896 - value_loss: 0.4975 - policy_loss: 1.6381 - val_loss: 6.1396 - val_value_loss: 0.6122 - val_policy_loss: 1.6235\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0869 - value_loss: 0.4929 - policy_loss: 1.6376 - val_loss: 6.1390 - val_value_loss: 0.6118 - val_policy_loss: 1.6230\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0841 - value_loss: 0.4886 - policy_loss: 1.6365 - val_loss: 6.1406 - val_value_loss: 0.6157 - val_policy_loss: 1.6225\n",
      "Saved model  tictactoe_c_puct_1_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.0\n",
      "Number of seen trajectories: 1000\n",
      "Number of unique trajectories: 925\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1408 - value_loss: 0.6116 - policy_loss: 1.6273 - val_loss: 6.1229 - val_value_loss: 0.5783 - val_policy_loss: 1.6246\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1275 - value_loss: 0.5863 - policy_loss: 1.6261 - val_loss: 6.1192 - val_value_loss: 0.5714 - val_policy_loss: 1.6243\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1202 - value_loss: 0.5721 - policy_loss: 1.6258 - val_loss: 6.1176 - val_value_loss: 0.5688 - val_policy_loss: 1.6240\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1116 - value_loss: 0.5566 - policy_loss: 1.6243 - val_loss: 6.1158 - val_value_loss: 0.5658 - val_policy_loss: 1.6236\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1063 - value_loss: 0.5461 - policy_loss: 1.6243 - val_loss: 6.1154 - val_value_loss: 0.5653 - val_policy_loss: 1.6234\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1017 - value_loss: 0.5382 - policy_loss: 1.6232 - val_loss: 6.1142 - val_value_loss: 0.5634 - val_policy_loss: 1.6231\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0976 - value_loss: 0.5309 - policy_loss: 1.6225 - val_loss: 6.1134 - val_value_loss: 0.5621 - val_policy_loss: 1.6228\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0945 - value_loss: 0.5252 - policy_loss: 1.6221 - val_loss: 6.1130 - val_value_loss: 0.5617 - val_policy_loss: 1.6226\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0910 - value_loss: 0.5188 - policy_loss: 1.6215 - val_loss: 6.1128 - val_value_loss: 0.5618 - val_policy_loss: 1.6223\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0891 - value_loss: 0.5155 - policy_loss: 1.6214 - val_loss: 6.1117 - val_value_loss: 0.5601 - val_policy_loss: 1.6220\n",
      "Saved model  tictactoe_c_puct_1_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.0\n",
      "Number of seen trajectories: 1100\n",
      "Number of unique trajectories: 1004\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1214 - value_loss: 0.5724 - policy_loss: 1.6293 - val_loss: 6.1096 - val_value_loss: 0.5622 - val_policy_loss: 1.6159\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1087 - value_loss: 0.5477 - policy_loss: 1.6287 - val_loss: 6.1034 - val_value_loss: 0.5505 - val_policy_loss: 1.6153\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1005 - value_loss: 0.5325 - policy_loss: 1.6275 - val_loss: 6.1006 - val_value_loss: 0.5456 - val_policy_loss: 1.6147\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0934 - value_loss: 0.5187 - policy_loss: 1.6273 - val_loss: 6.0973 - val_value_loss: 0.5398 - val_policy_loss: 1.6142\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0897 - value_loss: 0.5120 - policy_loss: 1.6268 - val_loss: 6.0954 - val_value_loss: 0.5364 - val_policy_loss: 1.6139\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0851 - value_loss: 0.5040 - policy_loss: 1.6257 - val_loss: 6.0939 - val_value_loss: 0.5341 - val_policy_loss: 1.6135\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0825 - value_loss: 0.4996 - policy_loss: 1.6252 - val_loss: 6.0930 - val_value_loss: 0.5327 - val_policy_loss: 1.6131\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0794 - value_loss: 0.4942 - policy_loss: 1.6243 - val_loss: 6.0931 - val_value_loss: 0.5335 - val_policy_loss: 1.6127\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0769 - value_loss: 0.4900 - policy_loss: 1.6239 - val_loss: 6.0914 - val_value_loss: 0.5306 - val_policy_loss: 1.6124\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0760 - value_loss: 0.4884 - policy_loss: 1.6239 - val_loss: 6.0909 - val_value_loss: 0.5300 - val_policy_loss: 1.6121\n",
      "Saved model  tictactoe_c_puct_1_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.01\n",
      "Number of seen trajectories: 1200\n",
      "Number of unique trajectories: 1079\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1352 - value_loss: 0.5965 - policy_loss: 1.6343 - val_loss: 6.1091 - val_value_loss: 0.5805 - val_policy_loss: 1.5981\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1235 - value_loss: 0.5742 - policy_loss: 1.6333 - val_loss: 6.1085 - val_value_loss: 0.5798 - val_policy_loss: 1.5978\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1184 - value_loss: 0.5646 - policy_loss: 1.6328 - val_loss: 6.1026 - val_value_loss: 0.5687 - val_policy_loss: 1.5974\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1104 - value_loss: 0.5500 - policy_loss: 1.6315 - val_loss: 6.1027 - val_value_loss: 0.5691 - val_policy_loss: 1.5971\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1071 - value_loss: 0.5439 - policy_loss: 1.6313 - val_loss: 6.1008 - val_value_loss: 0.5659 - val_policy_loss: 1.5969\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1030 - value_loss: 0.5362 - policy_loss: 1.6308 - val_loss: 6.0978 - val_value_loss: 0.5600 - val_policy_loss: 1.5968\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0994 - value_loss: 0.5299 - policy_loss: 1.6303 - val_loss: 6.0965 - val_value_loss: 0.5579 - val_policy_loss: 1.5966\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0955 - value_loss: 0.5229 - policy_loss: 1.6297 - val_loss: 6.0947 - val_value_loss: 0.5545 - val_policy_loss: 1.5964\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0928 - value_loss: 0.5182 - policy_loss: 1.6290 - val_loss: 6.0934 - val_value_loss: 0.5524 - val_policy_loss: 1.5962\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0907 - value_loss: 0.5146 - policy_loss: 1.6286 - val_loss: 6.0941 - val_value_loss: 0.5542 - val_policy_loss: 1.5960\n",
      "Saved model  tictactoe_c_puct_1_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.01\n",
      "Number of seen trajectories: 1300\n",
      "Number of unique trajectories: 1164\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1472 - value_loss: 0.6331 - policy_loss: 1.6232 - val_loss: 6.1273 - val_value_loss: 0.6267 - val_policy_loss: 1.5901\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1356 - value_loss: 0.6104 - policy_loss: 1.6229 - val_loss: 6.1256 - val_value_loss: 0.6236 - val_policy_loss: 1.5898\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1296 - value_loss: 0.6002 - policy_loss: 1.6213 - val_loss: 6.1235 - val_value_loss: 0.6197 - val_policy_loss: 1.5896\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1234 - value_loss: 0.5889 - policy_loss: 1.6204 - val_loss: 6.1230 - val_value_loss: 0.6191 - val_policy_loss: 1.5894\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1194 - value_loss: 0.5812 - policy_loss: 1.6203 - val_loss: 6.1210 - val_value_loss: 0.6155 - val_policy_loss: 1.5892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1142 - value_loss: 0.5720 - policy_loss: 1.6192 - val_loss: 6.1205 - val_value_loss: 0.6148 - val_policy_loss: 1.5890\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1118 - value_loss: 0.5678 - policy_loss: 1.6187 - val_loss: 6.1192 - val_value_loss: 0.6126 - val_policy_loss: 1.5887\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1068 - value_loss: 0.5589 - policy_loss: 1.6178 - val_loss: 6.1188 - val_value_loss: 0.6121 - val_policy_loss: 1.5885\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1063 - value_loss: 0.5582 - policy_loss: 1.6176 - val_loss: 6.1198 - val_value_loss: 0.6146 - val_policy_loss: 1.5883\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1022 - value_loss: 0.5510 - policy_loss: 1.6167 - val_loss: 6.1188 - val_value_loss: 0.6129 - val_policy_loss: 1.5882\n",
      "Saved model  tictactoe_c_puct_1_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.01\n",
      "Number of seen trajectories: 1400\n",
      "Number of unique trajectories: 1244\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1411 - value_loss: 0.6349 - policy_loss: 1.6109 - val_loss: 6.1112 - val_value_loss: 0.5673 - val_policy_loss: 1.6187\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1296 - value_loss: 0.6122 - policy_loss: 1.6106 - val_loss: 6.1090 - val_value_loss: 0.5633 - val_policy_loss: 1.6185\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1215 - value_loss: 0.5975 - policy_loss: 1.6094 - val_loss: 6.1084 - val_value_loss: 0.5623 - val_policy_loss: 1.6184\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1140 - value_loss: 0.5831 - policy_loss: 1.6089 - val_loss: 6.1076 - val_value_loss: 0.5611 - val_policy_loss: 1.6182\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1100 - value_loss: 0.5758 - policy_loss: 1.6084 - val_loss: 6.1087 - val_value_loss: 0.5636 - val_policy_loss: 1.6181\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1031 - value_loss: 0.5632 - policy_loss: 1.6073 - val_loss: 6.1075 - val_value_loss: 0.5616 - val_policy_loss: 1.6179\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1005 - value_loss: 0.5586 - policy_loss: 1.6069 - val_loss: 6.1075 - val_value_loss: 0.5618 - val_policy_loss: 1.6177\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0964 - value_loss: 0.5510 - policy_loss: 1.6065 - val_loss: 6.1085 - val_value_loss: 0.5643 - val_policy_loss: 1.6175\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0943 - value_loss: 0.5479 - policy_loss: 1.6054 - val_loss: 6.1079 - val_value_loss: 0.5633 - val_policy_loss: 1.6173\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0913 - value_loss: 0.5421 - policy_loss: 1.6056 - val_loss: 6.1074 - val_value_loss: 0.5627 - val_policy_loss: 1.6172\n",
      "Saved model  tictactoe_c_puct_1_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.02\n",
      "Number of seen trajectories: 1500\n",
      "Number of unique trajectories: 1326\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1484 - value_loss: 0.6453 - policy_loss: 1.6166 - val_loss: 6.1517 - val_value_loss: 0.6572 - val_policy_loss: 1.6114\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1399 - value_loss: 0.6284 - policy_loss: 1.6165 - val_loss: 6.1467 - val_value_loss: 0.6476 - val_policy_loss: 1.6110\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1332 - value_loss: 0.6164 - policy_loss: 1.6153 - val_loss: 6.1429 - val_value_loss: 0.6405 - val_policy_loss: 1.6107\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1280 - value_loss: 0.6062 - policy_loss: 1.6151 - val_loss: 6.1407 - val_value_loss: 0.6363 - val_policy_loss: 1.6105\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1228 - value_loss: 0.5969 - policy_loss: 1.6142 - val_loss: 6.1375 - val_value_loss: 0.6302 - val_policy_loss: 1.6103\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1201 - value_loss: 0.5913 - policy_loss: 1.6145 - val_loss: 6.1359 - val_value_loss: 0.6271 - val_policy_loss: 1.6101\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1164 - value_loss: 0.5846 - policy_loss: 1.6138 - val_loss: 6.1348 - val_value_loss: 0.6251 - val_policy_loss: 1.6100\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1136 - value_loss: 0.5793 - policy_loss: 1.6136 - val_loss: 6.1335 - val_value_loss: 0.6228 - val_policy_loss: 1.6099\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1109 - value_loss: 0.5747 - policy_loss: 1.6129 - val_loss: 6.1330 - val_value_loss: 0.6220 - val_policy_loss: 1.6097\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1084 - value_loss: 0.5699 - policy_loss: 1.6127 - val_loss: 6.1316 - val_value_loss: 0.6194 - val_policy_loss: 1.6096\n",
      "Saved model  tictactoe_c_puct_1_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.05\n",
      "Number of seen trajectories: 1600\n",
      "Number of unique trajectories: 1407\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 6.1431 - value_loss: 0.6169 - policy_loss: 1.6353 - val_loss: 6.1343 - val_value_loss: 0.6164 - val_policy_loss: 1.6182\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1365 - value_loss: 0.6045 - policy_loss: 1.6345 - val_loss: 6.1325 - val_value_loss: 0.6131 - val_policy_loss: 1.6179\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1301 - value_loss: 0.5925 - policy_loss: 1.6339 - val_loss: 6.1311 - val_value_loss: 0.6106 - val_policy_loss: 1.6177\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1251 - value_loss: 0.5829 - policy_loss: 1.6335 - val_loss: 6.1297 - val_value_loss: 0.6080 - val_policy_loss: 1.6175\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1208 - value_loss: 0.5743 - policy_loss: 1.6335 - val_loss: 6.1286 - val_value_loss: 0.6061 - val_policy_loss: 1.6173\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1175 - value_loss: 0.5677 - policy_loss: 1.6337 - val_loss: 6.1280 - val_value_loss: 0.6053 - val_policy_loss: 1.6171\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1151 - value_loss: 0.5632 - policy_loss: 1.6334 - val_loss: 6.1273 - val_value_loss: 0.6040 - val_policy_loss: 1.6170\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1129 - value_loss: 0.5596 - policy_loss: 1.6327 - val_loss: 6.1262 - val_value_loss: 0.6021 - val_policy_loss: 1.6168\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1097 - value_loss: 0.5536 - policy_loss: 1.6324 - val_loss: 6.1255 - val_value_loss: 0.6009 - val_policy_loss: 1.6166\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1073 - value_loss: 0.5487 - policy_loss: 1.6325 - val_loss: 6.1248 - val_value_loss: 0.5998 - val_policy_loss: 1.6164\n",
      "Saved model  tictactoe_c_puct_1_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.01\n",
      "Number of seen trajectories: 1700\n",
      "Number of unique trajectories: 1482\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1258 - value_loss: 0.6168 - policy_loss: 1.6014 - val_loss: 6.1252 - val_value_loss: 0.5941 - val_policy_loss: 1.6231\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1168 - value_loss: 0.5991 - policy_loss: 1.6012 - val_loss: 6.1222 - val_value_loss: 0.5883 - val_policy_loss: 1.6230\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1095 - value_loss: 0.5856 - policy_loss: 1.6003 - val_loss: 6.1197 - val_value_loss: 0.5833 - val_policy_loss: 1.6229\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1049 - value_loss: 0.5763 - policy_loss: 1.6006 - val_loss: 6.1178 - val_value_loss: 0.5798 - val_policy_loss: 1.6229\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0985 - value_loss: 0.5638 - policy_loss: 1.6001 - val_loss: 6.1170 - val_value_loss: 0.5782 - val_policy_loss: 1.6228\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0949 - value_loss: 0.5573 - policy_loss: 1.5995 - val_loss: 6.1171 - val_value_loss: 0.5786 - val_policy_loss: 1.6228\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0909 - value_loss: 0.5490 - policy_loss: 1.6001 - val_loss: 6.1167 - val_value_loss: 0.5779 - val_policy_loss: 1.6227\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0877 - value_loss: 0.5435 - policy_loss: 1.5992 - val_loss: 6.1164 - val_value_loss: 0.5775 - val_policy_loss: 1.6226\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0850 - value_loss: 0.5385 - policy_loss: 1.5989 - val_loss: 6.1169 - val_value_loss: 0.5787 - val_policy_loss: 1.6225\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0832 - value_loss: 0.5348 - policy_loss: 1.5990 - val_loss: 6.1165 - val_value_loss: 0.5779 - val_policy_loss: 1.6224\n",
      "Saved model  tictactoe_c_puct_1_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.81 - draw ratio 0.05\n",
      "Number of seen trajectories: 1800\n",
      "Number of unique trajectories: 1564\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1208 - value_loss: 0.5843 - policy_loss: 1.6249 - val_loss: 6.1262 - val_value_loss: 0.5877 - val_policy_loss: 1.6323\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1131 - value_loss: 0.5689 - policy_loss: 1.6249 - val_loss: 6.1222 - val_value_loss: 0.5800 - val_policy_loss: 1.6320\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1063 - value_loss: 0.5555 - policy_loss: 1.6247 - val_loss: 6.1195 - val_value_loss: 0.5748 - val_policy_loss: 1.6319\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1009 - value_loss: 0.5456 - policy_loss: 1.6240 - val_loss: 6.1165 - val_value_loss: 0.5692 - val_policy_loss: 1.6317\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0968 - value_loss: 0.5379 - policy_loss: 1.6235 - val_loss: 6.1151 - val_value_loss: 0.5664 - val_policy_loss: 1.6316\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0929 - value_loss: 0.5303 - policy_loss: 1.6235 - val_loss: 6.1145 - val_value_loss: 0.5654 - val_policy_loss: 1.6315\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0903 - value_loss: 0.5249 - policy_loss: 1.6237 - val_loss: 6.1130 - val_value_loss: 0.5627 - val_policy_loss: 1.6314\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0864 - value_loss: 0.5179 - policy_loss: 1.6230 - val_loss: 6.1125 - val_value_loss: 0.5619 - val_policy_loss: 1.6313\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0849 - value_loss: 0.5155 - policy_loss: 1.6224 - val_loss: 6.1116 - val_value_loss: 0.5602 - val_policy_loss: 1.6312\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0822 - value_loss: 0.5101 - policy_loss: 1.6227 - val_loss: 6.1112 - val_value_loss: 0.5595 - val_policy_loss: 1.6311\n",
      "Saved model  tictactoe_c_puct_1_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.04\n",
      "Number of seen trajectories: 1900\n",
      "Number of unique trajectories: 1634\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0965 - value_loss: 0.5651 - policy_loss: 1.5961 - val_loss: 6.0841 - val_value_loss: 0.5647 - val_policy_loss: 1.5719\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0869 - value_loss: 0.5464 - policy_loss: 1.5957 - val_loss: 6.0805 - val_value_loss: 0.5576 - val_policy_loss: 1.5718\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0804 - value_loss: 0.5339 - policy_loss: 1.5955 - val_loss: 6.0778 - val_value_loss: 0.5523 - val_policy_loss: 1.5717\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0766 - value_loss: 0.5261 - policy_loss: 1.5957 - val_loss: 6.0761 - val_value_loss: 0.5492 - val_policy_loss: 1.5716\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0708 - value_loss: 0.5155 - policy_loss: 1.5947 - val_loss: 6.0748 - val_value_loss: 0.5467 - val_policy_loss: 1.5716\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0667 - value_loss: 0.5079 - policy_loss: 1.5942 - val_loss: 6.0737 - val_value_loss: 0.5448 - val_policy_loss: 1.5715\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0646 - value_loss: 0.5037 - policy_loss: 1.5944 - val_loss: 6.0729 - val_value_loss: 0.5433 - val_policy_loss: 1.5714\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0610 - value_loss: 0.4971 - policy_loss: 1.5937 - val_loss: 6.0724 - val_value_loss: 0.5424 - val_policy_loss: 1.5713\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0574 - value_loss: 0.4909 - policy_loss: 1.5929 - val_loss: 6.0720 - val_value_loss: 0.5418 - val_policy_loss: 1.5712\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0556 - value_loss: 0.4871 - policy_loss: 1.5931 - val_loss: 6.0717 - val_value_loss: 0.5413 - val_policy_loss: 1.5711\n",
      "Saved model  tictactoe_c_puct_1_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.77 - draw ratio 0.04\n",
      "Number of seen trajectories: 2000\n",
      "Number of unique trajectories: 1710\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1223 - value_loss: 0.5965 - policy_loss: 1.6172 - val_loss: 6.1044 - val_value_loss: 0.5908 - val_policy_loss: 1.5870\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1189 - value_loss: 0.5899 - policy_loss: 1.6171 - val_loss: 6.1022 - val_value_loss: 0.5866 - val_policy_loss: 1.5868\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1149 - value_loss: 0.5820 - policy_loss: 1.6170 - val_loss: 6.1004 - val_value_loss: 0.5832 - val_policy_loss: 1.5867\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1114 - value_loss: 0.5745 - policy_loss: 1.6174 - val_loss: 6.0989 - val_value_loss: 0.5805 - val_policy_loss: 1.5866\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1074 - value_loss: 0.5677 - policy_loss: 1.6164 - val_loss: 6.0977 - val_value_loss: 0.5782 - val_policy_loss: 1.5865\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1051 - value_loss: 0.5636 - policy_loss: 1.6158 - val_loss: 6.0967 - val_value_loss: 0.5764 - val_policy_loss: 1.5864\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1021 - value_loss: 0.5579 - policy_loss: 1.6156 - val_loss: 6.0958 - val_value_loss: 0.5747 - val_policy_loss: 1.5863\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0993 - value_loss: 0.5529 - policy_loss: 1.6152 - val_loss: 6.0951 - val_value_loss: 0.5734 - val_policy_loss: 1.5862\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0966 - value_loss: 0.5472 - policy_loss: 1.6153 - val_loss: 6.0945 - val_value_loss: 0.5722 - val_policy_loss: 1.5862\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0957 - value_loss: 0.5450 - policy_loss: 1.6158 - val_loss: 6.0940 - val_value_loss: 0.5713 - val_policy_loss: 1.5861\n",
      "Saved model  tictactoe_c_puct_1_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.01\n",
      "Number of seen trajectories: 2100\n",
      "Number of unique trajectories: 1778\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.0944 - value_loss: 0.5705 - policy_loss: 1.5878 - val_loss: 6.1311 - val_value_loss: 0.6274 - val_policy_loss: 1.6043\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0885 - value_loss: 0.5589 - policy_loss: 1.5877 - val_loss: 6.1280 - val_value_loss: 0.6213 - val_policy_loss: 1.6043\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0846 - value_loss: 0.5513 - policy_loss: 1.5875 - val_loss: 6.1256 - val_value_loss: 0.6166 - val_policy_loss: 1.6042\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0802 - value_loss: 0.5431 - policy_loss: 1.5870 - val_loss: 6.1237 - val_value_loss: 0.6130 - val_policy_loss: 1.6042\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0776 - value_loss: 0.5380 - policy_loss: 1.5869 - val_loss: 6.1224 - val_value_loss: 0.6103 - val_policy_loss: 1.6041\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0749 - value_loss: 0.5329 - policy_loss: 1.5865 - val_loss: 6.1212 - val_value_loss: 0.6081 - val_policy_loss: 1.6041\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0726 - value_loss: 0.5284 - policy_loss: 1.5865 - val_loss: 6.1201 - val_value_loss: 0.6060 - val_policy_loss: 1.6040\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0696 - value_loss: 0.5227 - policy_loss: 1.5863 - val_loss: 6.1192 - val_value_loss: 0.6043 - val_policy_loss: 1.6040\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0685 - value_loss: 0.5202 - policy_loss: 1.5866 - val_loss: 6.1184 - val_value_loss: 0.6026 - val_policy_loss: 1.6039\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0659 - value_loss: 0.5159 - policy_loss: 1.5858 - val_loss: 6.1177 - val_value_loss: 0.6015 - val_policy_loss: 1.6039\n",
      "Saved model  tictactoe_c_puct_1_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.02\n",
      "Number of seen trajectories: 2200\n",
      "Number of unique trajectories: 1849\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1040 - value_loss: 0.5676 - policy_loss: 1.6104 - val_loss: 6.0905 - val_value_loss: 0.5470 - val_policy_loss: 1.6040\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0982 - value_loss: 0.5567 - policy_loss: 1.6097 - val_loss: 6.0881 - val_value_loss: 0.5423 - val_policy_loss: 1.6038\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0946 - value_loss: 0.5496 - policy_loss: 1.6096 - val_loss: 6.0859 - val_value_loss: 0.5381 - val_policy_loss: 1.6037\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0920 - value_loss: 0.5443 - policy_loss: 1.6096 - val_loss: 6.0843 - val_value_loss: 0.5351 - val_policy_loss: 1.6036\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0886 - value_loss: 0.5382 - policy_loss: 1.6090 - val_loss: 6.0825 - val_value_loss: 0.5317 - val_policy_loss: 1.6035\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0852 - value_loss: 0.5318 - policy_loss: 1.6086 - val_loss: 6.0810 - val_value_loss: 0.5287 - val_policy_loss: 1.6034\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0829 - value_loss: 0.5274 - policy_loss: 1.6086 - val_loss: 6.0799 - val_value_loss: 0.5265 - val_policy_loss: 1.6034\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0813 - value_loss: 0.5237 - policy_loss: 1.6090 - val_loss: 6.0785 - val_value_loss: 0.5239 - val_policy_loss: 1.6033\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0777 - value_loss: 0.5175 - policy_loss: 1.6081 - val_loss: 6.0775 - val_value_loss: 0.5220 - val_policy_loss: 1.6032\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0752 - value_loss: 0.5126 - policy_loss: 1.6081 - val_loss: 6.0764 - val_value_loss: 0.5198 - val_policy_loss: 1.6032\n",
      "Saved model  tictactoe_c_puct_1_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.03\n",
      "Number of seen trajectories: 2300\n",
      "Number of unique trajectories: 1913\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1154 - value_loss: 0.5859 - policy_loss: 1.6152 - val_loss: 6.1011 - val_value_loss: 0.5758 - val_policy_loss: 1.5966\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1089 - value_loss: 0.5737 - policy_loss: 1.6144 - val_loss: 6.0992 - val_value_loss: 0.5723 - val_policy_loss: 1.5965\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1061 - value_loss: 0.5682 - policy_loss: 1.6144 - val_loss: 6.0981 - val_value_loss: 0.5703 - val_policy_loss: 1.5964\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1022 - value_loss: 0.5607 - policy_loss: 1.6140 - val_loss: 6.0971 - val_value_loss: 0.5683 - val_policy_loss: 1.5963\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0996 - value_loss: 0.5552 - policy_loss: 1.6144 - val_loss: 6.0964 - val_value_loss: 0.5670 - val_policy_loss: 1.5962\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0980 - value_loss: 0.5523 - policy_loss: 1.6142 - val_loss: 6.0959 - val_value_loss: 0.5661 - val_policy_loss: 1.5962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0954 - value_loss: 0.5473 - policy_loss: 1.6140 - val_loss: 6.0955 - val_value_loss: 0.5654 - val_policy_loss: 1.5961\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0931 - value_loss: 0.5432 - policy_loss: 1.6135 - val_loss: 6.0949 - val_value_loss: 0.5643 - val_policy_loss: 1.5960\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0912 - value_loss: 0.5397 - policy_loss: 1.6134 - val_loss: 6.0945 - val_value_loss: 0.5636 - val_policy_loss: 1.5960\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0888 - value_loss: 0.5349 - policy_loss: 1.6133 - val_loss: 6.0940 - val_value_loss: 0.5627 - val_policy_loss: 1.5959\n",
      "Saved model  tictactoe_c_puct_1_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.03\n",
      "Number of seen trajectories: 2400\n",
      "Number of unique trajectories: 1984\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1345 - value_loss: 0.6291 - policy_loss: 1.6106 - val_loss: 6.1227 - val_value_loss: 0.6089 - val_policy_loss: 1.6073\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1275 - value_loss: 0.6157 - policy_loss: 1.6100 - val_loss: 6.1208 - val_value_loss: 0.6053 - val_policy_loss: 1.6071\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1233 - value_loss: 0.6079 - policy_loss: 1.6095 - val_loss: 6.1185 - val_value_loss: 0.6009 - val_policy_loss: 1.6070\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1201 - value_loss: 0.6019 - policy_loss: 1.6091 - val_loss: 6.1167 - val_value_loss: 0.5974 - val_policy_loss: 1.6069\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1167 - value_loss: 0.5956 - policy_loss: 1.6087 - val_loss: 6.1156 - val_value_loss: 0.5954 - val_policy_loss: 1.6068\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1154 - value_loss: 0.5923 - policy_loss: 1.6094 - val_loss: 6.1150 - val_value_loss: 0.5942 - val_policy_loss: 1.6067\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1119 - value_loss: 0.5858 - policy_loss: 1.6088 - val_loss: 6.1136 - val_value_loss: 0.5915 - val_policy_loss: 1.6066\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1093 - value_loss: 0.5810 - policy_loss: 1.6086 - val_loss: 6.1126 - val_value_loss: 0.5897 - val_policy_loss: 1.6065\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1078 - value_loss: 0.5785 - policy_loss: 1.6080 - val_loss: 6.1120 - val_value_loss: 0.5885 - val_policy_loss: 1.6065\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1054 - value_loss: 0.5742 - policy_loss: 1.6077 - val_loss: 6.1117 - val_value_loss: 0.5880 - val_policy_loss: 1.6064\n",
      "Saved model  tictactoe_c_puct_1_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.02\n",
      "Number of seen trajectories: 2500\n",
      "Number of unique trajectories: 2055\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1325 - value_loss: 0.6134 - policy_loss: 1.6226 - val_loss: 6.1304 - val_value_loss: 0.6102 - val_policy_loss: 1.6217\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1307 - value_loss: 0.6098 - policy_loss: 1.6227 - val_loss: 6.1302 - val_value_loss: 0.6098 - val_policy_loss: 1.6216\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1293 - value_loss: 0.6074 - policy_loss: 1.6222 - val_loss: 6.1298 - val_value_loss: 0.6092 - val_policy_loss: 1.6215\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1278 - value_loss: 0.6043 - policy_loss: 1.6225 - val_loss: 6.1295 - val_value_loss: 0.6088 - val_policy_loss: 1.6214\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1275 - value_loss: 0.6030 - policy_loss: 1.6231 - val_loss: 6.1293 - val_value_loss: 0.6085 - val_policy_loss: 1.6213\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1256 - value_loss: 0.5999 - policy_loss: 1.6225 - val_loss: 6.1293 - val_value_loss: 0.6086 - val_policy_loss: 1.6212\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1237 - value_loss: 0.5967 - policy_loss: 1.6218 - val_loss: 6.1292 - val_value_loss: 0.6085 - val_policy_loss: 1.6211\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1231 - value_loss: 0.5956 - policy_loss: 1.6218 - val_loss: 6.1292 - val_value_loss: 0.6085 - val_policy_loss: 1.6210\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1213 - value_loss: 0.5916 - policy_loss: 1.6222 - val_loss: 6.1292 - val_value_loss: 0.6087 - val_policy_loss: 1.6210\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1213 - value_loss: 0.5920 - policy_loss: 1.6219 - val_loss: 6.1292 - val_value_loss: 0.6088 - val_policy_loss: 1.6209\n",
      "Saved model  tictactoe_c_puct_1_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.03\n",
      "Number of seen trajectories: 2600\n",
      "Number of unique trajectories: 2125\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1088 - value_loss: 0.5870 - policy_loss: 1.6019 - val_loss: 6.1358 - val_value_loss: 0.6284 - val_policy_loss: 1.6146\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1044 - value_loss: 0.5786 - policy_loss: 1.6015 - val_loss: 6.1334 - val_value_loss: 0.6236 - val_policy_loss: 1.6144\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1012 - value_loss: 0.5723 - policy_loss: 1.6014 - val_loss: 6.1314 - val_value_loss: 0.6199 - val_policy_loss: 1.6143\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0983 - value_loss: 0.5671 - policy_loss: 1.6009 - val_loss: 6.1298 - val_value_loss: 0.6168 - val_policy_loss: 1.6142\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0962 - value_loss: 0.5625 - policy_loss: 1.6013 - val_loss: 6.1285 - val_value_loss: 0.6143 - val_policy_loss: 1.6142\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0942 - value_loss: 0.5586 - policy_loss: 1.6012 - val_loss: 6.1275 - val_value_loss: 0.6123 - val_policy_loss: 1.6141\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0917 - value_loss: 0.5538 - policy_loss: 1.6010 - val_loss: 6.1266 - val_value_loss: 0.6105 - val_policy_loss: 1.6140\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0904 - value_loss: 0.5515 - policy_loss: 1.6007 - val_loss: 6.1258 - val_value_loss: 0.6091 - val_policy_loss: 1.6140\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0892 - value_loss: 0.5488 - policy_loss: 1.6011 - val_loss: 6.1251 - val_value_loss: 0.6077 - val_policy_loss: 1.6139\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0867 - value_loss: 0.5442 - policy_loss: 1.6007 - val_loss: 6.1245 - val_value_loss: 0.6067 - val_policy_loss: 1.6138\n",
      "Saved model  tictactoe_c_puct_1_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.77 - draw ratio 0.02\n",
      "Number of seen trajectories: 2700\n",
      "Number of unique trajectories: 2183\n",
      "iteration 27 | self-play\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving memory position_memory_tictactoe_c_puct_1_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1376 - value_loss: 0.6231 - policy_loss: 1.6236 - val_loss: 6.1530 - val_value_loss: 0.6507 - val_policy_loss: 1.6267\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1349 - value_loss: 0.6175 - policy_loss: 1.6238 - val_loss: 6.1516 - val_value_loss: 0.6481 - val_policy_loss: 1.6267\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1319 - value_loss: 0.6121 - policy_loss: 1.6233 - val_loss: 6.1505 - val_value_loss: 0.6460 - val_policy_loss: 1.6266\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1307 - value_loss: 0.6093 - policy_loss: 1.6237 - val_loss: 6.1497 - val_value_loss: 0.6444 - val_policy_loss: 1.6265\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1297 - value_loss: 0.6074 - policy_loss: 1.6235 - val_loss: 6.1489 - val_value_loss: 0.6429 - val_policy_loss: 1.6265\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1273 - value_loss: 0.6031 - policy_loss: 1.6231 - val_loss: 6.1482 - val_value_loss: 0.6415 - val_policy_loss: 1.6265\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1260 - value_loss: 0.6008 - policy_loss: 1.6229 - val_loss: 6.1475 - val_value_loss: 0.6402 - val_policy_loss: 1.6264\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1241 - value_loss: 0.5971 - policy_loss: 1.6229 - val_loss: 6.1468 - val_value_loss: 0.6389 - val_policy_loss: 1.6264\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1235 - value_loss: 0.5954 - policy_loss: 1.6233 - val_loss: 6.1462 - val_value_loss: 0.6377 - val_policy_loss: 1.6263\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1219 - value_loss: 0.5927 - policy_loss: 1.6228 - val_loss: 6.1456 - val_value_loss: 0.6366 - val_policy_loss: 1.6263\n",
      "Saved model  tictactoe_c_puct_1_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.0\n",
      "Number of seen trajectories: 2800\n",
      "Number of unique trajectories: 2250\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1293 - value_loss: 0.6316 - policy_loss: 1.5988 - val_loss: 6.0795 - val_value_loss: 0.5492 - val_policy_loss: 1.5814\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1268 - value_loss: 0.6269 - policy_loss: 1.5983 - val_loss: 6.0783 - val_value_loss: 0.5470 - val_policy_loss: 1.5814\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1254 - value_loss: 0.6245 - policy_loss: 1.5980 - val_loss: 6.0773 - val_value_loss: 0.5450 - val_policy_loss: 1.5814\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1223 - value_loss: 0.6189 - policy_loss: 1.5974 - val_loss: 6.0765 - val_value_loss: 0.5433 - val_policy_loss: 1.5815\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1210 - value_loss: 0.6163 - policy_loss: 1.5975 - val_loss: 6.0758 - val_value_loss: 0.5418 - val_policy_loss: 1.5815\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1189 - value_loss: 0.6124 - policy_loss: 1.5973 - val_loss: 6.0752 - val_value_loss: 0.5406 - val_policy_loss: 1.5816\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1177 - value_loss: 0.6093 - policy_loss: 1.5980 - val_loss: 6.0747 - val_value_loss: 0.5395 - val_policy_loss: 1.5816\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1161 - value_loss: 0.6065 - policy_loss: 1.5976 - val_loss: 6.0743 - val_value_loss: 0.5387 - val_policy_loss: 1.5816\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1144 - value_loss: 0.6036 - policy_loss: 1.5970 - val_loss: 6.0739 - val_value_loss: 0.5380 - val_policy_loss: 1.5817\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1132 - value_loss: 0.6014 - policy_loss: 1.5969 - val_loss: 6.0735 - val_value_loss: 0.5372 - val_policy_loss: 1.5817\n",
      "Saved model  tictactoe_c_puct_1_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.02\n",
      "Number of seen trajectories: 2900\n",
      "Number of unique trajectories: 2324\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1484 - value_loss: 0.6362 - policy_loss: 1.6325 - val_loss: 6.1280 - val_value_loss: 0.5957 - val_policy_loss: 1.6322\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1456 - value_loss: 0.6309 - policy_loss: 1.6323 - val_loss: 6.1265 - val_value_loss: 0.5928 - val_policy_loss: 1.6321\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1442 - value_loss: 0.6285 - policy_loss: 1.6317 - val_loss: 6.1255 - val_value_loss: 0.5909 - val_policy_loss: 1.6320\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1423 - value_loss: 0.6244 - policy_loss: 1.6321 - val_loss: 6.1248 - val_value_loss: 0.5895 - val_policy_loss: 1.6320\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1415 - value_loss: 0.6230 - policy_loss: 1.6320 - val_loss: 6.1242 - val_value_loss: 0.5885 - val_policy_loss: 1.6319\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1393 - value_loss: 0.6191 - policy_loss: 1.6315 - val_loss: 6.1238 - val_value_loss: 0.5876 - val_policy_loss: 1.6319\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1377 - value_loss: 0.6158 - policy_loss: 1.6316 - val_loss: 6.1235 - val_value_loss: 0.5871 - val_policy_loss: 1.6318\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1359 - value_loss: 0.6127 - policy_loss: 1.6312 - val_loss: 6.1233 - val_value_loss: 0.5870 - val_policy_loss: 1.6318\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1359 - value_loss: 0.6119 - policy_loss: 1.6319 - val_loss: 6.1232 - val_value_loss: 0.5868 - val_policy_loss: 1.6317\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1339 - value_loss: 0.6085 - policy_loss: 1.6314 - val_loss: 6.1230 - val_value_loss: 0.5863 - val_policy_loss: 1.6317\n",
      "Saved model  tictactoe_c_puct_1_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.03\n",
      "Number of seen trajectories: 3000\n",
      "Number of unique trajectories: 2391\n"
     ]
    }
   ],
   "source": [
    "wins_1, draws_1, seen_trajectories_1, unique_trajectories_1 = test_pipeline.run(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - c_puct 1\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "losses_1 = np.ones(30) - wins_1 - draws_1\n",
    "\n",
    "plt.plot(x, wins_1, label=\"win ratio\")\n",
    "plt.plot(x, draws_1, label=\"draw ratio\")\n",
    "plt.plot(x, losses_1, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "exploration_rate_1 = unique_trajectories_1/seen_trajectories_1\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - c_puct 1\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "losses_1 = np.ones(30) - wins_1 - draws_1\n",
    "\n",
    "plt.plot(x, exploration_rate_1, label=\"unique/seen\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins_1 = [0.83, 0.72, 0.87, 0.85, 0.78, 0.85, 0.8, 0.88, 0.86, 0.84, 0.86, 0.79, 0.78, 0.85, 0.8, 0.82, 0.85, 0.81, 0.74, 0.77, 0.87, 0.8, 0.8, 0.86, 0.78, 0.82, 0.77, 0.84, 0.79, 0.85]\n",
      "draws_1 = [0.02, 0.01, 0.0, 0.0, 0.01, 0.01, 0.0, 0.0, 0.01, 0.0, 0.0, 0.01, 0.01, 0.01, 0.02, 0.05, 0.01, 0.05, 0.04, 0.04, 0.01, 0.02, 0.03, 0.03, 0.02, 0.03, 0.02, 0.0, 0.02, 0.03]\n",
      "losses_1 = [0.15 0.27 0.13 0.15 0.21 0.14 0.2  0.12 0.13 0.16 0.14 0.2  0.21 0.14\n",
      " 0.18 0.13 0.14 0.14 0.22 0.19 0.12 0.18 0.17 0.11 0.2  0.15 0.21 0.16\n",
      " 0.19 0.12]\n",
      "seen_trajectories_1 = [ 100.  200.  300.  400.  500.  600.  700.  800.  900. 1000. 1100. 1200.\n",
      " 1300. 1400. 1500. 1600. 1700. 1800. 1900. 2000. 2100. 2200. 2300. 2400.\n",
      " 2500. 2600. 2700. 2800. 2900. 3000.]\n",
      "unique_trajectories_1 = [  99.  197.  291.  386.  480.  570.  659.  753.  838.  925. 1004. 1079.\n",
      " 1164. 1244. 1326. 1407. 1482. 1564. 1634. 1710. 1778. 1849. 1913. 1984.\n",
      " 2055. 2125. 2183. 2250. 2324. 2391.]\n"
     ]
    }
   ],
   "source": [
    "print(\"wins_1 =\", wins_1)\n",
    "print(\"draws_1 =\", draws_1)\n",
    "print(\"losses_1 =\", losses_1)\n",
    "print(\"seen_trajectories_1 =\", seen_trajectories_1)\n",
    "print(\"unique_trajectories_1 =\", unique_trajectories_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $c_{puct}$ = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCTS = {\n",
    "    'c_puct': 0.5,\n",
    "    'dir_alpha': 0.6,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 10,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 10\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 0,\n",
    "    'show_games': False\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.002,\n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 512,\n",
    "    'num_filters_value': 512,\n",
    "    'num_filters_tower': 512,\n",
    "    'num_residual_blocks': 3,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 512\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"tictactoe_c_puct_0_5\", \"TicTacToe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (4872, 3, 3, 3)\n",
      "model_y_outcomes: (4872,)\n",
      "model_y_probabilities: (4872, 9)\n",
      "Train on 3897 samples, validate on 975 samples\n",
      "Epoch 1/10\n",
      "3897/3897 [==============================] - 4s 1ms/step - loss: 6.6499 - value_loss: 0.8127 - policy_loss: 2.3959 - val_loss: 6.8414 - val_value_loss: 1.3111 - val_policy_loss: 2.2810\n",
      "Epoch 2/10\n",
      "3897/3897 [==============================] - 1s 178us/step - loss: 6.4805 - value_loss: 0.6823 - policy_loss: 2.1881 - val_loss: 6.7606 - val_value_loss: 1.2575 - val_policy_loss: 2.1737\n",
      "Epoch 3/10\n",
      "3897/3897 [==============================] - 1s 177us/step - loss: 6.4015 - value_loss: 0.6283 - policy_loss: 2.0848 - val_loss: 6.7016 - val_value_loss: 1.2093 - val_policy_loss: 2.1043\n",
      "Epoch 4/10\n",
      "3897/3897 [==============================] - 1s 176us/step - loss: 6.3454 - value_loss: 0.5881 - policy_loss: 2.0134 - val_loss: 6.6290 - val_value_loss: 1.1158 - val_policy_loss: 2.0533\n",
      "Epoch 5/10\n",
      "3897/3897 [==============================] - 1s 176us/step - loss: 6.3002 - value_loss: 0.5492 - policy_loss: 1.9626 - val_loss: 6.5837 - val_value_loss: 1.0657 - val_policy_loss: 2.0136\n",
      "Epoch 6/10\n",
      "3897/3897 [==============================] - 1s 176us/step - loss: 6.2654 - value_loss: 0.5216 - policy_loss: 1.9212 - val_loss: 6.6193 - val_value_loss: 1.1680 - val_policy_loss: 1.9831\n",
      "Epoch 7/10\n",
      "3897/3897 [==============================] - 1s 176us/step - loss: 6.2431 - value_loss: 0.5079 - policy_loss: 1.8910 - val_loss: 6.6279 - val_value_loss: 1.2117 - val_policy_loss: 1.9571\n",
      "Epoch 8/10\n",
      "3897/3897 [==============================] - 1s 176us/step - loss: 6.2321 - value_loss: 0.5131 - policy_loss: 1.8645 - val_loss: 6.5205 - val_value_loss: 1.0196 - val_policy_loss: 1.9352\n",
      "Epoch 9/10\n",
      "3897/3897 [==============================] - 1s 176us/step - loss: 6.2153 - value_loss: 0.5029 - policy_loss: 1.8416 - val_loss: 6.5287 - val_value_loss: 1.0544 - val_policy_loss: 1.9173\n",
      "Epoch 10/10\n",
      "3897/3897 [==============================] - 1s 177us/step - loss: 6.2032 - value_loss: 0.4984 - policy_loss: 1.8227 - val_loss: 6.5526 - val_value_loss: 1.1192 - val_policy_loss: 1.9010\n",
      "Saved model  tictactoe_c_puct_0_5_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.01\n",
      "Number of seen trajectories: 100\n",
      "Number of unique trajectories: 99\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.2843 - value_loss: 0.6486 - policy_loss: 1.8353 - val_loss: 6.2478 - val_value_loss: 0.5789 - val_policy_loss: 1.8323\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2519 - value_loss: 0.6075 - policy_loss: 1.8122 - val_loss: 6.2404 - val_value_loss: 0.5758 - val_policy_loss: 1.8212\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2252 - value_loss: 0.5729 - policy_loss: 1.7940 - val_loss: 6.2332 - val_value_loss: 0.5746 - val_policy_loss: 1.8087\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2024 - value_loss: 0.5446 - policy_loss: 1.7773 - val_loss: 6.2121 - val_value_loss: 0.5431 - val_policy_loss: 1.7986\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1895 - value_loss: 0.5325 - policy_loss: 1.7643 - val_loss: 6.2075 - val_value_loss: 0.5431 - val_policy_loss: 1.7899\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1842 - value_loss: 0.5334 - policy_loss: 1.7534 - val_loss: 6.2110 - val_value_loss: 0.5583 - val_policy_loss: 1.7824\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1618 - value_loss: 0.4994 - policy_loss: 1.7433 - val_loss: 6.1955 - val_value_loss: 0.5355 - val_policy_loss: 1.7749\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1668 - value_loss: 0.5176 - policy_loss: 1.7357 - val_loss: 6.2078 - val_value_loss: 0.5673 - val_policy_loss: 1.7684\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1503 - value_loss: 0.4943 - policy_loss: 1.7266 - val_loss: 6.1838 - val_value_loss: 0.5266 - val_policy_loss: 1.7617\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1412 - value_loss: 0.4839 - policy_loss: 1.7195 - val_loss: 6.1794 - val_value_loss: 0.5234 - val_policy_loss: 1.7568\n",
      "Saved model  tictactoe_c_puct_0_5_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.75 - draw ratio 0.05\n",
      "Number of seen trajectories: 200\n",
      "Number of unique trajectories: 197\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.2304 - value_loss: 0.6337 - policy_loss: 1.7489 - val_loss: 6.2244 - val_value_loss: 0.6342 - val_policy_loss: 1.7367\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2124 - value_loss: 0.6142 - policy_loss: 1.7330 - val_loss: 6.2159 - val_value_loss: 0.6260 - val_policy_loss: 1.7284\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1761 - value_loss: 0.5552 - policy_loss: 1.7200 - val_loss: 6.2216 - val_value_loss: 0.6459 - val_policy_loss: 1.7207\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1642 - value_loss: 0.5424 - policy_loss: 1.7096 - val_loss: 6.1888 - val_value_loss: 0.5868 - val_policy_loss: 1.7148\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1391 - value_loss: 0.5006 - policy_loss: 1.7018 - val_loss: 6.2037 - val_value_loss: 0.6221 - val_policy_loss: 1.7098\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1559 - value_loss: 0.5432 - policy_loss: 1.6934 - val_loss: 6.1941 - val_value_loss: 0.6094 - val_policy_loss: 1.7041\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1340 - value_loss: 0.5068 - policy_loss: 1.6868 - val_loss: 6.1992 - val_value_loss: 0.6232 - val_policy_loss: 1.7009\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1305 - value_loss: 0.5064 - policy_loss: 1.6808 - val_loss: 6.2090 - val_value_loss: 0.6496 - val_policy_loss: 1.6949\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1145 - value_loss: 0.4795 - policy_loss: 1.6762 - val_loss: 6.1793 - val_value_loss: 0.5950 - val_policy_loss: 1.6907\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1117 - value_loss: 0.4798 - policy_loss: 1.6709 - val_loss: 6.1667 - val_value_loss: 0.5738 - val_policy_loss: 1.6873\n",
      "Saved model  tictactoe_c_puct_0_5_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.02\n",
      "Number of seen trajectories: 300\n",
      "Number of unique trajectories: 293\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1532 - value_loss: 0.5469 - policy_loss: 1.6876 - val_loss: 6.1534 - val_value_loss: 0.5671 - val_policy_loss: 1.6681\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1276 - value_loss: 0.5068 - policy_loss: 1.6770 - val_loss: 6.1583 - val_value_loss: 0.5833 - val_policy_loss: 1.6622\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1081 - value_loss: 0.4777 - policy_loss: 1.6678 - val_loss: 6.1473 - val_value_loss: 0.5671 - val_policy_loss: 1.6572\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0934 - value_loss: 0.4561 - policy_loss: 1.6605 - val_loss: 6.1543 - val_value_loss: 0.5857 - val_policy_loss: 1.6532\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0882 - value_loss: 0.4518 - policy_loss: 1.6551 - val_loss: 6.1412 - val_value_loss: 0.5633 - val_policy_loss: 1.6501\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0762 - value_loss: 0.4345 - policy_loss: 1.6492 - val_loss: 6.1379 - val_value_loss: 0.5606 - val_policy_loss: 1.6467\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0691 - value_loss: 0.4257 - policy_loss: 1.6443 - val_loss: 6.1417 - val_value_loss: 0.5719 - val_policy_loss: 1.6438\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0645 - value_loss: 0.4221 - policy_loss: 1.6395 - val_loss: 6.1312 - val_value_loss: 0.5551 - val_policy_loss: 1.6403\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0644 - value_loss: 0.4253 - policy_loss: 1.6366 - val_loss: 6.1336 - val_value_loss: 0.5632 - val_policy_loss: 1.6376\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0581 - value_loss: 0.4175 - policy_loss: 1.6325 - val_loss: 6.1330 - val_value_loss: 0.5648 - val_policy_loss: 1.6353\n",
      "Saved model  tictactoe_c_puct_0_5_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.81 - draw ratio 0.0\n",
      "Number of seen trajectories: 400\n",
      "Number of unique trajectories: 388\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1938 - value_loss: 0.6671 - policy_loss: 1.6550 - val_loss: 6.1956 - val_value_loss: 0.6736 - val_policy_loss: 1.6524\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1628 - value_loss: 0.6140 - policy_loss: 1.6468 - val_loss: 6.1720 - val_value_loss: 0.6304 - val_policy_loss: 1.6491\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1620 - value_loss: 0.6193 - policy_loss: 1.6405 - val_loss: 6.1573 - val_value_loss: 0.6044 - val_policy_loss: 1.6462\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1391 - value_loss: 0.5792 - policy_loss: 1.6354 - val_loss: 6.1816 - val_value_loss: 0.6561 - val_policy_loss: 1.6439\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1231 - value_loss: 0.5524 - policy_loss: 1.6308 - val_loss: 6.1579 - val_value_loss: 0.6123 - val_policy_loss: 1.6408\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1139 - value_loss: 0.5387 - policy_loss: 1.6267 - val_loss: 6.1695 - val_value_loss: 0.6385 - val_policy_loss: 1.6384\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1166 - value_loss: 0.5473 - policy_loss: 1.6242 - val_loss: 6.1565 - val_value_loss: 0.6148 - val_policy_loss: 1.6368\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1026 - value_loss: 0.5241 - policy_loss: 1.6201 - val_loss: 6.1515 - val_value_loss: 0.6078 - val_policy_loss: 1.6345\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0991 - value_loss: 0.5211 - policy_loss: 1.6166 - val_loss: 6.1494 - val_value_loss: 0.6061 - val_policy_loss: 1.6325\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0939 - value_loss: 0.5137 - policy_loss: 1.6144 - val_loss: 6.1595 - val_value_loss: 0.6283 - val_policy_loss: 1.6313\n",
      "Saved model  tictactoe_c_puct_0_5_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.02\n",
      "Number of seen trajectories: 500\n",
      "Number of unique trajectories: 476\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.2153 - value_loss: 0.6931 - policy_loss: 1.6781 - val_loss: 6.1736 - val_value_loss: 0.6475 - val_policy_loss: 1.6406\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1908 - value_loss: 0.6467 - policy_loss: 1.6759 - val_loss: 6.1660 - val_value_loss: 0.6343 - val_policy_loss: 1.6390\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1755 - value_loss: 0.6201 - policy_loss: 1.6721 - val_loss: 6.1587 - val_value_loss: 0.6213 - val_policy_loss: 1.6376\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1680 - value_loss: 0.6080 - policy_loss: 1.6696 - val_loss: 6.1654 - val_value_loss: 0.6361 - val_policy_loss: 1.6365\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1585 - value_loss: 0.5910 - policy_loss: 1.6680 - val_loss: 6.1525 - val_value_loss: 0.6117 - val_policy_loss: 1.6354\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1576 - value_loss: 0.5912 - policy_loss: 1.6663 - val_loss: 6.1537 - val_value_loss: 0.6156 - val_policy_loss: 1.6343\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1483 - value_loss: 0.5740 - policy_loss: 1.6653 - val_loss: 6.1505 - val_value_loss: 0.6105 - val_policy_loss: 1.6332\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1476 - value_loss: 0.5754 - policy_loss: 1.6626 - val_loss: 6.1491 - val_value_loss: 0.6092 - val_policy_loss: 1.6321\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1422 - value_loss: 0.5665 - policy_loss: 1.6612 - val_loss: 6.1492 - val_value_loss: 0.6107 - val_policy_loss: 1.6311\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1397 - value_loss: 0.5632 - policy_loss: 1.6598 - val_loss: 6.1465 - val_value_loss: 0.6064 - val_policy_loss: 1.6303\n",
      "Saved model  tictactoe_c_puct_0_5_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.0\n",
      "Number of seen trajectories: 600\n",
      "Number of unique trajectories: 564\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1285 - value_loss: 0.5421 - policy_loss: 1.6588 - val_loss: 6.1080 - val_value_loss: 0.5339 - val_policy_loss: 1.6262\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1116 - value_loss: 0.5118 - policy_loss: 1.6556 - val_loss: 6.1016 - val_value_loss: 0.5227 - val_policy_loss: 1.6249\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1020 - value_loss: 0.4949 - policy_loss: 1.6537 - val_loss: 6.0990 - val_value_loss: 0.5190 - val_policy_loss: 1.6237\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0954 - value_loss: 0.4843 - policy_loss: 1.6513 - val_loss: 6.0952 - val_value_loss: 0.5129 - val_policy_loss: 1.6225\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0919 - value_loss: 0.4797 - policy_loss: 1.6492 - val_loss: 6.0943 - val_value_loss: 0.5125 - val_policy_loss: 1.6215\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0902 - value_loss: 0.4765 - policy_loss: 1.6494 - val_loss: 6.0918 - val_value_loss: 0.5084 - val_policy_loss: 1.6208\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0825 - value_loss: 0.4650 - policy_loss: 1.6459 - val_loss: 6.0893 - val_value_loss: 0.5048 - val_policy_loss: 1.6199\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0807 - value_loss: 0.4622 - policy_loss: 1.6452 - val_loss: 6.0861 - val_value_loss: 0.4994 - val_policy_loss: 1.6190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0780 - value_loss: 0.4579 - policy_loss: 1.6446 - val_loss: 6.0882 - val_value_loss: 0.5046 - val_policy_loss: 1.6185\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0766 - value_loss: 0.4574 - policy_loss: 1.6425 - val_loss: 6.0853 - val_value_loss: 0.4998 - val_policy_loss: 1.6176\n",
      "Saved model  tictactoe_c_puct_0_5_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.02\n",
      "Number of seen trajectories: 700\n",
      "Number of unique trajectories: 651\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1015 - value_loss: 0.5019 - policy_loss: 1.6483 - val_loss: 6.1203 - val_value_loss: 0.5112 - val_policy_loss: 1.6767\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0892 - value_loss: 0.4803 - policy_loss: 1.6455 - val_loss: 6.1152 - val_value_loss: 0.5025 - val_policy_loss: 1.6755\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0806 - value_loss: 0.4658 - policy_loss: 1.6431 - val_loss: 6.1094 - val_value_loss: 0.4922 - val_policy_loss: 1.6745\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0741 - value_loss: 0.4547 - policy_loss: 1.6416 - val_loss: 6.1075 - val_value_loss: 0.4896 - val_policy_loss: 1.6736\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0677 - value_loss: 0.4429 - policy_loss: 1.6408 - val_loss: 6.1061 - val_value_loss: 0.4877 - val_policy_loss: 1.6729\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0636 - value_loss: 0.4372 - policy_loss: 1.6388 - val_loss: 6.1020 - val_value_loss: 0.4807 - val_policy_loss: 1.6722\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0596 - value_loss: 0.4309 - policy_loss: 1.6373 - val_loss: 6.1047 - val_value_loss: 0.4872 - val_policy_loss: 1.6713\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0567 - value_loss: 0.4267 - policy_loss: 1.6360 - val_loss: 6.1033 - val_value_loss: 0.4854 - val_policy_loss: 1.6706\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0536 - value_loss: 0.4217 - policy_loss: 1.6351 - val_loss: 6.1029 - val_value_loss: 0.4855 - val_policy_loss: 1.6700\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0530 - value_loss: 0.4214 - policy_loss: 1.6345 - val_loss: 6.1008 - val_value_loss: 0.4823 - val_policy_loss: 1.6693\n",
      "Saved model  tictactoe_c_puct_0_5_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.0\n",
      "Number of seen trajectories: 800\n",
      "Number of unique trajectories: 735\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1212 - value_loss: 0.5501 - policy_loss: 1.6427 - val_loss: 6.1235 - val_value_loss: 0.5464 - val_policy_loss: 1.6510\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1036 - value_loss: 0.5177 - policy_loss: 1.6400 - val_loss: 6.1235 - val_value_loss: 0.5474 - val_policy_loss: 1.6503\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0912 - value_loss: 0.4941 - policy_loss: 1.6391 - val_loss: 6.1182 - val_value_loss: 0.5378 - val_policy_loss: 1.6496\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0838 - value_loss: 0.4809 - policy_loss: 1.6380 - val_loss: 6.1162 - val_value_loss: 0.5345 - val_policy_loss: 1.6493\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0748 - value_loss: 0.4657 - policy_loss: 1.6354 - val_loss: 6.1131 - val_value_loss: 0.5292 - val_policy_loss: 1.6488\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0714 - value_loss: 0.4595 - policy_loss: 1.6351 - val_loss: 6.1107 - val_value_loss: 0.5249 - val_policy_loss: 1.6484\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0670 - value_loss: 0.4534 - policy_loss: 1.6328 - val_loss: 6.1103 - val_value_loss: 0.5250 - val_policy_loss: 1.6480\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0644 - value_loss: 0.4495 - policy_loss: 1.6318 - val_loss: 6.1074 - val_value_loss: 0.5201 - val_policy_loss: 1.6474\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0600 - value_loss: 0.4419 - policy_loss: 1.6309 - val_loss: 6.1068 - val_value_loss: 0.5194 - val_policy_loss: 1.6471\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0593 - value_loss: 0.4419 - policy_loss: 1.6298 - val_loss: 6.1064 - val_value_loss: 0.5194 - val_policy_loss: 1.6466\n",
      "Saved model  tictactoe_c_puct_0_5_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.0\n",
      "Number of seen trajectories: 900\n",
      "Number of unique trajectories: 822\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1391 - value_loss: 0.5891 - policy_loss: 1.6425 - val_loss: 6.1252 - val_value_loss: 0.5597 - val_policy_loss: 1.6445\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1178 - value_loss: 0.5492 - policy_loss: 1.6403 - val_loss: 6.1204 - val_value_loss: 0.5513 - val_policy_loss: 1.6435\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1057 - value_loss: 0.5266 - policy_loss: 1.6389 - val_loss: 6.1192 - val_value_loss: 0.5496 - val_policy_loss: 1.6432\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0975 - value_loss: 0.5120 - policy_loss: 1.6374 - val_loss: 6.1192 - val_value_loss: 0.5503 - val_policy_loss: 1.6426\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0914 - value_loss: 0.5019 - policy_loss: 1.6357 - val_loss: 6.1152 - val_value_loss: 0.5432 - val_policy_loss: 1.6421\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0878 - value_loss: 0.4962 - policy_loss: 1.6345 - val_loss: 6.1148 - val_value_loss: 0.5436 - val_policy_loss: 1.6413\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0848 - value_loss: 0.4920 - policy_loss: 1.6330 - val_loss: 6.1142 - val_value_loss: 0.5432 - val_policy_loss: 1.6407\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0810 - value_loss: 0.4858 - policy_loss: 1.6318 - val_loss: 6.1129 - val_value_loss: 0.5417 - val_policy_loss: 1.6401\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0767 - value_loss: 0.4787 - policy_loss: 1.6307 - val_loss: 6.1121 - val_value_loss: 0.5407 - val_policy_loss: 1.6397\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0754 - value_loss: 0.4772 - policy_loss: 1.6299 - val_loss: 6.1108 - val_value_loss: 0.5390 - val_policy_loss: 1.6390\n",
      "Saved model  tictactoe_c_puct_0_5_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.01\n",
      "Number of seen trajectories: 1000\n",
      "Number of unique trajectories: 903\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1331 - value_loss: 0.6038 - policy_loss: 1.6189 - val_loss: 6.1364 - val_value_loss: 0.5796 - val_policy_loss: 1.6498\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1189 - value_loss: 0.5778 - policy_loss: 1.6167 - val_loss: 6.1332 - val_value_loss: 0.5741 - val_policy_loss: 1.6491\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1087 - value_loss: 0.5592 - policy_loss: 1.6151 - val_loss: 6.1296 - val_value_loss: 0.5676 - val_policy_loss: 1.6486\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1015 - value_loss: 0.5451 - policy_loss: 1.6150 - val_loss: 6.1259 - val_value_loss: 0.5609 - val_policy_loss: 1.6482\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0953 - value_loss: 0.5339 - policy_loss: 1.6138 - val_loss: 6.1259 - val_value_loss: 0.5613 - val_policy_loss: 1.6478\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0889 - value_loss: 0.5225 - policy_loss: 1.6126 - val_loss: 6.1217 - val_value_loss: 0.5533 - val_policy_loss: 1.6475\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0850 - value_loss: 0.5151 - policy_loss: 1.6124 - val_loss: 6.1190 - val_value_loss: 0.5484 - val_policy_loss: 1.6472\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0801 - value_loss: 0.5068 - policy_loss: 1.6112 - val_loss: 6.1178 - val_value_loss: 0.5466 - val_policy_loss: 1.6469\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0757 - value_loss: 0.4986 - policy_loss: 1.6107 - val_loss: 6.1212 - val_value_loss: 0.5536 - val_policy_loss: 1.6466\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0740 - value_loss: 0.4961 - policy_loss: 1.6099 - val_loss: 6.1163 - val_value_loss: 0.5444 - val_policy_loss: 1.6463\n",
      "Saved model  tictactoe_c_puct_0_5_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.01\n",
      "Number of seen trajectories: 1100\n",
      "Number of unique trajectories: 986\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1402 - value_loss: 0.5993 - policy_loss: 1.6392 - val_loss: 6.1288 - val_value_loss: 0.5860 - val_policy_loss: 1.6299\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1299 - value_loss: 0.5803 - policy_loss: 1.6380 - val_loss: 6.1253 - val_value_loss: 0.5797 - val_policy_loss: 1.6294\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1215 - value_loss: 0.5643 - policy_loss: 1.6371 - val_loss: 6.1228 - val_value_loss: 0.5753 - val_policy_loss: 1.6289\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1145 - value_loss: 0.5521 - policy_loss: 1.6356 - val_loss: 6.1214 - val_value_loss: 0.5730 - val_policy_loss: 1.6286\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1106 - value_loss: 0.5449 - policy_loss: 1.6351 - val_loss: 6.1217 - val_value_loss: 0.5741 - val_policy_loss: 1.6282\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1058 - value_loss: 0.5363 - policy_loss: 1.6343 - val_loss: 6.1187 - val_value_loss: 0.5686 - val_policy_loss: 1.6279\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1025 - value_loss: 0.5311 - policy_loss: 1.6331 - val_loss: 6.1174 - val_value_loss: 0.5663 - val_policy_loss: 1.6277\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0992 - value_loss: 0.5253 - policy_loss: 1.6324 - val_loss: 6.1166 - val_value_loss: 0.5652 - val_policy_loss: 1.6274\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0970 - value_loss: 0.5216 - policy_loss: 1.6320 - val_loss: 6.1148 - val_value_loss: 0.5619 - val_policy_loss: 1.6271\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0952 - value_loss: 0.5187 - policy_loss: 1.6312 - val_loss: 6.1144 - val_value_loss: 0.5616 - val_policy_loss: 1.6269\n",
      "Saved model  tictactoe_c_puct_0_5_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.02\n",
      "Number of seen trajectories: 1200\n",
      "Number of unique trajectories: 1068\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1451 - value_loss: 0.6090 - policy_loss: 1.6409 - val_loss: 6.1655 - val_value_loss: 0.6351 - val_policy_loss: 1.6558\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1346 - value_loss: 0.5891 - policy_loss: 1.6399 - val_loss: 6.1592 - val_value_loss: 0.6228 - val_policy_loss: 1.6556\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1281 - value_loss: 0.5777 - policy_loss: 1.6385 - val_loss: 6.1553 - val_value_loss: 0.6152 - val_policy_loss: 1.6555\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1216 - value_loss: 0.5658 - policy_loss: 1.6377 - val_loss: 6.1531 - val_value_loss: 0.6111 - val_policy_loss: 1.6555\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1175 - value_loss: 0.5579 - policy_loss: 1.6375 - val_loss: 6.1507 - val_value_loss: 0.6065 - val_policy_loss: 1.6554\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1138 - value_loss: 0.5514 - policy_loss: 1.6368 - val_loss: 6.1488 - val_value_loss: 0.6029 - val_policy_loss: 1.6553\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1097 - value_loss: 0.5441 - policy_loss: 1.6361 - val_loss: 6.1489 - val_value_loss: 0.6034 - val_policy_loss: 1.6553\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1072 - value_loss: 0.5401 - policy_loss: 1.6352 - val_loss: 6.1494 - val_value_loss: 0.6046 - val_policy_loss: 1.6552\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1047 - value_loss: 0.5359 - policy_loss: 1.6345 - val_loss: 6.1490 - val_value_loss: 0.6041 - val_policy_loss: 1.6551\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1023 - value_loss: 0.5313 - policy_loss: 1.6345 - val_loss: 6.1461 - val_value_loss: 0.5984 - val_policy_loss: 1.6550\n",
      "Saved model  tictactoe_c_puct_0_5_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.77 - draw ratio 0.03\n",
      "Number of seen trajectories: 1300\n",
      "Number of unique trajectories: 1143\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1286 - value_loss: 0.5825 - policy_loss: 1.6361 - val_loss: 6.1057 - val_value_loss: 0.5756 - val_policy_loss: 1.5972\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1171 - value_loss: 0.5605 - policy_loss: 1.6352 - val_loss: 6.1025 - val_value_loss: 0.5699 - val_policy_loss: 1.5968\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1107 - value_loss: 0.5488 - policy_loss: 1.6342 - val_loss: 6.1014 - val_value_loss: 0.5681 - val_policy_loss: 1.5965\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1053 - value_loss: 0.5388 - policy_loss: 1.6337 - val_loss: 6.1013 - val_value_loss: 0.5684 - val_policy_loss: 1.5962\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1001 - value_loss: 0.5294 - policy_loss: 1.6328 - val_loss: 6.1007 - val_value_loss: 0.5677 - val_policy_loss: 1.5959\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0953 - value_loss: 0.5208 - policy_loss: 1.6320 - val_loss: 6.0981 - val_value_loss: 0.5627 - val_policy_loss: 1.5957\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0920 - value_loss: 0.5147 - policy_loss: 1.6316 - val_loss: 6.0975 - val_value_loss: 0.5619 - val_policy_loss: 1.5954\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0883 - value_loss: 0.5083 - policy_loss: 1.6307 - val_loss: 6.0979 - val_value_loss: 0.5631 - val_policy_loss: 1.5953\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0851 - value_loss: 0.5028 - policy_loss: 1.6301 - val_loss: 6.0977 - val_value_loss: 0.5630 - val_policy_loss: 1.5951\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0835 - value_loss: 0.5004 - policy_loss: 1.6295 - val_loss: 6.0969 - val_value_loss: 0.5617 - val_policy_loss: 1.5949\n",
      "Saved model  tictactoe_c_puct_0_5_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.0\n",
      "Number of seen trajectories: 1400\n",
      "Number of unique trajectories: 1213\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1102 - value_loss: 0.5640 - policy_loss: 1.6194 - val_loss: 6.0767 - val_value_loss: 0.5039 - val_policy_loss: 1.6125\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0993 - value_loss: 0.5431 - policy_loss: 1.6186 - val_loss: 6.0738 - val_value_loss: 0.4989 - val_policy_loss: 1.6120\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0923 - value_loss: 0.5300 - policy_loss: 1.6179 - val_loss: 6.0724 - val_value_loss: 0.4966 - val_policy_loss: 1.6116\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0869 - value_loss: 0.5204 - policy_loss: 1.6168 - val_loss: 6.0726 - val_value_loss: 0.4975 - val_policy_loss: 1.6112\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0817 - value_loss: 0.5105 - policy_loss: 1.6167 - val_loss: 6.0713 - val_value_loss: 0.4953 - val_policy_loss: 1.6110\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0785 - value_loss: 0.5047 - policy_loss: 1.6161 - val_loss: 6.0715 - val_value_loss: 0.4962 - val_policy_loss: 1.6107\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0745 - value_loss: 0.4976 - policy_loss: 1.6153 - val_loss: 6.0705 - val_value_loss: 0.4946 - val_policy_loss: 1.6105\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0700 - value_loss: 0.4897 - policy_loss: 1.6143 - val_loss: 6.0708 - val_value_loss: 0.4957 - val_policy_loss: 1.6102\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0683 - value_loss: 0.4872 - policy_loss: 1.6136 - val_loss: 6.0694 - val_value_loss: 0.4931 - val_policy_loss: 1.6100\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0652 - value_loss: 0.4815 - policy_loss: 1.6133 - val_loss: 6.0690 - val_value_loss: 0.4929 - val_policy_loss: 1.6097\n",
      "Saved model  tictactoe_c_puct_0_5_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.01\n",
      "Number of seen trajectories: 1500\n",
      "Number of unique trajectories: 1286\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.0898 - value_loss: 0.5341 - policy_loss: 1.6100 - val_loss: 6.1043 - val_value_loss: 0.5392 - val_policy_loss: 1.6340\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0834 - value_loss: 0.5224 - policy_loss: 1.6090 - val_loss: 6.1012 - val_value_loss: 0.5332 - val_policy_loss: 1.6338\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0792 - value_loss: 0.5138 - policy_loss: 1.6093 - val_loss: 6.0990 - val_value_loss: 0.5291 - val_policy_loss: 1.6336\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0754 - value_loss: 0.5077 - policy_loss: 1.6078 - val_loss: 6.0975 - val_value_loss: 0.5263 - val_policy_loss: 1.6334\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0723 - value_loss: 0.5019 - policy_loss: 1.6075 - val_loss: 6.0960 - val_value_loss: 0.5236 - val_policy_loss: 1.6333\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0697 - value_loss: 0.4965 - policy_loss: 1.6078 - val_loss: 6.0952 - val_value_loss: 0.5222 - val_policy_loss: 1.6332\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0672 - value_loss: 0.4926 - policy_loss: 1.6069 - val_loss: 6.0945 - val_value_loss: 0.5211 - val_policy_loss: 1.6330\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0652 - value_loss: 0.4888 - policy_loss: 1.6067 - val_loss: 6.0933 - val_value_loss: 0.5188 - val_policy_loss: 1.6329\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0638 - value_loss: 0.4858 - policy_loss: 1.6070 - val_loss: 6.0927 - val_value_loss: 0.5178 - val_policy_loss: 1.6328\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0615 - value_loss: 0.4821 - policy_loss: 1.6062 - val_loss: 6.0923 - val_value_loss: 0.5172 - val_policy_loss: 1.6327\n",
      "Saved model  tictactoe_c_puct_0_5_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.0\n",
      "Number of seen trajectories: 1600\n",
      "Number of unique trajectories: 1366\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1480 - value_loss: 0.6432 - policy_loss: 1.6181 - val_loss: 6.1163 - val_value_loss: 0.6029 - val_policy_loss: 1.5950\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1392 - value_loss: 0.6267 - policy_loss: 1.6172 - val_loss: 6.1142 - val_value_loss: 0.5991 - val_policy_loss: 1.5947\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1335 - value_loss: 0.6156 - policy_loss: 1.6169 - val_loss: 6.1127 - val_value_loss: 0.5962 - val_policy_loss: 1.5946\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1268 - value_loss: 0.6031 - policy_loss: 1.6160 - val_loss: 6.1114 - val_value_loss: 0.5939 - val_policy_loss: 1.5945\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1234 - value_loss: 0.5970 - policy_loss: 1.6154 - val_loss: 6.1102 - val_value_loss: 0.5918 - val_policy_loss: 1.5944\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1185 - value_loss: 0.5876 - policy_loss: 1.6151 - val_loss: 6.1094 - val_value_loss: 0.5902 - val_policy_loss: 1.5943\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1155 - value_loss: 0.5819 - policy_loss: 1.6149 - val_loss: 6.1084 - val_value_loss: 0.5886 - val_policy_loss: 1.5942\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1122 - value_loss: 0.5760 - policy_loss: 1.6142 - val_loss: 6.1077 - val_value_loss: 0.5872 - val_policy_loss: 1.5941\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1088 - value_loss: 0.5702 - policy_loss: 1.6134 - val_loss: 6.1076 - val_value_loss: 0.5871 - val_policy_loss: 1.5940\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1071 - value_loss: 0.5666 - policy_loss: 1.6137 - val_loss: 6.1066 - val_value_loss: 0.5853 - val_policy_loss: 1.5939\n",
      "Saved model  tictactoe_c_puct_0_5_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.02\n",
      "Number of seen trajectories: 1700\n",
      "Number of unique trajectories: 1449\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1239 - value_loss: 0.6084 - policy_loss: 1.6055 - val_loss: 6.1553 - val_value_loss: 0.6521 - val_policy_loss: 1.6248\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1155 - value_loss: 0.5923 - policy_loss: 1.6050 - val_loss: 6.1525 - val_value_loss: 0.6465 - val_policy_loss: 1.6246\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1105 - value_loss: 0.5827 - policy_loss: 1.6045 - val_loss: 6.1493 - val_value_loss: 0.6403 - val_policy_loss: 1.6245\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1052 - value_loss: 0.5726 - policy_loss: 1.6041 - val_loss: 6.1467 - val_value_loss: 0.6354 - val_policy_loss: 1.6244\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1009 - value_loss: 0.5650 - policy_loss: 1.6034 - val_loss: 6.1448 - val_value_loss: 0.6317 - val_policy_loss: 1.6244\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0977 - value_loss: 0.5587 - policy_loss: 1.6032 - val_loss: 6.1433 - val_value_loss: 0.6287 - val_policy_loss: 1.6244\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0939 - value_loss: 0.5517 - policy_loss: 1.6026 - val_loss: 6.1418 - val_value_loss: 0.6259 - val_policy_loss: 1.6243\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0916 - value_loss: 0.5477 - policy_loss: 1.6022 - val_loss: 6.1405 - val_value_loss: 0.6234 - val_policy_loss: 1.6243\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0899 - value_loss: 0.5442 - policy_loss: 1.6025 - val_loss: 6.1392 - val_value_loss: 0.6209 - val_policy_loss: 1.6242\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0876 - value_loss: 0.5404 - policy_loss: 1.6017 - val_loss: 6.1388 - val_value_loss: 0.6203 - val_policy_loss: 1.6242\n",
      "Saved model  tictactoe_c_puct_0_5_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.02\n",
      "Number of seen trajectories: 1800\n",
      "Number of unique trajectories: 1527\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0891 - value_loss: 0.5498 - policy_loss: 1.5954 - val_loss: 6.1161 - val_value_loss: 0.5872 - val_policy_loss: 1.6119\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0835 - value_loss: 0.5392 - policy_loss: 1.5947 - val_loss: 6.1139 - val_value_loss: 0.5832 - val_policy_loss: 1.6117\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0766 - value_loss: 0.5269 - policy_loss: 1.5934 - val_loss: 6.1134 - val_value_loss: 0.5825 - val_policy_loss: 1.6115\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0743 - value_loss: 0.5228 - policy_loss: 1.5931 - val_loss: 6.1122 - val_value_loss: 0.5804 - val_policy_loss: 1.6113\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0711 - value_loss: 0.5168 - policy_loss: 1.5927 - val_loss: 6.1123 - val_value_loss: 0.5809 - val_policy_loss: 1.6111\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0682 - value_loss: 0.5110 - policy_loss: 1.5929 - val_loss: 6.1111 - val_value_loss: 0.5787 - val_policy_loss: 1.6109\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0667 - value_loss: 0.5078 - policy_loss: 1.5930 - val_loss: 6.1104 - val_value_loss: 0.5775 - val_policy_loss: 1.6108\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0630 - value_loss: 0.5022 - policy_loss: 1.5914 - val_loss: 6.1099 - val_value_loss: 0.5766 - val_policy_loss: 1.6106\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0625 - value_loss: 0.5005 - policy_loss: 1.5921 - val_loss: 6.1095 - val_value_loss: 0.5762 - val_policy_loss: 1.6105\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0602 - value_loss: 0.4968 - policy_loss: 1.5912 - val_loss: 6.1091 - val_value_loss: 0.5756 - val_policy_loss: 1.6104\n",
      "Saved model  tictactoe_c_puct_0_5_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.01\n",
      "Number of seen trajectories: 1900\n",
      "Number of unique trajectories: 1599\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1283 - value_loss: 0.6059 - policy_loss: 1.6184 - val_loss: 6.1251 - val_value_loss: 0.5902 - val_policy_loss: 1.6277\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1222 - value_loss: 0.5942 - policy_loss: 1.6180 - val_loss: 6.1248 - val_value_loss: 0.5900 - val_policy_loss: 1.6275\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1172 - value_loss: 0.5850 - policy_loss: 1.6172 - val_loss: 6.1241 - val_value_loss: 0.5889 - val_policy_loss: 1.6272\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1129 - value_loss: 0.5762 - policy_loss: 1.6174 - val_loss: 6.1227 - val_value_loss: 0.5864 - val_policy_loss: 1.6271\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1088 - value_loss: 0.5684 - policy_loss: 1.6171 - val_loss: 6.1232 - val_value_loss: 0.5875 - val_policy_loss: 1.6269\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1057 - value_loss: 0.5631 - policy_loss: 1.6164 - val_loss: 6.1215 - val_value_loss: 0.5845 - val_policy_loss: 1.6267\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1020 - value_loss: 0.5561 - policy_loss: 1.6161 - val_loss: 6.1210 - val_value_loss: 0.5838 - val_policy_loss: 1.6266\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0996 - value_loss: 0.5518 - policy_loss: 1.6158 - val_loss: 6.1214 - val_value_loss: 0.5846 - val_policy_loss: 1.6265\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0970 - value_loss: 0.5473 - policy_loss: 1.6151 - val_loss: 6.1203 - val_value_loss: 0.5827 - val_policy_loss: 1.6263\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0949 - value_loss: 0.5433 - policy_loss: 1.6149 - val_loss: 6.1204 - val_value_loss: 0.5831 - val_policy_loss: 1.6262\n",
      "Saved model  tictactoe_c_puct_0_5_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.02\n",
      "Number of seen trajectories: 2000\n",
      "Number of unique trajectories: 1679\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1498 - value_loss: 0.6346 - policy_loss: 1.6336 - val_loss: 6.1464 - val_value_loss: 0.6441 - val_policy_loss: 1.6173\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1460 - value_loss: 0.6272 - policy_loss: 1.6333 - val_loss: 6.1449 - val_value_loss: 0.6412 - val_policy_loss: 1.6172\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1423 - value_loss: 0.6201 - policy_loss: 1.6330 - val_loss: 6.1435 - val_value_loss: 0.6385 - val_policy_loss: 1.6171\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1400 - value_loss: 0.6158 - policy_loss: 1.6328 - val_loss: 6.1424 - val_value_loss: 0.6365 - val_policy_loss: 1.6170\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1369 - value_loss: 0.6105 - policy_loss: 1.6320 - val_loss: 6.1413 - val_value_loss: 0.6344 - val_policy_loss: 1.6169\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1355 - value_loss: 0.6076 - policy_loss: 1.6321 - val_loss: 6.1403 - val_value_loss: 0.6326 - val_policy_loss: 1.6168\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1337 - value_loss: 0.6038 - policy_loss: 1.6323 - val_loss: 6.1397 - val_value_loss: 0.6316 - val_policy_loss: 1.6167\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1321 - value_loss: 0.6009 - policy_loss: 1.6321 - val_loss: 6.1391 - val_value_loss: 0.6304 - val_policy_loss: 1.6166\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1296 - value_loss: 0.5966 - policy_loss: 1.6314 - val_loss: 6.1385 - val_value_loss: 0.6293 - val_policy_loss: 1.6165\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1286 - value_loss: 0.5941 - policy_loss: 1.6320 - val_loss: 6.1376 - val_value_loss: 0.6277 - val_policy_loss: 1.6165\n",
      "Saved model  tictactoe_c_puct_0_5_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.03\n",
      "Number of seen trajectories: 2100\n",
      "Number of unique trajectories: 1754\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1157 - value_loss: 0.5820 - policy_loss: 1.6184 - val_loss: 6.1240 - val_value_loss: 0.6101 - val_policy_loss: 1.6068\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1113 - value_loss: 0.5741 - policy_loss: 1.6174 - val_loss: 6.1238 - val_value_loss: 0.6098 - val_policy_loss: 1.6068\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1071 - value_loss: 0.5660 - policy_loss: 1.6171 - val_loss: 6.1235 - val_value_loss: 0.6093 - val_policy_loss: 1.6068\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1044 - value_loss: 0.5607 - policy_loss: 1.6172 - val_loss: 6.1231 - val_value_loss: 0.6084 - val_policy_loss: 1.6068\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1022 - value_loss: 0.5559 - policy_loss: 1.6175 - val_loss: 6.1228 - val_value_loss: 0.6079 - val_policy_loss: 1.6068\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0996 - value_loss: 0.5512 - policy_loss: 1.6170 - val_loss: 6.1223 - val_value_loss: 0.6070 - val_policy_loss: 1.6068\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0975 - value_loss: 0.5471 - policy_loss: 1.6170 - val_loss: 6.1220 - val_value_loss: 0.6064 - val_policy_loss: 1.6068\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0948 - value_loss: 0.5422 - policy_loss: 1.6166 - val_loss: 6.1216 - val_value_loss: 0.6057 - val_policy_loss: 1.6068\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0932 - value_loss: 0.5391 - policy_loss: 1.6167 - val_loss: 6.1214 - val_value_loss: 0.6053 - val_policy_loss: 1.6067\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0911 - value_loss: 0.5357 - policy_loss: 1.6159 - val_loss: 6.1211 - val_value_loss: 0.6048 - val_policy_loss: 1.6067\n",
      "Saved model  tictactoe_c_puct_0_5_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.81 - draw ratio 0.02\n",
      "Number of seen trajectories: 2200\n",
      "Number of unique trajectories: 1825\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0784 - value_loss: 0.5170 - policy_loss: 1.6092 - val_loss: 6.0619 - val_value_loss: 0.4958 - val_policy_loss: 1.5972\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0736 - value_loss: 0.5082 - policy_loss: 1.6083 - val_loss: 6.0600 - val_value_loss: 0.4922 - val_policy_loss: 1.5972\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0704 - value_loss: 0.5022 - policy_loss: 1.6080 - val_loss: 6.0588 - val_value_loss: 0.4898 - val_policy_loss: 1.5971\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0682 - value_loss: 0.4975 - policy_loss: 1.6083 - val_loss: 6.0577 - val_value_loss: 0.4878 - val_policy_loss: 1.5971\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0659 - value_loss: 0.4932 - policy_loss: 1.6082 - val_loss: 6.0568 - val_value_loss: 0.4861 - val_policy_loss: 1.5971\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0636 - value_loss: 0.4894 - policy_loss: 1.6073 - val_loss: 6.0561 - val_value_loss: 0.4847 - val_policy_loss: 1.5970\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0616 - value_loss: 0.4849 - policy_loss: 1.6077 - val_loss: 6.0555 - val_value_loss: 0.4835 - val_policy_loss: 1.5970\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0594 - value_loss: 0.4812 - policy_loss: 1.6072 - val_loss: 6.0549 - val_value_loss: 0.4825 - val_policy_loss: 1.5970\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0585 - value_loss: 0.4792 - policy_loss: 1.6074 - val_loss: 6.0545 - val_value_loss: 0.4817 - val_policy_loss: 1.5969\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0563 - value_loss: 0.4751 - policy_loss: 1.6072 - val_loss: 6.0540 - val_value_loss: 0.4808 - val_policy_loss: 1.5969\n",
      "Saved model  tictactoe_c_puct_0_5_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.07\n",
      "Number of seen trajectories: 2300\n",
      "Number of unique trajectories: 1891\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.0712 - value_loss: 0.4989 - policy_loss: 1.6133 - val_loss: 6.0834 - val_value_loss: 0.5165 - val_policy_loss: 1.6199\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0682 - value_loss: 0.4934 - policy_loss: 1.6127 - val_loss: 6.0814 - val_value_loss: 0.5128 - val_policy_loss: 1.6198\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0651 - value_loss: 0.4881 - policy_loss: 1.6120 - val_loss: 6.0798 - val_value_loss: 0.5097 - val_policy_loss: 1.6196\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0634 - value_loss: 0.4843 - policy_loss: 1.6123 - val_loss: 6.0786 - val_value_loss: 0.5075 - val_policy_loss: 1.6195\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0611 - value_loss: 0.4801 - policy_loss: 1.6119 - val_loss: 6.0775 - val_value_loss: 0.5055 - val_policy_loss: 1.6194\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0588 - value_loss: 0.4760 - policy_loss: 1.6116 - val_loss: 6.0766 - val_value_loss: 0.5039 - val_policy_loss: 1.6193\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0578 - value_loss: 0.4739 - policy_loss: 1.6116 - val_loss: 6.0758 - val_value_loss: 0.5024 - val_policy_loss: 1.6192\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0561 - value_loss: 0.4714 - policy_loss: 1.6109 - val_loss: 6.0752 - val_value_loss: 0.5012 - val_policy_loss: 1.6191\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0553 - value_loss: 0.4700 - policy_loss: 1.6106 - val_loss: 6.0747 - val_value_loss: 0.5004 - val_policy_loss: 1.6190\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0541 - value_loss: 0.4672 - policy_loss: 1.6110 - val_loss: 6.0742 - val_value_loss: 0.4995 - val_policy_loss: 1.6190\n",
      "Saved model  tictactoe_c_puct_0_5_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.0\n",
      "Number of seen trajectories: 2400\n",
      "Number of unique trajectories: 1960\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1183 - value_loss: 0.5736 - policy_loss: 1.6331 - val_loss: 6.0988 - val_value_loss: 0.5747 - val_policy_loss: 1.5929\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1126 - value_loss: 0.5629 - policy_loss: 1.6325 - val_loss: 6.0973 - val_value_loss: 0.5722 - val_policy_loss: 1.5927\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1095 - value_loss: 0.5576 - policy_loss: 1.6315 - val_loss: 6.0964 - val_value_loss: 0.5706 - val_policy_loss: 1.5924\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1072 - value_loss: 0.5528 - policy_loss: 1.6319 - val_loss: 6.0961 - val_value_loss: 0.5702 - val_policy_loss: 1.5922\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1041 - value_loss: 0.5470 - policy_loss: 1.6314 - val_loss: 6.0957 - val_value_loss: 0.5697 - val_policy_loss: 1.5921\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1022 - value_loss: 0.5431 - policy_loss: 1.6316 - val_loss: 6.0954 - val_value_loss: 0.5692 - val_policy_loss: 1.5919\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1003 - value_loss: 0.5396 - policy_loss: 1.6313 - val_loss: 6.0952 - val_value_loss: 0.5690 - val_policy_loss: 1.5917\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0979 - value_loss: 0.5354 - policy_loss: 1.6308 - val_loss: 6.0949 - val_value_loss: 0.5686 - val_policy_loss: 1.5916\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0974 - value_loss: 0.5341 - policy_loss: 1.6311 - val_loss: 6.0946 - val_value_loss: 0.5683 - val_policy_loss: 1.5914\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0948 - value_loss: 0.5295 - policy_loss: 1.6307 - val_loss: 6.0946 - val_value_loss: 0.5683 - val_policy_loss: 1.5913\n",
      "Saved model  tictactoe_c_puct_0_5_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.01\n",
      "Number of seen trajectories: 2500\n",
      "Number of unique trajectories: 2026\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1161 - value_loss: 0.5886 - policy_loss: 1.6142 - val_loss: 6.1510 - val_value_loss: 0.6200 - val_policy_loss: 1.6525\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1130 - value_loss: 0.5825 - policy_loss: 1.6141 - val_loss: 6.1497 - val_value_loss: 0.6175 - val_policy_loss: 1.6524\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1108 - value_loss: 0.5778 - policy_loss: 1.6143 - val_loss: 6.1488 - val_value_loss: 0.6159 - val_policy_loss: 1.6523\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1086 - value_loss: 0.5733 - policy_loss: 1.6144 - val_loss: 6.1481 - val_value_loss: 0.6145 - val_policy_loss: 1.6523\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1086 - value_loss: 0.5736 - policy_loss: 1.6142 - val_loss: 6.1476 - val_value_loss: 0.6135 - val_policy_loss: 1.6522\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1063 - value_loss: 0.5695 - policy_loss: 1.6137 - val_loss: 6.1471 - val_value_loss: 0.6127 - val_policy_loss: 1.6521\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1049 - value_loss: 0.5666 - policy_loss: 1.6138 - val_loss: 6.1467 - val_value_loss: 0.6119 - val_policy_loss: 1.6521\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1035 - value_loss: 0.5644 - policy_loss: 1.6133 - val_loss: 6.1464 - val_value_loss: 0.6114 - val_policy_loss: 1.6520\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1013 - value_loss: 0.5594 - policy_loss: 1.6138 - val_loss: 6.1461 - val_value_loss: 0.6110 - val_policy_loss: 1.6520\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1000 - value_loss: 0.5575 - policy_loss: 1.6131 - val_loss: 6.1460 - val_value_loss: 0.6107 - val_policy_loss: 1.6519\n",
      "Saved model  tictactoe_c_puct_0_5_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.01\n",
      "Number of seen trajectories: 2600\n",
      "Number of unique trajectories: 2091\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1007 - value_loss: 0.5696 - policy_loss: 1.6025 - val_loss: 6.1492 - val_value_loss: 0.6244 - val_policy_loss: 1.6446\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0972 - value_loss: 0.5624 - policy_loss: 1.6027 - val_loss: 6.1488 - val_value_loss: 0.6238 - val_policy_loss: 1.6446\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0950 - value_loss: 0.5586 - policy_loss: 1.6021 - val_loss: 6.1487 - val_value_loss: 0.6235 - val_policy_loss: 1.6446\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0933 - value_loss: 0.5555 - policy_loss: 1.6020 - val_loss: 6.1485 - val_value_loss: 0.6232 - val_policy_loss: 1.6446\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0925 - value_loss: 0.5540 - policy_loss: 1.6019 - val_loss: 6.1483 - val_value_loss: 0.6228 - val_policy_loss: 1.6446\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0897 - value_loss: 0.5490 - policy_loss: 1.6013 - val_loss: 6.1481 - val_value_loss: 0.6225 - val_policy_loss: 1.6445\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0890 - value_loss: 0.5471 - policy_loss: 1.6018 - val_loss: 6.1479 - val_value_loss: 0.6220 - val_policy_loss: 1.6445\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0886 - value_loss: 0.5464 - policy_loss: 1.6017 - val_loss: 6.1477 - val_value_loss: 0.6217 - val_policy_loss: 1.6445\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0864 - value_loss: 0.5421 - policy_loss: 1.6015 - val_loss: 6.1474 - val_value_loss: 0.6211 - val_policy_loss: 1.6445\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0853 - value_loss: 0.5404 - policy_loss: 1.6011 - val_loss: 6.1472 - val_value_loss: 0.6207 - val_policy_loss: 1.6445\n",
      "Saved model  tictactoe_c_puct_0_5_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.02\n",
      "Number of seen trajectories: 2700\n",
      "Number of unique trajectories: 2158\n",
      "iteration 27 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1084 - value_loss: 0.5793 - policy_loss: 1.6084 - val_loss: 6.0883 - val_value_loss: 0.5646 - val_policy_loss: 1.5830\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1053 - value_loss: 0.5737 - policy_loss: 1.6078 - val_loss: 6.0875 - val_value_loss: 0.5630 - val_policy_loss: 1.5830\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1034 - value_loss: 0.5700 - policy_loss: 1.6077 - val_loss: 6.0869 - val_value_loss: 0.5619 - val_policy_loss: 1.5829\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1012 - value_loss: 0.5656 - policy_loss: 1.6076 - val_loss: 6.0865 - val_value_loss: 0.5610 - val_policy_loss: 1.5829\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0998 - value_loss: 0.5631 - policy_loss: 1.6075 - val_loss: 6.0861 - val_value_loss: 0.5603 - val_policy_loss: 1.5829\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0987 - value_loss: 0.5613 - policy_loss: 1.6071 - val_loss: 6.0858 - val_value_loss: 0.5597 - val_policy_loss: 1.5829\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0966 - value_loss: 0.5566 - policy_loss: 1.6077 - val_loss: 6.0855 - val_value_loss: 0.5592 - val_policy_loss: 1.5828\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0967 - value_loss: 0.5573 - policy_loss: 1.6072 - val_loss: 6.0852 - val_value_loss: 0.5587 - val_policy_loss: 1.5828\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0948 - value_loss: 0.5537 - policy_loss: 1.6070 - val_loss: 6.0850 - val_value_loss: 0.5582 - val_policy_loss: 1.5828\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0940 - value_loss: 0.5523 - policy_loss: 1.6068 - val_loss: 6.0847 - val_value_loss: 0.5576 - val_policy_loss: 1.5828\n",
      "Saved model  tictactoe_c_puct_0_5_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.01\n",
      "Number of seen trajectories: 2800\n",
      "Number of unique trajectories: 2227\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1725 - value_loss: 0.6978 - policy_loss: 1.6184 - val_loss: 6.1541 - val_value_loss: 0.6598 - val_policy_loss: 1.6196\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1668 - value_loss: 0.6862 - policy_loss: 1.6185 - val_loss: 6.1520 - val_value_loss: 0.6555 - val_policy_loss: 1.6196\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1628 - value_loss: 0.6783 - policy_loss: 1.6185 - val_loss: 6.1507 - val_value_loss: 0.6530 - val_policy_loss: 1.6196\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1600 - value_loss: 0.6723 - policy_loss: 1.6188 - val_loss: 6.1498 - val_value_loss: 0.6512 - val_policy_loss: 1.6196\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1575 - value_loss: 0.6681 - policy_loss: 1.6180 - val_loss: 6.1491 - val_value_loss: 0.6499 - val_policy_loss: 1.6196\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1565 - value_loss: 0.6661 - policy_loss: 1.6181 - val_loss: 6.1481 - val_value_loss: 0.6479 - val_policy_loss: 1.6196\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1544 - value_loss: 0.6618 - policy_loss: 1.6182 - val_loss: 6.1477 - val_value_loss: 0.6471 - val_policy_loss: 1.6196\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1527 - value_loss: 0.6587 - policy_loss: 1.6180 - val_loss: 6.1470 - val_value_loss: 0.6457 - val_policy_loss: 1.6196\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1517 - value_loss: 0.6564 - policy_loss: 1.6183 - val_loss: 6.1464 - val_value_loss: 0.6445 - val_policy_loss: 1.6195\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1509 - value_loss: 0.6554 - policy_loss: 1.6176 - val_loss: 6.1458 - val_value_loss: 0.6434 - val_policy_loss: 1.6195\n",
      "Saved model  tictactoe_c_puct_0_5_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.89 - draw ratio 0.02\n",
      "Number of seen trajectories: 2900\n",
      "Number of unique trajectories: 2295\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_5_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1495 - value_loss: 0.6531 - policy_loss: 1.6172 - val_loss: 6.1418 - val_value_loss: 0.6497 - val_policy_loss: 1.6052\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1457 - value_loss: 0.6457 - policy_loss: 1.6169 - val_loss: 6.1405 - val_value_loss: 0.6470 - val_policy_loss: 1.6052\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1447 - value_loss: 0.6439 - policy_loss: 1.6168 - val_loss: 6.1394 - val_value_loss: 0.6448 - val_policy_loss: 1.6052\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1428 - value_loss: 0.6406 - policy_loss: 1.6165 - val_loss: 6.1384 - val_value_loss: 0.6429 - val_policy_loss: 1.6053\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1404 - value_loss: 0.6364 - policy_loss: 1.6158 - val_loss: 6.1375 - val_value_loss: 0.6412 - val_policy_loss: 1.6053\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1388 - value_loss: 0.6335 - policy_loss: 1.6155 - val_loss: 6.1367 - val_value_loss: 0.6395 - val_policy_loss: 1.6053\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1373 - value_loss: 0.6304 - policy_loss: 1.6156 - val_loss: 6.1359 - val_value_loss: 0.6380 - val_policy_loss: 1.6053\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1357 - value_loss: 0.6274 - policy_loss: 1.6154 - val_loss: 6.1352 - val_value_loss: 0.6366 - val_policy_loss: 1.6053\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1342 - value_loss: 0.6248 - policy_loss: 1.6150 - val_loss: 6.1345 - val_value_loss: 0.6353 - val_policy_loss: 1.6053\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1324 - value_loss: 0.6212 - policy_loss: 1.6151 - val_loss: 6.1339 - val_value_loss: 0.6340 - val_policy_loss: 1.6053\n",
      "Saved model  tictactoe_c_puct_0_5_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.05\n",
      "Number of seen trajectories: 3000\n",
      "Number of unique trajectories: 2360\n"
     ]
    }
   ],
   "source": [
    "wins_2, draws_2, seen_trajectories_2, unique_trajectories_2 = test_pipeline.run(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - c_puct 0.5\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "losses_2 = np.ones(30) - wins_2 - draws_2\n",
    "\n",
    "plt.plot(x, wins_2, label=\"win ratio\")\n",
    "plt.plot(x, draws_2, label=\"draw ratio\")\n",
    "plt.plot(x, losses_2, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "exploration_rate_2 = unique_trajectories_2/seen_trajectories_2\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - c_puct 0.5\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "\n",
    "plt.plot(x, exploration_rate_2, label=\"unique/seen\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins_2 = [0.78, 0.75, 0.87, 0.81, 0.8, 0.84, 0.79, 0.85, 0.79, 0.76, 0.87, 0.86, 0.77, 0.8, 0.86, 0.87, 0.85, 0.83, 0.86, 0.76, 0.84, 0.81, 0.84, 0.88, 0.82, 0.8, 0.83, 0.88, 0.89, 0.79]\n",
      "draws_2 = [0.01, 0.05, 0.02, 0.0, 0.02, 0.0, 0.02, 0.0, 0.0, 0.01, 0.01, 0.02, 0.03, 0.0, 0.01, 0.0, 0.02, 0.02, 0.01, 0.02, 0.03, 0.02, 0.07, 0.0, 0.01, 0.01, 0.02, 0.01, 0.02, 0.05]\n",
      "losses_2 = [0.21 0.2  0.11 0.19 0.18 0.16 0.19 0.15 0.21 0.23 0.12 0.12 0.2  0.2\n",
      " 0.13 0.13 0.13 0.15 0.13 0.22 0.13 0.17 0.09 0.12 0.17 0.19 0.15 0.11\n",
      " 0.09 0.16]\n",
      "seen_trajectories_2 = [ 100.  200.  300.  400.  500.  600.  700.  800.  900. 1000. 1100. 1200.\n",
      " 1300. 1400. 1500. 1600. 1700. 1800. 1900. 2000. 2100. 2200. 2300. 2400.\n",
      " 2500. 2600. 2700. 2800. 2900. 3000.]\n",
      "unique_trajectories_2 = [  99.  197.  293.  388.  476.  564.  651.  735.  822.  903.  986. 1068.\n",
      " 1143. 1213. 1286. 1366. 1449. 1527. 1599. 1679. 1754. 1825. 1891. 1960.\n",
      " 2026. 2091. 2158. 2227. 2295. 2360.]\n"
     ]
    }
   ],
   "source": [
    "print(\"wins_2 =\", wins_2)\n",
    "print(\"draws_2 =\", draws_2)\n",
    "print(\"losses_2 =\", losses_2)\n",
    "print(\"seen_trajectories_2 =\", seen_trajectories_2)\n",
    "print(\"unique_trajectories_2 =\", unique_trajectories_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $c_{puct}$ = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCTS = {\n",
    "    'c_puct': 1.5,\n",
    "    'dir_alpha': 0.6,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 10,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 10\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 0,\n",
    "    'show_games': False\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.002,\n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 512,\n",
    "    'num_filters_value': 512,\n",
    "    'num_filters_tower': 512,\n",
    "    'num_residual_blocks': 3,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 512\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"tictactoe_c_puct_1_5\", \"TicTacToe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (4960, 3, 3, 3)\n",
      "model_y_outcomes: (4960,)\n",
      "model_y_probabilities: (4960, 9)\n",
      "Train on 3968 samples, validate on 992 samples\n",
      "Epoch 1/10\n",
      "3968/3968 [==============================] - 4s 1ms/step - loss: 6.7819 - value_loss: 1.1184 - policy_loss: 2.3581 - val_loss: 6.6737 - val_value_loss: 0.9958 - val_policy_loss: 2.2647\n",
      "Epoch 2/10\n",
      "3968/3968 [==============================] - 1s 173us/step - loss: 6.5658 - value_loss: 0.8665 - policy_loss: 2.1785 - val_loss: 6.6262 - val_value_loss: 0.9957 - val_policy_loss: 2.1706\n",
      "Epoch 3/10\n",
      "3968/3968 [==============================] - 1s 172us/step - loss: 6.4729 - value_loss: 0.7706 - policy_loss: 2.0893 - val_loss: 6.6279 - val_value_loss: 1.0676 - val_policy_loss: 2.1026\n",
      "Epoch 4/10\n",
      "3968/3968 [==============================] - 1s 172us/step - loss: 6.4352 - value_loss: 0.7580 - policy_loss: 2.0271 - val_loss: 6.5656 - val_value_loss: 0.9975 - val_policy_loss: 2.0487\n",
      "Epoch 5/10\n",
      "3968/3968 [==============================] - 1s 172us/step - loss: 6.3782 - value_loss: 0.6952 - policy_loss: 1.9765 - val_loss: 6.5850 - val_value_loss: 1.0779 - val_policy_loss: 2.0079\n",
      "Epoch 6/10\n",
      "3968/3968 [==============================] - 1s 173us/step - loss: 6.3603 - value_loss: 0.6964 - policy_loss: 1.9401 - val_loss: 6.5607 - val_value_loss: 1.0629 - val_policy_loss: 1.9749\n",
      "Epoch 7/10\n",
      "3968/3968 [==============================] - 1s 172us/step - loss: 6.3448 - value_loss: 0.6969 - policy_loss: 1.9093 - val_loss: 6.5560 - val_value_loss: 1.0794 - val_policy_loss: 1.9498\n",
      "Epoch 8/10\n",
      "3968/3968 [==============================] - 1s 173us/step - loss: 6.2967 - value_loss: 0.6272 - policy_loss: 1.8835 - val_loss: 6.5114 - val_value_loss: 1.0148 - val_policy_loss: 1.9256\n",
      "Epoch 9/10\n",
      "3968/3968 [==============================] - 1s 172us/step - loss: 6.2760 - value_loss: 0.6086 - policy_loss: 1.8612 - val_loss: 6.4925 - val_value_loss: 0.9979 - val_policy_loss: 1.9054\n",
      "Epoch 10/10\n",
      "3968/3968 [==============================] - 1s 173us/step - loss: 6.2709 - value_loss: 0.6170 - policy_loss: 1.8434 - val_loss: 6.4791 - val_value_loss: 0.9882 - val_policy_loss: 1.8889\n",
      "Saved model  tictactoe_c_puct_1_5_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.68 - draw ratio 0.03\n",
      "Number of seen trajectories: 100\n",
      "Number of unique trajectories: 100\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 182us/step - loss: 6.2616 - value_loss: 0.5958 - policy_loss: 1.8467 - val_loss: 6.2632 - val_value_loss: 0.5972 - val_policy_loss: 1.8487\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2248 - value_loss: 0.5496 - policy_loss: 1.8199 - val_loss: 6.2928 - val_value_loss: 0.6716 - val_policy_loss: 1.8342\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2017 - value_loss: 0.5239 - policy_loss: 1.8001 - val_loss: 6.2482 - val_value_loss: 0.5971 - val_policy_loss: 1.8202\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1879 - value_loss: 0.5126 - policy_loss: 1.7843 - val_loss: 6.2641 - val_value_loss: 0.6391 - val_policy_loss: 1.8105\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1739 - value_loss: 0.4988 - policy_loss: 1.7708 - val_loss: 6.2410 - val_value_loss: 0.6031 - val_policy_loss: 1.8010\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1536 - value_loss: 0.4711 - policy_loss: 1.7586 - val_loss: 6.2494 - val_value_loss: 0.6288 - val_policy_loss: 1.7928\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1453 - value_loss: 0.4647 - policy_loss: 1.7490 - val_loss: 6.2371 - val_value_loss: 0.6130 - val_policy_loss: 1.7846\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1422 - value_loss: 0.4682 - policy_loss: 1.7398 - val_loss: 6.2305 - val_value_loss: 0.6072 - val_policy_loss: 1.7779\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1316 - value_loss: 0.4564 - policy_loss: 1.7311 - val_loss: 6.2319 - val_value_loss: 0.6167 - val_policy_loss: 1.7719\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1242 - value_loss: 0.4486 - policy_loss: 1.7247 - val_loss: 6.2221 - val_value_loss: 0.6036 - val_policy_loss: 1.7659\n",
      "Saved model  tictactoe_c_puct_1_5_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.01\n",
      "Number of seen trajectories: 200\n",
      "Number of unique trajectories: 198\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2161 - value_loss: 0.6053 - policy_loss: 1.7526 - val_loss: 6.1863 - val_value_loss: 0.5547 - val_policy_loss: 1.7439\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1729 - value_loss: 0.5339 - policy_loss: 1.7380 - val_loss: 6.1909 - val_value_loss: 0.5732 - val_policy_loss: 1.7351\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1618 - value_loss: 0.5228 - policy_loss: 1.7277 - val_loss: 6.1789 - val_value_loss: 0.5562 - val_policy_loss: 1.7288\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1414 - value_loss: 0.4916 - policy_loss: 1.7187 - val_loss: 6.1597 - val_value_loss: 0.5240 - val_policy_loss: 1.7233\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1228 - value_loss: 0.4632 - policy_loss: 1.7106 - val_loss: 6.1948 - val_value_loss: 0.6005 - val_policy_loss: 1.7176\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1247 - value_loss: 0.4752 - policy_loss: 1.7029 - val_loss: 6.1536 - val_value_loss: 0.5241 - val_policy_loss: 1.7123\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1081 - value_loss: 0.4483 - policy_loss: 1.6975 - val_loss: 6.1525 - val_value_loss: 0.5267 - val_policy_loss: 1.7081\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1026 - value_loss: 0.4437 - policy_loss: 1.6915 - val_loss: 6.1450 - val_value_loss: 0.5166 - val_policy_loss: 1.7039\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0954 - value_loss: 0.4344 - policy_loss: 1.6872 - val_loss: 6.1399 - val_value_loss: 0.5111 - val_policy_loss: 1.6999\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0906 - value_loss: 0.4302 - policy_loss: 1.6824 - val_loss: 6.1455 - val_value_loss: 0.5266 - val_policy_loss: 1.6961\n",
      "Saved model  tictactoe_c_puct_1_5_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.01\n",
      "Number of seen trajectories: 300\n",
      "Number of unique trajectories: 297\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2254 - value_loss: 0.6698 - policy_loss: 1.7130 - val_loss: 6.1712 - val_value_loss: 0.5885 - val_policy_loss: 1.6862\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1933 - value_loss: 0.6134 - policy_loss: 1.7058 - val_loss: 6.1563 - val_value_loss: 0.5645 - val_policy_loss: 1.6811\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1693 - value_loss: 0.5742 - policy_loss: 1.6977 - val_loss: 6.1547 - val_value_loss: 0.5655 - val_policy_loss: 1.6775\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1604 - value_loss: 0.5625 - policy_loss: 1.6922 - val_loss: 6.1554 - val_value_loss: 0.5714 - val_policy_loss: 1.6736\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1440 - value_loss: 0.5351 - policy_loss: 1.6874 - val_loss: 6.1433 - val_value_loss: 0.5510 - val_policy_loss: 1.6706\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1365 - value_loss: 0.5251 - policy_loss: 1.6831 - val_loss: 6.1536 - val_value_loss: 0.5750 - val_policy_loss: 1.6678\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1438 - value_loss: 0.5433 - policy_loss: 1.6801 - val_loss: 6.1769 - val_value_loss: 0.6249 - val_policy_loss: 1.6651\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1364 - value_loss: 0.5327 - policy_loss: 1.6764 - val_loss: 6.1377 - val_value_loss: 0.5497 - val_policy_loss: 1.6626\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1189 - value_loss: 0.5021 - policy_loss: 1.6727 - val_loss: 6.1376 - val_value_loss: 0.5521 - val_policy_loss: 1.6604\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1231 - value_loss: 0.5144 - policy_loss: 1.6695 - val_loss: 6.1377 - val_value_loss: 0.5549 - val_policy_loss: 1.6586\n",
      "Saved model  tictactoe_c_puct_1_5_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.0\n",
      "Number of seen trajectories: 400\n",
      "Number of unique trajectories: 390\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1860 - value_loss: 0.6178 - policy_loss: 1.6927 - val_loss: 6.1695 - val_value_loss: 0.5971 - val_policy_loss: 1.6807\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1559 - value_loss: 0.5651 - policy_loss: 1.6857 - val_loss: 6.1771 - val_value_loss: 0.6154 - val_policy_loss: 1.6783\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1434 - value_loss: 0.5453 - policy_loss: 1.6812 - val_loss: 6.1545 - val_value_loss: 0.5733 - val_policy_loss: 1.6758\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1253 - value_loss: 0.5126 - policy_loss: 1.6783 - val_loss: 6.1527 - val_value_loss: 0.5729 - val_policy_loss: 1.6731\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1191 - value_loss: 0.5058 - policy_loss: 1.6733 - val_loss: 6.1490 - val_value_loss: 0.5691 - val_policy_loss: 1.6702\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1150 - value_loss: 0.5013 - policy_loss: 1.6703 - val_loss: 6.1586 - val_value_loss: 0.5895 - val_policy_loss: 1.6696\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1114 - value_loss: 0.4967 - policy_loss: 1.6684 - val_loss: 6.1479 - val_value_loss: 0.5711 - val_policy_loss: 1.6674\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1027 - value_loss: 0.4834 - policy_loss: 1.6649 - val_loss: 6.1456 - val_value_loss: 0.5688 - val_policy_loss: 1.6655\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1014 - value_loss: 0.4830 - policy_loss: 1.6634 - val_loss: 6.1426 - val_value_loss: 0.5656 - val_policy_loss: 1.6633\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0955 - value_loss: 0.4740 - policy_loss: 1.6611 - val_loss: 6.1412 - val_value_loss: 0.5650 - val_policy_loss: 1.6618\n",
      "Saved model  tictactoe_c_puct_1_5_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.0\n",
      "Number of seen trajectories: 500\n",
      "Number of unique trajectories: 488\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1863 - value_loss: 0.6351 - policy_loss: 1.6821 - val_loss: 6.1812 - val_value_loss: 0.6344 - val_policy_loss: 1.6728\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1676 - value_loss: 0.6014 - policy_loss: 1.6788 - val_loss: 6.1790 - val_value_loss: 0.6316 - val_policy_loss: 1.6715\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1546 - value_loss: 0.5779 - policy_loss: 1.6766 - val_loss: 6.1850 - val_value_loss: 0.6454 - val_policy_loss: 1.6701\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1450 - value_loss: 0.5609 - policy_loss: 1.6747 - val_loss: 6.1819 - val_value_loss: 0.6403 - val_policy_loss: 1.6692\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1424 - value_loss: 0.5582 - policy_loss: 1.6726 - val_loss: 6.1818 - val_value_loss: 0.6415 - val_policy_loss: 1.6681\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1332 - value_loss: 0.5419 - policy_loss: 1.6707 - val_loss: 6.1782 - val_value_loss: 0.6358 - val_policy_loss: 1.6671\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1273 - value_loss: 0.5320 - policy_loss: 1.6692 - val_loss: 6.1800 - val_value_loss: 0.6404 - val_policy_loss: 1.6663\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1228 - value_loss: 0.5247 - policy_loss: 1.6677 - val_loss: 6.1809 - val_value_loss: 0.6433 - val_policy_loss: 1.6654\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1194 - value_loss: 0.5199 - policy_loss: 1.6660 - val_loss: 6.1790 - val_value_loss: 0.6408 - val_policy_loss: 1.6647\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1162 - value_loss: 0.5156 - policy_loss: 1.6644 - val_loss: 6.1783 - val_value_loss: 0.6404 - val_policy_loss: 1.6640\n",
      "Saved model  tictactoe_c_puct_1_5_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.0\n",
      "Number of seen trajectories: 600\n",
      "Number of unique trajectories: 580\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1816 - value_loss: 0.6619 - policy_loss: 1.6491 - val_loss: 6.1838 - val_value_loss: 0.6743 - val_policy_loss: 1.6413\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1616 - value_loss: 0.6251 - policy_loss: 1.6463 - val_loss: 6.1788 - val_value_loss: 0.6659 - val_policy_loss: 1.6400\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1453 - value_loss: 0.5949 - policy_loss: 1.6440 - val_loss: 6.1768 - val_value_loss: 0.6636 - val_policy_loss: 1.6388\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1351 - value_loss: 0.5775 - policy_loss: 1.6415 - val_loss: 6.1730 - val_value_loss: 0.6570 - val_policy_loss: 1.6379\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1273 - value_loss: 0.5647 - policy_loss: 1.6391 - val_loss: 6.1725 - val_value_loss: 0.6573 - val_policy_loss: 1.6370\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1206 - value_loss: 0.5532 - policy_loss: 1.6375 - val_loss: 6.1658 - val_value_loss: 0.6449 - val_policy_loss: 1.6362\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1163 - value_loss: 0.5468 - policy_loss: 1.6356 - val_loss: 6.1657 - val_value_loss: 0.6459 - val_policy_loss: 1.6354\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1091 - value_loss: 0.5336 - policy_loss: 1.6346 - val_loss: 6.1717 - val_value_loss: 0.6592 - val_policy_loss: 1.6344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1059 - value_loss: 0.5295 - policy_loss: 1.6327 - val_loss: 6.1617 - val_value_loss: 0.6403 - val_policy_loss: 1.6336\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1004 - value_loss: 0.5201 - policy_loss: 1.6314 - val_loss: 6.1644 - val_value_loss: 0.6469 - val_policy_loss: 1.6328\n",
      "Saved model  tictactoe_c_puct_1_5_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.89 - draw ratio 0.0\n",
      "Number of seen trajectories: 700\n",
      "Number of unique trajectories: 668\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1371 - value_loss: 0.5823 - policy_loss: 1.6429 - val_loss: 6.1168 - val_value_loss: 0.5582 - val_policy_loss: 1.6267\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1193 - value_loss: 0.5494 - policy_loss: 1.6405 - val_loss: 6.1097 - val_value_loss: 0.5451 - val_policy_loss: 1.6259\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1075 - value_loss: 0.5278 - policy_loss: 1.6389 - val_loss: 6.1049 - val_value_loss: 0.5366 - val_policy_loss: 1.6250\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0997 - value_loss: 0.5145 - policy_loss: 1.6369 - val_loss: 6.1027 - val_value_loss: 0.5336 - val_policy_loss: 1.6241\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0937 - value_loss: 0.5045 - policy_loss: 1.6352 - val_loss: 6.1004 - val_value_loss: 0.5302 - val_policy_loss: 1.6231\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0889 - value_loss: 0.4966 - policy_loss: 1.6338 - val_loss: 6.0972 - val_value_loss: 0.5246 - val_policy_loss: 1.6226\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0837 - value_loss: 0.4875 - policy_loss: 1.6329 - val_loss: 6.0964 - val_value_loss: 0.5241 - val_policy_loss: 1.6218\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0785 - value_loss: 0.4786 - policy_loss: 1.6316 - val_loss: 6.0941 - val_value_loss: 0.5204 - val_policy_loss: 1.6212\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0773 - value_loss: 0.4775 - policy_loss: 1.6307 - val_loss: 6.0962 - val_value_loss: 0.5255 - val_policy_loss: 1.6206\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0740 - value_loss: 0.4722 - policy_loss: 1.6296 - val_loss: 6.0917 - val_value_loss: 0.5176 - val_policy_loss: 1.6199\n",
      "Saved model  tictactoe_c_puct_1_5_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.81 - draw ratio 0.0\n",
      "Number of seen trajectories: 800\n",
      "Number of unique trajectories: 753\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1539 - value_loss: 0.6318 - policy_loss: 1.6303 - val_loss: 6.1477 - val_value_loss: 0.6123 - val_policy_loss: 1.6374\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1344 - value_loss: 0.5958 - policy_loss: 1.6275 - val_loss: 6.1361 - val_value_loss: 0.5901 - val_policy_loss: 1.6368\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1210 - value_loss: 0.5709 - policy_loss: 1.6259 - val_loss: 6.1321 - val_value_loss: 0.5830 - val_policy_loss: 1.6362\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1110 - value_loss: 0.5525 - policy_loss: 1.6246 - val_loss: 6.1287 - val_value_loss: 0.5771 - val_policy_loss: 1.6357\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1028 - value_loss: 0.5376 - policy_loss: 1.6235 - val_loss: 6.1239 - val_value_loss: 0.5681 - val_policy_loss: 1.6353\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0963 - value_loss: 0.5273 - policy_loss: 1.6210 - val_loss: 6.1221 - val_value_loss: 0.5654 - val_policy_loss: 1.6348\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0916 - value_loss: 0.5187 - policy_loss: 1.6206 - val_loss: 6.1234 - val_value_loss: 0.5689 - val_policy_loss: 1.6342\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0862 - value_loss: 0.5103 - policy_loss: 1.6185 - val_loss: 6.1163 - val_value_loss: 0.5558 - val_policy_loss: 1.6334\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0824 - value_loss: 0.5041 - policy_loss: 1.6174 - val_loss: 6.1165 - val_value_loss: 0.5571 - val_policy_loss: 1.6329\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0792 - value_loss: 0.4979 - policy_loss: 1.6175 - val_loss: 6.1154 - val_value_loss: 0.5557 - val_policy_loss: 1.6323\n",
      "Saved model  tictactoe_c_puct_1_5_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.01\n",
      "Number of seen trajectories: 900\n",
      "Number of unique trajectories: 839\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1590 - value_loss: 0.6535 - policy_loss: 1.6219 - val_loss: 6.1630 - val_value_loss: 0.6427 - val_policy_loss: 1.6409\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1405 - value_loss: 0.6181 - policy_loss: 1.6206 - val_loss: 6.1628 - val_value_loss: 0.6436 - val_policy_loss: 1.6400\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1285 - value_loss: 0.5955 - policy_loss: 1.6196 - val_loss: 6.1524 - val_value_loss: 0.6232 - val_policy_loss: 1.6397\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1185 - value_loss: 0.5778 - policy_loss: 1.6175 - val_loss: 6.1524 - val_value_loss: 0.6243 - val_policy_loss: 1.6390\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1094 - value_loss: 0.5615 - policy_loss: 1.6161 - val_loss: 6.1500 - val_value_loss: 0.6206 - val_policy_loss: 1.6383\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1044 - value_loss: 0.5530 - policy_loss: 1.6147 - val_loss: 6.1491 - val_value_loss: 0.6195 - val_policy_loss: 1.6378\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0971 - value_loss: 0.5399 - policy_loss: 1.6136 - val_loss: 6.1431 - val_value_loss: 0.6084 - val_policy_loss: 1.6373\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0944 - value_loss: 0.5355 - policy_loss: 1.6129 - val_loss: 6.1422 - val_value_loss: 0.6078 - val_policy_loss: 1.6364\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0911 - value_loss: 0.5300 - policy_loss: 1.6122 - val_loss: 6.1421 - val_value_loss: 0.6083 - val_policy_loss: 1.6360\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0863 - value_loss: 0.5221 - policy_loss: 1.6109 - val_loss: 6.1489 - val_value_loss: 0.6228 - val_policy_loss: 1.6354\n",
      "Saved model  tictactoe_c_puct_1_5_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.02\n",
      "Number of seen trajectories: 1000\n",
      "Number of unique trajectories: 926\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1380 - value_loss: 0.5903 - policy_loss: 1.6462 - val_loss: 6.1414 - val_value_loss: 0.5815 - val_policy_loss: 1.6619\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1248 - value_loss: 0.5655 - policy_loss: 1.6448 - val_loss: 6.1374 - val_value_loss: 0.5743 - val_policy_loss: 1.6612\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1163 - value_loss: 0.5487 - policy_loss: 1.6448 - val_loss: 6.1348 - val_value_loss: 0.5699 - val_policy_loss: 1.6606\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1086 - value_loss: 0.5354 - policy_loss: 1.6428 - val_loss: 6.1321 - val_value_loss: 0.5652 - val_policy_loss: 1.6601\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1024 - value_loss: 0.5239 - policy_loss: 1.6419 - val_loss: 6.1299 - val_value_loss: 0.5614 - val_policy_loss: 1.6597\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0976 - value_loss: 0.5148 - policy_loss: 1.6417 - val_loss: 6.1287 - val_value_loss: 0.5596 - val_policy_loss: 1.6593\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0934 - value_loss: 0.5075 - policy_loss: 1.6407 - val_loss: 6.1274 - val_value_loss: 0.5573 - val_policy_loss: 1.6590\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0899 - value_loss: 0.5013 - policy_loss: 1.6401 - val_loss: 6.1266 - val_value_loss: 0.5562 - val_policy_loss: 1.6587\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0874 - value_loss: 0.4966 - policy_loss: 1.6400 - val_loss: 6.1259 - val_value_loss: 0.5553 - val_policy_loss: 1.6583\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0831 - value_loss: 0.4896 - policy_loss: 1.6387 - val_loss: 6.1245 - val_value_loss: 0.5531 - val_policy_loss: 1.6580\n",
      "Saved model  tictactoe_c_puct_1_5_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.9 - draw ratio 0.0\n",
      "Number of seen trajectories: 1100\n",
      "Number of unique trajectories: 1012\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1216 - value_loss: 0.5923 - policy_loss: 1.6131 - val_loss: 6.0882 - val_value_loss: 0.5291 - val_policy_loss: 1.6095\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1090 - value_loss: 0.5685 - policy_loss: 1.6118 - val_loss: 6.0818 - val_value_loss: 0.5169 - val_policy_loss: 1.6092\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1009 - value_loss: 0.5532 - policy_loss: 1.6110 - val_loss: 6.0789 - val_value_loss: 0.5115 - val_policy_loss: 1.6088\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0942 - value_loss: 0.5405 - policy_loss: 1.6105 - val_loss: 6.0762 - val_value_loss: 0.5066 - val_policy_loss: 1.6085\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0896 - value_loss: 0.5318 - policy_loss: 1.6102 - val_loss: 6.0736 - val_value_loss: 0.5019 - val_policy_loss: 1.6082\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0846 - value_loss: 0.5233 - policy_loss: 1.6088 - val_loss: 6.0729 - val_value_loss: 0.5011 - val_policy_loss: 1.6078\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0811 - value_loss: 0.5168 - policy_loss: 1.6084 - val_loss: 6.0723 - val_value_loss: 0.5002 - val_policy_loss: 1.6075\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0764 - value_loss: 0.5086 - policy_loss: 1.6073 - val_loss: 6.0732 - val_value_loss: 0.5025 - val_policy_loss: 1.6071\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0745 - value_loss: 0.5056 - policy_loss: 1.6069 - val_loss: 6.0708 - val_value_loss: 0.4983 - val_policy_loss: 1.6068\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0719 - value_loss: 0.5009 - policy_loss: 1.6065 - val_loss: 6.0684 - val_value_loss: 0.4939 - val_policy_loss: 1.6066\n",
      "Saved model  tictactoe_c_puct_1_5_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.01\n",
      "Number of seen trajectories: 1200\n",
      "Number of unique trajectories: 1091\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1318 - value_loss: 0.5913 - policy_loss: 1.6360 - val_loss: 6.1147 - val_value_loss: 0.5884 - val_policy_loss: 1.6049\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1232 - value_loss: 0.5753 - policy_loss: 1.6350 - val_loss: 6.1122 - val_value_loss: 0.5842 - val_policy_loss: 1.6043\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1146 - value_loss: 0.5595 - policy_loss: 1.6338 - val_loss: 6.1141 - val_value_loss: 0.5885 - val_policy_loss: 1.6037\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1103 - value_loss: 0.5522 - policy_loss: 1.6326 - val_loss: 6.1104 - val_value_loss: 0.5819 - val_policy_loss: 1.6031\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1061 - value_loss: 0.5441 - policy_loss: 1.6325 - val_loss: 6.1103 - val_value_loss: 0.5824 - val_policy_loss: 1.6026\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1023 - value_loss: 0.5379 - policy_loss: 1.6313 - val_loss: 6.1070 - val_value_loss: 0.5764 - val_policy_loss: 1.6023\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0991 - value_loss: 0.5317 - policy_loss: 1.6311 - val_loss: 6.1059 - val_value_loss: 0.5747 - val_policy_loss: 1.6019\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0953 - value_loss: 0.5252 - policy_loss: 1.6302 - val_loss: 6.1044 - val_value_loss: 0.5723 - val_policy_loss: 1.6015\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0934 - value_loss: 0.5219 - policy_loss: 1.6299 - val_loss: 6.1069 - val_value_loss: 0.5777 - val_policy_loss: 1.6012\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0902 - value_loss: 0.5164 - policy_loss: 1.6292 - val_loss: 6.1041 - val_value_loss: 0.5726 - val_policy_loss: 1.6009\n",
      "Saved model  tictactoe_c_puct_1_5_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.0\n",
      "Number of seen trajectories: 1300\n",
      "Number of unique trajectories: 1169\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1362 - value_loss: 0.5937 - policy_loss: 1.6441 - val_loss: 6.1578 - val_value_loss: 0.6453 - val_policy_loss: 1.6357\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1221 - value_loss: 0.5667 - policy_loss: 1.6430 - val_loss: 6.1494 - val_value_loss: 0.6290 - val_policy_loss: 1.6354\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1116 - value_loss: 0.5464 - policy_loss: 1.6425 - val_loss: 6.1471 - val_value_loss: 0.6246 - val_policy_loss: 1.6353\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1044 - value_loss: 0.5333 - policy_loss: 1.6413 - val_loss: 6.1462 - val_value_loss: 0.6232 - val_policy_loss: 1.6351\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0990 - value_loss: 0.5230 - policy_loss: 1.6409 - val_loss: 6.1427 - val_value_loss: 0.6166 - val_policy_loss: 1.6349\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0938 - value_loss: 0.5132 - policy_loss: 1.6406 - val_loss: 6.1426 - val_value_loss: 0.6167 - val_policy_loss: 1.6347\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0903 - value_loss: 0.5069 - policy_loss: 1.6401 - val_loss: 6.1399 - val_value_loss: 0.6117 - val_policy_loss: 1.6344\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0869 - value_loss: 0.5008 - policy_loss: 1.6394 - val_loss: 6.1421 - val_value_loss: 0.6165 - val_policy_loss: 1.6342\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0850 - value_loss: 0.4975 - policy_loss: 1.6391 - val_loss: 6.1406 - val_value_loss: 0.6139 - val_policy_loss: 1.6340\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0823 - value_loss: 0.4928 - policy_loss: 1.6386 - val_loss: 6.1376 - val_value_loss: 0.6082 - val_policy_loss: 1.6338\n",
      "Saved model  tictactoe_c_puct_1_5_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.0\n",
      "Number of seen trajectories: 1400\n",
      "Number of unique trajectories: 1250\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0937 - value_loss: 0.5392 - policy_loss: 1.6152 - val_loss: 6.1060 - val_value_loss: 0.5475 - val_policy_loss: 1.6315\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0856 - value_loss: 0.5239 - policy_loss: 1.6143 - val_loss: 6.1011 - val_value_loss: 0.5385 - val_policy_loss: 1.6309\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0789 - value_loss: 0.5115 - policy_loss: 1.6136 - val_loss: 6.0991 - val_value_loss: 0.5350 - val_policy_loss: 1.6305\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0748 - value_loss: 0.5047 - policy_loss: 1.6124 - val_loss: 6.0977 - val_value_loss: 0.5327 - val_policy_loss: 1.6302\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0709 - value_loss: 0.4971 - policy_loss: 1.6122 - val_loss: 6.0953 - val_value_loss: 0.5286 - val_policy_loss: 1.6297\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0665 - value_loss: 0.4899 - policy_loss: 1.6108 - val_loss: 6.0938 - val_value_loss: 0.5259 - val_policy_loss: 1.6294\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0638 - value_loss: 0.4848 - policy_loss: 1.6107 - val_loss: 6.0936 - val_value_loss: 0.5260 - val_policy_loss: 1.6292\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0613 - value_loss: 0.4807 - policy_loss: 1.6099 - val_loss: 6.0921 - val_value_loss: 0.5234 - val_policy_loss: 1.6289\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0583 - value_loss: 0.4752 - policy_loss: 1.6096 - val_loss: 6.0921 - val_value_loss: 0.5238 - val_policy_loss: 1.6287\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0566 - value_loss: 0.4728 - policy_loss: 1.6088 - val_loss: 6.0923 - val_value_loss: 0.5247 - val_policy_loss: 1.6284\n",
      "Saved model  tictactoe_c_puct_1_5_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.01\n",
      "Number of seen trajectories: 1500\n",
      "Number of unique trajectories: 1327\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1328 - value_loss: 0.5841 - policy_loss: 1.6499 - val_loss: 6.1100 - val_value_loss: 0.5554 - val_policy_loss: 1.6331\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1236 - value_loss: 0.5664 - policy_loss: 1.6495 - val_loss: 6.1076 - val_value_loss: 0.5512 - val_policy_loss: 1.6327\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1186 - value_loss: 0.5563 - policy_loss: 1.6495 - val_loss: 6.1061 - val_value_loss: 0.5485 - val_policy_loss: 1.6324\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1133 - value_loss: 0.5467 - policy_loss: 1.6485 - val_loss: 6.1045 - val_value_loss: 0.5457 - val_policy_loss: 1.6321\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1088 - value_loss: 0.5382 - policy_loss: 1.6482 - val_loss: 6.1036 - val_value_loss: 0.5441 - val_policy_loss: 1.6319\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1042 - value_loss: 0.5296 - policy_loss: 1.6478 - val_loss: 6.1028 - val_value_loss: 0.5429 - val_policy_loss: 1.6317\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1023 - value_loss: 0.5259 - policy_loss: 1.6476 - val_loss: 6.1025 - val_value_loss: 0.5424 - val_policy_loss: 1.6315\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0994 - value_loss: 0.5201 - policy_loss: 1.6478 - val_loss: 6.1020 - val_value_loss: 0.5417 - val_policy_loss: 1.6313\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0976 - value_loss: 0.5173 - policy_loss: 1.6470 - val_loss: 6.1020 - val_value_loss: 0.5420 - val_policy_loss: 1.6312\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0950 - value_loss: 0.5125 - policy_loss: 1.6468 - val_loss: 6.1012 - val_value_loss: 0.5406 - val_policy_loss: 1.6311\n",
      "Saved model  tictactoe_c_puct_1_5_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.01\n",
      "Number of seen trajectories: 1600\n",
      "Number of unique trajectories: 1400\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1137 - value_loss: 0.5798 - policy_loss: 1.6168 - val_loss: 6.0844 - val_value_loss: 0.5245 - val_policy_loss: 1.6136\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1067 - value_loss: 0.5665 - policy_loss: 1.6163 - val_loss: 6.0831 - val_value_loss: 0.5220 - val_policy_loss: 1.6135\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1029 - value_loss: 0.5585 - policy_loss: 1.6166 - val_loss: 6.0818 - val_value_loss: 0.5196 - val_policy_loss: 1.6134\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0981 - value_loss: 0.5499 - policy_loss: 1.6157 - val_loss: 6.0806 - val_value_loss: 0.5174 - val_policy_loss: 1.6133\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0929 - value_loss: 0.5406 - policy_loss: 1.6149 - val_loss: 6.0802 - val_value_loss: 0.5168 - val_policy_loss: 1.6132\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0901 - value_loss: 0.5350 - policy_loss: 1.6148 - val_loss: 6.0792 - val_value_loss: 0.5150 - val_policy_loss: 1.6131\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0872 - value_loss: 0.5300 - policy_loss: 1.6142 - val_loss: 6.0787 - val_value_loss: 0.5142 - val_policy_loss: 1.6131\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0857 - value_loss: 0.5266 - policy_loss: 1.6146 - val_loss: 6.0783 - val_value_loss: 0.5135 - val_policy_loss: 1.6130\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0822 - value_loss: 0.5202 - policy_loss: 1.6140 - val_loss: 6.0775 - val_value_loss: 0.5120 - val_policy_loss: 1.6129\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0799 - value_loss: 0.5162 - policy_loss: 1.6136 - val_loss: 6.0771 - val_value_loss: 0.5114 - val_policy_loss: 1.6128\n",
      "Saved model  tictactoe_c_puct_1_5_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.0\n",
      "Number of seen trajectories: 1700\n",
      "Number of unique trajectories: 1481\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 6.1067 - value_loss: 0.5607 - policy_loss: 1.6227 - val_loss: 6.1181 - val_value_loss: 0.5716 - val_policy_loss: 1.6347\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.0998 - value_loss: 0.5483 - policy_loss: 1.6216 - val_loss: 6.1168 - val_value_loss: 0.5693 - val_policy_loss: 1.6346\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.0955 - value_loss: 0.5398 - policy_loss: 1.6213 - val_loss: 6.1152 - val_value_loss: 0.5662 - val_policy_loss: 1.6344\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.0899 - value_loss: 0.5292 - policy_loss: 1.6208 - val_loss: 6.1152 - val_value_loss: 0.5665 - val_policy_loss: 1.6343\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0862 - value_loss: 0.5219 - policy_loss: 1.6209 - val_loss: 6.1136 - val_value_loss: 0.5633 - val_policy_loss: 1.6343\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.0839 - value_loss: 0.5176 - policy_loss: 1.6206 - val_loss: 6.1139 - val_value_loss: 0.5642 - val_policy_loss: 1.6342\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.0796 - value_loss: 0.5096 - policy_loss: 1.6202 - val_loss: 6.1135 - val_value_loss: 0.5636 - val_policy_loss: 1.6341\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.0772 - value_loss: 0.5053 - policy_loss: 1.6196 - val_loss: 6.1137 - val_value_loss: 0.5641 - val_policy_loss: 1.6340\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0750 - value_loss: 0.5013 - policy_loss: 1.6194 - val_loss: 6.1134 - val_value_loss: 0.5638 - val_policy_loss: 1.6339\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0732 - value_loss: 0.4976 - policy_loss: 1.6195 - val_loss: 6.1128 - val_value_loss: 0.5626 - val_policy_loss: 1.6338\n",
      "Saved model  tictactoe_c_puct_1_5_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.9 - draw ratio 0.0\n",
      "Number of seen trajectories: 1800\n",
      "Number of unique trajectories: 1552\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 6.0941 - value_loss: 0.5383 - policy_loss: 1.6206 - val_loss: 6.1192 - val_value_loss: 0.5657 - val_policy_loss: 1.6437\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0872 - value_loss: 0.5250 - policy_loss: 1.6204 - val_loss: 6.1169 - val_value_loss: 0.5614 - val_policy_loss: 1.6435\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0828 - value_loss: 0.5165 - policy_loss: 1.6200 - val_loss: 6.1144 - val_value_loss: 0.5566 - val_policy_loss: 1.6433\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0778 - value_loss: 0.5071 - policy_loss: 1.6195 - val_loss: 6.1126 - val_value_loss: 0.5532 - val_policy_loss: 1.6431\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0757 - value_loss: 0.5033 - policy_loss: 1.6194 - val_loss: 6.1109 - val_value_loss: 0.5500 - val_policy_loss: 1.6430\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0720 - value_loss: 0.4960 - policy_loss: 1.6192 - val_loss: 6.1096 - val_value_loss: 0.5477 - val_policy_loss: 1.6428\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.0692 - value_loss: 0.4909 - policy_loss: 1.6188 - val_loss: 6.1086 - val_value_loss: 0.5458 - val_policy_loss: 1.6427\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0665 - value_loss: 0.4857 - policy_loss: 1.6188 - val_loss: 6.1080 - val_value_loss: 0.5449 - val_policy_loss: 1.6426\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0640 - value_loss: 0.4812 - policy_loss: 1.6183 - val_loss: 6.1076 - val_value_loss: 0.5443 - val_policy_loss: 1.6425\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0615 - value_loss: 0.4772 - policy_loss: 1.6173 - val_loss: 6.1069 - val_value_loss: 0.5432 - val_policy_loss: 1.6423\n",
      "Saved model  tictactoe_c_puct_1_5_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.01\n",
      "Number of seen trajectories: 1900\n",
      "Number of unique trajectories: 1623\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1139 - value_loss: 0.5756 - policy_loss: 1.6238 - val_loss: 6.1105 - val_value_loss: 0.5753 - val_policy_loss: 1.6174\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1076 - value_loss: 0.5641 - policy_loss: 1.6230 - val_loss: 6.1083 - val_value_loss: 0.5712 - val_policy_loss: 1.6171\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1026 - value_loss: 0.5548 - policy_loss: 1.6223 - val_loss: 6.1076 - val_value_loss: 0.5700 - val_policy_loss: 1.6170\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0981 - value_loss: 0.5462 - policy_loss: 1.6219 - val_loss: 6.1061 - val_value_loss: 0.5673 - val_policy_loss: 1.6168\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0945 - value_loss: 0.5397 - policy_loss: 1.6213 - val_loss: 6.1057 - val_value_loss: 0.5668 - val_policy_loss: 1.6167\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0909 - value_loss: 0.5326 - policy_loss: 1.6214 - val_loss: 6.1045 - val_value_loss: 0.5645 - val_policy_loss: 1.6166\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0884 - value_loss: 0.5274 - policy_loss: 1.6214 - val_loss: 6.1039 - val_value_loss: 0.5635 - val_policy_loss: 1.6165\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0853 - value_loss: 0.5220 - policy_loss: 1.6208 - val_loss: 6.1044 - val_value_loss: 0.5647 - val_policy_loss: 1.6164\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0834 - value_loss: 0.5187 - policy_loss: 1.6204 - val_loss: 6.1044 - val_value_loss: 0.5648 - val_policy_loss: 1.6163\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0799 - value_loss: 0.5120 - policy_loss: 1.6201 - val_loss: 6.1039 - val_value_loss: 0.5639 - val_policy_loss: 1.6162\n",
      "Saved model  tictactoe_c_puct_1_5_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.01\n",
      "Number of seen trajectories: 2000\n",
      "Number of unique trajectories: 1700\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1331 - value_loss: 0.6087 - policy_loss: 1.6300 - val_loss: 6.1127 - val_value_loss: 0.5892 - val_policy_loss: 1.6088\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1297 - value_loss: 0.6026 - policy_loss: 1.6293 - val_loss: 6.1101 - val_value_loss: 0.5841 - val_policy_loss: 1.6087\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1262 - value_loss: 0.5955 - policy_loss: 1.6295 - val_loss: 6.1087 - val_value_loss: 0.5814 - val_policy_loss: 1.6086\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1229 - value_loss: 0.5895 - policy_loss: 1.6289 - val_loss: 6.1072 - val_value_loss: 0.5784 - val_policy_loss: 1.6085\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1206 - value_loss: 0.5851 - policy_loss: 1.6287 - val_loss: 6.1058 - val_value_loss: 0.5758 - val_policy_loss: 1.6085\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1173 - value_loss: 0.5785 - policy_loss: 1.6287 - val_loss: 6.1045 - val_value_loss: 0.5732 - val_policy_loss: 1.6084\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1159 - value_loss: 0.5757 - policy_loss: 1.6288 - val_loss: 6.1037 - val_value_loss: 0.5718 - val_policy_loss: 1.6084\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1135 - value_loss: 0.5713 - policy_loss: 1.6285 - val_loss: 6.1030 - val_value_loss: 0.5705 - val_policy_loss: 1.6084\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1120 - value_loss: 0.5684 - policy_loss: 1.6284 - val_loss: 6.1022 - val_value_loss: 0.5688 - val_policy_loss: 1.6083\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1093 - value_loss: 0.5634 - policy_loss: 1.6280 - val_loss: 6.1014 - val_value_loss: 0.5673 - val_policy_loss: 1.6083\n",
      "Saved model  tictactoe_c_puct_1_5_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.81 - draw ratio 0.02\n",
      "Number of seen trajectories: 2100\n",
      "Number of unique trajectories: 1773\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1024 - value_loss: 0.5577 - policy_loss: 1.6199 - val_loss: 6.1313 - val_value_loss: 0.5822 - val_policy_loss: 1.6531\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0994 - value_loss: 0.5520 - policy_loss: 1.6196 - val_loss: 6.1295 - val_value_loss: 0.5790 - val_policy_loss: 1.6530\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0959 - value_loss: 0.5454 - policy_loss: 1.6193 - val_loss: 6.1281 - val_value_loss: 0.5764 - val_policy_loss: 1.6528\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0936 - value_loss: 0.5408 - policy_loss: 1.6194 - val_loss: 6.1269 - val_value_loss: 0.5741 - val_policy_loss: 1.6527\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0914 - value_loss: 0.5371 - policy_loss: 1.6188 - val_loss: 6.1258 - val_value_loss: 0.5721 - val_policy_loss: 1.6526\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0894 - value_loss: 0.5331 - policy_loss: 1.6187 - val_loss: 6.1249 - val_value_loss: 0.5703 - val_policy_loss: 1.6525\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0875 - value_loss: 0.5292 - policy_loss: 1.6188 - val_loss: 6.1240 - val_value_loss: 0.5688 - val_policy_loss: 1.6524\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0860 - value_loss: 0.5266 - policy_loss: 1.6185 - val_loss: 6.1233 - val_value_loss: 0.5674 - val_policy_loss: 1.6523\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0853 - value_loss: 0.5252 - policy_loss: 1.6185 - val_loss: 6.1226 - val_value_loss: 0.5662 - val_policy_loss: 1.6522\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0831 - value_loss: 0.5211 - policy_loss: 1.6184 - val_loss: 6.1220 - val_value_loss: 0.5651 - val_policy_loss: 1.6522\n",
      "Saved model  tictactoe_c_puct_1_5_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.01\n",
      "Number of seen trajectories: 2200\n",
      "Number of unique trajectories: 1850\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1022 - value_loss: 0.5492 - policy_loss: 1.6283 - val_loss: 6.0993 - val_value_loss: 0.5441 - val_policy_loss: 1.6278\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0989 - value_loss: 0.5429 - policy_loss: 1.6282 - val_loss: 6.0983 - val_value_loss: 0.5422 - val_policy_loss: 1.6276\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0974 - value_loss: 0.5400 - policy_loss: 1.6281 - val_loss: 6.0978 - val_value_loss: 0.5413 - val_policy_loss: 1.6276\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0949 - value_loss: 0.5353 - policy_loss: 1.6278 - val_loss: 6.0971 - val_value_loss: 0.5402 - val_policy_loss: 1.6275\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0925 - value_loss: 0.5307 - policy_loss: 1.6277 - val_loss: 6.0966 - val_value_loss: 0.5392 - val_policy_loss: 1.6274\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0918 - value_loss: 0.5291 - policy_loss: 1.6279 - val_loss: 6.0962 - val_value_loss: 0.5385 - val_policy_loss: 1.6273\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0896 - value_loss: 0.5250 - policy_loss: 1.6277 - val_loss: 6.0958 - val_value_loss: 0.5379 - val_policy_loss: 1.6273\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0869 - value_loss: 0.5201 - policy_loss: 1.6272 - val_loss: 6.0956 - val_value_loss: 0.5375 - val_policy_loss: 1.6272\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0862 - value_loss: 0.5189 - policy_loss: 1.6270 - val_loss: 6.0952 - val_value_loss: 0.5369 - val_policy_loss: 1.6271\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0857 - value_loss: 0.5175 - policy_loss: 1.6276 - val_loss: 6.0952 - val_value_loss: 0.5369 - val_policy_loss: 1.6271\n",
      "Saved model  tictactoe_c_puct_1_5_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.01\n",
      "Number of seen trajectories: 2300\n",
      "Number of unique trajectories: 1915\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1151 - value_loss: 0.5785 - policy_loss: 1.6254 - val_loss: 6.1111 - val_value_loss: 0.5822 - val_policy_loss: 1.6137\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1103 - value_loss: 0.5692 - policy_loss: 1.6250 - val_loss: 6.1067 - val_value_loss: 0.5735 - val_policy_loss: 1.6136\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1050 - value_loss: 0.5592 - policy_loss: 1.6245 - val_loss: 6.1034 - val_value_loss: 0.5669 - val_policy_loss: 1.6135\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1024 - value_loss: 0.5542 - policy_loss: 1.6244 - val_loss: 6.1002 - val_value_loss: 0.5608 - val_policy_loss: 1.6135\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1001 - value_loss: 0.5500 - policy_loss: 1.6240 - val_loss: 6.0978 - val_value_loss: 0.5559 - val_policy_loss: 1.6134\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0972 - value_loss: 0.5442 - policy_loss: 1.6239 - val_loss: 6.0959 - val_value_loss: 0.5523 - val_policy_loss: 1.6133\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0952 - value_loss: 0.5406 - policy_loss: 1.6238 - val_loss: 6.0945 - val_value_loss: 0.5497 - val_policy_loss: 1.6132\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0934 - value_loss: 0.5378 - policy_loss: 1.6230 - val_loss: 6.0931 - val_value_loss: 0.5469 - val_policy_loss: 1.6132\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0924 - value_loss: 0.5354 - policy_loss: 1.6235 - val_loss: 6.0922 - val_value_loss: 0.5453 - val_policy_loss: 1.6131\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0902 - value_loss: 0.5312 - policy_loss: 1.6231 - val_loss: 6.0909 - val_value_loss: 0.5428 - val_policy_loss: 1.6131\n",
      "Saved model  tictactoe_c_puct_1_5_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.01\n",
      "Number of seen trajectories: 2400\n",
      "Number of unique trajectories: 1983\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1270 - value_loss: 0.6022 - policy_loss: 1.6258 - val_loss: 6.1144 - val_value_loss: 0.5771 - val_policy_loss: 1.6257\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1217 - value_loss: 0.5919 - policy_loss: 1.6256 - val_loss: 6.1138 - val_value_loss: 0.5761 - val_policy_loss: 1.6257\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1191 - value_loss: 0.5860 - policy_loss: 1.6262 - val_loss: 6.1134 - val_value_loss: 0.5753 - val_policy_loss: 1.6256\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1135 - value_loss: 0.5759 - policy_loss: 1.6252 - val_loss: 6.1130 - val_value_loss: 0.5745 - val_policy_loss: 1.6256\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1112 - value_loss: 0.5713 - policy_loss: 1.6252 - val_loss: 6.1127 - val_value_loss: 0.5740 - val_policy_loss: 1.6256\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1080 - value_loss: 0.5653 - policy_loss: 1.6249 - val_loss: 6.1126 - val_value_loss: 0.5739 - val_policy_loss: 1.6255\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1056 - value_loss: 0.5607 - policy_loss: 1.6248 - val_loss: 6.1124 - val_value_loss: 0.5736 - val_policy_loss: 1.6255\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1034 - value_loss: 0.5557 - policy_loss: 1.6253 - val_loss: 6.1123 - val_value_loss: 0.5735 - val_policy_loss: 1.6254\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1012 - value_loss: 0.5520 - policy_loss: 1.6248 - val_loss: 6.1123 - val_value_loss: 0.5737 - val_policy_loss: 1.6254\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0986 - value_loss: 0.5473 - policy_loss: 1.6243 - val_loss: 6.1123 - val_value_loss: 0.5737 - val_policy_loss: 1.6253\n",
      "Saved model  tictactoe_c_puct_1_5_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.02\n",
      "Number of seen trajectories: 2500\n",
      "Number of unique trajectories: 2052\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1130 - value_loss: 0.5838 - policy_loss: 1.6167 - val_loss: 6.1429 - val_value_loss: 0.6141 - val_policy_loss: 1.6462\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1091 - value_loss: 0.5760 - policy_loss: 1.6167 - val_loss: 6.1416 - val_value_loss: 0.6114 - val_policy_loss: 1.6462\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1065 - value_loss: 0.5712 - policy_loss: 1.6162 - val_loss: 6.1407 - val_value_loss: 0.6097 - val_policy_loss: 1.6461\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1042 - value_loss: 0.5666 - policy_loss: 1.6162 - val_loss: 6.1401 - val_value_loss: 0.6085 - val_policy_loss: 1.6461\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1028 - value_loss: 0.5640 - policy_loss: 1.6162 - val_loss: 6.1396 - val_value_loss: 0.6077 - val_policy_loss: 1.6460\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1016 - value_loss: 0.5614 - policy_loss: 1.6162 - val_loss: 6.1392 - val_value_loss: 0.6069 - val_policy_loss: 1.6460\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1000 - value_loss: 0.5585 - policy_loss: 1.6161 - val_loss: 6.1387 - val_value_loss: 0.6061 - val_policy_loss: 1.6460\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1006 - value_loss: 0.5589 - policy_loss: 1.6168 - val_loss: 6.1385 - val_value_loss: 0.6056 - val_policy_loss: 1.6460\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0982 - value_loss: 0.5550 - policy_loss: 1.6159 - val_loss: 6.1382 - val_value_loss: 0.6050 - val_policy_loss: 1.6459\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0970 - value_loss: 0.5529 - policy_loss: 1.6157 - val_loss: 6.1379 - val_value_loss: 0.6045 - val_policy_loss: 1.6459\n",
      "Saved model  tictactoe_c_puct_1_5_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.0\n",
      "Number of seen trajectories: 2600\n",
      "Number of unique trajectories: 2114\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.0946 - value_loss: 0.5490 - policy_loss: 1.6148 - val_loss: 6.0872 - val_value_loss: 0.5444 - val_policy_loss: 1.6045\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0931 - value_loss: 0.5466 - policy_loss: 1.6143 - val_loss: 6.0860 - val_value_loss: 0.5422 - val_policy_loss: 1.6045\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0917 - value_loss: 0.5439 - policy_loss: 1.6143 - val_loss: 6.0851 - val_value_loss: 0.5403 - val_policy_loss: 1.6044\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0896 - value_loss: 0.5398 - policy_loss: 1.6141 - val_loss: 6.0842 - val_value_loss: 0.5387 - val_policy_loss: 1.6044\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0886 - value_loss: 0.5377 - policy_loss: 1.6142 - val_loss: 6.0835 - val_value_loss: 0.5373 - val_policy_loss: 1.6044\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0874 - value_loss: 0.5356 - policy_loss: 1.6139 - val_loss: 6.0828 - val_value_loss: 0.5361 - val_policy_loss: 1.6043\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0860 - value_loss: 0.5330 - policy_loss: 1.6138 - val_loss: 6.0822 - val_value_loss: 0.5349 - val_policy_loss: 1.6043\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0858 - value_loss: 0.5327 - policy_loss: 1.6136 - val_loss: 6.0818 - val_value_loss: 0.5340 - val_policy_loss: 1.6043\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0837 - value_loss: 0.5289 - policy_loss: 1.6132 - val_loss: 6.0813 - val_value_loss: 0.5332 - val_policy_loss: 1.6042\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0839 - value_loss: 0.5290 - policy_loss: 1.6136 - val_loss: 6.0809 - val_value_loss: 0.5324 - val_policy_loss: 1.6042\n",
      "Saved model  tictactoe_c_puct_1_5_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.0\n",
      "Number of seen trajectories: 2700\n",
      "Number of unique trajectories: 2183\n",
      "iteration 27 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.0971 - value_loss: 0.5432 - policy_loss: 1.6258 - val_loss: 6.0874 - val_value_loss: 0.5331 - val_policy_loss: 1.6165\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0946 - value_loss: 0.5385 - policy_loss: 1.6255 - val_loss: 6.0864 - val_value_loss: 0.5312 - val_policy_loss: 1.6165\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0929 - value_loss: 0.5354 - policy_loss: 1.6251 - val_loss: 6.0855 - val_value_loss: 0.5295 - val_policy_loss: 1.6165\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0917 - value_loss: 0.5332 - policy_loss: 1.6250 - val_loss: 6.0847 - val_value_loss: 0.5279 - val_policy_loss: 1.6164\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0902 - value_loss: 0.5299 - policy_loss: 1.6254 - val_loss: 6.0840 - val_value_loss: 0.5266 - val_policy_loss: 1.6164\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0888 - value_loss: 0.5277 - policy_loss: 1.6249 - val_loss: 6.0834 - val_value_loss: 0.5253 - val_policy_loss: 1.6164\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0887 - value_loss: 0.5267 - policy_loss: 1.6256 - val_loss: 6.0828 - val_value_loss: 0.5241 - val_policy_loss: 1.6164\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0871 - value_loss: 0.5244 - policy_loss: 1.6248 - val_loss: 6.0822 - val_value_loss: 0.5230 - val_policy_loss: 1.6163\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0853 - value_loss: 0.5209 - policy_loss: 1.6247 - val_loss: 6.0817 - val_value_loss: 0.5220 - val_policy_loss: 1.6163\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0846 - value_loss: 0.5199 - policy_loss: 1.6243 - val_loss: 6.0811 - val_value_loss: 0.5210 - val_policy_loss: 1.6163\n",
      "Saved model  tictactoe_c_puct_1_5_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.81 - draw ratio 0.02\n",
      "Number of seen trajectories: 2800\n",
      "Number of unique trajectories: 2248\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.0854 - value_loss: 0.5278 - policy_loss: 1.6181 - val_loss: 6.1120 - val_value_loss: 0.5646 - val_policy_loss: 1.6344\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0828 - value_loss: 0.5226 - policy_loss: 1.6179 - val_loss: 6.1112 - val_value_loss: 0.5630 - val_policy_loss: 1.6344\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0804 - value_loss: 0.5184 - policy_loss: 1.6176 - val_loss: 6.1105 - val_value_loss: 0.5617 - val_policy_loss: 1.6344\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0790 - value_loss: 0.5151 - policy_loss: 1.6180 - val_loss: 6.1100 - val_value_loss: 0.5607 - val_policy_loss: 1.6344\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0771 - value_loss: 0.5117 - policy_loss: 1.6176 - val_loss: 6.1095 - val_value_loss: 0.5597 - val_policy_loss: 1.6344\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0761 - value_loss: 0.5094 - policy_loss: 1.6179 - val_loss: 6.1091 - val_value_loss: 0.5588 - val_policy_loss: 1.6344\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0741 - value_loss: 0.5061 - policy_loss: 1.6172 - val_loss: 6.1086 - val_value_loss: 0.5580 - val_policy_loss: 1.6344\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0733 - value_loss: 0.5046 - policy_loss: 1.6171 - val_loss: 6.1082 - val_value_loss: 0.5572 - val_policy_loss: 1.6344\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0714 - value_loss: 0.5009 - policy_loss: 1.6170 - val_loss: 6.1079 - val_value_loss: 0.5567 - val_policy_loss: 1.6344\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0711 - value_loss: 0.5007 - policy_loss: 1.6168 - val_loss: 6.1077 - val_value_loss: 0.5563 - val_policy_loss: 1.6344\n",
      "Saved model  tictactoe_c_puct_1_5_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.0\n",
      "Number of seen trajectories: 2900\n",
      "Number of unique trajectories: 2315\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_1_5_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1165 - value_loss: 0.5980 - policy_loss: 1.6102 - val_loss: 6.0818 - val_value_loss: 0.5390 - val_policy_loss: 1.5999\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1133 - value_loss: 0.5922 - policy_loss: 1.6095 - val_loss: 6.0808 - val_value_loss: 0.5370 - val_policy_loss: 1.5999\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1110 - value_loss: 0.5878 - policy_loss: 1.6094 - val_loss: 6.0799 - val_value_loss: 0.5353 - val_policy_loss: 1.5999\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1093 - value_loss: 0.5840 - policy_loss: 1.6098 - val_loss: 6.0793 - val_value_loss: 0.5340 - val_policy_loss: 1.5999\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1073 - value_loss: 0.5808 - policy_loss: 1.6091 - val_loss: 6.0786 - val_value_loss: 0.5327 - val_policy_loss: 1.5999\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1058 - value_loss: 0.5780 - policy_loss: 1.6090 - val_loss: 6.0780 - val_value_loss: 0.5315 - val_policy_loss: 1.5999\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1047 - value_loss: 0.5752 - policy_loss: 1.6096 - val_loss: 6.0775 - val_value_loss: 0.5305 - val_policy_loss: 1.5999\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1033 - value_loss: 0.5725 - policy_loss: 1.6094 - val_loss: 6.0770 - val_value_loss: 0.5296 - val_policy_loss: 1.5998\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1013 - value_loss: 0.5689 - policy_loss: 1.6091 - val_loss: 6.0765 - val_value_loss: 0.5286 - val_policy_loss: 1.5998\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0998 - value_loss: 0.5660 - policy_loss: 1.6090 - val_loss: 6.0761 - val_value_loss: 0.5277 - val_policy_loss: 1.5998\n",
      "Saved model  tictactoe_c_puct_1_5_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.01\n",
      "Number of seen trajectories: 3000\n",
      "Number of unique trajectories: 2374\n"
     ]
    }
   ],
   "source": [
    "wins_3, draws_3, seen_trajectories_3, unique_trajectories_3 = test_pipeline.run(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - c_puct 1.5\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "losses_3 = np.ones(30) - wins_3 - draws_3\n",
    "\n",
    "plt.plot(x, wins_3, label=\"win ratio\")\n",
    "plt.plot(x, draws_3, label=\"draw ratio\")\n",
    "plt.plot(x, losses_3, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3Xd8leX9//HXJxvCJmFPGbIUhMheFRniALVacaFYQStYW22rtT9X7bfVqm1VqqWKCgruiooCiiDIJixlGpaEGaas7Ov3x7mxkYbkADm5c07ez8fjPJJzr/O5z4Hzzn3d931d5pxDRESkKFF+FyAiImWfwkJERIqlsBARkWIpLEREpFgKCxERKZbCQkREiqWwkLBiZrPN7Och2vbvzeylUGxbJNwpLCQkzGyLmR03syMFHs/7XdcJZtbXzNILTnPO/Z9zLiRBFC68z+3iIubHmdm73nLOzPoWs73ZZpZZ4N/A+hIvWkqFwkJC6XLnXKUCj9F+FyQl4ivgRmBXkMuPLvBv4NwQ1iUhpLCQUmVm8WZ20MzaFZiW7B2F1DKz6mb2sZllmNkB7/cGp9jWI2b2eoHnTby/dmO857ea2VozO2xmm8xslDc9EfgUqFfgL956hWzvCjNb7dU728xaF5i3xczuM7NVZnbIzN4ys4SzeF96mtl877W2mdktxSz/qpm9aGafefv3pZk1Lux98Kb9qPnOzG4v8N6sMbOOZjYRaAR85L0nvz35dZ1z2c65vzvnvgLyznR/JfwoLKRUOeeygPeBYQUmXwt86ZzbQ+Df5CtAYwJfXMeBM22+2gNcBlQBbgX+ZmYdnXNHgUuAHQX+4t1RcEUzawlMBu4BkoFPCHyJxp1U9yCgKXA+cMuZFGlmjQiE13Pea3UAVgSx6g3AH4Ekb/k3gny9a4BHgJsJvDdXAPucczcB3/HfI8InT29PTunPZrbXzOYV12wlZZfCQkLpA+8v5ROP273pk/hxWFzvTcM5t885955z7phz7jDwJ6DPmby4c26qc26jC/gSmAH0CnL1nwFTnXOfOedygKeACkD3Ass865zb4ZzbD3xE4Ev+TNwAfO6cm+ycy/Heg2DCYqpzbo4XwA8C3cysYRDr/Rx40jm3xHtv0pxzW8+w9uL8DjgHqA+MIxC4zUL0WhJCCgsJpaHOuWoFHv/2pn8BVDCzLl7TSQfgPwBmVtHM/mVmW83se2AOUM3Mok/3xc3sEjNbaGb7zewgMJjAX+HBqAf88AXqnMsHthH40juhYJv9MaDSKepYXaC5q7CwaghsDLKugrYVqO8IsN+ruzhn+nqnzTm3yDl32DmX5Zx7DZhH4HOQMBNT/CIiJcs5l29mbxM4utgNfOwdRQDcC5wLdHHO7TKzDsBywArZ1FGgYoHndU78YmbxwHsEmlqmOOdyzOyDAtsprrvlHcB5BbZnBL5ktwe3l//lnGtbzCLbgM6nu12vHgDMrBJQg0Ddmd7kisD33u91Cqy3DTjVX/eh7obaUfhnKWWcjizEL5MINPXc4P1+QmUC5ykOmlkN4OEitrEC6G1mjcysKvBAgXlxQDyQAeSa2SXAgALzdwM1vfUK8zZwqZn1M7NYAiGWBcwPdgdPwxvAxWZ2rZnFmFlNLySLM9g7MR5H4NzFIufcNudcBoFQu9HMos1sBD8Oh5eA+8yskwU0P3FynMD7ck5RL+pdpHDiZH6cmSV4YXryctXMbKA3P8bMbgB6A9OD2DcpYxQWEkonrqo58fjPiRnOuUUEjgzqETi5e8LfCZwb2AssBKadauPOuc+At4BVQCrwcYF5h4G7CXzpHyBwXuTDAvPXETiBvck7n/Kj5hvn3HoCl4c+59VyOYETv9mn+yYUxzn3HYGmmXsJNCWtANoHseokAmG6H+hEIHhPuB34DbAPaEuBkHPOvUPgXNAk4DDwAYGjEoA/A3/w3pP7TvG66wkEen0CX/zHCVyQcOLGxhOfZyzwOIHA3guMIdA0qXstwpBp8COR8GNmrwLpzrk/+F2LlA86shARkWLpBLdIGWVmq/Gad04yqrRrEVEzlIiIFEvNUCIiUqyIaYZKSkpyTZo08bsMEZGwkpqautc5l1zcchETFk2aNGHp0qV+lyEiElbMLKiuXtQMJSIixVJYiIhIsRQWIiJSrIg5Z1GYnJwc0tPTyczMLH5hCYmEhAQaNGhAbGys36WIyFmI6LBIT0+ncuXKNGnShEL6OZMQc86xb98+0tPTadq0qd/liMhZCFkzlJmNN7M9ZvbNKeabmT1rZmne0JQdC8wbbmbfeo/hZ1pDZmYmNWvWVFD4xMyoWbOmjuxEIkAoz1m8SmDIyVO5BGjhPUYCLwAU6Ja6C4E+/h82s+pnWoSCwl96/0UiQ8jCwjk3h0DXyacyBJjgDeu4kMBoaHWBgcBnzrn9zrkDwGcUHTpnWyc7Dx0nO1djz4uInIqfV0PVp8CwkEC6N+1U0/+HmY00s6VmtjQjI+OMisjOzWf/0Ww2ZhzleLb/gbF06VLuvvvukGx7586dDBgwoPgFRURO4mdYFNY+caohFwvt7dA5N845l+KcS0lOLvZu9ULFx0bTLDkwdPKmvUc4kpV7RtspKSkpKTz77LMh2fa0adMYOHBgSLYtIpHNz7BIp8AYwkADAuMHn2p6yCR4gRETFcXmvUc5dLzkBkPbsmUL7dq1++H5U089xSOPPELfvn353e9+R+fOnWnZsiVz584FYPbs2Vx22WUA7Nu3jwEDBnDBBRcwatQoGjduzN69e0+5TYCNGzcyaNAgOnXqRK9evVi3bt0Py02bNo1LLrmEnTt30rt3bzp06EC7du1+eO0ZM2bQrVs3OnbsyDXXXMORI0cASE1NpU+fPnTq1ImBAweyc+dOgFPug4hEHj8vnf0QGG1mbxI4mX3IObfTzKYD/1fgpPYAfjy28hl59KPVrNnxfZHLOCAzJ4/8fEd8TBQx0UVnaZt6VXj48rZnXFNubi6LFy/mk08+4dFHH+Xzzz//cc2PPkrPnj156KGHmDp1KuPGjSt2myNHjuTFF1+kRYsWLFq0iF/84hd88cUX5OXlsX79etq0acPTTz/NwIEDefDBB8nLy+PYsWPs3buXxx9/nM8//5zExESeeOIJnnnmGR544AHGjBnDlClTSE5O5q233uLBBx9k/PjxQe2DiESGkIWFmU0G+gJJZpZO4AqnWADn3IvAJwTGHU4DjgG3evP2m9kfgSXeph5zzhV1orzkagYqxEaTmZNHVm4++UBcMYFxNq666ioAOnXqxJYtW/5n/pw5c3j//fcBuPTSS6leveiLwo4cOcL8+fO55pprfpiWlZUFwKJFi+jSpQsAF154ISNGjCAnJ4ehQ4fSoUMHvvzyS9asWUOPHj0AyM7Oplu3bqxfv55vvvmG/v37A5CXl0fdunWD3gcRiQwhCwvn3LBi5jvgrlPMGw+ML8l6TucIwDnH9gPH2X8smxqJcdSvVuGMLwGNiYkhPz//h+cF7zmIj48HIDo6mtzcws+VFPa6p9pmfn4+1apVY8WKFf+zzqeffsqgQYGLynr37s2cOXOYOnUqN910E7/5zW+oXr06/fv3Z/LkyT9a7+uvv6Zt27YsWLCg0PqC2QcRCX/qG6oQZkb96hWoVTme/Uez2brvGPn5ZzaiYO3atdmzZw/79u0jKyuLjz/+OOh1e/fuzRtvvAEEvuwPHDhQ5DarVKlC06ZNeeedd4BA6K1cuRKAmTNn0q9fPwC2bt1KrVq1uP3227nttttYtmwZXbt2Zd68eaSlpQFw7NgxNmzYwLnnnktGRsYPYZGTk8Pq1avP6L0QkfAV0d19nA0zo07VCsRER7Hj4HE27z1K45oViz2PcbLY2FgeeughunTpQtOmTWnVqlXQ6z788MMMGzaMjh070qdPHxo1alTsNt944w3uvPNOHn/8cXJycrjuuuuoV68eCQkJVKlSBQicRP/rX/9KbGwslSpVYsKECSQnJ/Pqq68ybNiwH5quHn/8cVq2bMm7777L3XffzaFDh8jNzeWee+6hbdszP1cjIuEnYsbgTklJcScPfrR27Vpat2591ts+eCybbQeOEx8dRZOkisREBREYBlElfPfyiQGekpKSTmu9119/nfT0dO6///4SrSdYJfU5iEjJM7NU51xKccvpyCII1SrGERNlbN13jHW7Dge1jmHUq5ZAzUrxIa6ueDfeeKPfJYhImFNYBKlSQizNalXi+8ycoJY/nJnLjkOZVIiLpmJcybzNutpIRPwS8WHhnCuxzuwSYqNJiI0OatkaFfP5ds8Rvtt/jBa1KhEdTNNVBIqUZk6R8i6iv8ESEhLYt2+fL19YMdFRNKpRkZxcx/YDmeXyS/PEeBYJCQl+lyIiZymijywaNGhAeno6Z9rJYEk4npnDruO57KkYS2J8RL/dhToxUp6IhLeI/vaKjY31fYS2vHzHzeMXkbp1Nx+O7knL2pV9rUdE5ExEdDNUWRAdZfztZx2oFB/D6EnLykQ36CIip0thUQpqVU7gmWs7sGH3ER77WHc/i0j4UViUkt4tk7mzbzMmL97GRytD2uO6iEiJU1iUol/3b0nHRtV44P2v2brvqN/liIgETWFRimKjo3h22AVEGYyetJwsjfstImFCYVHKGlSvyF+vac/X2w/xxKfr/S5HRCQoCgsfDGxbh+HdGjN+3mY+X7Pb73JERIoV0fdZlGUPDG7Nki0HuO/dlXxydy/qVavAsexc9h7OJuNIFnuPZJFxOPBz75Es9h7O5khWLiN6NuGiVrX9Ll9EypmI7qK8rNuUcYTLnvuK6CgjL99x7BT3YFSrGEtSpXiOZ+ex49BxHhzcmtt6Ni2xPq9EpPxSF+Vh4JzkSoy7KYX3lqVTIzGOpErxJFWKI6lyPMmV4kmqFE+NxDjiYgKthcez8/j12yt4fOpaNmYc4bEh7YgN4RjhIiIn6MgizOTnO57+bD1jZ22ke7Oa/POGjlSrGOd3WSISpoI9stCfpWEmKsr4zcBWPHNte5ZuOcCV/5zPpowjfpclIhFOYRGmrurYgDdu78Kh4zlc+c/5zN+41++SRCSCKSzC2IVNavDBL3pQq3I8N7+8mDcXf+d3SSISoRQWYa5RzYq894vudG+exP3vf82fpq4hLz8yzkOJSNmhsIgAVRJiGT88heHdGvPvuZsZOWEpR7Jy/S5LRCKIwiJCxERH8eiQdjw2pC2zN2Rw3bgFHM7M8bssEYkQCosIc3O3Joy7qRPrdh7mjtdTyc7N97skEYkACosI1K91bZ64+nzmpe3jvndWkq9zGCJylnQHd4S6ulMDdh/O5Mlp66lVOZ4/XNbG75JEJIwpLCLYnX2asftQJi99tZk6VRP4ea9z/C5JRMKUwiKCmRkPXd6WjCNZPD51LcmV4xnSob7fZYlIGNI5iwgXHWU8c20HOjetwX3vrGRemu70FpHTp7AoBxJio/n3TSk0TUpk1MRUVu845HdJIhJmFBblRNWKsbw2ojOVE2K45ZUlbNt/zO+SRCSMKCzKkbpVK/DaiM5k5eQxfPxi9h/N9rskEQkTCotypmXtyrx8y4WkHzzOba8t4fgpRucTESlIYVEOXdikBs9e14EV2w4yetIycvN0l7eIFE1hUU4NaleXx65oy8x1e3jko9VEyoiJIhIaIQ0LMxtkZuvNLM3M7i9kfmMzm2lmq8xstpk1KDAvz8xWeI8PQ1lneXVTtyaM6n0Ory/8jlfmbfG7HBEpw0J2U56ZRQNjgf5AOrDEzD50zq0psNhTwATn3GtmdhHwZ+Amb95x51yHUNUnAb8b1IrNe4/yx6lraFyzIv1a1/a7JBEpg0J5ZNEZSHPObXLOZQNvAkNOWqYNMNP7fVYh8yXEoqKMv1/Xgbb1qjBm8nLW7Pje75JEpAwKZVjUB7YVeJ7uTStoJXC19/uVQGUzq+k9TzCzpWa20MyGhrDOcq9iXAwvD7+QKgmx3PbaEvZ8n+l3SSJSxoQyLKyQaSefRb0P6GNmy4E+wHbgxBBvjZxzKcD1wN/NrNn/vIDZSC9QlmZkZJRg6eVP7SoJvHxLCoeO53Dba0s5lq2R9kTkv0IZFulAwwLPGwA7Ci7gnNvhnLvKOXcB8KA37dCJed7PTcBs4IKTX8A5N845l+KcS0lOTg7JTpQnbetV5dnrLuCbHYf41VsrNA6GiPwglGGxBGhhZk3NLA64DvjRVU1mlmRmJ2p4ABjvTa9uZvEnlgF6AAVPjEuIXNymNg8Obs301bt5Yvo6v8sRkTIiZFdDOedyzWw0MB2IBsY751ab2WPAUufch0Bf4M9m5oA5wF3e6q2Bf5lZPoFA+8tJV1FJCN3Wsymb9x7lX19u4pykRH52YSO/SxIRn1mk3IyVkpLili5d6ncZESMnL58Rry5hwcZ9TBjRme7Nk/wuSURCwMxSvfPDRdId3FKo2Ogonr++I02TErnj9VQ2ZhzxuyQR8ZHCQk6paoVYxt9yIbHRUYx4dYl6qRUpxxQWUqSGNSoy7uYUdh7KZMSrS9h7JMvvkkTEBwoLKVanxtV59roLWLvze4Y8P08j7YmUQwoLCcqgdnV4545u5OU7rn5hPh+v2lH8SiISMRQWErTzG1TjwzE9aFO3CqMnLeep6et1455IOaGwkNNSq3ICk0d25dqUBjw/K42RE5dyODPH77JEJMQUFnLa4mOieeLq83n0irbMWp/BVf+cz5a9R/0uS0RCSGEhZ8TMGN69CRNHdCbjSBZDxs5j7rfqzFEkUiks5Kx0b57Eh3f1pE6VBIaPX8xLczdpiFaRCKSwkLPWqGZF3v9Fd/q3qc3jU9dy3zurOJ6d53dZIlKCFBZSIhLjY3jhhk7cc3EL3luWzkVPz+b9Zem6WkokQigspMRERRn3XNySt0Z2JalSPL9+eyVDxs5j0aZ9fpcmImdJYSElrss5NZlyVw+eubY9GYez+Nm4hdwxMVVXTImEsZCNZyHlW1SUcVXHBlzSri4vzd3EC19uZOa63dzcrQl3X9SCqhVj/S5RRE6DjiwkpCrERTOmXwtm39eXqy5owPh5m+nz1CxembeZnLx8v8sTkSApLKRU1KqSwBM/PZ+pY3rRtl4VHv1oDQP+Nofpq3fpUluRMKCwkFLVpl4VXr+tC+NvSSHKYNTEVK55cQGpW/f7XZqIFEFhIaXOzLioVW2m39Ob/7vyPLbuP8bVLyxg5ISlpO3RiHwiZZHG4BbfHcvO5eW5m/nXnE0cz8nj2pSG/OriFtSqkuB3aSIRL9gxuBUWUmbsO5LFc1+k8caircRERXFbz6aM6nMOlRN05ZRIqCgsJGx9t+8YT81Yz4crd1AjMY4xFzXnhi6NiYtRq6lISQs2LPS/T8qcRjUr8uywC/hodE9a163Mox+tod8zs1n+3QG/SxMptxQWUmad16Aqr9/WhQkjOmMYN728mKVbdNWUiB8UFlKmmRm9Wybz9qhu1Kocz83jF7NQfU2JlDqFhYSFOlUTeHNUV+pXq8AtryxmXtpev0sSKVcUFhI2Toz/3aRmIiNeXcLs9Xv8Lkmk3FBYSFhJqhTP5Nu70rxWJUZOSGXm2t1+lyRSLigsJOxUT4xj0s+70rpuZe54PZVp3+zyuySRiKewkLBUtWIsE3/ehXb1q3LXpGVMXbXT75JEIprCQsJWlYRYJozoTMdG1RgzeRlTVmz3uySRiKWwkLBWOSGWV2/tTOemNfjVWyt4NzXd75JEIpLCQsJeYnwMr9zSme7NkvjNuyuZvPg7v0sSiTgKC4kIFeKieWl4Cn1aJvPA+18zdlaaBlUSKUEKC4kYCbHRjLsphaEd6vHX6et5aMpq8vIVGCIlIcbvAkRKUlxMFM9c24HaVRL415xNZBzO4u/XdSAhNtrv0kTCmo4sJOJERRkPDG7NHy5tzbTVu7h5/GIOHcvxuyyRsBZ0WJhZezMb7T3ah7IokZLw817n8OywC1j+3QGu+dd8dh467ndJImErqLAws18CbwC1vMfrZjYmlIWJlIQr2tfjtVs7s+NgJlf9cz4bdh/2uySRsBTskcVtQBfn3EPOuYeArsDtxa1kZoPMbL2ZpZnZ/YXMb2xmM81slZnNNrMGBeYNN7NvvcfwYHdI5GTdmyfx1qiu5OY7fvrCfJZoTAyR0xZsWBiQV+B5njft1CuYRQNjgUuANsAwM2tz0mJPAROcc+cDjwF/9tatATwMdAE6Aw+bWfUgaxX5H23rVeX9O7uTVCmeG19axPTV6k9K5HQEGxavAIvM7BEzewRYCLxczDqdgTTn3CbnXDbwJjDkpGXaADO932cVmD8Q+Mw5t985dwD4DBgUZK0ihWpYoyLv3tmd1nWrcOfrqby+cKvfJYmEjaDCwjn3DHArsB84ANzqnPt7MavVB7YVeJ7uTStoJXC19/uVQGUzqxnkupjZSDNbamZLMzIygtkVKedqJMYx6fYu9D23Fn/44BvGTF7O9oM68S1SnCLDwsyqeD9rAFuA14GJwFZvWpGrFzLt5Duk7gP6mNlyoA+wHcgNcl2cc+OccynOuZTk5ORiyhEJqBgXw7ibOnF3vxbMWL2Lfk/P5pnPNnAsO9fv0kTKrOKOLCZ5P1OBpQUeJ54XJR1oWOB5A2BHwQWcczucc1c55y4AHvSmHQpmXZGzERMdxa/7t2TmvX24uHVtnp35Lf2e/pIpK7armxCRQlio/mOYWQywAehH4IhhCXC9c251gWWSgP3OuXwz+xOQ55x7yDtqSQU6eosuAzo55055GUtKSopburS4/BIp3OLN+3ns49V8s/17OjaqxsOXt6V9w2p+lyUScmaW6pxLKW65YO+zmBnMtIKcc7nAaGA6sBZ42zm32sweM7MrvMX6AuvNbANQG/iTt+5+4I8EAmYJ8FhRQSFytjo3rcGUu3ry5NXn893+YwwZO497317J7u8z/S5NpEwo8sjCzBKAigSuVOrLf88lVAE+dc61DnWBwdKRhZSUw5k5PD8rjVe+2kJMtHHXT5pzW8+m6l9KIlJJHVmMItAc1Mr7eeIxhcA9FCIRp3JCLA9c0prPft2bns2T+Ov09Vzyj7l8s/2Q36WJ+CaocxZmNsY591wp1HPGdGQhoTL32wx+884q9h/N5veDWzG8exPMirwnVSRsBHtkEfQJbjNrR+AmuoQT05xzE864whKmsJBQ2n80m/veWckX6/YwoE1tnvzp+VSrGOd3WSJnraRPcD8MPOc9fgI8CVxR5EoiEaRGYhwvD0/hD5e2Ztb6PVz67FekbtU1F1J+BNvdx08JXAK7yzl3K9AeiA9ZVSJlkJnx817n8M4d3YmKgmv/tZB/zk4jX6PxSTkQbFhkOufygVzvru49wDmhK0uk7OrQsBpT7+7FoLZ1eHLaeoa/spiMw1l+lyUSUsWGhQXO5K0ys2rAvwlcDbUMWBzi2kTKrCoJsTx//QX86cp2LN68n8HPzmVe2l6/yxIJmWLDwgXOgHdwzh10zr0I9AeGe81RIuWWmXFDl8ZMGd2DKgkx3PjyIp6esZ7cvHy/SxMpccE2Qy00swsBnHNbnHOrQliTSFhpVacKH43pydUdG/DcF2mMnJjK0Sx1SiiRJdiw+AmwwMw2eqPafW1mCgwRT8W4GJ66pj1/HNqO2ev38LNxC9hzWF2FSOSICXK5S0JahUiEuKlrY+pVTWD0pOVcOXY+r956IS1qV/a7LJGzFuzgR1sLe4S6OJFw1K91bd4e1Y3svHyuemE+Czbu87skkbMWbDOUiJyG8xpU5T+/6E7tKgncPH4RHyzf7ndJImdFYSESIg2qV+S9O7rTqXF17nlrBc9/8a0GVpKwpbAQCaGqFWN5bURnhnaox1MzNvDA+1+To0trJQwFe4JbRM5QfEw0f/tZBxpUr8jzs9LYcSiTf97QkUrx+u8n4UNHFiKlwMy4b+C5/OWq85iXtpdrXlzArkO6tFbCh8JCpBRd17kR42+5kO/2HeUnT81mzOTlzFi9i6zcPL9LEymSjoNFSlmflslMGd2DV+Zt4ZOvd/LRyh1UTohhUNs6XN6+Ht2b1SQmWn/HSdkS9OBHZZ0GP5JwlJOXz7y0vXy0ciczVu/icFYuNRPjGHxeXS5vX4+UxtWJitKofBI6JT5SXlmnsJBwl5mTx+z1GXy0agcz1+4mMyefulUTuOz8utzZtzk1EjUyn5Q8hYVIGDualcvna3fz0codzF6fQe0qCYy7uRNt61X1uzSJMCU6rKqIlK7E+BiGdKjPS8Mv5P1fdCffOa5+YT4frdzhd2lSTiksRMq48xtUY8roHrSrV5Uxk5fzxLR15GkoVyllCguRMFCrcgKTbu/KsM6NeGH2Rm57bQmHjuf4XZaUIwoLkTARFxPFn686jz9d2Y6vvt3L0LHzSNtz2O+ypJxQWIiEmRu6NGbyyK4czsxh6Nj5fL5mt98lSTmgsBAJQxc2qcGHo3vSNCmR2ycu5bmZ35Kv8xgSQgoLkTBVr1oF3rmjG0M71OfpzzZw16RlGvtbQkZhIRLGEmKjeeba9vzh0tZMX72LoWPnsW7X936XJRFIYSES5syMn/c6h4m3deHAsRyueH4eExZs0UBLUqIUFiIRokfzJKbd04sezWry0JTV3D4hlf1Hs/0uSyKEwkIkgiRVimf8LRfy0GVtmLMhg0v+MYf5aXv9LksigMJCJMKYGSN6NuU/d3UnMT6GG15exBPT1mk4VzkrCguRCNW2XlU+HtOTn6U05IXZG/npiwvYuu+o32VJmFJYiESwinEx/OXq8/nnDR3ZnHGES5/9ig+Wb/e7LAlDCguRcmDweXX59J7etK5bmXveWsGv31rBjoPH/S5LwojGsxApR3Lz8nl+VhrPzvwWB/RsnsQ1KQ0Z0KY2CbHRfpcnPigTgx+Z2SDgH0A08JJz7i8nzW8EvAZU85a53zn3iZk1AdYC671FFzrn7ijqtRQWIsHbtv8Y76Sm815qOtsPHqdKQmD8jGtSGnBe/aqYaSjX8sL3sDCzaGAD0B9IB5YAw5xzawosMw5Y7px7wczaAJ8455p4YfGxc65dsK+nsBA5ffn5jvkb9/FO6jamfbOLrNx8zq1dmWtSGnDlBfWpWSne7xIlxIJr/JdJAAAQe0lEQVQNi5gQ1tAZSHPObfIKehMYAqwpsIwDqni/VwU0DJhIKYqKMnq2SKJniyQOHc/ho5U7eCc1ncenruUvn67jola1uKFrY3q3SNLRRjkXyrCoD2wr8Dwd6HLSMo8AM8xsDJAIXFxgXlMzWw58D/zBOTf35Bcws5HASIBGjRqVXOUi5VDVCrHc2LUxN3ZtzIbdh3k3NZ33l6UzY81uOjWuzr0DWtK9WZLfZYpPQnk1VGF/hpzc5jUMeNU51wAYDEw0syhgJ9DIOXcB8GtgkplVOWldnHPjnHMpzrmU5OTkEi5fpPxqWbsyvx/cmvn39+NPV7Zj+4HjXP/vRVz/74Wkbt3vd3nig1CGRTrQsMDzBvxvM9NtwNsAzrkFQAKQ5JzLcs7t86anAhuBliGsVUQKERcTxQ1dGjP7N3156LI2bNh9mKtfWMCtryzm6/RDfpcnpSiUYbEEaGFmTc0sDrgO+PCkZb4D+gGYWWsCYZFhZsneCXLM7BygBbAphLWKSBESYqMZ0bMpc377E343qBXLvjvI5c9/xaiJS1m/S0O7lgehvnR2MPB3ApfFjnfO/cnMHgOWOuc+9K6A+jdQiUAT1W+dczPM7GrgMSAXyAMeds59VNRr6WookdLzfWYO47/azEtzN3M0O5fLz6/HPRe34JzkSn6XJqfJ90tnS5vCQqT0HTiazbi5m3h13haycvNIaVKDAW1qc3Hr2jRJSvS7PAmCwkJESk3G4SwmLtjCjDW7Wec1SzWvVYmLW9emf5tadGhYnegoXXpbFiksRMQX2/Yf4/O1u/l87W4WbdpPbr6jZmIcF7WqxcVtatOrRRIV40J51b6cDoWFiPju0PEcvtyQwedrdjNr/R4OZ+YSFxPF5efX4+Er2lAlIdbvEsu9snAHt4iUc1UrxHJF+3pc0b4eOXn5LNm8n0+/2cWkxd+xdOt+xl7fkXb1q/pdpgRBXZSLSKmIjY6ie/Mk/ji0HW+N7Ep2bj5X/XM+ExdsIVJaOCKZwkJESl1KkxpMvbsXPZrX5P9NWc1dk5bxfWaO32VJERQWIuKLGolxvDz8Qu6/pBXTV+/msme/0l3hZZjCQkR8ExVl3NGnGW+N7EpOXj5XvzCfCQvULFUWKSxExHcpTWrwyd296NkiiYfULFUmKSxEpEyonhjHSzen8ICapcokhYWIlBlRUcaoPs14e1RXcr1mqaemr+doVq7fpZV7CgsRKXM6NQ5cLTX4vDo8PyuNi56ezXup6eTn61yGXxQWIlImVU+M4+/XXcB7d3anTpUE7n1nJVe+MJ/UrQf8Lq1cUliISJnWqXF1/vOLHjx9TXt2HjzO1S/M55dvLmfHweN+l1auKCxEpMyLijKu7tSAWff1ZcxFzZn2zS4ueno2f/tsA8ez8/wur1xQWIhI2EiMj+HeAecy894+9Gtdm3/M/JaLnp7NlBXbdW9GiCksRCTsNKhekbHXd+TtUd2oWSmOX765gqFj5/HFut0KjRBRWIhI2OrctAZT7urJkz89n31Hsxnx6lKueH4eM1bvUmiUMI1nISIRIScvn/8s387YWWls3XeM1nWrcPdFzRnYtg5RGqXvlDT4kYiUS7l5+UxZsYPnZ6Wxee9RWtauxJiLWjD4vLoa2rUQCgsRKdfy8h0fr9rBc1+kkbbnCM2SExlzUQsuO78uMdFqgT8h2LDQOyYiESk6yhjSoT4z7unN2Os7EhMVxT1vraD/3+YwL22v3+WFHYWFiES0qCjj0vPr8ukve/HijZ0wgxteWsRjH60hM0f3aARLYSEi5UJUlDGoXR2mjunF8G6NGT9vM5c/9xWrd6hn22AoLESkXKkQF82jQ9rx2ojOHDqew9Cx83hh9kby1ElhkRQWIlIu9WmZzPR7etO/TW2emLaOYeMWsm3/Mb/LKrMUFiJSblVPjGPs9R155tr2rN35PZf8Yy7vLN2mG/oKobAQkXLNzLiqYwM+vacXbepV4TfvruLO15ex/2i236WVKQoLEREC/U1Nvr0rvx/cii/W7WHA3+YwddVOcvPy/S6tTFBYiIh4oqOMkb2bMWV0D5IqxXHXpGX0enIWz878lj3fZ/pdnq90B7eISCFy8/KZuW4Pry/cytxv9xITZQxsW4cbujai2zk1MYuMrkOCvYM7pjSKEREJNzHRUQxsW4eBbeuwee9R3li4lXdS05n69U6aJSdyY9fGXNWxAVUrxPpdaqnQkYWISJAyc/L4eNVOJi7cysptB6kQG80V7etxU7fGtKtf1e/yzog6EhQRCaGv0w/x+sKtTFm5ncycfHq1SOLeAefSoWE1v0s7LQoLEZFScOh4DpMXf8e/vtzIgWM59GtVi1/1bxk2RxoKCxGRUnQkK5dX521m3JxNfJ+Zy8C2tflV/5a0qlPF79KKpLAQEfHB95k5vDx3M+O/2syR7FwuPa8u91zckua1KvldWqEUFiIiPjp4LJtxczbx6vwtZObkMbRDfe7u14ImSYl+l/YjCgsRkTJg35Es/jVnExMWbCEnzzGkfT1u7t6E9g2qlol7NcrESHlmNsjM1ptZmpndX8j8RmY2y8yWm9kqMxtcYN4D3nrrzWxgKOsUEQmVmpXi+f3g1sz57U+4uVtjpq/exdCx87ji+Xm8vWQbx7PDYwCmkB1ZmFk0sAHoD6QDS4Bhzrk1BZYZByx3zr1gZm2AT5xzTbzfJwOdgXrA50BL59wp31UdWYhIODiSlct/lm9n4oItbNh9hCoJMVyT0pAbujTinOTSP69RFu7g7gykOec2eQW9CQwB1hRYxgEnLhWoCuzwfh8CvOmcywI2m1mat70FIaxXRCTkKsXHcFPXxtzYpRFLthxg4sKtTFiwhZe/2kzP5knc1K0x/VrVIia6bHXdF8qwqA9sK/A8Hehy0jKPADPMbAyQCFxcYN2FJ61b/+QXMLORwEiARo0alUjRIiKlwczo3LQGnZvWYM/h1ry9ZBuTFn3HqImp1K2awLDOjbi1RxMqJ5SN7kRCGV2Fnbk5uc1rGPCqc64BMBiYaGZRQa6Lc26ccy7FOZeSnJx81gWLiPihVuUERl/Ugjm//QnjbupEi9qVeeazDfR/Zg7Tvtnld3lAaMMiHWhY4HkD/tvMdMJtwNsAzrkFQAKQFOS6IiIRJSY6igFt6zBhRGc+uKsH1RPjuOP1VG6fsJQdB4/7Wlsow2IJ0MLMmppZHHAd8OFJy3wH9AMws9YEwiLDW+46M4s3s6ZAC2BxCGsVESlTOjSsxoeje/DAJa2Y+20GFz/zJS9/tZm8fH9udwhZWDjncoHRwHRgLfC2c261mT1mZld4i90L3G5mKwlc/XSLC1hN4IhjDTANuKuoK6FERCJRbHQUo/o047Nf9aFz0xr88eM1DB07j6/TD5V6LbopT0QkDDjn+OTrXTzy0Wr2Hcnilu5NuXdASxLjz+46pTJxU56IiJQMM+PS8+vy+a/7cH2XRrwyfzP9n/mSz9bsLpXXV1iIiISRqhVieXzoebx7R3cqJ8Ry+4Sl3PXGMvJDfC5Dw6qKiIShTo2r8/HdPXlp7maOZuUSFRXafqYUFiIiYSo2Ooo7+zYrlddSM5SIiBRLYSEiIsVSWIiISLEUFiIiUiyFhYiIFEthISIixVJYiIhIsRQWIiJSrIjpSNDMMoCtZ7GJJGBvCZVTFkTa/kDk7VOk7Q9E3j5F2v7A/+5TY+dcsaPHRUxYnC0zWxpMz4vhItL2ByJvnyJtfyDy9inS9gfOfJ/UDCUiIsVSWIiISLEUFv81zu8CSlik7Q9E3j5F2v5A5O1TpO0PnOE+6ZyFiIgUS0cWIiJSLIWFiIgUq9yHhZkNMrP1ZpZmZvf7XU9JMLMtZva1ma0ws6V+13O6zGy8me0xs28KTKthZp+Z2bfez+p+1ni6TrFPj5jZdu9zWmFmg/2s8XSYWUMzm2Vma81stZn90pselp9TEfsTzp9RgpktNrOV3j496k1vamaLvM/oLTOLC2p75fmchZlFAxuA/kA6sAQY5pxb42thZ8nMtgApzrmwvJnIzHoDR4AJzrl23rQngf3Oub94oV7dOfc7P+s8HafYp0eAI865p/ys7UyYWV2grnNumZlVBlKBocAthOHnVMT+XEv4fkYGJDrnjphZLPAV8Evg18D7zrk3zexFYKVz7oXitlfejyw6A2nOuU3OuWzgTWCIzzWVe865OcD+kyYPAV7zfn+NwH/ksHGKfQpbzrmdzrll3u+HgbVAfcL0cypif8KWCzjiPY31Hg64CHjXmx70Z1Tew6I+sK3A83TC/B+IxwEzzCzVzEb6XUwJqe2c2wmB/9hALZ/rKSmjzWyV10wVFk02JzOzJsAFwCIi4HM6aX8gjD8jM4s2sxXAHuAzYCNw0DmX6y0S9HdeeQ8LK2RaJLTL9XDOdQQuAe7ymkCk7HkBaAZ0AHYCT/tbzukzs0rAe8A9zrnv/a7nbBWyP2H9GTnn8pxzHYAGBFpSWhe2WDDbKu9hkQ40LPC8AbDDp1pKjHNuh/dzD/AfAv9Iwt1ur135RPvyHp/rOWvOud3ef+Z84N+E2efktYO/B7zhnHvfmxy2n1Nh+xPun9EJzrmDwGygK1DNzGK8WUF/55X3sFgCtPCuDogDrgM+9Lmms2Jmid4JOswsERgAfFP0WmHhQ2C49/twYIqPtZSIE1+qnisJo8/JO3n6MrDWOfdMgVlh+Tmdan/C/DNKNrNq3u8VgIsJnIuZBfzUWyzoz6hcXw0F4F0K93cgGhjvnPuTzyWdFTM7h8DRBEAMMCnc9snMJgN9CXSlvBt4GPgAeBtoBHwHXOOcC5sTxqfYp74EmjccsAUYdaK9v6wzs57AXOBrIN+b/HsC7fxh9zkVsT/DCN/P6HwCJ7CjCRwYvO2ce8z7jngTqAEsB250zmUVu73yHhYiIlK88t4MJSIiQVBYiIhIsRQWIiJSLIWFiIgUS2EhIiLFUliIFMLM5ns/m5jZ9SW87d8X9loiZZkunRUpgpn1Be5zzl12GutEO+fyiph/xDlXqSTqEyktOrIQKYSZneit8y9AL28sg195HbP91cyWeJ3LjfKW7+uNhzCJwI1dmNkHXmeOq0906GhmfwEqeNt7o+BrWcBfzewbC4xH8rMC255tZu+a2Toze8O741ik1MQUv4hIuXY/BY4svC/9Q865C80sHphnZjO8ZTsD7Zxzm73nI5xz+72uFpaY2XvOufvNbLTXudvJriJwt3B7And6LzGzOd68C4C2BPrxmQf0IDA+gUip0JGFyOkZANzsdfu8CKgJtPDmLS4QFAB3m9lKYCGBDitbULSewGSv47rdwJfAhQW2ne51aLcCaFIieyMSJB1ZiJweA8Y456b/aGLg3MbRk55fDHRzzh0zs9lAQhDbPpWCfffkof+7Usp0ZCFStMNA5QLPpwN3et1ZY2Ytvd59T1YVOOAFRSsCXUOfkHNi/ZPMAX7mnRdJBnoDi0tkL0TOkv46ESnaKiDXa056FfgHgSagZd5J5gwKH5ZyGnCHma0C1hNoijphHLDKzJY5524oMP0/QDdgJYFeTn/rnNvlhY2Ir3TprIiIFEvNUCIiUiyFhYiIFEthISIixVJYiIhIsRQWIiJSLIWFiIgUS2EhIiLF+v9gLLHNkp3I6AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "exploration_rate_3 = unique_trajectories_3/seen_trajectories_3\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - c_puct 1.5\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "\n",
    "plt.plot(x, exploration_rate_3, label=\"unique/seen\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins_3 = [0.82, 0.79, 0.75, 0.74, 0.82, 0.8, 0.84, 0.85, 0.75, 0.85, 0.83, 0.83, 0.84, 0.79, 0.82, 0.81, 0.7, 0.74, 0.77, 0.89, 0.85, 0.77, 0.9, 0.84, 0.7, 0.83, 0.77, 0.83, 0.8, 0.77]\n",
      "draws_3 = [0.01, 0.02, 0.01, 0.03, 0.0, 0.01, 0.01, 0.0, 0.02, 0.02, 0.0, 0.0, 0.01, 0.01, 0.0, 0.02, 0.05, 0.03, 0.04, 0.0, 0.01, 0.0, 0.01, 0.01, 0.03, 0.01, 0.03, 0.02, 0.01, 0.02]\n",
      "losses_3 = [0.17 0.19 0.24 0.23 0.18 0.19 0.15 0.15 0.23 0.13 0.17 0.17 0.15 0.2\n",
      " 0.18 0.17 0.25 0.23 0.19 0.11 0.14 0.23 0.09 0.15 0.27 0.16 0.2  0.15\n",
      " 0.19 0.21]\n",
      "seen_trajectories_3 = [ 100.  200.  300.  400.  500.  600.  700.  800.  900. 1000. 1100. 1200.\n",
      " 1300. 1400. 1500. 1600. 1700. 1800. 1900. 2000. 2100. 2200. 2300. 2400.\n",
      " 2500. 2600. 2700. 2800. 2900. 3000.]\n",
      "unique_trajectories_3 = [  99.  195.  288.  382.  474.  564.  651.  739.  824.  906.  989. 1076.\n",
      " 1158. 1237. 1315. 1388. 1462. 1537. 1608. 1675. 1744. 1817. 1890. 1952.\n",
      " 2017. 2089. 2149. 2212. 2274. 2339.]\n"
     ]
    }
   ],
   "source": [
    "print(\"wins_3 =\", wins_3)\n",
    "print(\"draws_3 =\", draws_3)\n",
    "print(\"losses_3 =\", losses_3)\n",
    "print(\"seen_trajectories_3 =\", seen_trajectories_3)\n",
    "print(\"unique_trajectories_3 =\", unique_trajectories_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $c_{puct}$ = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCTS = {\n",
    "    'c_puct': 0.1,\n",
    "    'dir_alpha': 0.6,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 10,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 10\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 0,\n",
    "    'show_games': False\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.002,\n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 512,\n",
    "    'num_filters_value': 512,\n",
    "    'num_filters_tower': 512,\n",
    "    'num_residual_blocks': 3,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 512\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"tictactoe_c_puct_0_1\", \"TicTacToe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (4768, 3, 3, 3)\n",
      "model_y_outcomes: (4768,)\n",
      "model_y_probabilities: (4768, 9)\n",
      "Train on 3814 samples, validate on 954 samples\n",
      "Epoch 1/10\n",
      "3814/3814 [==============================] - 4s 1ms/step - loss: 6.6681 - value_loss: 0.8986 - policy_loss: 2.3510 - val_loss: 6.7121 - val_value_loss: 1.1312 - val_policy_loss: 2.2068\n",
      "Epoch 2/10\n",
      "3814/3814 [==============================] - 1s 176us/step - loss: 6.4665 - value_loss: 0.6979 - policy_loss: 2.1492 - val_loss: 6.6374 - val_value_loss: 1.0726 - val_policy_loss: 2.1166\n",
      "Epoch 3/10\n",
      "3814/3814 [==============================] - 1s 176us/step - loss: 6.3866 - value_loss: 0.6315 - policy_loss: 2.0563 - val_loss: 6.5872 - val_value_loss: 1.0349 - val_policy_loss: 2.0545\n",
      "Epoch 4/10\n",
      "3814/3814 [==============================] - 1s 175us/step - loss: 6.3343 - value_loss: 0.5904 - policy_loss: 1.9934 - val_loss: 6.5928 - val_value_loss: 1.0902 - val_policy_loss: 2.0111\n",
      "Epoch 5/10\n",
      "3814/3814 [==============================] - 1s 175us/step - loss: 6.2971 - value_loss: 0.5656 - policy_loss: 1.9446 - val_loss: 6.5231 - val_value_loss: 0.9889 - val_policy_loss: 1.9737\n",
      "Epoch 6/10\n",
      "3814/3814 [==============================] - 1s 175us/step - loss: 6.2744 - value_loss: 0.5585 - policy_loss: 1.9069 - val_loss: 6.5268 - val_value_loss: 1.0270 - val_policy_loss: 1.9437\n",
      "Epoch 7/10\n",
      "3814/3814 [==============================] - 1s 176us/step - loss: 6.2442 - value_loss: 0.5285 - policy_loss: 1.8772 - val_loss: 6.5084 - val_value_loss: 1.0146 - val_policy_loss: 1.9198\n",
      "Epoch 8/10\n",
      "3814/3814 [==============================] - 1s 175us/step - loss: 6.2368 - value_loss: 0.5385 - policy_loss: 1.8530 - val_loss: 6.5055 - val_value_loss: 1.0299 - val_policy_loss: 1.8993\n",
      "Epoch 9/10\n",
      "3814/3814 [==============================] - 1s 175us/step - loss: 6.1996 - value_loss: 0.4862 - policy_loss: 1.8315 - val_loss: 6.4688 - val_value_loss: 0.9753 - val_policy_loss: 1.8813\n",
      "Epoch 10/10\n",
      "3814/3814 [==============================] - 1s 176us/step - loss: 6.1854 - value_loss: 0.4770 - policy_loss: 1.8129 - val_loss: 6.4609 - val_value_loss: 0.9747 - val_policy_loss: 1.8667\n",
      "Saved model  tictactoe_c_puct_0_1_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.71 - draw ratio 0.01\n",
      "Number of seen trajectories: 100\n",
      "Number of unique trajectories: 99\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.2662 - value_loss: 0.6179 - policy_loss: 1.8344 - val_loss: 6.2428 - val_value_loss: 0.5890 - val_policy_loss: 1.8167\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2195 - value_loss: 0.5502 - policy_loss: 1.8092 - val_loss: 6.2483 - val_value_loss: 0.6150 - val_policy_loss: 1.8024\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2172 - value_loss: 0.5629 - policy_loss: 1.7926 - val_loss: 6.2334 - val_value_loss: 0.5979 - val_policy_loss: 1.7903\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1950 - value_loss: 0.5352 - policy_loss: 1.7766 - val_loss: 6.2156 - val_value_loss: 0.5741 - val_policy_loss: 1.7792\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1656 - value_loss: 0.4920 - policy_loss: 1.7615 - val_loss: 6.2153 - val_value_loss: 0.5840 - val_policy_loss: 1.7693\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1598 - value_loss: 0.4932 - policy_loss: 1.7494 - val_loss: 6.2299 - val_value_loss: 0.6223 - val_policy_loss: 1.7608\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1492 - value_loss: 0.4810 - policy_loss: 1.7410 - val_loss: 6.2029 - val_value_loss: 0.5761 - val_policy_loss: 1.7536\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1399 - value_loss: 0.4734 - policy_loss: 1.7308 - val_loss: 6.1901 - val_value_loss: 0.5587 - val_policy_loss: 1.7461\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1327 - value_loss: 0.4669 - policy_loss: 1.7234 - val_loss: 6.1858 - val_value_loss: 0.5569 - val_policy_loss: 1.7400\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1259 - value_loss: 0.4599 - policy_loss: 1.7174 - val_loss: 6.1863 - val_value_loss: 0.5642 - val_policy_loss: 1.7344\n",
      "Saved model  tictactoe_c_puct_0_1_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.75 - draw ratio 0.02\n",
      "Number of seen trajectories: 200\n",
      "Number of unique trajectories: 194\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.2104 - value_loss: 0.6039 - policy_loss: 1.7431 - val_loss: 6.2074 - val_value_loss: 0.5913 - val_policy_loss: 1.7501\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1764 - value_loss: 0.5514 - policy_loss: 1.7282 - val_loss: 6.2054 - val_value_loss: 0.5956 - val_policy_loss: 1.7424\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1575 - value_loss: 0.5266 - policy_loss: 1.7160 - val_loss: 6.2090 - val_value_loss: 0.6095 - val_policy_loss: 1.7364\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1426 - value_loss: 0.5072 - policy_loss: 1.7061 - val_loss: 6.1830 - val_value_loss: 0.5634 - val_policy_loss: 1.7311\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1267 - value_loss: 0.4825 - policy_loss: 1.6996 - val_loss: 6.1856 - val_value_loss: 0.5740 - val_policy_loss: 1.7264\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1164 - value_loss: 0.4714 - policy_loss: 1.6909 - val_loss: 6.2215 - val_value_loss: 0.6504 - val_policy_loss: 1.7224\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1156 - value_loss: 0.4763 - policy_loss: 1.6850 - val_loss: 6.1764 - val_value_loss: 0.5647 - val_policy_loss: 1.7185\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1054 - value_loss: 0.4622 - policy_loss: 1.6793 - val_loss: 6.1860 - val_value_loss: 0.5880 - val_policy_loss: 1.7150\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1002 - value_loss: 0.4571 - policy_loss: 1.6746 - val_loss: 6.1978 - val_value_loss: 0.6149 - val_policy_loss: 1.7125\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0972 - value_loss: 0.4564 - policy_loss: 1.6700 - val_loss: 6.1790 - val_value_loss: 0.5811 - val_policy_loss: 1.7091\n",
      "Saved model  tictactoe_c_puct_0_1_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.71 - draw ratio 0.01\n",
      "Number of seen trajectories: 300\n",
      "Number of unique trajectories: 290\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1695 - value_loss: 0.5817 - policy_loss: 1.6898 - val_loss: 6.1958 - val_value_loss: 0.6081 - val_policy_loss: 1.7164\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1395 - value_loss: 0.5333 - policy_loss: 1.6788 - val_loss: 6.1907 - val_value_loss: 0.6039 - val_policy_loss: 1.7110\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1211 - value_loss: 0.5050 - policy_loss: 1.6710 - val_loss: 6.1782 - val_value_loss: 0.5836 - val_policy_loss: 1.7069\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1101 - value_loss: 0.4901 - policy_loss: 1.6647 - val_loss: 6.1717 - val_value_loss: 0.5745 - val_policy_loss: 1.7037\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0997 - value_loss: 0.4763 - policy_loss: 1.6581 - val_loss: 6.1704 - val_value_loss: 0.5768 - val_policy_loss: 1.6996\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0980 - value_loss: 0.4777 - policy_loss: 1.6540 - val_loss: 6.1996 - val_value_loss: 0.6376 - val_policy_loss: 1.6979\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0996 - value_loss: 0.4863 - policy_loss: 1.6494 - val_loss: 6.1650 - val_value_loss: 0.5733 - val_policy_loss: 1.6934\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0877 - value_loss: 0.4667 - policy_loss: 1.6457 - val_loss: 6.1774 - val_value_loss: 0.6015 - val_policy_loss: 1.6908\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0816 - value_loss: 0.4590 - policy_loss: 1.6418 - val_loss: 6.1691 - val_value_loss: 0.5876 - val_policy_loss: 1.6886\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0770 - value_loss: 0.4533 - policy_loss: 1.6390 - val_loss: 6.1708 - val_value_loss: 0.5934 - val_policy_loss: 1.6869\n",
      "Saved model  tictactoe_c_puct_0_1_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.01\n",
      "Number of seen trajectories: 400\n",
      "Number of unique trajectories: 380\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1967 - value_loss: 0.6392 - policy_loss: 1.6932 - val_loss: 6.1491 - val_value_loss: 0.5815 - val_policy_loss: 1.6559\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1769 - value_loss: 0.6080 - policy_loss: 1.6855 - val_loss: 6.1446 - val_value_loss: 0.5765 - val_policy_loss: 1.6526\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1521 - value_loss: 0.5648 - policy_loss: 1.6796 - val_loss: 6.1500 - val_value_loss: 0.5900 - val_policy_loss: 1.6506\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1356 - value_loss: 0.5370 - policy_loss: 1.6752 - val_loss: 6.1478 - val_value_loss: 0.5892 - val_policy_loss: 1.6477\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1323 - value_loss: 0.5342 - policy_loss: 1.6719 - val_loss: 6.1428 - val_value_loss: 0.5823 - val_policy_loss: 1.6452\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1267 - value_loss: 0.5270 - policy_loss: 1.6686 - val_loss: 6.1252 - val_value_loss: 0.5499 - val_policy_loss: 1.6430\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1149 - value_loss: 0.5078 - policy_loss: 1.6647 - val_loss: 6.1260 - val_value_loss: 0.5536 - val_policy_loss: 1.6415\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1117 - value_loss: 0.5046 - policy_loss: 1.6622 - val_loss: 6.1343 - val_value_loss: 0.5723 - val_policy_loss: 1.6401\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1180 - value_loss: 0.5198 - policy_loss: 1.6602 - val_loss: 6.1301 - val_value_loss: 0.5664 - val_policy_loss: 1.6383\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1083 - value_loss: 0.5035 - policy_loss: 1.6579 - val_loss: 6.1333 - val_value_loss: 0.5746 - val_policy_loss: 1.6371\n",
      "Saved model  tictactoe_c_puct_0_1_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.03\n",
      "Number of seen trajectories: 500\n",
      "Number of unique trajectories: 468\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1716 - value_loss: 0.6297 - policy_loss: 1.6586 - val_loss: 6.1571 - val_value_loss: 0.6042 - val_policy_loss: 1.6554\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1512 - value_loss: 0.5939 - policy_loss: 1.6540 - val_loss: 6.1540 - val_value_loss: 0.5992 - val_policy_loss: 1.6545\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1352 - value_loss: 0.5651 - policy_loss: 1.6512 - val_loss: 6.1516 - val_value_loss: 0.5956 - val_policy_loss: 1.6536\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1234 - value_loss: 0.5448 - policy_loss: 1.6481 - val_loss: 6.1516 - val_value_loss: 0.5965 - val_policy_loss: 1.6531\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1139 - value_loss: 0.5286 - policy_loss: 1.6457 - val_loss: 6.1520 - val_value_loss: 0.5984 - val_policy_loss: 1.6522\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1093 - value_loss: 0.5216 - policy_loss: 1.6438 - val_loss: 6.1503 - val_value_loss: 0.5961 - val_policy_loss: 1.6516\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1034 - value_loss: 0.5118 - policy_loss: 1.6420 - val_loss: 6.1527 - val_value_loss: 0.6018 - val_policy_loss: 1.6509\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0981 - value_loss: 0.5035 - policy_loss: 1.6402 - val_loss: 6.1485 - val_value_loss: 0.5944 - val_policy_loss: 1.6502\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0935 - value_loss: 0.4966 - policy_loss: 1.6381 - val_loss: 6.1495 - val_value_loss: 0.5973 - val_policy_loss: 1.6496\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0904 - value_loss: 0.4923 - policy_loss: 1.6365 - val_loss: 6.1479 - val_value_loss: 0.5952 - val_policy_loss: 1.6489\n",
      "Saved model  tictactoe_c_puct_0_1_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.89 - draw ratio 0.0\n",
      "Number of seen trajectories: 600\n",
      "Number of unique trajectories: 556\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1432 - value_loss: 0.6057 - policy_loss: 1.6290 - val_loss: 6.1462 - val_value_loss: 0.5891 - val_policy_loss: 1.6518\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1232 - value_loss: 0.5704 - policy_loss: 1.6247 - val_loss: 6.1412 - val_value_loss: 0.5812 - val_policy_loss: 1.6501\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1104 - value_loss: 0.5479 - policy_loss: 1.6220 - val_loss: 6.1329 - val_value_loss: 0.5662 - val_policy_loss: 1.6488\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0985 - value_loss: 0.5264 - policy_loss: 1.6200 - val_loss: 6.1328 - val_value_loss: 0.5672 - val_policy_loss: 1.6479\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0918 - value_loss: 0.5156 - policy_loss: 1.6176 - val_loss: 6.1324 - val_value_loss: 0.5678 - val_policy_loss: 1.6467\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0854 - value_loss: 0.5057 - policy_loss: 1.6151 - val_loss: 6.1273 - val_value_loss: 0.5591 - val_policy_loss: 1.6458\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0821 - value_loss: 0.5009 - policy_loss: 1.6136 - val_loss: 6.1275 - val_value_loss: 0.5608 - val_policy_loss: 1.6446\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0762 - value_loss: 0.4917 - policy_loss: 1.6113 - val_loss: 6.1310 - val_value_loss: 0.5691 - val_policy_loss: 1.6437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0741 - value_loss: 0.4888 - policy_loss: 1.6102 - val_loss: 6.1267 - val_value_loss: 0.5618 - val_policy_loss: 1.6427\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0694 - value_loss: 0.4820 - policy_loss: 1.6081 - val_loss: 6.1264 - val_value_loss: 0.5624 - val_policy_loss: 1.6417\n",
      "Saved model  tictactoe_c_puct_0_1_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.01\n",
      "Number of seen trajectories: 700\n",
      "Number of unique trajectories: 633\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1252 - value_loss: 0.5780 - policy_loss: 1.6240 - val_loss: 6.1502 - val_value_loss: 0.5996 - val_policy_loss: 1.6526\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1122 - value_loss: 0.5551 - policy_loss: 1.6212 - val_loss: 6.1457 - val_value_loss: 0.5913 - val_policy_loss: 1.6522\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1024 - value_loss: 0.5378 - policy_loss: 1.6191 - val_loss: 6.1426 - val_value_loss: 0.5863 - val_policy_loss: 1.6514\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0961 - value_loss: 0.5273 - policy_loss: 1.6176 - val_loss: 6.1469 - val_value_loss: 0.5957 - val_policy_loss: 1.6507\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0925 - value_loss: 0.5223 - policy_loss: 1.6156 - val_loss: 6.1417 - val_value_loss: 0.5864 - val_policy_loss: 1.6500\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0856 - value_loss: 0.5104 - policy_loss: 1.6141 - val_loss: 6.1399 - val_value_loss: 0.5836 - val_policy_loss: 1.6496\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0814 - value_loss: 0.5035 - policy_loss: 1.6129 - val_loss: 6.1371 - val_value_loss: 0.5787 - val_policy_loss: 1.6493\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0768 - value_loss: 0.4965 - policy_loss: 1.6110 - val_loss: 6.1362 - val_value_loss: 0.5778 - val_policy_loss: 1.6485\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0741 - value_loss: 0.4927 - policy_loss: 1.6098 - val_loss: 6.1361 - val_value_loss: 0.5788 - val_policy_loss: 1.6478\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0723 - value_loss: 0.4902 - policy_loss: 1.6089 - val_loss: 6.1305 - val_value_loss: 0.5683 - val_policy_loss: 1.6472\n",
      "Saved model  tictactoe_c_puct_0_1_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.01\n",
      "Number of seen trajectories: 800\n",
      "Number of unique trajectories: 710\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1459 - value_loss: 0.6053 - policy_loss: 1.6412 - val_loss: 6.1573 - val_value_loss: 0.6333 - val_policy_loss: 1.6363\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1294 - value_loss: 0.5752 - policy_loss: 1.6387 - val_loss: 6.1554 - val_value_loss: 0.6311 - val_policy_loss: 1.6350\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1176 - value_loss: 0.5537 - policy_loss: 1.6369 - val_loss: 6.1587 - val_value_loss: 0.6392 - val_policy_loss: 1.6339\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1082 - value_loss: 0.5370 - policy_loss: 1.6352 - val_loss: 6.1529 - val_value_loss: 0.6284 - val_policy_loss: 1.6333\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1021 - value_loss: 0.5268 - policy_loss: 1.6335 - val_loss: 6.1581 - val_value_loss: 0.6399 - val_policy_loss: 1.6325\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0974 - value_loss: 0.5193 - policy_loss: 1.6320 - val_loss: 6.1574 - val_value_loss: 0.6396 - val_policy_loss: 1.6317\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0915 - value_loss: 0.5088 - policy_loss: 1.6309 - val_loss: 6.1536 - val_value_loss: 0.6331 - val_policy_loss: 1.6309\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0881 - value_loss: 0.5036 - policy_loss: 1.6296 - val_loss: 6.1568 - val_value_loss: 0.6405 - val_policy_loss: 1.6303\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0849 - value_loss: 0.4985 - policy_loss: 1.6287 - val_loss: 6.1514 - val_value_loss: 0.6304 - val_policy_loss: 1.6298\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0852 - value_loss: 0.5004 - policy_loss: 1.6277 - val_loss: 6.1546 - val_value_loss: 0.6376 - val_policy_loss: 1.6294\n",
      "Saved model  tictactoe_c_puct_0_1_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.01\n",
      "Number of seen trajectories: 900\n",
      "Number of unique trajectories: 797\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1331 - value_loss: 0.6064 - policy_loss: 1.6178 - val_loss: 6.1379 - val_value_loss: 0.6015 - val_policy_loss: 1.6325\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1156 - value_loss: 0.5737 - policy_loss: 1.6158 - val_loss: 6.1332 - val_value_loss: 0.5928 - val_policy_loss: 1.6320\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1037 - value_loss: 0.5523 - policy_loss: 1.6138 - val_loss: 6.1293 - val_value_loss: 0.5861 - val_policy_loss: 1.6312\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0952 - value_loss: 0.5367 - policy_loss: 1.6126 - val_loss: 6.1276 - val_value_loss: 0.5837 - val_policy_loss: 1.6306\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0873 - value_loss: 0.5225 - policy_loss: 1.6112 - val_loss: 6.1304 - val_value_loss: 0.5903 - val_policy_loss: 1.6300\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0818 - value_loss: 0.5131 - policy_loss: 1.6100 - val_loss: 6.1185 - val_value_loss: 0.5674 - val_policy_loss: 1.6294\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0759 - value_loss: 0.5034 - policy_loss: 1.6082 - val_loss: 6.1192 - val_value_loss: 0.5695 - val_policy_loss: 1.6289\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0721 - value_loss: 0.4976 - policy_loss: 1.6067 - val_loss: 6.1194 - val_value_loss: 0.5709 - val_policy_loss: 1.6282\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0676 - value_loss: 0.4898 - policy_loss: 1.6060 - val_loss: 6.1169 - val_value_loss: 0.5666 - val_policy_loss: 1.6279\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0638 - value_loss: 0.4840 - policy_loss: 1.6046 - val_loss: 6.1146 - val_value_loss: 0.5628 - val_policy_loss: 1.6275\n",
      "Saved model  tictactoe_c_puct_0_1_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.02\n",
      "Number of seen trajectories: 1000\n",
      "Number of unique trajectories: 872\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1391 - value_loss: 0.6010 - policy_loss: 1.6384 - val_loss: 6.1171 - val_value_loss: 0.5878 - val_policy_loss: 1.6075\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1295 - value_loss: 0.5828 - policy_loss: 1.6376 - val_loss: 6.1154 - val_value_loss: 0.5853 - val_policy_loss: 1.6068\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1200 - value_loss: 0.5655 - policy_loss: 1.6360 - val_loss: 6.1095 - val_value_loss: 0.5745 - val_policy_loss: 1.6061\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1145 - value_loss: 0.5551 - policy_loss: 1.6354 - val_loss: 6.1072 - val_value_loss: 0.5706 - val_policy_loss: 1.6055\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1104 - value_loss: 0.5478 - policy_loss: 1.6348 - val_loss: 6.1092 - val_value_loss: 0.5753 - val_policy_loss: 1.6050\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1070 - value_loss: 0.5419 - policy_loss: 1.6340 - val_loss: 6.1045 - val_value_loss: 0.5665 - val_policy_loss: 1.6045\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1031 - value_loss: 0.5347 - policy_loss: 1.6336 - val_loss: 6.1042 - val_value_loss: 0.5666 - val_policy_loss: 1.6039\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1003 - value_loss: 0.5298 - policy_loss: 1.6330 - val_loss: 6.1039 - val_value_loss: 0.5665 - val_policy_loss: 1.6036\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0979 - value_loss: 0.5264 - policy_loss: 1.6318 - val_loss: 6.1029 - val_value_loss: 0.5652 - val_policy_loss: 1.6032\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0948 - value_loss: 0.5209 - policy_loss: 1.6312 - val_loss: 6.1013 - val_value_loss: 0.5624 - val_policy_loss: 1.6027\n",
      "Saved model  tictactoe_c_puct_0_1_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.01\n",
      "Number of seen trajectories: 1100\n",
      "Number of unique trajectories: 956\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1454 - value_loss: 0.6292 - policy_loss: 1.6242 - val_loss: 6.1447 - val_value_loss: 0.6315 - val_policy_loss: 1.6207\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1331 - value_loss: 0.6057 - policy_loss: 1.6234 - val_loss: 6.1417 - val_value_loss: 0.6262 - val_policy_loss: 1.6201\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1228 - value_loss: 0.5866 - policy_loss: 1.6221 - val_loss: 6.1401 - val_value_loss: 0.6236 - val_policy_loss: 1.6197\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1145 - value_loss: 0.5708 - policy_loss: 1.6215 - val_loss: 6.1404 - val_value_loss: 0.6248 - val_policy_loss: 1.6192\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1081 - value_loss: 0.5590 - policy_loss: 1.6205 - val_loss: 6.1379 - val_value_loss: 0.6204 - val_policy_loss: 1.6189\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1024 - value_loss: 0.5485 - policy_loss: 1.6197 - val_loss: 6.1357 - val_value_loss: 0.6166 - val_policy_loss: 1.6185\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0988 - value_loss: 0.5422 - policy_loss: 1.6191 - val_loss: 6.1357 - val_value_loss: 0.6170 - val_policy_loss: 1.6182\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0960 - value_loss: 0.5372 - policy_loss: 1.6185 - val_loss: 6.1343 - val_value_loss: 0.6147 - val_policy_loss: 1.6179\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0927 - value_loss: 0.5313 - policy_loss: 1.6180 - val_loss: 6.1330 - val_value_loss: 0.6125 - val_policy_loss: 1.6176\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0896 - value_loss: 0.5255 - policy_loss: 1.6178 - val_loss: 6.1329 - val_value_loss: 0.6126 - val_policy_loss: 1.6173\n",
      "Saved model  tictactoe_c_puct_0_1_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.0\n",
      "Number of seen trajectories: 1200\n",
      "Number of unique trajectories: 1037\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1218 - value_loss: 0.5811 - policy_loss: 1.6267 - val_loss: 6.0707 - val_value_loss: 0.5216 - val_policy_loss: 1.5841\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1095 - value_loss: 0.5582 - policy_loss: 1.6254 - val_loss: 6.0662 - val_value_loss: 0.5134 - val_policy_loss: 1.5836\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1020 - value_loss: 0.5440 - policy_loss: 1.6246 - val_loss: 6.0637 - val_value_loss: 0.5089 - val_policy_loss: 1.5831\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0958 - value_loss: 0.5331 - policy_loss: 1.6234 - val_loss: 6.0625 - val_value_loss: 0.5072 - val_policy_loss: 1.5828\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0915 - value_loss: 0.5254 - policy_loss: 1.6225 - val_loss: 6.0611 - val_value_loss: 0.5047 - val_policy_loss: 1.5824\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0871 - value_loss: 0.5174 - policy_loss: 1.6220 - val_loss: 6.0605 - val_value_loss: 0.5041 - val_policy_loss: 1.5820\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0850 - value_loss: 0.5131 - policy_loss: 1.6222 - val_loss: 6.0587 - val_value_loss: 0.5011 - val_policy_loss: 1.5817\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0819 - value_loss: 0.5087 - policy_loss: 1.6206 - val_loss: 6.0580 - val_value_loss: 0.5001 - val_policy_loss: 1.5814\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0783 - value_loss: 0.5022 - policy_loss: 1.6200 - val_loss: 6.0568 - val_value_loss: 0.4982 - val_policy_loss: 1.5810\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0770 - value_loss: 0.4996 - policy_loss: 1.6202 - val_loss: 6.0563 - val_value_loss: 0.4976 - val_policy_loss: 1.5808\n",
      "Saved model  tictactoe_c_puct_0_1_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.01\n",
      "Number of seen trajectories: 1300\n",
      "Number of unique trajectories: 1113\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1154 - value_loss: 0.5751 - policy_loss: 1.6215 - val_loss: 6.1313 - val_value_loss: 0.6098 - val_policy_loss: 1.6187\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1056 - value_loss: 0.5572 - policy_loss: 1.6200 - val_loss: 6.1272 - val_value_loss: 0.6024 - val_policy_loss: 1.6182\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0965 - value_loss: 0.5403 - policy_loss: 1.6190 - val_loss: 6.1262 - val_value_loss: 0.6009 - val_policy_loss: 1.6178\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0909 - value_loss: 0.5299 - policy_loss: 1.6183 - val_loss: 6.1245 - val_value_loss: 0.5980 - val_policy_loss: 1.6174\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0870 - value_loss: 0.5225 - policy_loss: 1.6180 - val_loss: 6.1232 - val_value_loss: 0.5958 - val_policy_loss: 1.6172\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0825 - value_loss: 0.5150 - policy_loss: 1.6167 - val_loss: 6.1227 - val_value_loss: 0.5954 - val_policy_loss: 1.6168\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0792 - value_loss: 0.5092 - policy_loss: 1.6159 - val_loss: 6.1220 - val_value_loss: 0.5945 - val_policy_loss: 1.6166\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0760 - value_loss: 0.5035 - policy_loss: 1.6156 - val_loss: 6.1219 - val_value_loss: 0.5945 - val_policy_loss: 1.6163\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0728 - value_loss: 0.4980 - policy_loss: 1.6148 - val_loss: 6.1215 - val_value_loss: 0.5942 - val_policy_loss: 1.6161\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0701 - value_loss: 0.4936 - policy_loss: 1.6141 - val_loss: 6.1195 - val_value_loss: 0.5906 - val_policy_loss: 1.6158\n",
      "Saved model  tictactoe_c_puct_0_1_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.01\n",
      "Number of seen trajectories: 1400\n",
      "Number of unique trajectories: 1197\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1328 - value_loss: 0.6014 - policy_loss: 1.6316 - val_loss: 6.1265 - val_value_loss: 0.5852 - val_policy_loss: 1.6353\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1194 - value_loss: 0.5756 - policy_loss: 1.6309 - val_loss: 6.1216 - val_value_loss: 0.5761 - val_policy_loss: 1.6348\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1121 - value_loss: 0.5624 - policy_loss: 1.6296 - val_loss: 6.1187 - val_value_loss: 0.5709 - val_policy_loss: 1.6344\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1051 - value_loss: 0.5489 - policy_loss: 1.6292 - val_loss: 6.1155 - val_value_loss: 0.5649 - val_policy_loss: 1.6341\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1010 - value_loss: 0.5413 - policy_loss: 1.6288 - val_loss: 6.1131 - val_value_loss: 0.5606 - val_policy_loss: 1.6338\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0952 - value_loss: 0.5307 - policy_loss: 1.6279 - val_loss: 6.1132 - val_value_loss: 0.5612 - val_policy_loss: 1.6336\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0923 - value_loss: 0.5257 - policy_loss: 1.6273 - val_loss: 6.1103 - val_value_loss: 0.5557 - val_policy_loss: 1.6334\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0876 - value_loss: 0.5174 - policy_loss: 1.6265 - val_loss: 6.1094 - val_value_loss: 0.5543 - val_policy_loss: 1.6331\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0853 - value_loss: 0.5130 - policy_loss: 1.6263 - val_loss: 6.1101 - val_value_loss: 0.5560 - val_policy_loss: 1.6330\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0840 - value_loss: 0.5114 - policy_loss: 1.6255 - val_loss: 6.1079 - val_value_loss: 0.5521 - val_policy_loss: 1.6328\n",
      "Saved model  tictactoe_c_puct_0_1_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.89 - draw ratio 0.0\n",
      "Number of seen trajectories: 1500\n",
      "Number of unique trajectories: 1279\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1310 - value_loss: 0.6249 - policy_loss: 1.6061 - val_loss: 6.1482 - val_value_loss: 0.6267 - val_policy_loss: 1.6388\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1223 - value_loss: 0.6096 - policy_loss: 1.6041 - val_loss: 6.1457 - val_value_loss: 0.6219 - val_policy_loss: 1.6386\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1148 - value_loss: 0.5953 - policy_loss: 1.6035 - val_loss: 6.1427 - val_value_loss: 0.6163 - val_policy_loss: 1.6384\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1096 - value_loss: 0.5852 - policy_loss: 1.6033 - val_loss: 6.1420 - val_value_loss: 0.6151 - val_policy_loss: 1.6382\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1047 - value_loss: 0.5760 - policy_loss: 1.6028 - val_loss: 6.1393 - val_value_loss: 0.6100 - val_policy_loss: 1.6381\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1010 - value_loss: 0.5690 - policy_loss: 1.6025 - val_loss: 6.1384 - val_value_loss: 0.6083 - val_policy_loss: 1.6379\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0976 - value_loss: 0.5628 - policy_loss: 1.6019 - val_loss: 6.1366 - val_value_loss: 0.6050 - val_policy_loss: 1.6378\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0939 - value_loss: 0.5559 - policy_loss: 1.6015 - val_loss: 6.1366 - val_value_loss: 0.6052 - val_policy_loss: 1.6377\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0912 - value_loss: 0.5507 - policy_loss: 1.6014 - val_loss: 6.1358 - val_value_loss: 0.6037 - val_policy_loss: 1.6376\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0885 - value_loss: 0.5453 - policy_loss: 1.6014 - val_loss: 6.1368 - val_value_loss: 0.6060 - val_policy_loss: 1.6375\n",
      "Saved model  tictactoe_c_puct_0_1_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.01\n",
      "Number of seen trajectories: 1600\n",
      "Number of unique trajectories: 1351\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1354 - value_loss: 0.6253 - policy_loss: 1.6153 - val_loss: 6.1511 - val_value_loss: 0.6099 - val_policy_loss: 1.6621\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1244 - value_loss: 0.6048 - policy_loss: 1.6140 - val_loss: 6.1480 - val_value_loss: 0.6040 - val_policy_loss: 1.6619\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1196 - value_loss: 0.5957 - policy_loss: 1.6134 - val_loss: 6.1472 - val_value_loss: 0.6027 - val_policy_loss: 1.6617\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1145 - value_loss: 0.5863 - policy_loss: 1.6128 - val_loss: 6.1485 - val_value_loss: 0.6055 - val_policy_loss: 1.6616\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1110 - value_loss: 0.5796 - policy_loss: 1.6126 - val_loss: 6.1431 - val_value_loss: 0.5950 - val_policy_loss: 1.6614\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1081 - value_loss: 0.5739 - policy_loss: 1.6126 - val_loss: 6.1442 - val_value_loss: 0.5975 - val_policy_loss: 1.6613\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1051 - value_loss: 0.5690 - policy_loss: 1.6116 - val_loss: 6.1415 - val_value_loss: 0.5923 - val_policy_loss: 1.6611\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1032 - value_loss: 0.5653 - policy_loss: 1.6115 - val_loss: 6.1418 - val_value_loss: 0.5930 - val_policy_loss: 1.6610\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1011 - value_loss: 0.5614 - policy_loss: 1.6113 - val_loss: 6.1411 - val_value_loss: 0.5918 - val_policy_loss: 1.6609\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0997 - value_loss: 0.5590 - policy_loss: 1.6109 - val_loss: 6.1416 - val_value_loss: 0.5931 - val_policy_loss: 1.6607\n",
      "Saved model  tictactoe_c_puct_0_1_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.01\n",
      "Number of seen trajectories: 1700\n",
      "Number of unique trajectories: 1422\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1487 - value_loss: 0.6435 - policy_loss: 1.6246 - val_loss: 6.1324 - val_value_loss: 0.6209 - val_policy_loss: 1.6147\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1416 - value_loss: 0.6296 - policy_loss: 1.6243 - val_loss: 6.1311 - val_value_loss: 0.6186 - val_policy_loss: 1.6144\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1359 - value_loss: 0.6186 - policy_loss: 1.6240 - val_loss: 6.1307 - val_value_loss: 0.6179 - val_policy_loss: 1.6143\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1312 - value_loss: 0.6099 - policy_loss: 1.6234 - val_loss: 6.1304 - val_value_loss: 0.6176 - val_policy_loss: 1.6142\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1265 - value_loss: 0.6017 - policy_loss: 1.6223 - val_loss: 6.1303 - val_value_loss: 0.6177 - val_policy_loss: 1.6140\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1240 - value_loss: 0.5963 - policy_loss: 1.6228 - val_loss: 6.1301 - val_value_loss: 0.6174 - val_policy_loss: 1.6139\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1189 - value_loss: 0.5878 - policy_loss: 1.6212 - val_loss: 6.1299 - val_value_loss: 0.6173 - val_policy_loss: 1.6138\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1175 - value_loss: 0.5851 - policy_loss: 1.6212 - val_loss: 6.1301 - val_value_loss: 0.6178 - val_policy_loss: 1.6137\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1148 - value_loss: 0.5799 - policy_loss: 1.6209 - val_loss: 6.1297 - val_value_loss: 0.6171 - val_policy_loss: 1.6136\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1119 - value_loss: 0.5744 - policy_loss: 1.6208 - val_loss: 6.1295 - val_value_loss: 0.6168 - val_policy_loss: 1.6136\n",
      "Saved model  tictactoe_c_puct_0_1_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.01\n",
      "Number of seen trajectories: 1800\n",
      "Number of unique trajectories: 1496\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1240 - value_loss: 0.6162 - policy_loss: 1.6032 - val_loss: 6.1544 - val_value_loss: 0.6350 - val_policy_loss: 1.6454\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1167 - value_loss: 0.6023 - policy_loss: 1.6025 - val_loss: 6.1516 - val_value_loss: 0.6295 - val_policy_loss: 1.6452\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1110 - value_loss: 0.5919 - policy_loss: 1.6018 - val_loss: 6.1501 - val_value_loss: 0.6269 - val_policy_loss: 1.6450\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1065 - value_loss: 0.5836 - policy_loss: 1.6011 - val_loss: 6.1502 - val_value_loss: 0.6273 - val_policy_loss: 1.6449\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1028 - value_loss: 0.5767 - policy_loss: 1.6006 - val_loss: 6.1487 - val_value_loss: 0.6245 - val_policy_loss: 1.6448\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1005 - value_loss: 0.5724 - policy_loss: 1.6006 - val_loss: 6.1473 - val_value_loss: 0.6218 - val_policy_loss: 1.6446\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0972 - value_loss: 0.5664 - policy_loss: 1.6000 - val_loss: 6.1456 - val_value_loss: 0.6185 - val_policy_loss: 1.6446\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0956 - value_loss: 0.5628 - policy_loss: 1.6004 - val_loss: 6.1451 - val_value_loss: 0.6177 - val_policy_loss: 1.6445\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0924 - value_loss: 0.5578 - policy_loss: 1.5991 - val_loss: 6.1445 - val_value_loss: 0.6168 - val_policy_loss: 1.6444\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0904 - value_loss: 0.5535 - policy_loss: 1.5995 - val_loss: 6.1453 - val_value_loss: 0.6185 - val_policy_loss: 1.6443\n",
      "Saved model  tictactoe_c_puct_0_1_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.01\n",
      "Number of seen trajectories: 1900\n",
      "Number of unique trajectories: 1573\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0954 - value_loss: 0.5471 - policy_loss: 1.6158 - val_loss: 6.1131 - val_value_loss: 0.6005 - val_policy_loss: 1.5979\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0885 - value_loss: 0.5333 - policy_loss: 1.6160 - val_loss: 6.1112 - val_value_loss: 0.5970 - val_policy_loss: 1.5977\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0842 - value_loss: 0.5254 - policy_loss: 1.6154 - val_loss: 6.1097 - val_value_loss: 0.5943 - val_policy_loss: 1.5976\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.0797 - value_loss: 0.5174 - policy_loss: 1.6146 - val_loss: 6.1082 - val_value_loss: 0.5914 - val_policy_loss: 1.5975\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0775 - value_loss: 0.5127 - policy_loss: 1.6149 - val_loss: 6.1073 - val_value_loss: 0.5897 - val_policy_loss: 1.5974\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0742 - value_loss: 0.5069 - policy_loss: 1.6142 - val_loss: 6.1065 - val_value_loss: 0.5884 - val_policy_loss: 1.5974\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0714 - value_loss: 0.5022 - policy_loss: 1.6134 - val_loss: 6.1060 - val_value_loss: 0.5875 - val_policy_loss: 1.5973\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0686 - value_loss: 0.4962 - policy_loss: 1.6137 - val_loss: 6.1052 - val_value_loss: 0.5860 - val_policy_loss: 1.5972\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0673 - value_loss: 0.4941 - policy_loss: 1.6134 - val_loss: 6.1050 - val_value_loss: 0.5858 - val_policy_loss: 1.5971\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0653 - value_loss: 0.4908 - policy_loss: 1.6128 - val_loss: 6.1046 - val_value_loss: 0.5851 - val_policy_loss: 1.5970\n",
      "Saved model  tictactoe_c_puct_0_1_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.02\n",
      "Number of seen trajectories: 2000\n",
      "Number of unique trajectories: 1641\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1137 - value_loss: 0.5762 - policy_loss: 1.6241 - val_loss: 6.1054 - val_value_loss: 0.5944 - val_policy_loss: 1.5895\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1103 - value_loss: 0.5698 - policy_loss: 1.6239 - val_loss: 6.1040 - val_value_loss: 0.5917 - val_policy_loss: 1.5894\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1079 - value_loss: 0.5652 - policy_loss: 1.6236 - val_loss: 6.1029 - val_value_loss: 0.5896 - val_policy_loss: 1.5893\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1050 - value_loss: 0.5587 - policy_loss: 1.6245 - val_loss: 6.1018 - val_value_loss: 0.5876 - val_policy_loss: 1.5892\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1030 - value_loss: 0.5560 - policy_loss: 1.6232 - val_loss: 6.1010 - val_value_loss: 0.5862 - val_policy_loss: 1.5891\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1004 - value_loss: 0.5507 - policy_loss: 1.6233 - val_loss: 6.1004 - val_value_loss: 0.5850 - val_policy_loss: 1.5890\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0990 - value_loss: 0.5487 - policy_loss: 1.6225 - val_loss: 6.0998 - val_value_loss: 0.5839 - val_policy_loss: 1.5889\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0970 - value_loss: 0.5448 - policy_loss: 1.6224 - val_loss: 6.0993 - val_value_loss: 0.5830 - val_policy_loss: 1.5888\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0959 - value_loss: 0.5427 - policy_loss: 1.6225 - val_loss: 6.0989 - val_value_loss: 0.5824 - val_policy_loss: 1.5887\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0946 - value_loss: 0.5404 - policy_loss: 1.6222 - val_loss: 6.0985 - val_value_loss: 0.5817 - val_policy_loss: 1.5887\n",
      "Saved model  tictactoe_c_puct_0_1_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.0\n",
      "Number of seen trajectories: 2100\n",
      "Number of unique trajectories: 1707\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1221 - value_loss: 0.6084 - policy_loss: 1.6093 - val_loss: 6.1123 - val_value_loss: 0.5922 - val_policy_loss: 1.6058\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1188 - value_loss: 0.6016 - policy_loss: 1.6094 - val_loss: 6.1116 - val_value_loss: 0.5910 - val_policy_loss: 1.6058\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1148 - value_loss: 0.5939 - policy_loss: 1.6092 - val_loss: 6.1112 - val_value_loss: 0.5902 - val_policy_loss: 1.6058\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1126 - value_loss: 0.5901 - policy_loss: 1.6087 - val_loss: 6.1110 - val_value_loss: 0.5897 - val_policy_loss: 1.6058\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1108 - value_loss: 0.5862 - policy_loss: 1.6090 - val_loss: 6.1107 - val_value_loss: 0.5892 - val_policy_loss: 1.6058\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1077 - value_loss: 0.5805 - policy_loss: 1.6085 - val_loss: 6.1105 - val_value_loss: 0.5889 - val_policy_loss: 1.6058\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1056 - value_loss: 0.5770 - policy_loss: 1.6079 - val_loss: 6.1104 - val_value_loss: 0.5887 - val_policy_loss: 1.6058\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1046 - value_loss: 0.5749 - policy_loss: 1.6081 - val_loss: 6.1102 - val_value_loss: 0.5884 - val_policy_loss: 1.6058\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1019 - value_loss: 0.5701 - policy_loss: 1.6075 - val_loss: 6.1101 - val_value_loss: 0.5882 - val_policy_loss: 1.6059\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1012 - value_loss: 0.5686 - policy_loss: 1.6075 - val_loss: 6.1099 - val_value_loss: 0.5877 - val_policy_loss: 1.6059\n",
      "Saved model  tictactoe_c_puct_0_1_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.01\n",
      "Number of seen trajectories: 2200\n",
      "Number of unique trajectories: 1775\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1451 - value_loss: 0.6405 - policy_loss: 1.6236 - val_loss: 6.1361 - val_value_loss: 0.6454 - val_policy_loss: 1.6007\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1392 - value_loss: 0.6290 - policy_loss: 1.6234 - val_loss: 6.1330 - val_value_loss: 0.6394 - val_policy_loss: 1.6005\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1352 - value_loss: 0.6213 - policy_loss: 1.6231 - val_loss: 6.1306 - val_value_loss: 0.6348 - val_policy_loss: 1.6003\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1316 - value_loss: 0.6139 - policy_loss: 1.6232 - val_loss: 6.1287 - val_value_loss: 0.6313 - val_policy_loss: 1.6002\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1282 - value_loss: 0.6077 - policy_loss: 1.6227 - val_loss: 6.1273 - val_value_loss: 0.6284 - val_policy_loss: 1.6001\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1264 - value_loss: 0.6033 - policy_loss: 1.6235 - val_loss: 6.1259 - val_value_loss: 0.6259 - val_policy_loss: 1.6000\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1228 - value_loss: 0.5969 - policy_loss: 1.6227 - val_loss: 6.1248 - val_value_loss: 0.6238 - val_policy_loss: 1.5999\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1209 - value_loss: 0.5936 - policy_loss: 1.6223 - val_loss: 6.1239 - val_value_loss: 0.6220 - val_policy_loss: 1.5998\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1184 - value_loss: 0.5888 - policy_loss: 1.6222 - val_loss: 6.1231 - val_value_loss: 0.6206 - val_policy_loss: 1.5997\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1173 - value_loss: 0.5867 - policy_loss: 1.6221 - val_loss: 6.1224 - val_value_loss: 0.6194 - val_policy_loss: 1.5997\n",
      "Saved model  tictactoe_c_puct_0_1_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.71 - draw ratio 0.0\n",
      "Number of seen trajectories: 2300\n",
      "Number of unique trajectories: 1849\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1024 - value_loss: 0.5806 - policy_loss: 1.5985 - val_loss: 6.1203 - val_value_loss: 0.5676 - val_policy_loss: 1.6474\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0992 - value_loss: 0.5752 - policy_loss: 1.5974 - val_loss: 6.1190 - val_value_loss: 0.5648 - val_policy_loss: 1.6474\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0965 - value_loss: 0.5698 - policy_loss: 1.5976 - val_loss: 6.1182 - val_value_loss: 0.5632 - val_policy_loss: 1.6474\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0938 - value_loss: 0.5646 - policy_loss: 1.5974 - val_loss: 6.1174 - val_value_loss: 0.5617 - val_policy_loss: 1.6475\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0919 - value_loss: 0.5612 - policy_loss: 1.5970 - val_loss: 6.1170 - val_value_loss: 0.5608 - val_policy_loss: 1.6475\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0895 - value_loss: 0.5570 - policy_loss: 1.5964 - val_loss: 6.1163 - val_value_loss: 0.5596 - val_policy_loss: 1.6475\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0872 - value_loss: 0.5526 - policy_loss: 1.5962 - val_loss: 6.1159 - val_value_loss: 0.5587 - val_policy_loss: 1.6475\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0855 - value_loss: 0.5491 - policy_loss: 1.5964 - val_loss: 6.1154 - val_value_loss: 0.5578 - val_policy_loss: 1.6475\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0843 - value_loss: 0.5473 - policy_loss: 1.5959 - val_loss: 6.1150 - val_value_loss: 0.5570 - val_policy_loss: 1.6475\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0821 - value_loss: 0.5434 - policy_loss: 1.5954 - val_loss: 6.1145 - val_value_loss: 0.5562 - val_policy_loss: 1.6475\n",
      "Saved model  tictactoe_c_puct_0_1_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.81 - draw ratio 0.0\n",
      "Number of seen trajectories: 2400\n",
      "Number of unique trajectories: 1932\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.0900 - value_loss: 0.5571 - policy_loss: 1.5976 - val_loss: 6.0681 - val_value_loss: 0.5392 - val_policy_loss: 1.5717\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0869 - value_loss: 0.5510 - policy_loss: 1.5974 - val_loss: 6.0665 - val_value_loss: 0.5360 - val_policy_loss: 1.5716\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0839 - value_loss: 0.5456 - policy_loss: 1.5969 - val_loss: 6.0652 - val_value_loss: 0.5335 - val_policy_loss: 1.5716\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0802 - value_loss: 0.5387 - policy_loss: 1.5965 - val_loss: 6.0642 - val_value_loss: 0.5317 - val_policy_loss: 1.5716\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0777 - value_loss: 0.5339 - policy_loss: 1.5964 - val_loss: 6.0633 - val_value_loss: 0.5298 - val_policy_loss: 1.5715\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0755 - value_loss: 0.5294 - policy_loss: 1.5965 - val_loss: 6.0624 - val_value_loss: 0.5282 - val_policy_loss: 1.5715\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0736 - value_loss: 0.5263 - policy_loss: 1.5958 - val_loss: 6.0617 - val_value_loss: 0.5268 - val_policy_loss: 1.5715\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0710 - value_loss: 0.5208 - policy_loss: 1.5961 - val_loss: 6.0612 - val_value_loss: 0.5259 - val_policy_loss: 1.5715\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0690 - value_loss: 0.5173 - policy_loss: 1.5956 - val_loss: 6.0606 - val_value_loss: 0.5248 - val_policy_loss: 1.5714\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0677 - value_loss: 0.5150 - policy_loss: 1.5954 - val_loss: 6.0600 - val_value_loss: 0.5237 - val_policy_loss: 1.5714\n",
      "Saved model  tictactoe_c_puct_0_1_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.0\n",
      "Number of seen trajectories: 2500\n",
      "Number of unique trajectories: 2005\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1188 - value_loss: 0.5980 - policy_loss: 1.6146 - val_loss: 6.0899 - val_value_loss: 0.5672 - val_policy_loss: 1.5875\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1162 - value_loss: 0.5933 - policy_loss: 1.6142 - val_loss: 6.0897 - val_value_loss: 0.5670 - val_policy_loss: 1.5874\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1157 - value_loss: 0.5923 - policy_loss: 1.6141 - val_loss: 6.0895 - val_value_loss: 0.5667 - val_policy_loss: 1.5873\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1131 - value_loss: 0.5874 - policy_loss: 1.6138 - val_loss: 6.0891 - val_value_loss: 0.5662 - val_policy_loss: 1.5872\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1115 - value_loss: 0.5843 - policy_loss: 1.6137 - val_loss: 6.0889 - val_value_loss: 0.5657 - val_policy_loss: 1.5871\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1111 - value_loss: 0.5836 - policy_loss: 1.6137 - val_loss: 6.0886 - val_value_loss: 0.5652 - val_policy_loss: 1.5871\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1091 - value_loss: 0.5800 - policy_loss: 1.6134 - val_loss: 6.0882 - val_value_loss: 0.5646 - val_policy_loss: 1.5870\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1090 - value_loss: 0.5793 - policy_loss: 1.6138 - val_loss: 6.0880 - val_value_loss: 0.5643 - val_policy_loss: 1.5869\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1066 - value_loss: 0.5747 - policy_loss: 1.6136 - val_loss: 6.0877 - val_value_loss: 0.5638 - val_policy_loss: 1.5869\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1056 - value_loss: 0.5735 - policy_loss: 1.6130 - val_loss: 6.0875 - val_value_loss: 0.5634 - val_policy_loss: 1.5868\n",
      "Saved model  tictactoe_c_puct_0_1_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.0\n",
      "Number of seen trajectories: 2600\n",
      "Number of unique trajectories: 2074\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 181us/step - loss: 6.1080 - value_loss: 0.5731 - policy_loss: 1.6183 - val_loss: 6.1323 - val_value_loss: 0.6208 - val_policy_loss: 1.6191\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1068 - value_loss: 0.5708 - policy_loss: 1.6180 - val_loss: 6.1311 - val_value_loss: 0.6184 - val_policy_loss: 1.6190\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1036 - value_loss: 0.5651 - policy_loss: 1.6173 - val_loss: 6.1297 - val_value_loss: 0.6158 - val_policy_loss: 1.6189\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1013 - value_loss: 0.5605 - policy_loss: 1.6173 - val_loss: 6.1286 - val_value_loss: 0.6138 - val_policy_loss: 1.6188\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1000 - value_loss: 0.5579 - policy_loss: 1.6173 - val_loss: 6.1276 - val_value_loss: 0.6118 - val_policy_loss: 1.6187\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0973 - value_loss: 0.5532 - policy_loss: 1.6167 - val_loss: 6.1266 - val_value_loss: 0.6100 - val_policy_loss: 1.6186\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0964 - value_loss: 0.5511 - policy_loss: 1.6171 - val_loss: 6.1257 - val_value_loss: 0.6082 - val_policy_loss: 1.6185\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0947 - value_loss: 0.5483 - policy_loss: 1.6166 - val_loss: 6.1248 - val_value_loss: 0.6066 - val_policy_loss: 1.6185\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.0927 - value_loss: 0.5443 - policy_loss: 1.6166 - val_loss: 6.1240 - val_value_loss: 0.6050 - val_policy_loss: 1.6184\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0921 - value_loss: 0.5424 - policy_loss: 1.6172 - val_loss: 6.1232 - val_value_loss: 0.6036 - val_policy_loss: 1.6183\n",
      "Saved model  tictactoe_c_puct_0_1_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.91 - draw ratio 0.0\n",
      "Number of seen trajectories: 2700\n",
      "Number of unique trajectories: 2136\n",
      "iteration 27 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 180us/step - loss: 6.1476 - value_loss: 0.6516 - policy_loss: 1.6190 - val_loss: 6.1505 - val_value_loss: 0.6837 - val_policy_loss: 1.5927\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1434 - value_loss: 0.6430 - policy_loss: 1.6193 - val_loss: 6.1464 - val_value_loss: 0.6756 - val_policy_loss: 1.5926\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1397 - value_loss: 0.6360 - policy_loss: 1.6188 - val_loss: 6.1432 - val_value_loss: 0.6694 - val_policy_loss: 1.5926\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1373 - value_loss: 0.6316 - policy_loss: 1.6185 - val_loss: 6.1408 - val_value_loss: 0.6647 - val_policy_loss: 1.5925\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1351 - value_loss: 0.6273 - policy_loss: 1.6184 - val_loss: 6.1390 - val_value_loss: 0.6611 - val_policy_loss: 1.5924\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1333 - value_loss: 0.6235 - policy_loss: 1.6185 - val_loss: 6.1376 - val_value_loss: 0.6583 - val_policy_loss: 1.5924\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1313 - value_loss: 0.6196 - policy_loss: 1.6185 - val_loss: 6.1364 - val_value_loss: 0.6561 - val_policy_loss: 1.5923\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1290 - value_loss: 0.6153 - policy_loss: 1.6183 - val_loss: 6.1354 - val_value_loss: 0.6541 - val_policy_loss: 1.5923\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1279 - value_loss: 0.6134 - policy_loss: 1.6180 - val_loss: 6.1346 - val_value_loss: 0.6527 - val_policy_loss: 1.5922\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1260 - value_loss: 0.6099 - policy_loss: 1.6176 - val_loss: 6.1341 - val_value_loss: 0.6516 - val_policy_loss: 1.5922\n",
      "Saved model  tictactoe_c_puct_0_1_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.0\n",
      "Number of seen trajectories: 2800\n",
      "Number of unique trajectories: 2205\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1296 - value_loss: 0.6263 - policy_loss: 1.6086 - val_loss: 6.1309 - val_value_loss: 0.6082 - val_policy_loss: 1.6291\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1282 - value_loss: 0.6239 - policy_loss: 1.6082 - val_loss: 6.1310 - val_value_loss: 0.6085 - val_policy_loss: 1.6291\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1264 - value_loss: 0.6201 - policy_loss: 1.6083 - val_loss: 6.1310 - val_value_loss: 0.6088 - val_policy_loss: 1.6290\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1247 - value_loss: 0.6166 - policy_loss: 1.6086 - val_loss: 6.1309 - val_value_loss: 0.6086 - val_policy_loss: 1.6289\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1231 - value_loss: 0.6141 - policy_loss: 1.6078 - val_loss: 6.1308 - val_value_loss: 0.6084 - val_policy_loss: 1.6289\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1216 - value_loss: 0.6108 - policy_loss: 1.6082 - val_loss: 6.1306 - val_value_loss: 0.6082 - val_policy_loss: 1.6288\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1197 - value_loss: 0.6074 - policy_loss: 1.6077 - val_loss: 6.1305 - val_value_loss: 0.6080 - val_policy_loss: 1.6288\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1185 - value_loss: 0.6052 - policy_loss: 1.6076 - val_loss: 6.1304 - val_value_loss: 0.6079 - val_policy_loss: 1.6287\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1169 - value_loss: 0.6023 - policy_loss: 1.6073 - val_loss: 6.1302 - val_value_loss: 0.6074 - val_policy_loss: 1.6287\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1158 - value_loss: 0.5999 - policy_loss: 1.6075 - val_loss: 6.1299 - val_value_loss: 0.6071 - val_policy_loss: 1.6286\n",
      "Saved model  tictactoe_c_puct_0_1_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.0\n",
      "Number of seen trajectories: 2900\n",
      "Number of unique trajectories: 2258\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_0_1_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 180us/step - loss: 6.0935 - value_loss: 0.5596 - policy_loss: 1.6033 - val_loss: 6.0917 - val_value_loss: 0.5685 - val_policy_loss: 1.5908\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0909 - value_loss: 0.5548 - policy_loss: 1.6028 - val_loss: 6.0897 - val_value_loss: 0.5645 - val_policy_loss: 1.5907\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0877 - value_loss: 0.5487 - policy_loss: 1.6025 - val_loss: 6.0883 - val_value_loss: 0.5617 - val_policy_loss: 1.5907\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0861 - value_loss: 0.5453 - policy_loss: 1.6027 - val_loss: 6.0871 - val_value_loss: 0.5595 - val_policy_loss: 1.5906\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0848 - value_loss: 0.5426 - policy_loss: 1.6029 - val_loss: 6.0861 - val_value_loss: 0.5576 - val_policy_loss: 1.5905\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.0827 - value_loss: 0.5387 - policy_loss: 1.6027 - val_loss: 6.0853 - val_value_loss: 0.5560 - val_policy_loss: 1.5905\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0802 - value_loss: 0.5341 - policy_loss: 1.6023 - val_loss: 6.0845 - val_value_loss: 0.5545 - val_policy_loss: 1.5904\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.0790 - value_loss: 0.5320 - policy_loss: 1.6019 - val_loss: 6.0837 - val_value_loss: 0.5531 - val_policy_loss: 1.5904\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.0774 - value_loss: 0.5289 - policy_loss: 1.6019 - val_loss: 6.0831 - val_value_loss: 0.5519 - val_policy_loss: 1.5903\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.0777 - value_loss: 0.5290 - policy_loss: 1.6024 - val_loss: 6.0825 - val_value_loss: 0.5506 - val_policy_loss: 1.5903\n",
      "Saved model  tictactoe_c_puct_0_1_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.0\n",
      "Number of seen trajectories: 3000\n",
      "Number of unique trajectories: 2318\n"
     ]
    }
   ],
   "source": [
    "wins_4, draws_4, seen_trajectories_4, unique_trajectories_4 = test_pipeline.run(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzs3Xd8U1UbwPHf6W7pgDJklLJ3KHtDmSpDQEVAUYYKuHChouIeOHj1VVAcoFDZoGwFEZQ9hJZdZoECbRkt0D2TnPePlLwFSpuOtLQ838+nH0ly7rlPYnKfe8+6SmuNEEIIAeBQ3AEIIYS4fUhSEEIIYSVJQQghhJUkBSGEEFaSFIQQQlhJUhBCCGElSUHclpRSG5VSo+1U90Sl1E/2qFuIkk6SgigQpVS4UipFKZWY5e/b4o7rGqVUN6VURNbntNafaK3tknBKisz/b71yKdNTKXVUKZWslNqglKqRQ9mPlFIHlVJGpdT7hR6wKDKSFERh6K+19szyN664AxIFo5SqACwF3gF8gWBgUQ6bhAETgD/sH52wJ0kKwi6UUq5KqVillCHLcxUzryoqKaXKKaV+V0pFK6WuZv7b7xZ1va+UmpvlcU2llFZKOWU+flwpdUQplaCUOqWUeirz+TLAGqBqlquYqtnUN0ApFZoZ70alVKMsr4UrpV5VSh1QSsUppRYppdwK8Ll0Vkptz9zXOaXUqFzKBymlflBKrct8f5uunbHf+DlkPndds5tSakyWz+awUqqlUmoO4A+syvxMJmSz6weBUK31r1rrVOB9oJlSqmF2cWqtf9FarwES8viRiNuMJAVhF1rrNCxnmo9keXoIsElrfQnLd28WUAPLASoFyG+z0yXgPsAbeBz4SinVUmudBPQBorJcxURl3VApVR9YALwEVARWYzlYutwQd2+gFhAAjMpPkEopfyxJ6pvMfTUH9tmw6aPAR0CFzPLzbNzfYCwH8xFYPpsBwGWt9XDgLP+/wpuczeZNgP3XHmR+licznxelmCQFURiWZ575Xvsbk/n8fK5PCsMyn0NrfVlrvURrnay1TgAmAV3zs3Ot9R9a65PaYhPwF9DFxs2HAn9orddprTOALwB3oGOWMlO11lFa6yvAKiwH8/x4FFivtV6gtc7I/AxsSQp/aK03Zybat4AOSqnqNmw3Gpistd6d+dmEaa3P2BirJxB3w3NxgJeN24sSSpKCKAz3a63LZvmbkfn8P4C7UqpdZpNHc2AZgFLKQyn1o1LqjFIqHtgMlFVKOeZ150qpPkqpnUqpK0qpWKAvlrNqW1QFrAdKrbUZOAdUy1LmQpZ/J2M5YGYXR2iWZqrsklJ1LGfbeXUuS3yJwJXMuHOT3/0BJGK5usjKG2keKvUkKQi7yTzALsZytTAM+D3zqgDgFaAB0E5r7Q0EZj6vsqkqCfDI8rjytX8opVyBJVjO8O/SWpfF0gR0rZ7clgGOwtKEda0+heVgGpnb+7uR1rpJlmaqLdkUOQfUyWu9mfFci88TS8dvFJbPBW7x2eSyv9w+l1CgWZb9lsmsK9S2kEVJJUlB2Nt8LE00j2b++xovLP0IsUopX+C9HOrYBwQqpfyVUj7Am1lecwFcgWjAqJTqA9yT5fWLQPnM7bKzGOiXOfzSGUuySgO22/oG82Ae0EspNUQp5aSUKq+UsqUpqm9mB7ULlr6Ff7XW57TW0ViS12NKKUel1BNcnwR+Al5VSrVSFnWzDCu9CNTOYZ/LAINSalBmx/q7wAGt9dHsCiulnDPLOQBOSim3/Fz1ieInSUEUhmujWK79Lbv2gtb6XyxntFWxdLJe8zWWtvsYYCfw560q11qvwzIc8gAQAvye5bUE4AUsB/erWK5IVmZ5/SiWjuRTmf0d1zW7aK2PAY9h6fyNAfpj6YBNz+uHkBut9VksTVuvYGkC2keWs/EczMeSNK8ArbAk2GvGAK8Bl7F0AluTmdb6Vyx9NfOxNPssx3KVAfAp8HbmZ/JqNrFGA4Myt78KtAMevvZ65oioH7JsMgNLkn8ES79HCjDchvcmbjNKbrIjxO1LKRUERGit3y7uWMSdQa4UhBBCWDnlXkQIYU9KqVCydHZn8VRRxyKENB8JIYSwkuYjIYQQViWu+ahChQq6Zs2axR2GEEKUKCEhITFa64q5lStxSaFmzZoEBwcXdxhCCFGiKKVsWuJEmo+EEEJYSVIQQghhJUlBCCGEVYnrU8hORkYGERERpKamFncopYqbmxt+fn44OzsXdyhCiCJSKpJCREQEXl5e1KxZE8sil6KgtNZcvnyZiIgIatWqVdzhCCGKSKloPkpNTaV8+fKSEAqRUory5cvL1ZcQd5hSkRQASQh2IJ+pEHeeUpMUhBDCnkLOXOWv0Au5FyzhJCkUkb59+xIbG1vo9e7bt4/Vq1dbH69cuZLPPvus0PcjxJ0qNjmd1387wKDvt/PU3BCOXSjddySVpFBEVq9eTdmyZfO1rdFovOVrNyaFAQMG8MYbb+RrP0KI/9NasyQkgh5fbuK3PRE80akWnq5O/GdttjefKzUkKRSCyZMnM3XqVABefvllevToAcDff//NY489BliW54iJiSE8PJxGjRoxZswYmjRpwj333ENKSspNdY4aNYrx48fTvXt3Xn/9dXbt2kXHjh1p0aIFHTt25NixY6Snp/Puu++yaNEimjdvzqJFiwgKCmLcuHEAnDlzhp49exIQEEDPnj05e/ZsEX0iQpRsJ6MTefSnf3nl1/3UKO/B78935t3+jXm6ax3WH7nE7vArxR2i3ZSKIalZfbAqlMNR8YVaZ+Oq3rzXv8ktXw8MDOTLL7/khRdeIDg4mLS0NDIyMti6dStdunS5qfyJEydYsGABM2bMYMiQISxZssSaPLI6fvw469evx9HRkfj4eDZv3oyTkxPr169n4sSJLPr1Vz744ANCQkL49ttvAQgKCrJuP27cOEaMGMHIkSOZOXMmL7zwAsuXLy/4B3KHM5rMJKWb8HGX+RulTWqGie82nuSHjSdxc3Zg0gMGHmnjj4ODZdDFE51q8cv2cD5bc5Tfnu5QKgdjlLqkUBxatWpFSEgICQkJuLq60rJlS4KDg9myZYv1CiKrWrVq0bx5c+u24eHh2dY7ePBgHB0t9z6Pi4tj5MiRnDhxAqUUGRkZHLuQQFxKxi3j2rFjB0uXLgVg+PDhTJgwoYDvVOwOv8Jbyw4SFZvKkmc60qCyV3GHJArJtrAY3l5+iNMxSQxsXpW3+zWmopfrdWXcXRx5qVd9Ji47yPojl7i78V3FFK39lLqkkNMZvb04OztTs2ZNZs2aRceOHQkICGDDhg2cPHmSRo0a3VTe1fX/XzRHR8dsm48AypQpY/33O++8Q/fu3Vm2bBnh4eEEdu2KyaxJTDNitvFGSaXxrKaoxCan8+nqoywKPke1su64OTsydk4wK57rRFkPl+IOTxRATGIak/44wrK9kdQs78GcJ9vSpd6tV5ge0tqPn7acYvKfR+nRsBKODqXrd1XqkkJxCQwM5IsvvmDmzJk0bdqU8ePH06pVq0I7EMfFxVGtWjUAZs2ahckMrk6OeJTxJOZKXLbbdOzYkYULFzJ8+HDmzZtH586dCyWWvEg3mun99WbCLyfZVN63jAuDWvnxWLsaVPf1sHN0udNas3RPJJNWHyEuJYOxgbV5qVc9jpyP5+HpO3l+wV6CHm9b6g4MdwKzWbNw9zk+W3OElAwTL/Soy7Pd6+Lm7Jjjdk6ODrx2bwOembeHJXsiGNK6ehFFXDQkKRSSLl26MGnSJDp06ECZMmVwc3PLtj8hvyZMmMDIkSP573//S8cuXQFNZR83evbozszvvqZZ8+ZMfPPN67aZOnUqTzzxBP/5z3+oWLEis2bNKrR4bLX5eDSnYpIY2ro6lbxdcy1//GICP205zfTNp+hWvyLDO9Sga/3iORs7GZ3IO8sPsf3kZVr4l+WTB5rSqIo3AK1q+PLhQANvLj3I5LVHebPPzVeE4vZ19EI8by07RMiZq7Sr5cukB5pSt5Knzdv3NlSmWfWyfLXuOAOaVc01kZQkJe4eza1bt9Y33mTnyJEj2TbTlFZhlxIxms00uMuL1AwzJy4lcJe3G3d5uxX6vgr62b64cC+bjkez+61eODvaNtjtfFwKC3adY8Gus0QnpOFXzp1H29VgSGs/ynvmnlgK6sbOxtf7NLyuszGrt5YdZN6/Z5n6SAsGNKuar/1prZm1LZyQM1f5dFBTvN2kA9tektONTPn7BD9vOY23uzMT+zZiUMtq+bqi33HyMo/M2MnEvg0ZG1gnX/HM2RHOmkMXaFjZm2bVfQjwK0vN8h52aepVSoVorVvnVk6uFEqY5DQjyelGqpZ1RymFu4sj3m7OxCSmUcHT9bZqxkhJN7Hu8EUGNq9mc0IAqOLjzvi76/N8j7r8FXqROTvD+fzPo3y17jj9AqrwWPsatPQva5cfji2djVm9178Jxy8mMOG3/dSpWIYmVX3ytL80o4mJSw+xZE8EABfjU/nlibaUcZWfZmH75+hF3lkeSmRsCkNa+/Fmn0aUK5P//qAOdcrTtX5Fpm04ydA2/nkejfbz1tN89PthapT3YM/Zq8zcZgbA282JAL+yBPhZkkSz6j5U9nYrsj5B+eaVMDGJ6TgqRbksnZuVvFwJi87gSlIaFb0K/2ohv/4+epHkdBP9m1XJ1/bOjg70C6hCv4AqnLiYwNydZ1iyJ5JleyNpXMWbl3rV454mlQsl1pjEND7+/TDL90XZ1Nl4jYuTA9892or+32xl7OwQVj3fGV8bDzTRCWk8PTeEkDNXealXPepV8uL5BXsY/Uswsx5vU6qaJIrThbhUPlgVyppDF6hbyZPFT3WgbS3fQql7Qu8G9Ju6lR82neT13g1t3m7uzjN89Pth+hgq880jLQA4fjGRAxGx7I+I40BELNM3n8JotrTkVPRypZmfD6M61qJzvQqFEvutSFIoQdKNZuJSMijv6XLdFYGHqxOerk5EJ6RTvoxrts0cxWHV/igqebnSrlb5AtdV7y4vPhhoYELvhizfF8msbeGMnRPC3Y3v4oMBTaha1j1f9ea3szGril6u/Di8FYN/3MFz8/Yw58m2OOVyZRQaFceYX4K5kpzOtGEt6RdgSZwZpua8vHgfY+eEMGNEK1ydJDHkl8msmb0jnC//Ok6Gycxr9zZgTJfauDgV3pzdJlV9uL95VWZtO82ojjVtasL9Nfgcby8/RM+GlZjycAvrd6VxVW8aV/Xm4baWcqkZJg6fj+fAuVgORMSxPyI2xyHohUWSQhGJT8nAzdkBlwL8yC8npQGaCp43n4lW8nbjVHQiV5LTqVAE7e65iU/NYMOxaB5t51+oTVplXJ0y+xeqM3Prab5ef4Je/93E+LvrM6pjzVwPxlkVtLMxq2bVy/LpA0155df9fLL6KO/2b3zLsn8eOs/Li/ZT1sOZ357uiKHa/5uc7m9RjTSjideXHOS5eXv5/rGWeWp6ExZHL8Tz2q8HOBgZR2D9inw0sAk1ypfJfcN8eOWeBvxx8Dxfrz/Bpw82zbHsin2RvL7kAF3qVWDaoy1zTFBuzo609C9HS/9yhR1yjuTbVgQyjGbCLycRfjnZ5jkFNzKZNVeS0vF2d842sXi6OlHGxYnohLR876Mw/RV6kXSjmf757HzNjbOjA091rcNfLwfSvnZ5Pv7jCP2/3cbes1dz3TY53cina45w39StnIpO5IvBzVg4tn2+E8I1g1r58XinmszcdpolIRE3va615pu/T/D03D00qOzFiuc6XZcQrhnaxp8PBzZh/ZGLvLRwH0aTuUBx3Wn+PHSBB6Zt53xcKt880oJfHm9jt4QAUN3Xg0fb1WBx8DlORifmENd5xi/eT+uavkwf3vq2bR6UpFAEYjMv+VIzTFyMz99Na2KT0zGZdY5XAZW8XckwmYlNTs/XPgrTqv1R+JVzp0X1/C0CaKvqvh78PLI1PzzWkqtJ6Tz4/XbeXn7wlpfZ/xy9yN3/3cyPm07xYMtq/PNKNx5q5VdonXgT+zaiQ+3yvLnsIAci/r8qbmqGiRcW7uPLdcd5oEU1Fo5tT6UcmhpGdKjJW30b8cfB80z47QBmc94T/aWEVI5fLN0remaltebbf07w9NwQGlT2YvULnenfrGqRdNCO61EXNycHvlh7LNvXNxy9xPML9hLg58PMUW1wd7k9EwJIUrCL999/ny+++ML6OC4lA3dnR3zLuBCdkEZS2q1XPc2O1pqYxHTcXRzxyOHL5OnqhLuLI5cS0rg21PiTTz65rkzHjh3ztO/8uJyYxtawmCL7QSql6G2owvpXujKqY03m/3uWXv/dxMr9UdbP4UJcKs/MDeGJoGDcXRxZNLY9kx9qVqDRJ9lxdnTg22EtqOjpylNzQohOSONCXCpDftzB7weieL13Q/47pJlNZ4ljAmvz6j31Wbo3konLDtqUGLTW/HvqMuPm76Hjp//QZ8oW/jxU+u8BcC3pfvHXce5vXjXXpFvYKni6MiawNmsOXbjpanXriRieykxUQY+3xfM2H1l2e0dXCqQZTSSnG6ni44a3qyOJaUbOXU2mXiUvm9vaE9KMpBlNVPe9efyyyWSyro+klKKSlxtnLicRm5JBOQ8XPvnkEyZOnGgtv3379sJ7c7ew5tAFTGZN/wD7NB3diqerE+/1b8KDLfyYuOwgLyzYy6/B5+hUtwLf/hNmt87GG5X3tHQ8P/TDdp78ZTcX4lJJSjMyY3hreuVxrZxxPeqRmmHm2w1huDo58P6AJtkm2oTUDJbvjWTOzjMcv5iIj7szozrWZM/Zqzy/YA/Th7eme8NKBX5vZrMmMjb7ZVlu5OCgqOpj/6GUF+JSGTsnmIORcUzo3YBnutYpliVdRnepzdydZ/hszVEWjm2PUop/T11m9Ozd1K5QhjlPtCsRiyhKUigkkyZNYvbs2VSvXp2KFSvSqlUrAHp0706jZq05fiCYgQMH4l+rDh9+9DHalEHlShWZN28ed911F02bNmXLli34+PhQoUIFvvrqK0aMGMHw4cO5Z+AQWnfqav1Cbdy4kQ8++IAqVaqwb98+Dh8+zP3338+5c+dITU3l4cefYshjj/PZB++QkpJC8+bNadKkCfPmzcPT05PExES01kyYMIE1a9aglOLtt99m6NChhfJZrNofRd1KnjSqUjyLxTX182H5c52YsyOcL/46zpYTMXbvbLyRoZoPnw8K4MWF+/Ar586cJzvle/G8V+6pT2qGiZ+2nsbN2ZE3+jS0HvSOXohn7s4zLNsTSVK6iabVfJj8UAD9A6ri7uJIfGoGj874l6fmhjBzZJsCDWe8kpTO03ND2HXa9mWj372vMU90rpXvfeZm/7lYxswOJinNyPThrYt1gTpPVyee71GP91aGsvF4ND7uzjwRtJtqZd2Z82S7Qr8qtZfSlxTWvAEXDhZunZWbQp9b380sJCSEhQsXsnfvXoxGIy1btrQmBaNJk5KUwObNmwG4evUqnXrcQ0xiOptWLmLy5Ml8+eWXdOrUiW3btlGjRg1q167Nli1bGDFiBDt27uS5tz+lfBkXHLKc/ezatYtDhw5Rq5blBzdz5kx8fX1JSUmhZavWdL33Pia+9xHTpk1j3759N8W8dOlS9u3bx/79+4mJiaFNmzYEBgZSpUr+5hRccyEulV3hV3ipZ/1iXYDP0UExqlMt+jStwslLiXSoU77I4xnYvBpVy7pTr5JngRbNU0rxVr9GpBnN/Lj5FM6ODtSv7MXcHWfYFX4FVycH+jeryvD2NWh2Qx+Ot5szs59oyyMzdjJ69m5+ebwt7WrnfYjw0QvxjP4lmOiENF7v3TDHCX3XzNp2mtk7whnVsaZdhkmv2BfJhN8OUNHLldlPdqRhZe9C30dePdLWn5+3nubDVYctE0q9XJk/pr1Nn9ftovQlhWKwZcsWHnjgATw8LAu4DRgwALC0c5q1ZsjQIdayERERjH/lFc6eiyQ9PZ36dWsDlrWTNm/eTI0aNXjmmWeYPn06kZGReHmXxdPT66YJUW3btrUmBLCsc7Rs2TIAoiIjOH/2NFUq3Xry1datW3nkkUdwdHTkrrvuomvXruzevdsae379fiAKrcn3hLXCZq/lP2zVpmbhTJJSSvHBgCakGy1NSQA1ynvwVt9GPNTKL8ez0HJlXJg7uh1Df9zBE0G7mTO6XZ6GOa47fJGXFu6ljKsTi5/qcFPiuRUHBeMX72fHqct0qlt4E67MZs1/1x3n2w1htK3py/ePtSyS5U9s4eLkwCv31OfFhfuoVtadeaPbFev3Lz9KX1LI4YzenrI7C41NtoyAuavc/4cdPv/884wfP567e/djwYo1TP/6c7TWBAYGMm3aNM6ePcukSZNYtmwZixb/SrM27Snr4XzT+Pusy2pv3LiR9evXs2PHDjw8POjWrRvuDmZSMky3jNdea16t2h+FoZo3tSsWbHinuJmDg+KTB5vSqIoXNSuUIbBeRZvPwCt4Ws5Yh/y4g5Ezd7FgTPtsh8NmpbXmh02nmLz2KE2r+TB9eGsq+9h+gOvbtAofrDrM/H/PFlpSSEoz8vKiffx1+CIPt6nOhwMNdu0fyo/+AVVJTjfRpV4F/MoV/0q/eWXXT1Mp1VspdUwpFaaUuunGwUopf6XUBqXUXqXUAaVUX3vGYy+BgYEsW7aMlJQUEhISWLVqFVpr4lLScXRQ1x3Qry2B7e7iyLoVizGZNbHJGVSvXp2YmBhOnDhB7dq16dy5M19++QUt2nTIdTJaXFwc5cqVw8PDg6NHj7Jz50483ZxwcXTA0cmZ9PSbh6gGBgayaNEiTCYT0dHRbN68mbZt2xboczhzOYn9EXFF3sF8J7nWLNatQaU8N8nc5e3G/DHt8XZz5rGf/+XohVvfoTA1w8T4xfv5/M+j3BdQlcVPdchTQgDL5KtBLf1YG3qB6IS0PG17q5iG/LiD9Ucu8u59jfn0waa3XUIAS/J+pK1/iUwIYMekoJRyBKYBfYDGwCNKqRuneb4NLNZatwAeBr6zVzz21LJlS4YOHUrz5s0ZNGgQXbp0IcOkSTOacbrhh/v+++8zePBgunTpQrXKlh92VGwK6UYz7dq1o379+gB06tyZ81FRdOnSOdfhi71798ZoNBIQEMA777xD+/btcVCKil6uPDhsBE0DAnj00Uev2+aBBx4gICCAZs2a0aNHDyZPnkzlygVbR+j3A+cBuM9OE9ZEwVUr6878Me1wc3LksZ/+JezSzZOtLsWn8vD0nSzbG8mr99Rn6sPN8z3Ralg7f4xmza8h5woaOr+GRBAaFc+3w1ryROdactMoO7Hb0tlKqQ7A+1rrezMfvwmgtf40S5kfgVNa688zy3+ptc5xIH1JWTr7fFwKMYnpNKrslePSC2lGEycuJuLh4kitCmWsX/Sryemcu5JMrQpl8MrnUspms+bYxQRcnRzy3ZyTl8/23q824+XmxG/P2H8uhCiYk9GJDP1xJ44OsPipDtZRWYci4xgzO5jY5Ay+Gtqc3oaCLzg49McdnI9LZeOr3fLd4ZxhMtPtPxu5y9uVJc90lISQD7YunW3Pa69qQNbTg4jM57J6H3hMKRUBrAaez64ipdRYpVSwUio4OjraHrEWKq0tTUJerk65rsXj6uRI1bJuJKYZiUlMt24fk5CGq5NjgSa6ODgoKni6kphmzPOEubw6diGBYxcT7LashShcdSp6Mm90O9KNZobN+JeIq8n8ceA8D/2wHQX89kyHQkkIYLlaOHslma1hMfmuY/neSCJjUxjXo64kBDuzZ1LI7v/cjZcljwBBWms/oC8wRyl1U0xa6+la69Za69YVK+a+nHFxS043kWEyU9bDtjP8ch4ueLs5cyE+ldQME8npJlIyTFTwdCnwD8C3jAtODooL8akkp9t+P+e8+v1AFA7K0rkoSoYGlb2Y82Q7ElIzGPDtNp6bv4cmVX1YMa5znu8LkZPehsr4lnFh/r9n87W9yaz5buNJGlfxpnuDgk/AEzmzZ1KIALLevNQPiLqhzJPAYgCt9Q7ADbDvYuFFIDYlAwelbG72UUpRrZw7jgrOXUkmOiENR4fr75mQX44OikrebiSlGQm7lEhoVDxhlxKIvJrClaR0UjNMBR6JpLVm5f4oOtapUKLGYwvLJLtfnmiLWWsGt/Jj/ph2hf7/0NXJkYda+bHuyEUu5WPtrz8Onud0TBLPy1VCkbBnUtgN1FNK1VJKuWDpSF55Q5mzQE8ApVQjLEnh9m8fyoHWmrjkDLzcnPK0ZLSzowPVyrmTkmEiPjXDMlmtkCb8VPB0pWFlL/x9PaxXH7HJ6URcTeb4xQRCo+I5GZ3I+dgU68J7eXEwMo4zl5Nvm7kJIm9a+Jcj5O27+c/gZna7f8Mjbf0xmTWLg/PW4Ww2a6b9E0bdSp7cW0g3VBI5s9s8Ba21USk1DlgLOAIztdahSqkPgWCt9UrgFWCGUuplLE1Lo3RJu2n0DRLTjBjNZsp65P2mLz7uLpTzMBKXkoFvmcI9W3NxcsTFyZFr0460toyOSkk3kZxhIiXdRExSOjpR4+bsSI3yHjYfIFbui8LZUdG7iSSFksret3GtVaEMHeuUZ8GuczzTra7N+1t/5CLHLibw1dBmt83No0o7u05e01qvxtKBnPW5d7P8+zDQyZ4xFLW45AwclcIrnx3EfuXcqezjZvcbqyilcHN2xM3ZkWtzW81ak5hqWbDv5KVE/G1YJ8hs1vx+4Dxd61fEx8Y+FHFnGtbOn3Hz97L5RLRNfQNaa6ZtCMPf10PmvhSh22/mRwnl6emJWWviUjPwdnfO91mNUipfCWHfvn2sXv3//Lty5Uo++yxvs7sdlMLb3Zm6FT1xdHDgdHRSrqOWgs9c5UJ8qow6Erm6p3FlKnja3uG85UQM+yPieLZbnTzdUU8UjHzShSgx1YjJrG0edZRXRuOtD9A3JoUBAwbwxhs3TSK3iauzI3UqlcHTzYmryRm8vzL0lnf/Wrk/EjdnB3o1Kr7VKUXJ4OLkwEOtqvP3kYucj8t9+e1v/wmjio8bD7b0K4LoxDWSFApRbHIGjgo+ePtNDAYDTZs2ZdGiRQCcP3+ewMBAmjdvjsFgYMuWLZhMJkaVxGeTAAAgAElEQVSNGmUt+9VXX91U56hRoxg/fjzdu3fn9ddfZ9euXXTs2JEWLVrQsWNHjh07Rnp6Ou+++y6LFi2iefPmLFq0iKCgIMaNGwfAmTNn6NmzJwEBAfTs2ZOzZ3M/U3NycKBmeQ+83JwI2h7O40G7iUu+/m5mRpOZ1Qcv0LPRXZS5zW8cIm4Pj7StjlnDot05dzj/e+oyu8Kv8FSgfe99IW5W6n7Jn+/6nKNXjhZqnQ19G/J629dzLRefmsH29avZv3//TUtSz58/n3vvvZe33noLk8lEcnIy+/btIzIykkOHDgEQGxubbb3Hjx9n/fr1ODo6Eh8fz+bNm3FycmL9+vVMnDiRJUuW8OGHHxIcHMy3334LQFBQkHX7cePGMWLECEaOHMnMmTN54YUXWL58ea7vRymFj7szkwcF8Nbygzzw3TZ+GtnaOjt6+8nLXElKl/ZeYbMa5cvQpV4FFu0+x7judW/ZLPTthjAqeLrwcFv/Io5QSAq+gdaQZjRjNOV9EJRZaw6E/JvtktRt2rRh1qxZvP/++xw8eBAvLy9q167NqVOneP755/nzzz/x9s5+PfjBgwdb764WFxfH4MGDMRgMvPzyy4SGhuYa144dOxg2bBgAw4cPZ+vWrXl6X0PaVGf+mPbEpmRw/7RtbDlhGTW8cn8UXq5OdGtw+08oFLePYW39LcteHMt+9Pn+c7FsORHD6C61b9ub25dmpe5KwZYz+ltJyzARfjmZNKNlyekKnq5UsfF2glpb5ho43qJoYGAgmzdv5o8//mD48OG89tprjBgxgv3797N27VqmTZvG4sWLmTlz5k3bZl0m+5133qF79+4sW7aM8PBwunXrluf3mZ8JQG1q+rLiuU6MmR3MqFm7eaN3Q9YeusA9TSrLD1fkSa/Gd1HRy5X5u85me3vSbzeE4ePuzGPtaxRDdEKuFDIlpGYQFp2IyaypXcGTCp6uxCSmEX45GaM5+07Wa4xmMxrwcXema9eu2S5JfebMGSpVqsSYMWN48skn2bNnDzExMZjNZgYNGsRHH33Enj17co3z2tLbcH0TkZeXFwkJCdlu07FjRxYuXAjAvHnz6Ny5s20fyg2q+3rw2zMd6dGwEpNWHyEhzSgT1kSeOTs6MKS1HxuPXbrpfs9Hzsez7vBFnuhU67a/wX1pdccnBa215eAfk4yzowN1M0fdVC3rTrVy7iSmGjl5KYm0HG5YE59iGRVU1sP5lktSb9y4kebNm9OiRQuWLFnCiy++SGRkJN26daN58+aMGjWKTz/99Jb7uGbChAm8+eabdOrUCZPp/zF1796dw4cPWzuas5o6dSqzZs0iICCAOXPmMGXKlHx+Wpb70P74WCte6FGXTnXLF+odtcSd4+E2/mhg0a7rBz1M2xCGp6sTozrWLJa4hB2XzraXwlw626w1UbGWNYC83Zyp7utx00zLxDQjZy8noQF/X49s1zM6HZNEmtFEg7u8St3aLLfjsuSidBg5cxdHL8Sz7fUeODk6cDI6kV7/3cTTXevweu+GxR1eqXM7LJ19WzOazJyOSeJKUjqVvFypUf7mhACWM+O6lTxxdnQgPCaZmMS06xaQM5rMJKYaKevuXOoSghD2NKydPxfj0/j76CUAvt94ElcnB57sXCuXLYU93ZFJITXDRFh0IsnpJqr7elDZxz3HA7qLkyN1Knri5eZEVGwKUbEp1iWo41Iy0Gh8CmFFUyHuJD0bVuIub1fm/3uWc1eSWb43kkfa+ud6+1lhX6UmKdjaDBafkkHYpUTMGupULGPz8tSODooa5T2o6OXK5aR0TsckYTSZiU3JwM3JEbdSOMGmpDUtipLFydGBoW382XwimvdXhuKgFGMDaxd3WHe8UnEkc3Nz4/LlyzkexLTWRCekEn45CVcnB+pW9MTDJW+jG5RSVPFxp3o5D5LTTYRdSiQpzYiPR+lrOtJac/nyZdzc8nazdiHy4uE21VHA30cv8VBrP6r45H11YVG4SsWYLz8/PyIiIsjpVp3xqRnEpxjxcHHEycOZk1cKdhA3G81EJVnuPaC8XblSChfscnNzw89P1p0R9lO1rDvdG1Ri4/Fonulap7jDEZSSpODs7EytWjl3Tp2PS2HV/ijGdKhdaGf1F+NTOXExkab1ZFimEPn10f0GwmOSqO7rUdyhCErJkFQhhBA5kyGpQggh8kySghBCCCtJCkIIIawkKQghhLCSpCCEEMJKkoIQQggrSQpCCCGsJCkIIYSwkqQghBDCSpKCEEIIK0kKQgghrCQpCCGEsJKkIIQQwkqSghBCCCtJCkIIIawkKQghhLCSpCCEEMJKkoIQQggruyYFpVRvpdQxpVSYUuqNW5QZopQ6rJQKVUrNt2c8QgghcuZkr4qVUo7ANOBuIALYrZRaqbU+nKVMPeBNoJPW+qpSqpK94hFCCJE7e14ptAXCtNantNbpwEJg4A1lxgDTtNZXAbTWl+wYjxBCiFzYMylUA85leRyR+VxW9YH6SqltSqmdSqnedoxHCCFELuzWfASobJ7T2ey/HtAN8AO2KKUMWuvY6ypSaiwwFsDf37/wIxVCCAHY90ohAqie5bEfEJVNmRVa6wyt9WngGJYkcR2t9XStdWutdeuKFSvaLWAhhLjT2TMp7AbqKaVqKaVcgIeBlTeUWQ50B1BKVcDSnHTKjjEJIYTIgd2SgtbaCIwD1gJHgMVa61Cl1IdKqQGZxdYCl5VSh4ENwGta68v2ikkIIUTOlNY3NvPf3lq3bq2Dg4OLOwwhhChRlFIhWuvWuZWTGc1CCCGsJCkIIYSwkqQghBDCSpKCEEIIK0kKQgghrCQpCCGEsJKkIIQQwkqSghBCCCtJCkIIIawkKQghhLCSpCCEEMJKkoIQQggrSQpCCCGsJCkIIYSwkqQghBDCSpKCEEIIK0kKQgghrJxsLaiUagZ0yXy4RWu93z4hCSGEKC42XSkopV4E5gGVMv/mKqWet2dgQgghip6tVwpPAu201kkASqnPgR3AN/YKTAghRNGztU9BAaYsj02ZzwkhhChFbL1SmAX8q5Ralvn4fuBn+4QkhBCiuNiUFLTW/1VKbQQ6Y7lCeFxrvdeegQkhhCh6OSYFpZS31jpeKeULhGf+XXvNV2t9xb7hCSGEKEq5XSnMB+4DQgCd5XmV+bi2neISQghRDHJMClrr+zL/W6towhFCCFGcbJ2n8LctzwkhhCjZcutTcAM8gApKqXL8fxiqN1DVzrEJIYQoYrn1KTwFvIQlAYTw/6QQD0yzY1xCCCGKQW59ClOAKUqp57XWMntZCCFKOVvnKXyjlDIAjQG3LM/PtldgQgghip5NSUEp9R7QDUtSWA30AbYCkhSEEKIUsXXto4eAnsAFrfXjQDPA1W5RCSGEKBa2JoVUrbUZMCqlvIFLyMQ1IYQodXJtPlJKKeCAUqosMAPLKKREYJedYxNCCFHEcr1S0FproLnWOlZr/QNwNzAysxkpR0qp3kqpY0qpMKXUGzmUe0gppZVSrfMUvRBCiEJla/PRTqVUGwCtdbjW+kBuGyilHLHMZeiDpYP6EaVU42zKeQEvAP/aHLUQQgi7sDUpdAd2KKVOKqUOKKUOKqVySwxtgTCt9SmtdTqwEBiYTbmPgMlAqs1RCyGEsAtbb7LTJx91VwPOZXkcAbTLWkAp1QKorrX+XSn16q0qUkqNBcYC+Pv75yMUIYQQtrB18tqZfNSd3e06rctvK6UcgK+AUTbsfzowHaB169Y6l+JCCCHyydbmo/yIAKpneewHRGV57AUYgI1KqXCgPbBSOpuFEKL42DMp7AbqKaVqKaVcgIeBldde1FrHaa0raK1raq1rAjuBAVrrYDvGJIQQIgd2SwpaayMwDlgLHAEWa61DlVIfKqUG2Gu/Qggh8s/WjuZ80VqvxrJWUtbn3r1F2W72jEUIIUTu7Nl8JIQQooSRpCCEEMJKkoIQQggrSQpCCCGsJCkIIYSwkqQghBDCSpKCEEIIK0kKQgghrCQpCCGEsJKkIIQQwkqSghBCCCtJCkIIIawkKQghhLCSpCCEEMJKkoIQQggrSQpCCCGsJCkIIYSwkqQghChWa8PXMnHLRLTWxR2KQJKCEKIYaa35Yf8PrDq1ik0Rm4o7HMEdlBT2XNzDyxteJs2UVmh1Hoo5xE8Hf5IzHCHy6fCVw4TFhuGgHJhxYIb8lm4Dd0xSiEyM5O+zf/PyhpfJMGUUuL6D0QcZ/ddopuyZwsGYg4UQoRB3npVhK3FxcOGFFi9wIOYAO8/vLO6Q7nh3TFLoX6c/73R4hy2RW3ht82tkmPOfGI5eOcpT65+irGtZnB2cWXN6TSFGKsSdIcOUwerTq+nu353hjYdTyaMS0w9ML+6w7nh3TFIAGFx/MG+0fYO/z/7NW1vewmQ25bmOsKthjPlrDJ7Onsy8dyZdqnVhbfjafNUlxJ1sc+RmYtNiGVBnAC6OLjze5HGCLwaz5+Ke4g7tjnZHJQWARxs9ysutXmZN+Bre2/4eZm22edvwuHBG/zUaZwdnfrrnJ6p6VqVPrT5Ep0Sz55J8kYXIixVhK6jgXoGOVTsCMKj+IHzdfJl+UK4WitMdlxQAnjA8wbPNn2XFyRVM2jnJps6tcwnnePKvJ9FofrrnJ/y9/QEI9AvE3cmd1adX2ztsIUqNK6lX2BKxhX61+uHk4ASAu5M7IxqPYFvkNkJjQos5wjvXHZkUAJ4OeJonDU+y+PhiJu+enGNiOJ94njF/jSHNlMb0u6dTu2xt62sezh50q96NdWfWFaifoqTRWpNqTC3uMEQJteb0GozayIC6A657fmiDoXi5eEnfQjG6Y5OCUooXW77IY40eY+6RuUzZMyXbxHAp+RKj/xpNfFo8P979Iw18G9xUpk/NPsSlxbEz6s4YORGXFsdT657i3iX3kpyRXNzhiBJoRdgKGvk2on65+tc97+niyWONHuOfc/9w4uqJYoruznbHJgWwJIYJbSYwpP4Qfj70Mz8c+OG61y+nXGbMX2OITonmu17f0aR8k2zr6VStE14uXnfEKKTTcad5dPWj7Dy/kyupV9gaubW4QxIlzImrJzhy5QgD6w7M9vVHGz2Kh5MHMw7OKOLIBNzhSQEsieGt9m8xsM5Avtv3HTMPzQQsZ8Nj140lKjGKaT2n0bxS81vW4eLoQi//Xvxz7p9S3aSyPXI7j/7xKPFp8fx878/4uvmy/sz64g5LlDArT67ESTnRp1afbF/3cfVhaMOhrA1fy5n4M0UcnbjjkwKAg3Lgg44f0KdmH74K+YqfDv7EU+ueIjwunCk9ptCmcptc6+hTqw9JGUml8sxZa83cw3N55u9nqOxZmQX3LaBN5TZ0r96dTRGbCnWWuCjdjGYjq06uootfF3zdfG9ZbkTjETg7OPPzwZ+LMDoBkhSsHB0cmdRlEj39ezJlzxSOXT3Gf7v91zpcLjdtKrfB18231I1CyjBl8MGOD/h89+d09evK3D5zqeZZDYBeNXqRbEy+Y/pSRMFtj9rO5dTLDKyTfdPRNRXcKzCo3iBWnVxFVGJUEUUnQJLCdZwdnPlP4H8Y2XgkU7pPoWv1rjZv6+TgxD017mFzxGaSMpLsGGXRuZp6lTHrxrDkxBLGNB3D192/xsPZw/p6u8rt8HL2Yv1ZaUIStll5ciVlXcsS6BeYa9nHDY+DwtqkK4qGJIUbODs682qbV2360t6ob+2+pJnS+OfsP3aIrGiduHqCR/54hIPRB/msy2e80PIFHNT1XxdnR2e6Vu/KhnMbMJqNxRSpKCni0uLYcHYDfWr1wdnROdfylctUZmCdgSw7sYzo5OgiiFCAJIVC1axiMyqXqcyf4X8WdygFsvHcRh5b/RhppjSCegfRr3a/W5bt5d+LuLQ4gi8GF2GEoiRaG76WdHP6LUcdZedJw5MYtZFfQn+xY2QiK7smBaVUb6XUMaVUmFLqjWxeH6+UOqyUOqCU+lspVcOe8dibg3Kgd83ebI/cTlxaXHGHkyfppnQORh9k6p6pvPDPC9T0qcmCfgtoWrFpjtt1rNYRdyd3GYUkcrXy5Erqlq1LY9/GNm9T3bs6fWv1ZfHxxVxNvWrH6MQ1dksKSilHYBrQB2gMPKKUuvHbsBdorbUOAH4DJtsrnqLSp1YfjNrIujPrijuUWzKZTRy/epxlJ5bx0Y6PGPr7UNrNb8ew1cOYcXAGvWv2Jqh3EJXLVM61LncndzpX68w/Z//J0zpS4s5yOu40+6P3M6DOAJRSedp2dNPRpBpTmXtkrp2iE1k52bHutkCY1voUgFJqITAQOHytgNZ6Q5byO4HH7BhPkWjk24ga3jX48/SfPFT/oeIOB7CMIFp/dj0HYw4SGhPKkStHSDGmAODp7Enj8o0Z3ng4hvIGDBUMVPWsmqf6e/n3Yt2ZdRyIPpDjfA5x51p1chUOyoH7at+X523rlK1Drxq9mH9kPiObjMTbxdsOEYpr7JkUqgHnsjyOANrlUP5JINspwUqpscBYAH9//8KKzy6UUvSu2ZvpB6YTnRxNRY+KxR0Sn+z6hN+O/4aLgwsNyzfkgboPYKhgoEmFJtT0rnlTB3JeBfoF4uzgzLoz6yQpiJuYtZlVp1bRoWqHfP8exjQdw7oz61h4dCFjA8YWcoQiK3v2KWR3jZjtqnNKqceA1sB/sntdaz1da91aa926YsXiP8jmpk+tPmg0f535K1/bF8ad4a45FXeKpSeWMqT+EHY+upN5fefxZrs36V+nP7V9ahc4IYBlvZr2Vdrz99m/5XaKJVRyRrLd/t/turCLC0kXcp2bkJNG5RsR6BfInMNzZL0tO7NnUogAqmd57AfcNAtFKdULeAsYoLUuFVNj65StQ/1y9fO8FpJZm3ln2zv0+LUHF5IuFEos3+z5Bncnd55r8RzODrkPA8yvu2vcTWRiJEeuHLHbPoR9/Hn6T7ou6srAFQOZd2QeCekJhVr/yrCVeDl70b169wLVM6bpGGLTYnln2zulejmZ4mbPpLAbqKeUqqWUcgEeBlZmLaCUagH8iCUhXLJjLEWuT60+7I/eT2RipE3ltdZ8tPMjloctJz49nsm7C97nvj96P+vPrmdkk5E5LilQGLpV74ajcpRRSCWIWZv5du+3vLb5NeqXq4+Xsxef7fqMnr/25IMdH3D0ytEC7yMpI4n1Z9dzb617cXNyK1BdzSs1Z3yr8aw7s45Rf47iYtLFAscnbma3pKC1NgLjgLXAEWCx1jpUKfWhUuraIur/ATyBX5VS+5RSK29RXYnTu2ZvwHIWlhutNZ/v/pzfjv/G6KajebbZs6w7s47tkdvzvX+tNV+FfIWvmy8jG4/Mdz22KudWjtZ3tZbZzSVEckYyr2x8hR8P/MgDdR8gqHcQ8/rNY+F9C+lTqw+/n/ydwasGM3z1cH4/9TvppvR87eev8L9IMaYUqOkoq8cNjzOl+xROx53mkT8e4VDMoUKptzBdTb3KsD+G8dvx34o7lPzRWpeov1atWumSYtjvw/RDKx/KsYzZbNZfBn+pDUEG/dm/n2mz2azTjGm675K+ut/SfjrNmJavfW86t0kbggx6/pH5+do+P+Yfma8NQQZ98urJItunyLuohCg9aMUgHfBLgJ4dOlubzeabysSmxurZobN1v6X9tCHIoLss6KK/Cv5KRyRE5Glfo9aM0v2W9st2HwVx7Moxfe9v9+pWc1rpP07+Uah1F9Rn/36mDUEGbQgy6KXHlxZ3OFZAsLbhGCszmu2oT60+HL1ylFNxp25Z5vv93zPr0CyG1B/ChDYTUErh4ujCxHYTORN/hqDQoDzv12Q28fWer6nuVZ2H6hXdsNie/j0B5GrBjuLT43l98+t8v+97LiXnvcV136V9PPzHw0QmRjKt5zSGNx6e7bwBH1cfhjcezsr7VzL97um0vKsls0Jn0WdJH0b/NZpv9n7DhrMbclx+IiIhguCLwfSv3T/PcxNyU79cfeb3m4+hgoHXt7zO1D1Tb4t5MlGJUSw6toh+tfvRoUoH3tv+HqtPlaxFMu05JPWOd0/Ne5i8ezJ/nv6TZ5s/e9PrPx/8me/3f8/AOgN5q/1b1/1wOlXrxN017mbGgRn0q93PujKpLVafXs2JqyeYHDjZpjVmCkslj0o0q9iM9WfWy7BBO0jKSOKZ9c8QGhOKWZv58cCP9PDvwcMNHqZN5Ta5HnhXhK3ggx0fUKVMFb6595vrbit7Kw7KgQ5VO9ChagcuJF3gt+O/seHcBn4++DMmbQIs/9+vzXFpUqEJTco3wcfVh1WnVgHQv07/gr/5bPi6+TLj7hlM+ncSMw7O4GTsST7t8ul1izYWtWn7puGgHHip5Uv4uPrw7Ppnmbh1ouWeKzV6FVtceaF0CRtC2Lp1ax0cXHLW2Xli7RNEJ0ez8v6V1/1o5x6ey+e7P6dPrT582vlTHB0cb9r2QtIFBiwfQPsq7ZnaY6pN+0s3pdN/WX98XH1YeN/CQhlymhdBh4L4MuRL1jy4Bj8vvyLd943STemsP7OeS8mXGNxgMGWcyxTp/o1mI3MOz6FdlXY0Lm/70g7ZSTGm8Mz6Z9h3aR9fdvuS+uXq8+vxX1l2YhmxabHU8qnF0AZDGVBnAF4uXtdtazKbmLJnCrNCZ9GuSju+7PolPq4+BY7n6JWjHIo5xKGYQ4ReDr3uhjj+Xv7EpcfRoFwDfr7XvvdE0Foz78g8/hP8H+qWrcs3Pb7J8wTMwnDsyjEGrxrMqCajGN96PGBJ5E+te4rQy6FM6T4lXwttFhalVIjWunWuBW1pY7qd/kpSn4LWWi8+tlgbggz6yOUj1ucWHV2kDUEG/eI/L+p0U3qO2/904CdtCDLoTec22bS/2aGztSHIoLdFbitQ3Pl1Nv6sNgQZdNChoGLZv9ZaRyZE6ikhU3TgwkBr226PxT30uvB1hd62fStGk1FP2DRBG4IMBW73TjWm6tFrR+uAXwL0mlNrbnptRdgKPez3YdoQZNBt5rbR7217z/p9S0hL0M+uf1Ybggz64x0f5/p9K4jY1Fi9PXK7nnFghn7xnxd1v6X9bP7eFoatEVt1h3kddODCQB1yIaTI9nvNs+uf1R3md9CxqbHXPR+XFqeHrBqiW85uqbdHbi/yuK7Bxj4FuVKws6upV+mxuAfDmwxnfKvxrAhbwdvb3ibQL5Cvu32da/NOhimDQasGkWHKYNnAZTkO60tMT6Tv0r408G3AjHuK7/62g1cNxs3RjTl95xTZPs3azI6oHSw8tpDNEZsB6OrXlYcbPIyHswcf7/yYY1eP0dWvKxPbTbTrmaRZm3l/+/ssC1vGmKZj2HNpDyEXQxgbMJbnmj+Xp6u3DFMGL218ic0Rm/m408c5rjAaejmUxccWs/rUalJNqTSr2IyE9ATOxJ/hzbZvMrTh0MJ4e7e103Gnef6f54lMjOStdm8xqN6gQu/PyE7whWAeX/s4L7V8iSebPnnT67GpsTzx1xOciz/H972+p3Xl3E/YC5tcKdxGnl73tL7717v16lOrdcAvAXr02tE61Zhq8/Y7o3ZqQ5BBf7f3uxzLfbPnG20IMuhDMYcKGnKB/LDvB20IMuiLSRftvq+rKVf1rIOzdJ8lfbQhyKADFwbqKSFTdFRC1HXlMkwZOuhQkG4zt41uM7eNnnlwpl3Oms1ms/5ox0faEGTQ3+79VmutdboxXb+37T3r1WFSepJNdaWb0vWL/7yoDUEGvfjYYptjyDpyqNOCTnpn1M58vZeSKjY1Vo9ZO0Ybggx69NrROjwu3K77M5vNetgfw3SPRT10ckbyLcvFJMfo/sv667Zz2+q9F/faNabsYOOVQrEf5PP6VxKTwsqwldZmjBGrR9h8UMjqtY2v6ZazW+qzcWezfT06OVq3mdtGv7rx1YKGW2BhV8O0IcigFxxZYLd9HIo5pCdumahbzm5p/VxXn1qt0405H+ijEqL0uL/HaUOQQT+w4oFC/XGazWY9eddkbQgy6C93f3ldU5XZbNZzQufogF8C9IMrHtSRCZE51mU0GfVrG1/ThiCDnnt4br7jye+Q5pLOaDLqBUcW6Pbz2uuWs1vq7/Z9Z7fPYv2Z9doQZNC/Hfst17IXky7qPkv66A7zOuTp5C0pPUmHXAgp0ImWrUlBmo+KQGJ6Inf/dje1y9Zm+t3T89XheSn5Ev2X9afVXa2Y1nPaTZfEH+/8mCXHl7Di/hX4exf/ooEDlg+gknslfrr3p0KtNzY1lq/2fMXSE0vxcPKgf53+DGkwhPrl6uepnr/P/s2n/37KpeRLPFT/IV5s+WKBO1+n7pnKjIMzGNZwGG+0fSPbZottkdt4bdNrODs683X3r2lRqcVNZczazLvb3mXFyRW3bI4QtolOjraMAAz/k5reNXmn/Tu0rdK20Oo3mo08uPJBAJYOWIqTQ+4DOs8nnmfUn6NIMibx8z0/08C3wXWvZ5gyOB57nNCYUEtH/uVDnIw9iVmbebPtmwxrNCxfsdrafCRJoYhcSr5EWdeyuDi65LuOX0J/4YvgL5jSfQo9/HtYnz8bf5aBywcyqP4g3m7/dmGEW2BT90xl5qGZbBiygXJu5Qpcn9aalSdX8mXwl8SnxzOi8QjGBozF08Uz33UmZSQxbd805h2ZR1nXskxoM4G+tfrmqw36x/0/8u2+bxlUbxDvdXgvxzqytnu/1+E97q97v/U1rTUf7/yYxccX82yzZ3mm+TP5em/ietsit/Hxzo+JSIxgQJ0BvNL6lUJZ+mXpiaW8t/09vur2VZ6GnJ6LP8eotaMwmo182uVTopOjraO4jl05RrrZMoO8rGtZmlRoYh3y26xis3z/niQplEIZ5gyGrBpCckYyy+9fjruTOwCvbXqNTRGbWP3gaiq4VyjmKC1CL4fy8O8P82HHD3mg3gMFqutU3Ck+3vkxuy/splnFZrzT/p2bzq4K4sjlI3y440MOXT5E/XL1GdpgKNjD9e8AABC0SURBVPfVvs/m8e7XknX/2v35uPPHNnUkx6XF8eqmV9l5ficjG4/k5VYv46AcmLx7MnOPzOUJwxO81PKlIukkvVOkGlOZfmA6s0JnUca5DONbjef+uvfne9h2qjGVfsv6UdmjMnP7zs3z/6vTcad5/M/HuZx6GQAPJw8al29sne9hKG+gmme1QvsOSEdzKRV8IVgbggx6SsgUrbWlbd0QZNBT90wt5siuZzab9T2/3qOfXf9svutINabqb/Z8o1vMbqE7zO+gFx9brE1mUyFG+X9Gk1EvPb5UP7TyIW0IMuh289rpSTsn6bCrYTlud21pj1c2vqIzTBl52meGKUN/svMTbQgy6GfWPWPtj/j030+LbOjsnSjsapgesXqEtS/qxJUT+arn54M/a0OQQe86vyvfsUQlROk/Tv6hw66GaaPJmO96bIH0KZReE7dM5M/wP1k6YCmT/p3E0StHWfPgmgI1pdjD5N2TWXh0IZuHbs5zbDv+1969R0dZ3gkc//4SAsFwJ1yScBOX+y1cQqEqi4uA13VZQVAX2LNadRdqbY8rbEtZatlKdaGl7dEeraytB5WbIt1SlJ7VqhQwkHCn3ORiCLcQCQQSJMxv/3jeTCYhl8llGGbm9zknZ+a9zDvPb57M+3uf533neXM3Mn/TfI5dOMa93e/l2WHPXpdWkKqyI28Hy/66jHVH1nHFd4VhHYYxufdkxnQeU+4S4lX7VzFv4zzu6HwHC0cvrPPQ5Mv3LeeFzS9QoiVM6jmJH474obUQQsynPt4/+D4Lty7k4tcXmd5vOk8OetLf+q5JweUC7n73btLbpfPynS+HuLQNw7qPolheUR73v3c/bRLbcOzCMZ7LeI6pfaeGu1jXyD6dzbQ/TuOnt/+Ue7rfE9Rr8oryeCnzJdYeXkuX5l2YM2IOI1NHhriklcsvzmf1wdUs37ec44XHSW6azIM9HmRiz4lknszkB5/9gG+mfZNf3PGLep0rAsg6lcXOvJ1M7Tv1uv8KPZblF+ezcMtC1hxaQ1qzNOaMmMNtabfV+LpFWxfxxq43WHH/igbtygwlSwpRbunepSz4fAGpSan8fsLv671TCgWf+hizYgyD2w9m0ehFla5T4ivh0LlD7D7rrrRYd2QdxSXFPDbgMR4f8DhN4ptc51Jf66rvKhtyN7Bs3zI+zfmUOIlDUTI6ZPCrMb+q930CTPhlnszk+Y3Pc+T8EcZ3G8+sjFlV3jr05MWT3PfefYzrOo6f3P6T61zSugs2KdiAeBFqcq/JHC44zNiuY2/IhABuMLUxXcaw5tAaikqKSIxP5NiFY+XGy9l7di/FV91dtJolNCOjYwbPDH2G7i1rHqzteomPi2dUp1GM6jSKnAs5rNi/gjOXzjBnxBxLCFEio2MGq/5+FUt2LeG1Ha+x4fgGnh7yNA/1fOiaccle2f4KPvUxY/CMMJU2tKylYEJqY+5Gnlj/BH3a9CGnMMd/q8cm8U3o06ZPuSsturToYl0nJuyOnj/K/E3z2XRiE/3b9mfuyLn0adsHgC/OfcGENRN4pPcjzBo+K8wlrR1rKZgbwrCOw+jftj9X9Srju433X299S6tbgvqhjzHXW9cWXXl17KusPbyWFzNfZMofpvBon0eZmT6TxVmLadqoKd8a+K1wFzNkrKVgjDFVKLhcwOKsxazYv4LkpsnkFeUxI30GTw16KtxFq7VgWwrWVjfGmCq0bNKSuSPn8ubdb9I6sTUpSSlM6zst3MUKKWu/G2NMDdLbp7Py/pVc8V25Ia6ICyVrKRhjTBDiJC7qEwJYUjDGGBPAkoIxxhg/SwrGGGP8LCkYY4zxs6RgjDHGz5KCMcYYP0sKxhhj/CwpGGOM8bOkYIwxxs+Swo2m4Dgc2wwRNlChMSY62NhHNwKfDw7/GTJ/A/v+CHoVut8B9y6EtreEu3TGmBhiSaEiVTh3DJq2gsSWoX2voq9g21uQ+TrkH4Kb2sKtT8NNyfDxAnh5JIz6dzevUYSOueLzQcExF1uT5uEujamMzwcFX0KLVIhPCHdpTJhZUjifC8ezIDfLe8yG4nNuWdsekDYEUoe4x44DIKFp/d8zN9u1CnaugpIi6PwNGD0b+j5QtvPv/yCsmw0fzYedy+G+n0G3mm8oHlaqcP54hc9zG1wuAASSe5b/PDv0hwS7neV1peoSQGAdndgOl89D8xQYMh2GTncJwsSk2LrJzqV874uQXfaFKDzplkk8dOjrdlgpgwLWDVgnrhG071O2U0sdAu16u/k1KSmGPatdMji+FRJugoEPwbDHIGVg1a87sB7+8D3Xekl/FMb+GJLa1j52n6/2r6lJUb5LcIE7mIun3bK4RtChn/d5DoTCM9WvkzYEUgdDuz4Q38DHKrWJPa6BT7Ophvf80KWzAQnae7yU55bFJUDH/mX/xwc+hIN/AomD3vdCxuNw8ygQCV/5TYMJ9iY7IU0KInIXsBiIB36jqgsqLG8C/A4YCpwFJqvqkeq2Week8NnP4E/zyqZr0wq4pjWRBcUFtS8DuKPljMdh0JTgu6e+vgSfvAh/+SU0aQHjfuwSRFVf1ssX3BF6YOvn3NG6lTcoAsk9yifLjgMqbwVU25oAGjV1STmwbtp0D37HVHweTmwL2H62674KVquu5d87ZVDw3V4+n+sGDIzt5A53QBB24nb8pcm3tKVWsVsy/wvY8j+Q/abr3gz2/9Xng7MHysd+ajc073jt59k4KbShmkqFPSmISDywHxgL5ACZwMOquidgnX8DBqrqUyIyBZigqpOr226dk0LOFjjyqfvnTE2v3/kCVfflyc12j8F8hiKum6g+R16n9sD/fhe+3ARdb3VdSq27wcld5RPWmX2AV6aWXSBtMCT3Cq5FUxuNb3Jf8pR0SGxR9+3UtDNNbOl2ZIFJp0UqlFyGU7vc+se3utfmHcAfe+kOPrmnawnWWI4SyNtXIZEItOtV9t6lO9P4xlCQU/5zz91eltwSvM8mdTAktqr7Z1NfTZq5+kkZ5J4H60oR7C5t2W4p37LtOKDqLiiAhCT3fh0HuAOA3Gz3CK4V0q6393l6ddqhPzRq3PCxm3JuhKQwEpinquO96f8AUNUXAtb5wFtno4g0Ak4C7bSaQsX8PZp9PncUt34ufF0ICPiuuGVJ7crvONOGQFJyWItbZ1evwOm95Xe6p/a4K7PAnYwvPud25ABJ7SFtaFnsqYPr1s1WqvCM25kFvv/FM25ZXIJLgpfOlk136Ff+c0/u1fDdYOGSm+0uhti50p0DS2xZ1lIO7ILyd6n2grgKSfjCqWu7sYry3bL4xu7gRuwK+Rr97XPufGMd3AhJYSJwl6o+7k1PBb6hqjMD1tnlrZPjTR/y1smrsK0ngCcAunTpMvTo0VB2hUSIwjOw4efu6L/0y9iyU3T3/14pKmsVndgBzQKSYIu00MauGtAy2OoSQkq6d6TbLzZOmBd9BdvehjN7oePAqrugglF6lV9pgghp92YUGTId/mZMnV56IySFScD4CklhuKp+O2Cd3d46gUlhuKqerWq7Md9SMMaYOgg2KYSyvZYDdA6Y7gTkVrWO133UEsgPYZmMMcZUI5RJIRPoISI3i0hjYAqwpsI6a4Dp3vOJwP9Vdz7BGGNMaIXsTJiqlojITOAD3CWpS1R1t4g8D2xR1TXA68CbInIQ10KYEqryGGOMqVlIL49Q1bXA2grz5gY8LwYmhbIMxhhjgmfXgBljjPGzpGCMMcbPkoIxxhg/SwrGGGP8Im6UVBE5A9T154/JQF6Na0WWaIsp2uKB6Isp2uKB6Iupsni6qmq7ml4YcUmhPkRkSzC/6Isk0RZTtMUD0RdTtMUD0RdTfeKx7iNjjDF+lhSMMcb4xVpSeDXcBQiBaIsp2uKB6Isp2uKB6IupzvHE1DkFY4wx1Yu1loIxxphqWFIwxhjjFzNJQUTuEpF9InJQRGaHuzz1JSJHRGSniGwTkYi865CILBGR094d+ErntRGR9SJywHtsHc4y1kYV8cwTkeNePW0TkXvCWcbaEpHOIvKRiOwVkd0i8h1vfkTWUzXxRGw9iUiiiHwuItu9mH7kzb9ZRDZ7dbTMu4VBzduLhXMKIhIP7AfG4m7skwk8rKp7wlqwehCRI8CwircujSQiMgooBH6nqv29eS8C+aq6wEverVV1VjjLGawq4pkHFKrqf4ezbHUlIilAiqpmiUhzYCvwD8A/E4H1VE08DxGh9SQiAiSpaqGIJACfAd8Bvge8q6rviMivge2q+kpN24uVlsJw4KCqfqGqXwPvAA+EuUwxT1U/4do77T0A/NZ7/lvcFzYiVBFPRFPVE6qa5T2/AOwF0ojQeqomnoilTqE3meD9KfB3wEpvftB1FCtJIQ34MmA6hwj/R8BV+ocislVEngh3YRpQB1U9Ae4LDLQPc3kawkwR2eF1L0VEN0tlRKQbMBjYTBTUU4V4IILrSUTiRWQbcBpYDxwCzqlqibdK0Pu8WEkKUsm8SO83u1VVhwB3AzO8rgtz43kFuAVIB04AC8NbnLoRkWbAKuAZVT0f7vLUVyXxRHQ9qepVVU0HOuF6RvpUtlow24qVpJADdA6Y7gTkhqksDUJVc73H08B7uH+EaHDK6/ct7f89Heby1IuqnvK+sD7gNSKwnrx+6lXAUlV915sdsfVUWTzRUE8AqnoO+BgYAbQSkdK7awa9z4uVpJAJ9PDOxjfG3Qt6TZjLVGcikuSdJENEkoBxwK7qXxUx1gDTvefTgffDWJZ6K91xeiYQYfXkncR8HdirqosCFkVkPVUVTyTXk4i0E5FW3vOmwJ24cyUfARO91YKuo5i4+gjAu8Ts50A8sERV/yvMRaozEemOax2Au8/2W5EYj4i8DYzGDfN7CvhPYDWwHOgCHAMmqWpEnLytIp7RuC4JBY4AT5b2xUcCEbkN+BTYCfi82d/H9cNHXD1VE8/DRGg9ichA3InkeNyB/nJVfd7bT7wDtAGygX9S1cs1bi9WkoIxxpiaxUr3kTHGmCBYUjDGGONnScEYY4yfJQVjjDF+lhSMMcb4WVIwMUtE/uI9dhORRxp429+v7L2MudHZJakm5onIaOBZVb2vFq+JV9Wr1SwvVNVmDVE+Y64naymYmCUipSNLLgBu98bR/643uNhLIpLpDZD2pLf+aG8s/rdwP35CRFZ7gxLuLh2YUEQWAE297S0NfC9xXhKRXeLuhzE5YNsfi8hKEfmriCz1fn1rzHXVqOZVjIl6swloKXg79wJVzRCRJsAGEfnQW3c40F9VD3vT/6Kq+d7wApkiskpVZ4vITG+Asor+EffL2UG4Xz5nisgn3rLBQD/cGDUbgFtxY+Mbc91YS8GYa40DpnlDEW8G2gI9vGWfByQEgKdFZDuwCTfoYg+qdxvwtjf42ingz0BGwLZzvEHZtgHdGiQaY2rBWgrGXEuAb6vqB+VmunMPFytM3wmMVNVLIvIxkBjEtqsSOC7NVez7acLAWgrGwAWgecD0B8C/ekMsIyI9vdFoK2oJfOUlhN644YpLXSl9fQWfAJO98xbtgFHA5w0ShTENwI5EjIEdQInXDfQGsBjXdZPlnew9Q+W3MlwHPCUiO4B9uC6kUq8CO0QkS1UfDZj/HjAS2I4bkfM5VT3pJRVjws4uSTXGGONn3UfGGGP8LCkYY4zxs6RgjDHGz5KCMcYYP0sKxhhj/CwpGGOM8bOkYIwxxu//ARsGaMkP8YF/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - c_puct 0.1\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "losses_4 = np.ones(30) - wins_4 - draws_4\n",
    "\n",
    "plt.plot(x, wins_4, label=\"win ratio\")\n",
    "plt.plot(x, draws_4, label=\"draw ratio\")\n",
    "plt.plot(x, losses_4, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "exploration_rate_4 = unique_trajectories_4/seen_trajectories_4\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - c_puct 0.1\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "\n",
    "plt.plot(x, exploration_rate_4, label=\"unique/seen\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins_4 = [0.71, 0.75, 0.71, 0.85, 0.78, 0.89, 0.79, 0.78, 0.74, 0.88, 0.88, 0.86, 0.83, 0.86, 0.89, 0.83, 0.87, 0.82, 0.84, 0.79, 0.83, 0.83, 0.71, 0.81, 0.85, 0.88, 0.91, 0.82, 0.87, 0.86]\n",
      "draws_4 = [0.01, 0.02, 0.01, 0.01, 0.03, 0.0, 0.01, 0.01, 0.01, 0.02, 0.01, 0.0, 0.01, 0.01, 0.0, 0.01, 0.01, 0.01, 0.01, 0.02, 0.0, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "losses_4 = [0.28 0.23 0.28 0.14 0.19 0.11 0.2  0.21 0.25 0.1  0.11 0.14 0.16 0.13\n",
      " 0.11 0.16 0.12 0.17 0.15 0.19 0.17 0.16 0.29 0.19 0.15 0.12 0.09 0.18\n",
      " 0.13 0.14]\n",
      "seen_trajectories_4 = [ 100.  200.  300.  400.  500.  600.  700.  800.  900. 1000. 1100. 1200.\n",
      " 1300. 1400. 1500. 1600. 1700. 1800. 1900. 2000. 2100. 2200. 2300. 2400.\n",
      " 2500. 2600. 2700. 2800. 2900. 3000.]\n",
      "unique_trajectories_4 = [  99.  194.  290.  380.  468.  556.  633.  710.  797.  872.  956. 1037.\n",
      " 1113. 1197. 1279. 1351. 1422. 1496. 1573. 1641. 1707. 1775. 1849. 1932.\n",
      " 2005. 2074. 2136. 2205. 2258. 2318.]\n"
     ]
    }
   ],
   "source": [
    "print(\"wins_4 =\", wins_4)\n",
    "print(\"draws_4 =\", draws_4)\n",
    "print(\"losses_4 =\", losses_4)\n",
    "print(\"seen_trajectories_4 =\", seen_trajectories_4)\n",
    "print(\"unique_trajectories_4 =\", unique_trajectories_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $c_{puct}$ = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCTS = {\n",
    "    'c_puct': 5,\n",
    "    'dir_alpha': 0.6,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 10,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 10\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 0,\n",
    "    'show_games': False\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.002,\n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 512,\n",
    "    'num_filters_value': 512,\n",
    "    'num_filters_tower': 512,\n",
    "    'num_residual_blocks': 3,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 512\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"tictactoe_c_puct_5\", \"TicTacToe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 4s 937us/step - loss: 6.6513 - value_loss: 0.8839 - policy_loss: 2.3341 - val_loss: 6.5295 - val_value_loss: 0.7540 - val_policy_loss: 2.2207\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.4829 - value_loss: 0.7229 - policy_loss: 2.1589 - val_loss: 6.4892 - val_value_loss: 0.7787 - val_policy_loss: 2.1159\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.4158 - value_loss: 0.6802 - policy_loss: 2.0680 - val_loss: 6.4323 - val_value_loss: 0.7363 - val_policy_loss: 2.0453\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.3540 - value_loss: 0.6211 - policy_loss: 2.0041 - val_loss: 6.3896 - val_value_loss: 0.7046 - val_policy_loss: 1.9923\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.3179 - value_loss: 0.5981 - policy_loss: 1.9556 - val_loss: 6.3703 - val_value_loss: 0.7067 - val_policy_loss: 1.9523\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2787 - value_loss: 0.5579 - policy_loss: 1.9180 - val_loss: 6.3260 - val_value_loss: 0.6504 - val_policy_loss: 1.9204\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2528 - value_loss: 0.5365 - policy_loss: 1.8884 - val_loss: 6.3138 - val_value_loss: 0.6539 - val_policy_loss: 1.8933\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2233 - value_loss: 0.5024 - policy_loss: 1.8641 - val_loss: 6.2967 - val_value_loss: 0.6410 - val_policy_loss: 1.8725\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2210 - value_loss: 0.5179 - policy_loss: 1.8444 - val_loss: 6.2803 - val_value_loss: 0.6266 - val_policy_loss: 1.8548\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1953 - value_loss: 0.4847 - policy_loss: 1.8270 - val_loss: 6.2876 - val_value_loss: 0.6576 - val_policy_loss: 1.8391\n",
      "Saved model  tictactoe_c_puct_5_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.73 - draw ratio 0.01\n",
      "Number of seen trajectories: 100\n",
      "Number of unique trajectories: 100\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.3282 - value_loss: 0.7146 - policy_loss: 1.8634 - val_loss: 6.2602 - val_value_loss: 0.5993 - val_policy_loss: 1.8431\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2796 - value_loss: 0.6412 - policy_loss: 1.8402 - val_loss: 6.2674 - val_value_loss: 0.6304 - val_policy_loss: 1.8272\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2455 - value_loss: 0.5919 - policy_loss: 1.8221 - val_loss: 6.2431 - val_value_loss: 0.5959 - val_policy_loss: 1.8136\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2132 - value_loss: 0.5444 - policy_loss: 1.8058 - val_loss: 6.2354 - val_value_loss: 0.5925 - val_policy_loss: 1.8023\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2105 - value_loss: 0.5526 - policy_loss: 1.7926 - val_loss: 6.2181 - val_value_loss: 0.5673 - val_policy_loss: 1.7936\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1949 - value_loss: 0.5329 - policy_loss: 1.7817 - val_loss: 6.2164 - val_value_loss: 0.5724 - val_policy_loss: 1.7858\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1884 - value_loss: 0.5292 - policy_loss: 1.7732 - val_loss: 6.2216 - val_value_loss: 0.5909 - val_policy_loss: 1.7782\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1611 - value_loss: 0.4841 - policy_loss: 1.7643 - val_loss: 6.2177 - val_value_loss: 0.5910 - val_policy_loss: 1.7708\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1610 - value_loss: 0.4925 - policy_loss: 1.7563 - val_loss: 6.2037 - val_value_loss: 0.5691 - val_policy_loss: 1.7656\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1450 - value_loss: 0.4680 - policy_loss: 1.7495 - val_loss: 6.2224 - val_value_loss: 0.6127 - val_policy_loss: 1.7600\n",
      "Saved model  tictactoe_c_puct_5_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.03\n",
      "Number of seen trajectories: 200\n",
      "Number of unique trajectories: 199\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.3056 - value_loss: 0.7590 - policy_loss: 1.7802 - val_loss: 6.3033 - val_value_loss: 0.7309 - val_policy_loss: 1.8043\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.2607 - value_loss: 0.6808 - policy_loss: 1.7695 - val_loss: 6.2961 - val_value_loss: 0.7232 - val_policy_loss: 1.7980\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2329 - value_loss: 0.6326 - policy_loss: 1.7627 - val_loss: 6.2910 - val_value_loss: 0.7182 - val_policy_loss: 1.7935\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2142 - value_loss: 0.6036 - policy_loss: 1.7549 - val_loss: 6.2811 - val_value_loss: 0.7033 - val_policy_loss: 1.7893\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1992 - value_loss: 0.5796 - policy_loss: 1.7495 - val_loss: 6.2769 - val_value_loss: 0.6987 - val_policy_loss: 1.7861\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2008 - value_loss: 0.5879 - policy_loss: 1.7450 - val_loss: 6.2716 - val_value_loss: 0.6921 - val_policy_loss: 1.7828\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1846 - value_loss: 0.5609 - policy_loss: 1.7403 - val_loss: 6.2639 - val_value_loss: 0.6818 - val_policy_loss: 1.7784\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1675 - value_loss: 0.5319 - policy_loss: 1.7356 - val_loss: 6.2759 - val_value_loss: 0.7091 - val_policy_loss: 1.7758\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1629 - value_loss: 0.5266 - policy_loss: 1.7324 - val_loss: 6.2589 - val_value_loss: 0.6791 - val_policy_loss: 1.7724\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1561 - value_loss: 0.5177 - policy_loss: 1.7284 - val_loss: 6.2537 - val_value_loss: 0.6716 - val_policy_loss: 1.7700\n",
      "Saved model  tictactoe_c_puct_5_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.02\n",
      "Number of seen trajectories: 300\n",
      "Number of unique trajectories: 296\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2849 - value_loss: 0.7736 - policy_loss: 1.7308 - val_loss: 6.2992 - val_value_loss: 0.7871 - val_policy_loss: 1.7462\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2467 - value_loss: 0.7045 - policy_loss: 1.7242 - val_loss: 6.2897 - val_value_loss: 0.7727 - val_policy_loss: 1.7423\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2147 - value_loss: 0.6466 - policy_loss: 1.7186 - val_loss: 6.2734 - val_value_loss: 0.7437 - val_policy_loss: 1.7393\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2004 - value_loss: 0.6239 - policy_loss: 1.7132 - val_loss: 6.2660 - val_value_loss: 0.7321 - val_policy_loss: 1.7368\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1868 - value_loss: 0.6013 - policy_loss: 1.7093 - val_loss: 6.2607 - val_value_loss: 0.7235 - val_policy_loss: 1.7353\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1645 - value_loss: 0.5606 - policy_loss: 1.7062 - val_loss: 6.2631 - val_value_loss: 0.7317 - val_policy_loss: 1.7325\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1675 - value_loss: 0.5705 - policy_loss: 1.7028 - val_loss: 6.2554 - val_value_loss: 0.7193 - val_policy_loss: 1.7303\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1522 - value_loss: 0.5437 - policy_loss: 1.6996 - val_loss: 6.2577 - val_value_loss: 0.7259 - val_policy_loss: 1.7288\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1396 - value_loss: 0.5214 - policy_loss: 1.6975 - val_loss: 6.2561 - val_value_loss: 0.7260 - val_policy_loss: 1.7262\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1383 - value_loss: 0.5216 - policy_loss: 1.6953 - val_loss: 6.2573 - val_value_loss: 0.7304 - val_policy_loss: 1.7247\n",
      "Saved model  tictactoe_c_puct_5_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.89 - draw ratio 0.0\n",
      "Number of seen trajectories: 400\n",
      "Number of unique trajectories: 393\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.2442 - value_loss: 0.7040 - policy_loss: 1.7253 - val_loss: 6.2103 - val_value_loss: 0.6439 - val_policy_loss: 1.7179\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2017 - value_loss: 0.6250 - policy_loss: 1.7199 - val_loss: 6.1999 - val_value_loss: 0.6269 - val_policy_loss: 1.7148\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1874 - value_loss: 0.6012 - policy_loss: 1.7158 - val_loss: 6.2044 - val_value_loss: 0.6382 - val_policy_loss: 1.7131\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1729 - value_loss: 0.5761 - policy_loss: 1.7126 - val_loss: 6.1982 - val_value_loss: 0.6284 - val_policy_loss: 1.7112\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1606 - value_loss: 0.5547 - policy_loss: 1.7099 - val_loss: 6.1884 - val_value_loss: 0.6109 - val_policy_loss: 1.7098\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1519 - value_loss: 0.5406 - policy_loss: 1.7073 - val_loss: 6.1921 - val_value_loss: 0.6205 - val_policy_loss: 1.7082\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1428 - value_loss: 0.5253 - policy_loss: 1.7049 - val_loss: 6.1947 - val_value_loss: 0.6276 - val_policy_loss: 1.7069\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1380 - value_loss: 0.5180 - policy_loss: 1.7033 - val_loss: 6.1982 - val_value_loss: 0.6371 - val_policy_loss: 1.7049\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1341 - value_loss: 0.5131 - policy_loss: 1.7011 - val_loss: 6.1853 - val_value_loss: 0.6132 - val_policy_loss: 1.7038\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1265 - value_loss: 0.5011 - policy_loss: 1.6985 - val_loss: 6.1840 - val_value_loss: 0.6124 - val_policy_loss: 1.7027\n",
      "Saved model  tictactoe_c_puct_5_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.05\n",
      "Number of seen trajectories: 500\n",
      "Number of unique trajectories: 491\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1905 - value_loss: 0.6264 - policy_loss: 1.7018 - val_loss: 6.1776 - val_value_loss: 0.5987 - val_policy_loss: 1.7039\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1693 - value_loss: 0.5870 - policy_loss: 1.6991 - val_loss: 6.1667 - val_value_loss: 0.5784 - val_policy_loss: 1.7026\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1534 - value_loss: 0.5569 - policy_loss: 1.6977 - val_loss: 6.1611 - val_value_loss: 0.5685 - val_policy_loss: 1.7016\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1414 - value_loss: 0.5358 - policy_loss: 1.6951 - val_loss: 6.1602 - val_value_loss: 0.5680 - val_policy_loss: 1.7006\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1339 - value_loss: 0.5234 - policy_loss: 1.6928 - val_loss: 6.1533 - val_value_loss: 0.5554 - val_policy_loss: 1.6998\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1250 - value_loss: 0.5068 - policy_loss: 1.6920 - val_loss: 6.1524 - val_value_loss: 0.5547 - val_policy_loss: 1.6991\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1188 - value_loss: 0.4964 - policy_loss: 1.6902 - val_loss: 6.1503 - val_value_loss: 0.5514 - val_policy_loss: 1.6984\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1131 - value_loss: 0.4865 - policy_loss: 1.6891 - val_loss: 6.1480 - val_value_loss: 0.5477 - val_policy_loss: 1.6980\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1081 - value_loss: 0.4777 - policy_loss: 1.6882 - val_loss: 6.1463 - val_value_loss: 0.5453 - val_policy_loss: 1.6972\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1019 - value_loss: 0.4677 - policy_loss: 1.6862 - val_loss: 6.1441 - val_value_loss: 0.5416 - val_policy_loss: 1.6967\n",
      "Saved model  tictactoe_c_puct_5_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.01\n",
      "Number of seen trajectories: 600\n",
      "Number of unique trajectories: 583\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2012 - value_loss: 0.6497 - policy_loss: 1.7031 - val_loss: 6.1885 - val_value_loss: 0.6139 - val_policy_loss: 1.7136\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1786 - value_loss: 0.6076 - policy_loss: 1.7004 - val_loss: 6.1819 - val_value_loss: 0.6019 - val_policy_loss: 1.7128\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1604 - value_loss: 0.5738 - policy_loss: 1.6981 - val_loss: 6.1783 - val_value_loss: 0.5960 - val_policy_loss: 1.7118\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1461 - value_loss: 0.5477 - policy_loss: 1.6958 - val_loss: 6.1748 - val_value_loss: 0.5900 - val_policy_loss: 1.7110\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1367 - value_loss: 0.5303 - policy_loss: 1.6947 - val_loss: 6.1718 - val_value_loss: 0.5850 - val_policy_loss: 1.7105\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1279 - value_loss: 0.5150 - policy_loss: 1.6928 - val_loss: 6.1695 - val_value_loss: 0.5815 - val_policy_loss: 1.7097\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1209 - value_loss: 0.5023 - policy_loss: 1.6917 - val_loss: 6.1683 - val_value_loss: 0.5800 - val_policy_loss: 1.7091\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1156 - value_loss: 0.4927 - policy_loss: 1.6910 - val_loss: 6.1659 - val_value_loss: 0.5760 - val_policy_loss: 1.7087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1103 - value_loss: 0.4836 - policy_loss: 1.6899 - val_loss: 6.1652 - val_value_loss: 0.5752 - val_policy_loss: 1.7083\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1077 - value_loss: 0.4798 - policy_loss: 1.6887 - val_loss: 6.1639 - val_value_loss: 0.5737 - val_policy_loss: 1.7075\n",
      "Saved model  tictactoe_c_puct_5_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.02\n",
      "Number of seen trajectories: 700\n",
      "Number of unique trajectories: 675\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2412 - value_loss: 0.7406 - policy_loss: 1.6954 - val_loss: 6.2567 - val_value_loss: 0.7508 - val_policy_loss: 1.7164\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2200 - value_loss: 0.7006 - policy_loss: 1.6933 - val_loss: 6.2491 - val_value_loss: 0.7369 - val_policy_loss: 1.7154\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2032 - value_loss: 0.6689 - policy_loss: 1.6916 - val_loss: 6.2448 - val_value_loss: 0.7294 - val_policy_loss: 1.7145\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1922 - value_loss: 0.6487 - policy_loss: 1.6902 - val_loss: 6.2424 - val_value_loss: 0.7258 - val_policy_loss: 1.7137\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1822 - value_loss: 0.6303 - policy_loss: 1.6889 - val_loss: 6.2404 - val_value_loss: 0.7227 - val_policy_loss: 1.7131\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1750 - value_loss: 0.6168 - policy_loss: 1.6884 - val_loss: 6.2421 - val_value_loss: 0.7272 - val_policy_loss: 1.7124\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1687 - value_loss: 0.6055 - policy_loss: 1.6873 - val_loss: 6.2390 - val_value_loss: 0.7219 - val_policy_loss: 1.7118\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1613 - value_loss: 0.5918 - policy_loss: 1.6865 - val_loss: 6.2382 - val_value_loss: 0.7210 - val_policy_loss: 1.7113\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1572 - value_loss: 0.5853 - policy_loss: 1.6853 - val_loss: 6.2375 - val_value_loss: 0.7206 - val_policy_loss: 1.7107\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1543 - value_loss: 0.5800 - policy_loss: 1.6851 - val_loss: 6.2400 - val_value_loss: 0.7264 - val_policy_loss: 1.7102\n",
      "Saved model  tictactoe_c_puct_5_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.0\n",
      "Number of seen trajectories: 800\n",
      "Number of unique trajectories: 765\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.2575 - value_loss: 0.7589 - policy_loss: 1.7129 - val_loss: 6.2326 - val_value_loss: 0.7167 - val_policy_loss: 1.7055\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.2277 - value_loss: 0.7006 - policy_loss: 1.7119 - val_loss: 6.2239 - val_value_loss: 0.7005 - val_policy_loss: 1.7045\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2117 - value_loss: 0.6700 - policy_loss: 1.7107 - val_loss: 6.2202 - val_value_loss: 0.6943 - val_policy_loss: 1.7036\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1984 - value_loss: 0.6452 - policy_loss: 1.7093 - val_loss: 6.2218 - val_value_loss: 0.6985 - val_policy_loss: 1.7031\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1884 - value_loss: 0.6269 - policy_loss: 1.7080 - val_loss: 6.2187 - val_value_loss: 0.6931 - val_policy_loss: 1.7025\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1827 - value_loss: 0.6168 - policy_loss: 1.7070 - val_loss: 6.2156 - val_value_loss: 0.6879 - val_policy_loss: 1.7019\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1752 - value_loss: 0.6021 - policy_loss: 1.7069 - val_loss: 6.2149 - val_value_loss: 0.6873 - val_policy_loss: 1.7013\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1715 - value_loss: 0.5965 - policy_loss: 1.7054 - val_loss: 6.2166 - val_value_loss: 0.6916 - val_policy_loss: 1.7009\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1644 - value_loss: 0.5838 - policy_loss: 1.7043 - val_loss: 6.2161 - val_value_loss: 0.6913 - val_policy_loss: 1.7004\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1614 - value_loss: 0.5786 - policy_loss: 1.7037 - val_loss: 6.2141 - val_value_loss: 0.6880 - val_policy_loss: 1.7000\n",
      "Saved model  tictactoe_c_puct_5_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.0\n",
      "Number of seen trajectories: 900\n",
      "Number of unique trajectories: 861\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2131 - value_loss: 0.6723 - policy_loss: 1.7137 - val_loss: 6.1992 - val_value_loss: 0.6800 - val_policy_loss: 1.6785\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1911 - value_loss: 0.6297 - policy_loss: 1.7126 - val_loss: 6.1922 - val_value_loss: 0.6668 - val_policy_loss: 1.6781\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1781 - value_loss: 0.6056 - policy_loss: 1.7112 - val_loss: 6.1881 - val_value_loss: 0.6594 - val_policy_loss: 1.6776\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1650 - value_loss: 0.5809 - policy_loss: 1.7100 - val_loss: 6.1856 - val_value_loss: 0.6552 - val_policy_loss: 1.6771\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1582 - value_loss: 0.5684 - policy_loss: 1.7093 - val_loss: 6.1815 - val_value_loss: 0.6479 - val_policy_loss: 1.6765\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1527 - value_loss: 0.5579 - policy_loss: 1.7090 - val_loss: 6.1846 - val_value_loss: 0.6551 - val_policy_loss: 1.6759\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1465 - value_loss: 0.5473 - policy_loss: 1.7076 - val_loss: 6.1810 - val_value_loss: 0.6487 - val_policy_loss: 1.6753\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1428 - value_loss: 0.5405 - policy_loss: 1.7072 - val_loss: 6.1803 - val_value_loss: 0.6481 - val_policy_loss: 1.6748\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1384 - value_loss: 0.5331 - policy_loss: 1.7062 - val_loss: 6.1792 - val_value_loss: 0.6466 - val_policy_loss: 1.6744\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1359 - value_loss: 0.5290 - policy_loss: 1.7055 - val_loss: 6.1817 - val_value_loss: 0.6525 - val_policy_loss: 1.6739\n",
      "Saved model  tictactoe_c_puct_5_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.0\n",
      "Number of seen trajectories: 1000\n",
      "Number of unique trajectories: 956\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1943 - value_loss: 0.6614 - policy_loss: 1.6902 - val_loss: 6.1939 - val_value_loss: 0.6635 - val_policy_loss: 1.6874\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1798 - value_loss: 0.6332 - policy_loss: 1.6896 - val_loss: 6.1902 - val_value_loss: 0.6568 - val_policy_loss: 1.6869\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1701 - value_loss: 0.6149 - policy_loss: 1.6888 - val_loss: 6.1853 - val_value_loss: 0.6475 - val_policy_loss: 1.6865\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1623 - value_loss: 0.6001 - policy_loss: 1.6879 - val_loss: 6.1827 - val_value_loss: 0.6428 - val_policy_loss: 1.6861\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1549 - value_loss: 0.5861 - policy_loss: 1.6875 - val_loss: 6.1808 - val_value_loss: 0.6396 - val_policy_loss: 1.6859\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1510 - value_loss: 0.5791 - policy_loss: 1.6868 - val_loss: 6.1789 - val_value_loss: 0.6362 - val_policy_loss: 1.6856\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1454 - value_loss: 0.5688 - policy_loss: 1.6860 - val_loss: 6.1778 - val_value_loss: 0.6344 - val_policy_loss: 1.6854\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 170us/step - loss: 6.1433 - value_loss: 0.5650 - policy_loss: 1.6858 - val_loss: 6.1766 - val_value_loss: 0.6325 - val_policy_loss: 1.6850\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1397 - value_loss: 0.5583 - policy_loss: 1.6855 - val_loss: 6.1767 - val_value_loss: 0.6331 - val_policy_loss: 1.6847\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1365 - value_loss: 0.5523 - policy_loss: 1.6853 - val_loss: 6.1752 - val_value_loss: 0.6306 - val_policy_loss: 1.6844\n",
      "Saved model  tictactoe_c_puct_5_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.81 - draw ratio 0.01\n",
      "Number of seen trajectories: 1100\n",
      "Number of unique trajectories: 1049\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1687 - value_loss: 0.6156 - policy_loss: 1.6865 - val_loss: 6.1575 - val_value_loss: 0.6007 - val_policy_loss: 1.6790\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1526 - value_loss: 0.5848 - policy_loss: 1.6852 - val_loss: 6.1518 - val_value_loss: 0.5898 - val_policy_loss: 1.6787\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1422 - value_loss: 0.5650 - policy_loss: 1.6844 - val_loss: 6.1486 - val_value_loss: 0.5839 - val_policy_loss: 1.6784\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1351 - value_loss: 0.5511 - policy_loss: 1.6843 - val_loss: 6.1456 - val_value_loss: 0.5782 - val_policy_loss: 1.6781\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1296 - value_loss: 0.5406 - policy_loss: 1.6838 - val_loss: 6.1438 - val_value_loss: 0.5750 - val_policy_loss: 1.6779\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1226 - value_loss: 0.5279 - policy_loss: 1.6828 - val_loss: 6.1415 - val_value_loss: 0.5707 - val_policy_loss: 1.6778\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1173 - value_loss: 0.5176 - policy_loss: 1.6825 - val_loss: 6.1395 - val_value_loss: 0.5671 - val_policy_loss: 1.6776\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1136 - value_loss: 0.5113 - policy_loss: 1.6817 - val_loss: 6.1385 - val_value_loss: 0.5655 - val_policy_loss: 1.6774\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1098 - value_loss: 0.5042 - policy_loss: 1.6814 - val_loss: 6.1377 - val_value_loss: 0.5641 - val_policy_loss: 1.6774\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1059 - value_loss: 0.4967 - policy_loss: 1.6813 - val_loss: 6.1364 - val_value_loss: 0.5618 - val_policy_loss: 1.6772\n",
      "Saved model  tictactoe_c_puct_5_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.89 - draw ratio 0.03\n",
      "Number of seen trajectories: 1200\n",
      "Number of unique trajectories: 1138\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1953 - value_loss: 0.6753 - policy_loss: 1.6815 - val_loss: 6.1928 - val_value_loss: 0.6662 - val_policy_loss: 1.6858\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1822 - value_loss: 0.6501 - policy_loss: 1.6808 - val_loss: 6.1898 - val_value_loss: 0.6606 - val_policy_loss: 1.6856\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1728 - value_loss: 0.6324 - policy_loss: 1.6799 - val_loss: 6.1870 - val_value_loss: 0.6553 - val_policy_loss: 1.6853\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1659 - value_loss: 0.6189 - policy_loss: 1.6796 - val_loss: 6.1848 - val_value_loss: 0.6513 - val_policy_loss: 1.6852\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1588 - value_loss: 0.6058 - policy_loss: 1.6787 - val_loss: 6.1834 - val_value_loss: 0.6488 - val_policy_loss: 1.6850\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1523 - value_loss: 0.5929 - policy_loss: 1.6787 - val_loss: 6.1817 - val_value_loss: 0.6457 - val_policy_loss: 1.6849\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1478 - value_loss: 0.5850 - policy_loss: 1.6779 - val_loss: 6.1800 - val_value_loss: 0.6426 - val_policy_loss: 1.6848\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1424 - value_loss: 0.5749 - policy_loss: 1.6774 - val_loss: 6.1794 - val_value_loss: 0.6417 - val_policy_loss: 1.6846\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1384 - value_loss: 0.5673 - policy_loss: 1.6770 - val_loss: 6.1779 - val_value_loss: 0.6389 - val_policy_loss: 1.6845\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1335 - value_loss: 0.5579 - policy_loss: 1.6768 - val_loss: 6.1766 - val_value_loss: 0.6367 - val_policy_loss: 1.6844\n",
      "Saved model  tictactoe_c_puct_5_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.01\n",
      "Number of seen trajectories: 1300\n",
      "Number of unique trajectories: 1224\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1956 - value_loss: 0.6714 - policy_loss: 1.6877 - val_loss: 6.1977 - val_value_loss: 0.6743 - val_policy_loss: 1.6889\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1823 - value_loss: 0.6456 - policy_loss: 1.6870 - val_loss: 6.1921 - val_value_loss: 0.6636 - val_policy_loss: 1.6887\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1731 - value_loss: 0.6281 - policy_loss: 1.6862 - val_loss: 6.1882 - val_value_loss: 0.6562 - val_policy_loss: 1.6884\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1655 - value_loss: 0.6137 - policy_loss: 1.6857 - val_loss: 6.1848 - val_value_loss: 0.6499 - val_policy_loss: 1.6882\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1580 - value_loss: 0.5998 - policy_loss: 1.6847 - val_loss: 6.1824 - val_value_loss: 0.6454 - val_policy_loss: 1.6880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1526 - value_loss: 0.5896 - policy_loss: 1.6844 - val_loss: 6.1800 - val_value_loss: 0.6410 - val_policy_loss: 1.6879\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1477 - value_loss: 0.5807 - policy_loss: 1.6836 - val_loss: 6.1790 - val_value_loss: 0.6393 - val_policy_loss: 1.6877\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1423 - value_loss: 0.5704 - policy_loss: 1.6832 - val_loss: 6.1767 - val_value_loss: 0.6351 - val_policy_loss: 1.6874\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1382 - value_loss: 0.5628 - policy_loss: 1.6827 - val_loss: 6.1759 - val_value_loss: 0.6338 - val_policy_loss: 1.6873\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1357 - value_loss: 0.5583 - policy_loss: 1.6825 - val_loss: 6.1734 - val_value_loss: 0.6291 - val_policy_loss: 1.6871\n",
      "Saved model  tictactoe_c_puct_5_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.03\n",
      "Number of seen trajectories: 1400\n",
      "Number of unique trajectories: 1316\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2035 - value_loss: 0.6992 - policy_loss: 1.6772 - val_loss: 6.1858 - val_value_loss: 0.6856 - val_policy_loss: 1.6555\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1872 - value_loss: 0.6678 - policy_loss: 1.6763 - val_loss: 6.1828 - val_value_loss: 0.6801 - val_policy_loss: 1.6552\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1777 - value_loss: 0.6492 - policy_loss: 1.6759 - val_loss: 6.1773 - val_value_loss: 0.6696 - val_policy_loss: 1.6549\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1680 - value_loss: 0.6306 - policy_loss: 1.6754 - val_loss: 6.1758 - val_value_loss: 0.6671 - val_policy_loss: 1.6547\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1603 - value_loss: 0.6157 - policy_loss: 1.6751 - val_loss: 6.1736 - val_value_loss: 0.6629 - val_policy_loss: 1.6544\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1528 - value_loss: 0.6018 - policy_loss: 1.6741 - val_loss: 6.1711 - val_value_loss: 0.6582 - val_policy_loss: 1.6543\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1479 - value_loss: 0.5922 - policy_loss: 1.6740 - val_loss: 6.1701 - val_value_loss: 0.6565 - val_policy_loss: 1.6542\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1427 - value_loss: 0.5822 - policy_loss: 1.6738 - val_loss: 6.1679 - val_value_loss: 0.6524 - val_policy_loss: 1.6540\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1379 - value_loss: 0.5733 - policy_loss: 1.6734 - val_loss: 6.1675 - val_value_loss: 0.6519 - val_policy_loss: 1.6539\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1334 - value_loss: 0.5652 - policy_loss: 1.6726 - val_loss: 6.1657 - val_value_loss: 0.6486 - val_policy_loss: 1.6538\n",
      "Saved model  tictactoe_c_puct_5_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.01\n",
      "Number of seen trajectories: 1500\n",
      "Number of unique trajectories: 1407\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1641 - value_loss: 0.6545 - policy_loss: 1.6448 - val_loss: 6.1979 - val_value_loss: 0.6781 - val_policy_loss: 1.6888\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1564 - value_loss: 0.6402 - policy_loss: 1.6437 - val_loss: 6.1953 - val_value_loss: 0.6731 - val_policy_loss: 1.6887\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1500 - value_loss: 0.6280 - policy_loss: 1.6433 - val_loss: 6.1935 - val_value_loss: 0.6697 - val_policy_loss: 1.6886\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1442 - value_loss: 0.6169 - policy_loss: 1.6429 - val_loss: 6.1911 - val_value_loss: 0.6649 - val_policy_loss: 1.6885\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1403 - value_loss: 0.6095 - policy_loss: 1.6424 - val_loss: 6.1893 - val_value_loss: 0.6617 - val_policy_loss: 1.6884\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1358 - value_loss: 0.6011 - policy_loss: 1.6419 - val_loss: 6.1877 - val_value_loss: 0.6585 - val_policy_loss: 1.6883\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1319 - value_loss: 0.5934 - policy_loss: 1.6418 - val_loss: 6.1866 - val_value_loss: 0.6565 - val_policy_loss: 1.6882\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1274 - value_loss: 0.5853 - policy_loss: 1.6411 - val_loss: 6.1851 - val_value_loss: 0.6538 - val_policy_loss: 1.6881\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1252 - value_loss: 0.5811 - policy_loss: 1.6411 - val_loss: 6.1842 - val_value_loss: 0.6521 - val_policy_loss: 1.6881\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1217 - value_loss: 0.5743 - policy_loss: 1.6408 - val_loss: 6.1832 - val_value_loss: 0.6502 - val_policy_loss: 1.6880\n",
      "Saved model  tictactoe_c_puct_5_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.0\n",
      "Number of seen trajectories: 1600\n",
      "Number of unique trajectories: 1498\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1300 - value_loss: 0.5762 - policy_loss: 1.6556 - val_loss: 6.1248 - val_value_loss: 0.5810 - val_policy_loss: 1.6406\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1226 - value_loss: 0.5619 - policy_loss: 1.6553 - val_loss: 6.1211 - val_value_loss: 0.5740 - val_policy_loss: 1.6403\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1168 - value_loss: 0.5505 - policy_loss: 1.6552 - val_loss: 6.1184 - val_value_loss: 0.5688 - val_policy_loss: 1.6401\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1114 - value_loss: 0.5403 - policy_loss: 1.6545 - val_loss: 6.1167 - val_value_loss: 0.5656 - val_policy_loss: 1.6399\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1072 - value_loss: 0.5327 - policy_loss: 1.6539 - val_loss: 6.1146 - val_value_loss: 0.5618 - val_policy_loss: 1.6397\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1032 - value_loss: 0.5249 - policy_loss: 1.6537 - val_loss: 6.1130 - val_value_loss: 0.5587 - val_policy_loss: 1.6395\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0999 - value_loss: 0.5191 - policy_loss: 1.6531 - val_loss: 6.1115 - val_value_loss: 0.5559 - val_policy_loss: 1.6394\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0958 - value_loss: 0.5109 - policy_loss: 1.6531 - val_loss: 6.1100 - val_value_loss: 0.5532 - val_policy_loss: 1.6393\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0931 - value_loss: 0.5060 - policy_loss: 1.6527 - val_loss: 6.1090 - val_value_loss: 0.5513 - val_policy_loss: 1.6391\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.0895 - value_loss: 0.4994 - policy_loss: 1.6521 - val_loss: 6.1074 - val_value_loss: 0.5484 - val_policy_loss: 1.6390\n",
      "Saved model  tictactoe_c_puct_5_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.0\n",
      "Number of seen trajectories: 1700\n",
      "Number of unique trajectories: 1587\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1560 - value_loss: 0.6177 - policy_loss: 1.6670 - val_loss: 6.1184 - val_value_loss: 0.5562 - val_policy_loss: 1.6533\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1481 - value_loss: 0.6022 - policy_loss: 1.6667 - val_loss: 6.1163 - val_value_loss: 0.5524 - val_policy_loss: 1.6530\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1425 - value_loss: 0.5913 - policy_loss: 1.6664 - val_loss: 6.1147 - val_value_loss: 0.5494 - val_policy_loss: 1.6529\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1381 - value_loss: 0.5824 - policy_loss: 1.6666 - val_loss: 6.1137 - val_value_loss: 0.5477 - val_policy_loss: 1.6527\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1329 - value_loss: 0.5734 - policy_loss: 1.6653 - val_loss: 6.1128 - val_value_loss: 0.5460 - val_policy_loss: 1.6526\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1278 - value_loss: 0.5639 - policy_loss: 1.6648 - val_loss: 6.1119 - val_value_loss: 0.5443 - val_policy_loss: 1.6525\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1243 - value_loss: 0.5572 - policy_loss: 1.6646 - val_loss: 6.1114 - val_value_loss: 0.5436 - val_policy_loss: 1.6523\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1214 - value_loss: 0.5519 - policy_loss: 1.6641 - val_loss: 6.1105 - val_value_loss: 0.5420 - val_policy_loss: 1.6522\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1188 - value_loss: 0.5469 - policy_loss: 1.6640 - val_loss: 6.1105 - val_value_loss: 0.5422 - val_policy_loss: 1.6521\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1146 - value_loss: 0.5389 - policy_loss: 1.6637 - val_loss: 6.1099 - val_value_loss: 0.5411 - val_policy_loss: 1.6520\n",
      "Saved model  tictactoe_c_puct_5_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.01\n",
      "Number of seen trajectories: 1800\n",
      "Number of unique trajectories: 1669\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 6.1929 - value_loss: 0.6759 - policy_loss: 1.6834 - val_loss: 6.1685 - val_value_loss: 0.6258 - val_policy_loss: 1.6847\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1839 - value_loss: 0.6589 - policy_loss: 1.6825 - val_loss: 6.1646 - val_value_loss: 0.6183 - val_policy_loss: 1.6845\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1788 - value_loss: 0.6487 - policy_loss: 1.6825 - val_loss: 6.1624 - val_value_loss: 0.6140 - val_policy_loss: 1.6844\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1744 - value_loss: 0.6400 - policy_loss: 1.6824 - val_loss: 6.1606 - val_value_loss: 0.6107 - val_policy_loss: 1.6842\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1695 - value_loss: 0.6310 - policy_loss: 1.6816 - val_loss: 6.1593 - val_value_loss: 0.6084 - val_policy_loss: 1.6841\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1654 - value_loss: 0.6237 - policy_loss: 1.6810 - val_loss: 6.1585 - val_value_loss: 0.6069 - val_policy_loss: 1.6840\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1620 - value_loss: 0.6173 - policy_loss: 1.6807 - val_loss: 6.1577 - val_value_loss: 0.6056 - val_policy_loss: 1.6839\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1588 - value_loss: 0.6112 - policy_loss: 1.6805 - val_loss: 6.1574 - val_value_loss: 0.6051 - val_policy_loss: 1.6838\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1558 - value_loss: 0.6054 - policy_loss: 1.6803 - val_loss: 6.1569 - val_value_loss: 0.6043 - val_policy_loss: 1.6837\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1528 - value_loss: 0.5998 - policy_loss: 1.6799 - val_loss: 6.1568 - val_value_loss: 0.6043 - val_policy_loss: 1.6836\n",
      "Saved model  tictactoe_c_puct_5_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.93 - draw ratio 0.0\n",
      "Number of seen trajectories: 1900\n",
      "Number of unique trajectories: 1757\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1741 - value_loss: 0.6679 - policy_loss: 1.6546 - val_loss: 6.1838 - val_value_loss: 0.6352 - val_policy_loss: 1.7067\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1665 - value_loss: 0.6534 - policy_loss: 1.6539 - val_loss: 6.1824 - val_value_loss: 0.6325 - val_policy_loss: 1.7066\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1610 - value_loss: 0.6426 - policy_loss: 1.6538 - val_loss: 6.1809 - val_value_loss: 0.6297 - val_policy_loss: 1.7065\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1545 - value_loss: 0.6303 - policy_loss: 1.6531 - val_loss: 6.1795 - val_value_loss: 0.6271 - val_policy_loss: 1.7064\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1509 - value_loss: 0.6233 - policy_loss: 1.6530 - val_loss: 6.1796 - val_value_loss: 0.6276 - val_policy_loss: 1.7063\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1477 - value_loss: 0.6170 - policy_loss: 1.6531 - val_loss: 6.1785 - val_value_loss: 0.6255 - val_policy_loss: 1.7061\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1432 - value_loss: 0.6087 - policy_loss: 1.6525 - val_loss: 6.1802 - val_value_loss: 0.6291 - val_policy_loss: 1.7061\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1406 - value_loss: 0.6039 - policy_loss: 1.6521 - val_loss: 6.1780 - val_value_loss: 0.6249 - val_policy_loss: 1.7060\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1374 - value_loss: 0.5979 - policy_loss: 1.6518 - val_loss: 6.1776 - val_value_loss: 0.6242 - val_policy_loss: 1.7059\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1342 - value_loss: 0.5919 - policy_loss: 1.6514 - val_loss: 6.1768 - val_value_loss: 0.6229 - val_policy_loss: 1.7058\n",
      "Saved model  tictactoe_c_puct_5_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.0\n",
      "Number of seen trajectories: 2000\n",
      "Number of unique trajectories: 1834\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1637 - value_loss: 0.6379 - policy_loss: 1.6646 - val_loss: 6.1617 - val_value_loss: 0.6358 - val_policy_loss: 1.6626\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1590 - value_loss: 0.6290 - policy_loss: 1.6641 - val_loss: 6.1589 - val_value_loss: 0.6306 - val_policy_loss: 1.6624\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1558 - value_loss: 0.6231 - policy_loss: 1.6636 - val_loss: 6.1569 - val_value_loss: 0.6267 - val_policy_loss: 1.6623\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1527 - value_loss: 0.6168 - policy_loss: 1.6637 - val_loss: 6.1553 - val_value_loss: 0.6236 - val_policy_loss: 1.6621\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1501 - value_loss: 0.6121 - policy_loss: 1.6632 - val_loss: 6.1540 - val_value_loss: 0.6212 - val_policy_loss: 1.6620\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1481 - value_loss: 0.6080 - policy_loss: 1.6634 - val_loss: 6.1529 - val_value_loss: 0.6191 - val_policy_loss: 1.6620\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1452 - value_loss: 0.6031 - policy_loss: 1.6625 - val_loss: 6.1519 - val_value_loss: 0.6172 - val_policy_loss: 1.6619\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1424 - value_loss: 0.5975 - policy_loss: 1.6625 - val_loss: 6.1511 - val_value_loss: 0.6157 - val_policy_loss: 1.6618\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1406 - value_loss: 0.5944 - policy_loss: 1.6621 - val_loss: 6.1503 - val_value_loss: 0.6141 - val_policy_loss: 1.6618\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1395 - value_loss: 0.5918 - policy_loss: 1.6626 - val_loss: 6.1495 - val_value_loss: 0.6128 - val_policy_loss: 1.6617\n",
      "Saved model  tictactoe_c_puct_5_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.01\n",
      "Number of seen trajectories: 2100\n",
      "Number of unique trajectories: 1915\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1893 - value_loss: 0.6675 - policy_loss: 1.6866 - val_loss: 6.1938 - val_value_loss: 0.6809 - val_policy_loss: 1.6820\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1846 - value_loss: 0.6586 - policy_loss: 1.6860 - val_loss: 6.1910 - val_value_loss: 0.6756 - val_policy_loss: 1.6819\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1805 - value_loss: 0.6507 - policy_loss: 1.6857 - val_loss: 6.1888 - val_value_loss: 0.6713 - val_policy_loss: 1.6818\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1763 - value_loss: 0.6423 - policy_loss: 1.6858 - val_loss: 6.1871 - val_value_loss: 0.6681 - val_policy_loss: 1.6817\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1729 - value_loss: 0.6366 - policy_loss: 1.6848 - val_loss: 6.1858 - val_value_loss: 0.6655 - val_policy_loss: 1.6817\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1716 - value_loss: 0.6334 - policy_loss: 1.6854 - val_loss: 6.1847 - val_value_loss: 0.6634 - val_policy_loss: 1.6816\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1672 - value_loss: 0.6251 - policy_loss: 1.6849 - val_loss: 6.1836 - val_value_loss: 0.6613 - val_policy_loss: 1.6815\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1656 - value_loss: 0.6220 - policy_loss: 1.6848 - val_loss: 6.1827 - val_value_loss: 0.6596 - val_policy_loss: 1.6815\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1633 - value_loss: 0.6177 - policy_loss: 1.6846 - val_loss: 6.1818 - val_value_loss: 0.6579 - val_policy_loss: 1.6814\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1599 - value_loss: 0.6113 - policy_loss: 1.6844 - val_loss: 6.1809 - val_value_loss: 0.6563 - val_policy_loss: 1.6814\n",
      "Saved model  tictactoe_c_puct_5_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.03\n",
      "Number of seen trajectories: 2200\n",
      "Number of unique trajectories: 1993\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1719 - value_loss: 0.6475 - policy_loss: 1.6721 - val_loss: 6.1510 - val_value_loss: 0.5969 - val_policy_loss: 1.6809\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1689 - value_loss: 0.6417 - policy_loss: 1.6720 - val_loss: 6.1485 - val_value_loss: 0.5919 - val_policy_loss: 1.6809\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1645 - value_loss: 0.6335 - policy_loss: 1.6715 - val_loss: 6.1466 - val_value_loss: 0.5882 - val_policy_loss: 1.6808\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1626 - value_loss: 0.6297 - policy_loss: 1.6714 - val_loss: 6.1450 - val_value_loss: 0.5853 - val_policy_loss: 1.6808\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1594 - value_loss: 0.6239 - policy_loss: 1.6709 - val_loss: 6.1436 - val_value_loss: 0.5825 - val_policy_loss: 1.6807\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1579 - value_loss: 0.6204 - policy_loss: 1.6713 - val_loss: 6.1425 - val_value_loss: 0.5803 - val_policy_loss: 1.6807\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1552 - value_loss: 0.6159 - policy_loss: 1.6707 - val_loss: 6.1415 - val_value_loss: 0.5783 - val_policy_loss: 1.6807\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1528 - value_loss: 0.6108 - policy_loss: 1.6709 - val_loss: 6.1406 - val_value_loss: 0.5766 - val_policy_loss: 1.6806\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1506 - value_loss: 0.6069 - policy_loss: 1.6703 - val_loss: 6.1396 - val_value_loss: 0.5748 - val_policy_loss: 1.6806\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1492 - value_loss: 0.6041 - policy_loss: 1.6705 - val_loss: 6.1391 - val_value_loss: 0.5737 - val_policy_loss: 1.6806\n",
      "Saved model  tictactoe_c_puct_5_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.85 - draw ratio 0.04\n",
      "Number of seen trajectories: 2300\n",
      "Number of unique trajectories: 2077\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1413 - value_loss: 0.6012 - policy_loss: 1.6577 - val_loss: 6.1482 - val_value_loss: 0.5802 - val_policy_loss: 1.6925\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1380 - value_loss: 0.5943 - policy_loss: 1.6580 - val_loss: 6.1468 - val_value_loss: 0.5774 - val_policy_loss: 1.6924\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1353 - value_loss: 0.5893 - policy_loss: 1.6575 - val_loss: 6.1456 - val_value_loss: 0.5750 - val_policy_loss: 1.6924\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1321 - value_loss: 0.5835 - policy_loss: 1.6571 - val_loss: 6.1445 - val_value_loss: 0.5730 - val_policy_loss: 1.6924\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1292 - value_loss: 0.5779 - policy_loss: 1.6569 - val_loss: 6.1437 - val_value_loss: 0.5715 - val_policy_loss: 1.6923\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1274 - value_loss: 0.5743 - policy_loss: 1.6569 - val_loss: 6.1429 - val_value_loss: 0.5699 - val_policy_loss: 1.6923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1254 - value_loss: 0.5700 - policy_loss: 1.6571 - val_loss: 6.1421 - val_value_loss: 0.5685 - val_policy_loss: 1.6923\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1232 - value_loss: 0.5665 - policy_loss: 1.6563 - val_loss: 6.1416 - val_value_loss: 0.5675 - val_policy_loss: 1.6923\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1212 - value_loss: 0.5626 - policy_loss: 1.6564 - val_loss: 6.1410 - val_value_loss: 0.5664 - val_policy_loss: 1.6923\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 193us/step - loss: 6.1195 - value_loss: 0.5591 - policy_loss: 1.6564 - val_loss: 6.1404 - val_value_loss: 0.5651 - val_policy_loss: 1.6922\n",
      "Saved model  tictactoe_c_puct_5_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.01\n",
      "Number of seen trajectories: 2400\n",
      "Number of unique trajectories: 2153\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 6.1943 - value_loss: 0.6681 - policy_loss: 1.6971 - val_loss: 6.1587 - val_value_loss: 0.6488 - val_policy_loss: 1.6452\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1907 - value_loss: 0.6608 - policy_loss: 1.6973 - val_loss: 6.1572 - val_value_loss: 0.6461 - val_policy_loss: 1.6450\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1859 - value_loss: 0.6517 - policy_loss: 1.6967 - val_loss: 6.1561 - val_value_loss: 0.6440 - val_policy_loss: 1.6449\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1828 - value_loss: 0.6454 - policy_loss: 1.6970 - val_loss: 6.1553 - val_value_loss: 0.6425 - val_policy_loss: 1.6448\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1802 - value_loss: 0.6403 - policy_loss: 1.6967 - val_loss: 6.1547 - val_value_loss: 0.6415 - val_policy_loss: 1.6447\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1769 - value_loss: 0.6340 - policy_loss: 1.6966 - val_loss: 6.1541 - val_value_loss: 0.6405 - val_policy_loss: 1.6446\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1743 - value_loss: 0.6289 - policy_loss: 1.6964 - val_loss: 6.1537 - val_value_loss: 0.6398 - val_policy_loss: 1.6445\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1738 - value_loss: 0.6274 - policy_loss: 1.6970 - val_loss: 6.1533 - val_value_loss: 0.6391 - val_policy_loss: 1.6445\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1705 - value_loss: 0.6214 - policy_loss: 1.6966 - val_loss: 6.1529 - val_value_loss: 0.6385 - val_policy_loss: 1.6444\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1678 - value_loss: 0.6163 - policy_loss: 1.6963 - val_loss: 6.1525 - val_value_loss: 0.6377 - val_policy_loss: 1.6443\n",
      "Saved model  tictactoe_c_puct_5_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.01\n",
      "Number of seen trajectories: 2500\n",
      "Number of unique trajectories: 2229\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1848 - value_loss: 0.6732 - policy_loss: 1.6735 - val_loss: 6.1903 - val_value_loss: 0.6763 - val_policy_loss: 1.6814\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1825 - value_loss: 0.6687 - policy_loss: 1.6734 - val_loss: 6.1889 - val_value_loss: 0.6735 - val_policy_loss: 1.6813\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1797 - value_loss: 0.6638 - policy_loss: 1.6726 - val_loss: 6.1876 - val_value_loss: 0.6710 - val_policy_loss: 1.6813\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1767 - value_loss: 0.6579 - policy_loss: 1.6727 - val_loss: 6.1864 - val_value_loss: 0.6687 - val_policy_loss: 1.6813\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1752 - value_loss: 0.6544 - policy_loss: 1.6730 - val_loss: 6.1853 - val_value_loss: 0.6665 - val_policy_loss: 1.6812\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1731 - value_loss: 0.6508 - policy_loss: 1.6724 - val_loss: 6.1843 - val_value_loss: 0.6646 - val_policy_loss: 1.6812\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1713 - value_loss: 0.6475 - policy_loss: 1.6722 - val_loss: 6.1834 - val_value_loss: 0.6628 - val_policy_loss: 1.6812\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1686 - value_loss: 0.6426 - policy_loss: 1.6717 - val_loss: 6.1826 - val_value_loss: 0.6612 - val_policy_loss: 1.6811\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1670 - value_loss: 0.6392 - policy_loss: 1.6720 - val_loss: 6.1818 - val_value_loss: 0.6596 - val_policy_loss: 1.6811\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1656 - value_loss: 0.6364 - policy_loss: 1.6720 - val_loss: 6.1810 - val_value_loss: 0.6580 - val_policy_loss: 1.6811\n",
      "Saved model  tictactoe_c_puct_5_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.81 - draw ratio 0.01\n",
      "Number of seen trajectories: 2600\n",
      "Number of unique trajectories: 2309\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1903 - value_loss: 0.6947 - policy_loss: 1.6631 - val_loss: 6.1684 - val_value_loss: 0.6413 - val_policy_loss: 1.6728\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1885 - value_loss: 0.6912 - policy_loss: 1.6630 - val_loss: 6.1683 - val_value_loss: 0.6410 - val_policy_loss: 1.6728\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1868 - value_loss: 0.6883 - policy_loss: 1.6625 - val_loss: 6.1681 - val_value_loss: 0.6408 - val_policy_loss: 1.6728\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1849 - value_loss: 0.6850 - policy_loss: 1.6621 - val_loss: 6.1681 - val_value_loss: 0.6406 - val_policy_loss: 1.6728\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1830 - value_loss: 0.6812 - policy_loss: 1.6620 - val_loss: 6.1678 - val_value_loss: 0.6402 - val_policy_loss: 1.6728\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1820 - value_loss: 0.6789 - policy_loss: 1.6623 - val_loss: 6.1675 - val_value_loss: 0.6397 - val_policy_loss: 1.6727\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1799 - value_loss: 0.6749 - policy_loss: 1.6622 - val_loss: 6.1673 - val_value_loss: 0.6392 - val_policy_loss: 1.6727\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1789 - value_loss: 0.6732 - policy_loss: 1.6620 - val_loss: 6.1673 - val_value_loss: 0.6391 - val_policy_loss: 1.6727\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1764 - value_loss: 0.6686 - policy_loss: 1.6615 - val_loss: 6.1672 - val_value_loss: 0.6389 - val_policy_loss: 1.6727\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1763 - value_loss: 0.6681 - policy_loss: 1.6619 - val_loss: 6.1668 - val_value_loss: 0.6383 - val_policy_loss: 1.6728\n",
      "Saved model  tictactoe_c_puct_5_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.01\n",
      "Number of seen trajectories: 2700\n",
      "Number of unique trajectories: 2387\n",
      "iteration 27 | self-play\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving memory position_memory_tictactoe_c_puct_5_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1829 - value_loss: 0.6948 - policy_loss: 1.6484 - val_loss: 6.2288 - val_value_loss: 0.7680 - val_policy_loss: 1.6670\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1812 - value_loss: 0.6920 - policy_loss: 1.6478 - val_loss: 6.2276 - val_value_loss: 0.7657 - val_policy_loss: 1.6670\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1800 - value_loss: 0.6897 - policy_loss: 1.6478 - val_loss: 6.2268 - val_value_loss: 0.7640 - val_policy_loss: 1.6670\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1778 - value_loss: 0.6852 - policy_loss: 1.6479 - val_loss: 6.2260 - val_value_loss: 0.7626 - val_policy_loss: 1.6670\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1763 - value_loss: 0.6825 - policy_loss: 1.6476 - val_loss: 6.2253 - val_value_loss: 0.7610 - val_policy_loss: 1.6670\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1752 - value_loss: 0.6804 - policy_loss: 1.6476 - val_loss: 6.2247 - val_value_loss: 0.7599 - val_policy_loss: 1.6670\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1731 - value_loss: 0.6760 - policy_loss: 1.6478 - val_loss: 6.2241 - val_value_loss: 0.7588 - val_policy_loss: 1.6670\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1712 - value_loss: 0.6727 - policy_loss: 1.6473 - val_loss: 6.2236 - val_value_loss: 0.7577 - val_policy_loss: 1.6670\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1712 - value_loss: 0.6723 - policy_loss: 1.6477 - val_loss: 6.2231 - val_value_loss: 0.7569 - val_policy_loss: 1.6670\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1695 - value_loss: 0.6694 - policy_loss: 1.6472 - val_loss: 6.2228 - val_value_loss: 0.7561 - val_policy_loss: 1.6670\n",
      "Saved model  tictactoe_c_puct_5_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.75 - draw ratio 0.03\n",
      "Number of seen trajectories: 2800\n",
      "Number of unique trajectories: 2459\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1839 - value_loss: 0.6582 - policy_loss: 1.6873 - val_loss: 6.2208 - val_value_loss: 0.7416 - val_policy_loss: 1.6776\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1809 - value_loss: 0.6525 - policy_loss: 1.6870 - val_loss: 6.2201 - val_value_loss: 0.7403 - val_policy_loss: 1.6775\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1791 - value_loss: 0.6495 - policy_loss: 1.6864 - val_loss: 6.2194 - val_value_loss: 0.7390 - val_policy_loss: 1.6774\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1775 - value_loss: 0.6456 - policy_loss: 1.6870 - val_loss: 6.2185 - val_value_loss: 0.7374 - val_policy_loss: 1.6773\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1755 - value_loss: 0.6425 - policy_loss: 1.6863 - val_loss: 6.2178 - val_value_loss: 0.7360 - val_policy_loss: 1.6772\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1754 - value_loss: 0.6411 - policy_loss: 1.6874 - val_loss: 6.2170 - val_value_loss: 0.7345 - val_policy_loss: 1.6772\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1719 - value_loss: 0.6354 - policy_loss: 1.6860 - val_loss: 6.2163 - val_value_loss: 0.7331 - val_policy_loss: 1.6771\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1712 - value_loss: 0.6338 - policy_loss: 1.6864 - val_loss: 6.2153 - val_value_loss: 0.7313 - val_policy_loss: 1.6771\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1704 - value_loss: 0.6317 - policy_loss: 1.6868 - val_loss: 6.2147 - val_value_loss: 0.7302 - val_policy_loss: 1.6770\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1678 - value_loss: 0.6276 - policy_loss: 1.6858 - val_loss: 6.2141 - val_value_loss: 0.7291 - val_policy_loss: 1.6770\n",
      "Saved model  tictactoe_c_puct_5_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.01\n",
      "Number of seen trajectories: 2900\n",
      "Number of unique trajectories: 2526\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_5_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1754 - value_loss: 0.6438 - policy_loss: 1.6849 - val_loss: 6.1759 - val_value_loss: 0.6593 - val_policy_loss: 1.6703\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1715 - value_loss: 0.6356 - policy_loss: 1.6851 - val_loss: 6.1737 - val_value_loss: 0.6551 - val_policy_loss: 1.6702\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1679 - value_loss: 0.6292 - policy_loss: 1.6846 - val_loss: 6.1722 - val_value_loss: 0.6521 - val_policy_loss: 1.6701\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1655 - value_loss: 0.6244 - policy_loss: 1.6845 - val_loss: 6.1709 - val_value_loss: 0.6496 - val_policy_loss: 1.6700\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1636 - value_loss: 0.6206 - policy_loss: 1.6845 - val_loss: 6.1699 - val_value_loss: 0.6476 - val_policy_loss: 1.6700\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1612 - value_loss: 0.6157 - policy_loss: 1.6845 - val_loss: 6.1690 - val_value_loss: 0.6459 - val_policy_loss: 1.6699\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 171us/step - loss: 6.1595 - value_loss: 0.6127 - policy_loss: 1.6842 - val_loss: 6.1682 - val_value_loss: 0.6444 - val_policy_loss: 1.6699\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1569 - value_loss: 0.6072 - policy_loss: 1.6845 - val_loss: 6.1674 - val_value_loss: 0.6430 - val_policy_loss: 1.6698\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1551 - value_loss: 0.6041 - policy_loss: 1.6840 - val_loss: 6.1668 - val_value_loss: 0.6418 - val_policy_loss: 1.6698\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1535 - value_loss: 0.6008 - policy_loss: 1.6841 - val_loss: 6.1662 - val_value_loss: 0.6407 - val_policy_loss: 1.6698\n",
      "Saved model  tictactoe_c_puct_5_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.04\n",
      "Number of seen trajectories: 3000\n",
      "Number of unique trajectories: 2599\n"
     ]
    }
   ],
   "source": [
    "wins_5, draws_5, seen_trajectories_5, unique_trajectories_5 = test_pipeline.run(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - c_puct 5\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "losses_5 = np.ones(30) - wins_5 - draws_5\n",
    "\n",
    "plt.plot(x, wins_5, label=\"win ratio\")\n",
    "plt.plot(x, draws_5, label=\"draw ratio\")\n",
    "plt.plot(x, losses_5, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3Xd4VGXax/HvnUknCS2hBgggIL0FAlIVCyp2RVFRRIVVUddd3dXVV11XV3etq2tZVMCCBTsrKChKESkJXUCK1JgAgdBCCKTc7x9zwg4xkACZnMzk/lxXLmZOm/tkdH55zjPneURVMcYYY44nxO0CjDHGVH0WFsYYY8pkYWGMMaZMFhbGGGPKZGFhjDGmTBYWxhhjymRhYYKCiMwUkVv8dOy/iMgb/ji2MYHCwsJUKhHZJCIHRSTH5+ffbtdVTEQGiki67zJV/buq+iWIAoXzvp19nPVJIqIl3tf/q8wajX+Ful2AqZYuUtVv3S7C+EUtVS1wuwhT8axlYaoEEYkQkT0i0sFnWYLTCqknIrVF5EsRyRKR3c7jxGMc61ERedfnefFfvaHO85tEZLWI7BeRDSIy2lleA/gKaOTz13GjUo53sYisdOqdKSJtfdZtEpF7RWS5iOwVkQ9FJPIUfi99ReRH57W2isiIMrafICKvicg3zvnNEpFmpf0enGVHXb4TkVt9fjerRKSbiLwDNAX+6/xO/nSy52MCl4WFqRJU9RDwKTDMZ/FQYJaq7sD73+p4oBneD66DwMlevtoBDAHigJuA50Wkm6oeAM4HMlQ1xvnJ8N1RRFoD7wO/BxKAqXg/RMNL1D0YaA50AkacTJEi0hRveL3kvFYXYGk5dr0O+BsQ72w/sZyvdxXwKHAD3t/NxcAuVR0ObMHbIoxR1X8e5zCbRSRdRMaLSHx5XtcEBgsL44bPnb+Ui39udZa/x9Fhca2zDFXdpaqfqGququ4HngAGnMyLq+oUVf1FvWYB04F+5dz9amCKqn6jqvnAM0AUcIbPNi+qaoaqZgP/xfshfzKuA75V1fdVNd/5HZQnLKao6mwngB8EeotIk3LsdwvwT1VNdX4361V1czlr3Qn0wBvm3YFYyhlSJjBYn4Vxw6XH6LP4DogSkRRgG94P2c8ARCQaeB7vX+y1ne1jRcSjqoUn8uIicj7wCNAa7x9M0cCKcu7eCDjyAaqqRSKyFWjss802n8e5zj6l1bES74crwPmqOqfEJk2AX8pZl6+tPvXliEi2U8P2MvY72ddDVXOANOfpdhEZA2SKSJyq7juZY5qqxcLCVBnOB+8kvK2L7cCXTisC4I9AGyBFVbeJSBdgCSClHOoA3gAo1qD4gYhEAJ/gvdTyharmi8jnPscpaxjmDKCjz/EE74fsr+U7y/9R1fZlbLIV6Hmix3XqAUBEYoA6eOvOcxZHA8Uf4A189tsKtDzGMU90eOri7Ut7f0wAsstQpqp5D++lnuucx8Vi8fZT7BGROnhbBseyFOgvIk1FpCbwgM+6cCACyAIKnFbGuT7rtwN1nf1KMwm4UEQGiUgY3hA7BPxY3hM8AROBs0VkqIiEikhdJyTLcoHTMR6Ot+9igapuVdUsvKF2vYh4RGQkR4fDG8C9ItJdvE4r7hzH+3tpcawXFJEUEWkjIiEiUhd4EZipqntP4rxNFWRhYdxQ/K2a4p/Pileo6gK8LYNGeDt3i72At29gJzAf+PpYB1fVb4APgeXAIuBLn3X7gbvwfujvxtsvMtln/c94O7A3OP0pR11CUtU1wPV4O513Ahfh7fg9fKK/hLKo6hbgAryBlI03BDuXY9f38IZpNt7+g+t81t0K3AfsAtrjE3Kq+hHevqD3gP3A53hbJQBPAg85v5N7S3nNFnjfk/3AT3gDdFgp25kAJTb5kTHBQ0QmAOmq+pDbtZjgYi0LY4wxZbIObmMCTIlvUfkaXdm1mOrDLkMZY4wpk12GMsYYU6aguQwVHx+vSUlJbpdhjDEBZdGiRTtVNaGs7YImLJKSkkhLSyt7Q2OMMUeISLmGdLHLUMYYY8pkYWGMMaZMFhbGGGPKFDR9FqXJz88nPT2dvLy8sjc2fhEZGUliYiJhYWFul2KMOQVBHRbp6enExsaSlJSEd3BQU5lUlV27dpGenk7z5s3dLscYcwr8dhlKRMaJyA4R+ekY60VEXhSR9c4UlN181t0oIuucnxtPtoa8vDzq1q1rQeESEaFu3brWsjMmCPizz2IC3olqjuV8oJXzMwp4FcBn+OkUvGP5PyIitY91kLJYULjLfv/GBAe/hYWqzsY7RPKxXAK87UzfOB+oJSINgfOAb1Q1W1V3A99w/NA51TrJ3HuQQ/knNNmaMcZUK25+G6oxPtM/AunOsmMt/w0RGSUiaSKSlpWVdVJFHC4oIvvAYdbtyCH7wGHcHisrLS2Nu+66yy/HzszM5Nxzzy17Q2OMKcHNDu7Srk/ocZb/dqHqWGAsQHJy8kl9ykeEeWhVL5b03bmk785lf14YjWtFEepxJ0eTk5NJTk72y7G//vprzjvvPL8c2xgT3NxsWaTjM1cwkIh3nuBjLfeb8NAQmsfXoGHNSPblFbBuRw778/Ir5NibNm2iQ4cOR54/88wzPProowwcOJA///nP9OzZk9atWzNnzhwAZs6cyZAhQwDYtWsX5557Ll27dmX06NE0a9aMnTt3HvOYAL/88guDBw+me/fu9OvXj59//vnIdl9//TXnn38+mZmZ9O/fny5dutChQ4cjrz19+nR69+5Nt27duOqqq8jJyQFg0aJFDBgwgO7du3PeeeeRmZkJcMxzMMYEHzdbFpOBMSLyAd7O7L2qmiki04C/+3Rqn8vRcyiflL/+dyWrMvaVuV2RKofyiyhSJcwTQnjosfO0XaM4Hrmo/UnXVFBQwMKFC5k6dSp//etf+fbbb4+u+a9/pW/fvjz88MNMmTKFsWPHlnnMUaNG8dprr9GqVSsWLFjA7bffznfffUdhYSFr1qyhXbt2PPvss5x33nk8+OCDFBYWkpuby86dO3n88cf59ttvqVGjBv/4xz947rnneOCBB7jzzjv54osvSEhI4MMPP+TBBx9k3Lhx5ToHY0xw8FtYiMj7wEAgXkTS8X7DKQxAVV8DpuKdX3g9kAvc5KzLFpG/AanOoR5T1eN1lFeoEBGiwj0cLigiv7CIQlUiQkMI8cO3ei6//HIAunfvzqZNm36zfvbs2Xz66acAXHjhhdSuffwvheXk5PDjjz9y1VVXHVl26NAhABYsWEBKSgoAPXr0YOTIkeTn53PppZfSpUsXZs2axapVq+jTpw8Ahw8fpnfv3qxZs4affvqJc845B4DCwkIaNmxY7nMwxgQHv4WFqh53snb19iTfcYx144BxFVnPybQA9ufls3X3QQqLlAZxEcTHRJzwV0FDQ0MpKio68tz3noOIiAgAPB4PBQUFpe5f2usd65hFRUXUqlWLpUuX/mafr776isGDvV8q69+/P7Nnz2bKlCkMHz6c++67j9q1a3POOefw/vvvH7XfihUraN++PfPmzSu1vvKcgzEm8NnYUMcRGxlG63oxxEWGkrk3j407D3C4oKjsHX3Ur1+fHTt2sGvXLg4dOsSXX35Z7n379+/PxIkTAe+H/e7du497zLi4OJo3b85HH30EeL8WvGzZMgBmzJjBoEGDANi8eTP16tXj1ltv5eabb2bx4sX06tWLuXPnsn79egByc3NZu3Ytbdq0ISsr60hY5Ofns3LlyhP6HRhjAl9QD/dREUI9ITStE83u3Hwy9hxk/Y4cTqtXg/BQT7n2DwsL4+GHHyYlJYXmzZtz+umnl/u1H3nkEYYNG0a3bt0YMGAATZs2LfOYEydO5LbbbuPxxx8nPz+fa665hkaNGhEZGUlcXBzg7UR/+umnCQsLIyYmhrfffpuEhAQmTJjAsGHDjly6evzxx2ndujUff/wxd911F3v37qWgoIDf//73tG9/8n01xpjAEzRzcCcnJ2vJyY9Wr15N27ZtK+w18vIL+SUrhzBPCC0TauAJqdyGWfEET/Hx8Se037vvvkt6ejr333+/nyo7vop+H4wxFUdEFqlqmd/Xt5bFCYgM89CsTjQbd+ayJfsgSXWjA2I4i+uvv97tEowxAc76LE5QTGQYjWtHsj/Pe1mqMltmmzZtOuFWhTHGVISgb1moaoX/9V+nRgSHCorI2n+I8FAPCbERFXr8YBIslzmNqe6CumURGRnJrl27/PKB1SAukppRYWTuPci+gxVzt3ewKZ7PIjIy0u1SjDGnKKhbFomJiaSnp3OygwyWRVXZnXOIrK1KfEzEce/2rq6KZ8ozxgS2oA6LsLAwv8/QtmNfHpe8PBdV+PyOPjSoaX9FG2OCj/0pfIrqxUXy5o092J+Xz81vpXLgkN3FbIwJPhYWFaBdozheurYrqzP3cfcHSykssk5dY0xwsbCoIGedXp+Hh7Tj29Xbeeqr1W6XY4wxFSqo+ywq24g+zdm48wCvz9lIUnwNrktp5nZJxhhTISwsKtj/DWnH5uxcHv5iJQWFynUpTV2bdc8YYyqKfYpVsFBPCC8N60rvFnV5ZPJKhrz0A/M37HK7LGOMOSUWFn4QGxnGOzf35JXrurE/r4Brxs7nzveXkLHnoNulGWPMSbGw8BMR4YKODfn2DwO4e1Arpq/cxqBnZ/Hv79aRl1/odnnGGHNCLCz8LCrcwz3ntObbPwxgQOsEnpm+lnOen8X0ldts3CRjTMCwsKgkTepE89rw7rx7cwqRoR5GvbOIG8ensn5HjtulGWNMmYJ68qOqKr+wiHfmbeb5b9dy8HAhF3ZqSIOakdSKCqdWdBi1osKoGR32v+fRYUSFeQJi7gxjTGCxyY+qsDBPCCP7NufiLo14dvoaZqzewZ7cfA4XHnt+73BPCPEx4fz98o4MbFOvEqs1xhg/tyxEZDDwL8ADvKGqT5VY3wwYByQA2cD1qprurPsncCHeS2XfAHfrcYoNpJZFaVSVvPwi9hw8zJ7cfPbk5rO3+PFB7/Ppq7axNzefaff0Jz7G5tAwxpw611sWIuIBXgbOAdKBVBGZrKqrfDZ7BnhbVd8SkbOAJ4HhInIG0Afo5Gz3AzAAmOmvet0mIkSFe4gKj6JhzahSt7msa2MueukHHvh0BWOHd7fLUsaYSuPPDu6ewHpV3aCqh4EPgEtKbNMOmOE8/t5nvQKRQDgQAYQB2/1Ya0Bo0yCWe89rzTertvPJ4l/dLscYU434MywaA1t9nqc7y3wtA65wHl8GxIpIXVWdhzc8Mp2faar6m9H5RGSUiKSJSJq/Jjiqam7u24KeSXX46+SV/Go3+RljKok/w6K0ayQl+xzuBQaIyBK8l5l+BQpE5DSgLZCIN2DOEpH+vzmY6lhVTVbV5ISEhIqtvoryhAjPXNWZIlXu+2gZRTYcujGmEvgzLNKBJj7PE4EM3w1UNUNVL1fVrsCDzrK9eFsZ81U1R1VzgK+AXn6sNaA0rRvN/w1px4+/7OKteZvcLscYUw34MyxSgVYi0lxEwoFrgMm+G4hIvIgU1/AA3m9GAWzB2+IIFZEwvK0OmyTCx9U9mnDW6fV46quf7cY+Y4zf+S0sVLUAGANMw/tBP0lVV4rIYyJysbPZQGCNiKwF6gNPOMs/Bn4BVuDt11imqv/1V62BSER46vKORIV7+OOkpRQc5x4NY4w5VXYHd4CbsjyTO95bzB/Oac1dg1q5XY4xJsCU9z4LGxsqwF3YqSGXdGnEizPWsSJ9r9vlGGOClIVFEHjs4g7UjQnnnklLbfhzY4xfWFgEgZrRYTx9ZWfW78jhmWlr3C7HGBOELCyCRP/WCQzv1Yw35260aVyNMRXOwiKIPHDB6TSrE829Hy1jf16+2+UYY4KIhUUQiQ4P5dmhncnYc5BHJ6+ymfiMMRXGwiLIdG9WhzFnteKTxen8c9oaCwxjTIWwyY+C0D1nt2JXziFenfkLUWEeu//CGHPKLCyCkIjwt0s6kJdfxHPfrCUyLIRR/Vu6XZYxJoBZWASpkBDhn1d24lBBIX+f+jNRYR6G905yuyxjTICysAhinhDh+au7cKigiP/7YiURYR6GJjcpe0djjCnBOriDXJgnhH9f25V+reL58yfL+WKpzbBnjDlxFhbVQESoh7HDk+mZVIc/TFrG1z9tc7skY0yAsbCoJqLCPbw5ogedE2ty5/uL+X7NDrdLMsYEEAuLaiQmIpTxN/WkTYNYfvfOIn5cv9PtkowxAcLCopqpGRXGOyNTSKpbg1veTiNtU7bbJRljAoCFRTVUu0Y479zSkwZxkdw0PpWffrV5MIwxx2dhUU3Vi41k4q0pxEWFMWJ8Kluzc90uyRhThVlYVGMNa0bx1sge5BcWceP4hezJPex2ScaYKsrCopo7rV4sb9yYTPrug9zyVprNtGeMKZVfw0JEBovIGhFZLyL3l7K+mYjMEJHlIjJTRBJ91jUVkekislpEVolIkj9rrc56JNXhhau7sGjLbn7/wVIKi2ykWmPM0fwWFiLiAV4GzgfaAcNEpF2JzZ4B3lbVTsBjwJM+694GnlbVtkBPwG4M8KMLOjbkoQvb8fXKbfztS5sLwxhzNH+ODdUTWK+qGwBE5APgEmCVzzbtgHucx98DnzvbtgNCVfUbAFXN8WOdxnFz3+Zk7DnImz9sJLF2FLf0a+F2ScaYKsKfl6EaA1t9nqc7y3wtA65wHl8GxIpIXaA1sEdEPhWRJSLytNNSOYqIjBKRNBFJy8rK8sMpVD8PXtCWCzs25PEpq/nvsgy3yzHGVBH+DAspZVnJaxv3AgNEZAkwAPgVKMDb4unnrO8BtABG/OZgqmNVNVlVkxMSEiqw9OorJER4dmhneiTV5o+TlrFgwy63SzLGVAH+DIt0wHc87ETgqD9VVTVDVS9X1a7Ag86yvc6+S1R1g6oW4L081c2PtRofkWEeXr8hmSZ1orj17TTWbd/vdknGGJf5MyxSgVYi0lxEwoFrgMm+G4hIvIgU1/AAMM5n39oiUtxcOIuj+zqMn9WKDmfCTT2JCPMwYnwq2/fluV2SMcZFfuvgVtUCERkDTAM8wDhVXSkijwFpqjoZGAg8KSIKzAbucPYtFJF7gRkiIsAi4HV/1WpK16RONONH9ODq/8xjxPhUJo3uRWxkGAAFhUXkHCpgf14B+/Ly2Z9X4Pzkc+BwITWjwkiIiSAh1vsTFxmK9600xgQiCZavSCYnJ2taWprbZQSlWWuzGDkhldrR4XhCYH9eAbmHT+zmvfDQkKPCIyE2goSYCFrWi+HMNglHQsgYU7lEZJGqJpe1nU2raso0oHUCr1zXjclLM6gR4SE2MozYyNAj/8b5PI6NDKNGuId9efns2H+IrOKfnP893pqdy5Itu9l14DCq3iAZ0DqBCzs2ZFDbehYcxlRB1rIwrikoLGJZ+h6+XJ7JVyu2sW1fHuGhIfRvlcCQThYcxlSG8rYsLCxMlVBUpCzZupspy7cxdUWmBYcxlcTCwgQs3+D46qdMMvd6g+PuQa24bUBLQkKso9yYimJhYYKCNzj28MacDXz10zb6t07guaGdiY+JcLs0Y4JCecPChig3VVpIiNC9WW1eua4bT1zWgfkbdnHBv+Yw3+4sN6ZSWViYgCAiXJfSjM9v70NMRCjXvj6fl2ass+HUjakkFhYmoLRrFMfkO/tyUedGPPvNWm4ct5Cs/YfcLsuYoGdhYQJOTEQoL1zdhacu70jqpmwueHEOP/6y0+2yjAlqFhYmIIkI1/Rsyhdj+hAXGcr1byzghW/X2mUpY/zEwsIEtNMbxDF5TF8u7dKYF75dx/A3F7Bjvw16aExFs7AwAa9GRCjPDu3MP6/sxOItu7n4pbms32GTKxpTkSwsTFAQEYYmN+HT2/pQUFTE1f+Zx+rMfW6XZUzQsLAwQaVdozg+HN2bME8I14ydz7Kte9wuyZigYGFhgk7LhBg++l1v4qJCue6NBaRuyna7JGMCnoWFCUpN6kQzaXRv6sVGMPzNBfywzr5aa8ypsLAwQathzSg+HN2bpLo1GPlWKjNWb3e7JGMCloWFCWoJsRF8MKoXpzeIZfQ7i5iyPNPtkowJSBYWJujVig7n3VtS6Nq0Fne+v5hPFqW7XZIxAcfCwlQLcZFhvDWyJ2e0jOePHy3j3fmb3S7JmIBiYWGqjejwUN64MZlBp9fjoc9/4o05G9wuyZiA4dewEJHBIrJGRNaLyP2lrG8mIjNEZLmIzBSRxBLr40TkVxH5tz/rNNVHZJiHV6/vzoUdG/L4lNX0eeo77nhvMW/M2cCizdnk5Re6XaIxVVKovw4sIh7gZeAcIB1IFZHJqrrKZ7NngLdV9S0ROQt4Ehjus/5vwCx/1Wiqp/DQEP51TRd6tazL/A27WLplz5GO79AQoV2jOLo0qUXXprXo0qQ2SXWjEbGpXE315rewAHoC61V1A4CIfABcAviGRTvgHufx98DnxStEpDtQH/gaKHPKP2NORKgnhOG9mjG8VzMAduzPY+mWPSzZuoelW/bw8aJ03p7n7deoFR1GcrPaDGidwIDW9WhaN9rN0o1xhT/DojGw1ed5OpBSYptlwBXAv4DLgFgRqQvsBp7F28oYdKwXEJFRwCiApk2bVljhpvqpFxvJue0bcG77BgAUFinrduxnyZY9LNmym3kbdvHt6h3ASprH1/AGR5sEejWvS1S4x93ijakE5Q4LEekM9HOezlHVZWXtUsqykpMN3Av8W0RGALOBX4EC4HZgqqpuPV7zX1XHAmMBkpOTbSIDU2E8IcLpDeI4vUEcw3o2RVXZtCuXWWt2MGttFh+kbmHCj5sIDw0hpXkdBrROYGCbBFomxNglKxOURLXsz1gRuRu4FfjUWXQZMFZVXzrOPr2BR1X1POf5AwCq+uQxto8BflbVRBGZiDeYioAYIBx4RVV/00leLDk5WdPS0so8F2MqQl5+IQs3ZjNrbRaz1mYdGRK9ca0oeresS0rzOvRqUZfE2lEWHqZKE5FFqlrmpf7yhsVyoLeqHnCe1wDmqWqn4+wTCqzFexnpVyAVuFZVV/psEw9kq2qRiDwBFKrqwyWOMwJIVtUxx6vRwsK4KX13LrPX7mT22iwWbNzF7tx8ABrVjCSlRV16tahDSvO6NLPOclPFlDcsynsZSgDf7xQWUvplpiNUtUBExgDTAA8wTlVXishjQJqqTgYGAk+KiOK9DHVHOesxpkpJrB3NtSlNuTalKUVFyrodOSzYuIsFG7KZvTaLz5b8CkD9uAhSmtclpUUd+rdKoEkd6yw3gaG8LYs/ADcCnzmLLgUmqOoLfqzthFjLwlRVqsovWTnM35DNgo3ZLNiwix37DwHQq0UdhiY34fwODa2j3LiiQi9DOQfsBvTF26KYrapLTq3EimVhYQKFqrJx5wG++mkbk9K2snlXLrERoQzp3IihyYl0aVLLLlWZSlMhYSEicaq6T0TqlLZeVavMrDIWFiYQFRUpCzdlMyltK1NXZJKXX0Tr+jEMTW7CpV0bEx8T4XaJJshVVFh8qapDRGQjR3/tVQBV1RanXmrFsLAwgW5/Xj5fLs9kUtpWlmzZQ2iIMKhtPYYmN+HMNvUICbHWhql4FX4ZqqqzsDDBZN32/Xy0KJ1PF6ezM+cwF3duxNNXdSIi1Po1TMUqb1iUayBBEZlRnmXGmIrRqn4sf7mgLfMeGMR957Vh8rIMbhqfyr68fLdLM9XUccNCRCKd/op4EaktInWcnySgUWUUaEx1FuYJ4Y4zT+O5oZ1ZuDGboa/NY9vePLfLMtVQWS2L0cAi4HTn3+KfL/COKGuMqQSXd0tk/E09SN99kMtfmcva7fvdLslUM8cNC1X9l6o2B+5V1Raq2tz56ayqNseEMZWoX6sEPhzdi/wi5cpXf2TBhl1ul2SqkXL1WajqSyLSQUSGisgNxT/+Ls4Yc7T2jWry6W1nkBAbwfA3Fx6Zh8MYfytvB/cjwEvOz5nAP4GL/ViXMeYYmtSJ5pPbzqBTYk3GvL+YcT9sdLskUw2Ud1rVK/EOCLhNVW8COgN2t5AxLqkVHc67t6Rwbrv6PPblKp6YsoqiouD4GrypmsobFnmqWgQUiEgcsAOoMjfkGVMdRYZ5eOW67tzYuxmvz9nI3R8u5VCBzSFu/KPMUWfFO0jNchGpBbyO99tQOcBCP9dmjCmDJ0R49OL2NKwVxVNf/cy67fsZmtyEIZ0bUi820u3yTBAp76izi1S1u/M4CYhT1eX+Le3E2B3cprqbuiKTf3+3nlWZ+wgROKNlPBd3acR57RtQMyrM7fJMFVXRkx+9jHdI8tSKKM4fLCyM8Vq/Yz+Tl2bwxbIMNu/KJdwTwpmnJ3BJl8acdXo9IsNsyBDzPxUdFquA1sBm4AD/G0jwmDPlVTYLC2OOpqosS9/L5KUZ/Hd5Bln7DxETEcq57etzaZfG9GsVb0OhmwoPi2alLVfVzSdRm19YWBhzbIVFyvwNu5i8NIOpP2WyP6+Am/ok8fCQdhYY1VyFTqtalULBGHPiPCFCn9Pi6XNaPI9d2p6/T1nN+LmbiI+J4I4zT3O7PBMAyjsHtzEmSESEenjkovbsPZjP09PWUDs6nGtTmrpdlqniLCyMqYZCQoSnr+rMnoP5PPT5CmpHh3F+x4Zul2WqsPLelHdSRGSwiKwRkfUicn8p65uJyAwRWS4iM0Uk0VneRUTmichKZ93V/qzTmOoozBPCK9d1o0uTWtz9wVJ+XL/T7ZJMFea3sBARD95hzM8H2gHDRKRdic2eAd52vlX1GPCkszwXuEFV2wODgRecmwKNMRUoOjyUcSN6kBQfza1vp7Eifa/bJZkqyp8ti57AelXdoKqHgQ+AS0ps0w4onnHv++L1qrpWVdc5jzPwDi+S4Mdajam2akWH8/bIFGpFhzNi/EI2ZOW4XZKpgvwZFo2BrT7P051lvpYBVziPLwNiRaSu7wYi0hMIB37xU53GVHsNakby7i0pAAx/c6HNxmd+w59hUdqXt0ve1HEvMEBElgADgF+BgiMHEGkIvAPc5AxkePQLiIwSkTQRScvKyqq4yo2phprH1+CtkT3ZezCfG8YtYE/uYbdLMlWIP8MiHWji8zwRyPA9XmXtAAAT0ElEQVTdQFUzVPVyVe0KPOgs2wvgjG47BXhIVeeX9gKqOlZVk1U1OSHBrlIZc6o6NK7J2Bu6s2lnLiMnpJJ7uKDsnUy14M+wSAVaiUhzEQkHrgEm+24gIvEiUlzDA8A4Z3k48Bnezu+P/FijMaaEM1rG8+KwLizduofbJy4mv/A3jXpTDfktLFS1ABgDTANWA5NUdaWIPCYixbPsDQTWiMhaoD7whLN8KNAfGCEiS52fLv6q1RhztMEdGvLEZR2ZuSaLO99bwv68fLdLMi4r19hQgcDGhjKm4r35w0aemLKKxNrR/OuaLnRtWtvtkkwFK+/YUH69Kc8YE9hu7tucSaN7U1ikXPnaPP793ToKbfrWasnCwhhzXMlJdZh6dz8u6NiQZ6avZdjr88nYc9Dtskwls7AwxpSpZlQYL17ThWev6szKX/cy+IXZTF2R6XZZphJZWBhjykVEuKJ7IlPu6kfz+BrcPnExf/54uX29tpqwsDDGnJCk+Bp8fNsZ3HFmSyYt2sqQF3+wMaWqAQsLY8wJC/OEcN95p/PeLb3IPVzI5a/O5T+zfqHIOr+DloWFMeak9W5Zl69/349Bp9fnya9+5vaJizl4uNDtsowfWFgYY05JrehwXr2+Gw9d2JZpq7Yx9D/z2L7PBiIMNhYWxphTJiLc0q8Frw9P5pesHC7591x++tX6MYKJhYUxpsKc3a4+H//uDEIErnptHtNXbnO7JFNBLCyMMRWqXaM4Pr+jD63rxzD63UWMnf0LwTKsUHVmYWGMqXD14iL5cHRvLujQkL9P/Zn7P1nB4QIbvTaQhbpdgDEmOEWGeXhpWFdaJNTgpe/Wszn7AK9d351a0eFul2ZOgrUsjDF+ExIi/PHcNjx/dWcWb97DZa/8aHN8BygLC2OM313WNZH3bk1h78F8LnvlR777ebv1YwQYCwtjTKVITqrD57f3oV5sBCMnpHH2c7N4Y84Gm+s7QNjkR8aYSpWXX8iXyzOZuGAzS7bsITw0hCEdG3Jdr6Z0a1obEXG7xGqlvJMfWVgYY1yzKmMf7y3czOdLMsg5VECb+rFc16spl3ZtTFxkmNvlVQsWFsaYgHHgUAH/XZbBxAVbWPHrXqLCPFzUuSHXpTSjc5NabpcX1CwsjDEBaUX6Xt5buJkvlmaQe7iQEWck8dCFbQn1WBerP9gc3MaYgNQxsSZPXt6JBX8ZxE19kpjw4yZufiuNfXn5bpdWrfk1LERksIisEZH1InJ/KeubicgMEVkuIjNFJNFn3Y0iss75udGfdRpjqp7YyDAeuag9T17ekbnrd3LFKz+yNTvX7bKqLb+FhYh4gJeB84F2wDARaVdis2eAt1W1E/AY8KSzbx3gESAF6Ak8IiK1/VWrMabqGtazKW/f3JMd+w9xyctzSd2U7XZJ1ZI/WxY9gfWqukFVDwMfAJeU2KYdMMN5/L3P+vOAb1Q1W1V3A98Ag/1YqzGmCjujZTyf3X4GtaLCuO71BXyyKN3tkqodf4ZFY2Crz/N0Z5mvZcAVzuPLgFgRqVvOfRGRUSKSJiJpWVlZFVa4MabqaZEQw2e39yE5qTZ//GgZ//j6Z5vGtRL5MyxKu7Om5Dt7LzBARJYAA4BfgYJy7ouqjlXVZFVNTkhIONV6jTFVXM3oMN4a2ZNrU5ry6sxfuG3iInIPF7hdVrXgz7BIB5r4PE8EMnw3UNUMVb1cVbsCDzrL9pZnX2NM9RTmCeGJSzvw8JB2fLNqO1e+Oo/MvQfdLivo+TMsUoFWItJcRMKBa4DJvhuISLyIFNfwADDOeTwNOFdEajsd2+c6y4wxBhFhZN/mvDmiB1uyc7n433NZtnWP22UFNb+FhaoWAGPwfsivBiap6koReUxELnY2GwisEZG1QH3gCWffbOBveAMnFXjMWWaMMUec2aYen9x2BhGhIVz1n3m8v3CLjWbrJ3YHtzEm4GUfOMzdHyxhzrqdXNk9kb9d0oGocI/bZQUEu4PbGFNt1KkRzoSbenLXoFZ8vCidy1/9kU07D7hdVlCxsDDGBAVPiPCHc1oz/qYeZO49yEUv/cD0ldvcLitoWFgYY4LKmW3q8d8xfUmKr8Godxbx5FerKSgscrusgGdhYYwJOk3qRPPR73pzbUpT/jNrA9e/uYAd+/PcLiugWVgYY4JSZJiHv1/WkWev6szSrXsY8uIPNq7UKbCwMMYEtSu6J/LZ7X2IDvdwzdj5vDFngw0TchIsLIwxQa9twzgm39mXQafX4/Epq7ngxTl8tSLTQuMEWFgYY6qFuMgw/jO8O89f3ZnDBUXcNnEx5/9rDlOWW2iUh92UZ4ypdgqLlP8uy+DF79axIesArevHcOdZrbigY0M8IaWNYxq8bA5uY4wpQ2GR8uXyDF76bj3rd+RwWr0Y7jzrNIZ0alRtQsPCwhhjyqmwSJm6IpMXZ6xj3Y4cWibU4K5BrapFaNhwH8YYU06eEOGizo2Y9vv+vHxtNzwhwt0fLGXwC7P5fs0Ot8urEiwsjDHGERIiXNipIV/f7Q2N/MIibhqfyg3jFrJm2363y3OVhYUxxpRQHBrT7xnAQxe2ZemW3Zz/r9n85bMV7Mw55HZ5rrCwMMaYYwgPDeGWfi2Ydd+Z3NA7iUmpWxn49ExenfkLefmFbpdXqSwsjDGmDLVrhPPoxe2Zdk9/erWowz++/pmzn5vFl8szqs1kSxYWxhhTTi0TYnjjxh5MvCWFmIhQxry3hCtfm8fSajClq4WFMcacoD6nxTPlrn7844qObN6Vy6Uvz+W56WuC+k5wCwtjjDkJnhDh6h5NmXnfQK7qnsiL363n9omLyT1c4HZpfmFhYYwxpyAmIpR/XtmJhy5sy/RV27ji1Xmk7851u6wKZ2FhjDGnSES4pV8Lxo3oQXq297JUWpDNneHXsBCRwSKyRkTWi8j9paxvKiLfi8gSEVkuIhc4y8NE5C0RWSEiq0XkAX/WaYwxFWFgm3p8dkcfYiJCGfb6fCalbXW7pArjt7AQEQ/wMnA+0A4YJiLtSmz2EDBJVbsC1wCvOMuvAiJUtSPQHRgtIkn+qtUYYyrKafVi+PyOPqQ0r8ufPl7O41+uojAIOr792bLoCaxX1Q2qehj4ALikxDYKxDmPawIZPstriEgoEAUcBvb5sVZjjKkwtaLDmXBTD0ackcQbP2xk5IRU9uXlu13WKfFnWDQGfNtg6c4yX48C14tIOjAVuNNZ/jFwAMgEtgDPqOpvLgCKyCgRSRORtKysrAou3xhjTl6oJ4RHL27P3y/ryNz1O7ns5bls3HnA7bJOmj/DorRxfUu2xYYBE1Q1EbgAeEdEQvC2SgqBRkBz4I8i0uI3B1Mdq6rJqpqckJBQsdUbY0wFuDalKe/ekkL2gcNc+vJc5q7f6XZJJ8WfYZEONPF5nsj/LjMVuxmYBKCq84BIIB64FvhaVfNVdQcwFyhzvHVjjKmKerWoy+QxfWkQF8lNE1KZtTbwroT4MyxSgVYi0lxEwvF2YE8usc0WYBCAiLTFGxZZzvKzxKsG0Av42Y+1GmOMXzWpE82Ho3txWkIMt76dxpx1gRUYfgsLVS0AxgDTgNV4v/W0UkQeE5GLnc3+CNwqIsuA94ER6h2V62UgBvgJb+iMV9Xl/qrVGGMqQ63ocCbekkKL+Brc8lZaQF2SsmlVjTGmku3KOcS1ry9gc/YBxo3owRkt412rxaZVNcaYKqpuTAQTb02haZ1obp6QxvwNu9wuqUwWFsYY44L4mAgm3tKLxrWjGDkhlYUbq/bwIBYWxhjjkoTYCN67NYWGNSO5afzCKj2elIWFMca4qF5sJO/f2ov6cZGMGJ/K4i273S6pVBYWxhjjsnpxkbx3ay/iY8K58c2FLKmCgWFhYYwxVUCDmpG8P6oXdWLCueHNhSyrYlO1WlgYY0wV0bBmFO/f2otaNcK4/s0FzFi93e2SjrCwMMaYKqRRLW9gNK4Vxc1vpfGHD5eyJ/ew22VZWBhjTFWTWDuayWP6ctegVkxelsE5z89m2sptrtZkYWGMMVVQeGgIfzinNV+M6UN8TASj31nEXe8vIfuAO60MCwtjjKnC2jeqyeQxfbjn7NZ89VMm5z4/i69WZFZ6HRYWxhhTxYV5Qrj77FbeYc5rRnLbxMXc8d5iduUcqrQaLCyMMSZAtG0Yx2e39+G+89owfeU2znl+NlOWV04rw8LCGGMCSJgnhDvOPI0v7+xHYu0o7njP28ooKvLvCOKhfj26McYYv2jTIJZPbzuD1+ds5MChAkJCSpvJuuJYWBhjTIAK9YRw28CWlfJadhnKGGNMmSwsjDHGlMnCwhhjTJksLIwxxpTJr2EhIoNFZI2IrBeR+0tZ31REvheRJSKyXEQu8FnXSUTmichKEVkhIpH+rNUYY8yx+e3bUCLiAV4GzgHSgVQRmayqq3w2ewiYpKqvikg7YCqQJCKhwLvAcFVdJiJ1gXx/1WqMMeb4/Nmy6AmsV9UNqnoY+AC4pMQ2CsQ5j2sCGc7jc4HlqroMQFV3qWqhH2s1xhhzHP4Mi8bAVp/n6c4yX48C14tIOt5WxZ3O8taAisg0EVksIn8q7QVEZJSIpIlIWlZWVsVWb4wx5gh/3pRX2u2EJe9HHwZMUNVnRaQ38I6IdHDq6gv0AHKBGSKySFVnHHUw1bHAWAARyRKRzadQbzyw8xT2r2qC7Xwg+M4p2M4Hgu+cgu184Lfn1Kw8O/kzLNKBJj7PE/nfZaZiNwODAVR1ntOJHe/sO0tVdwKIyFSgGzCDY1DVhFMpVkTSVDX5VI5RlQTb+UDwnVOwnQ8E3zkF2/nAyZ+TPy9DpQKtRKS5iIQD1wCTS2yzBRgEICJtgUggC5gGdBKRaKezewCwCmOMMa7wW8tCVQtEZAzeD34PME5VV4rIY0Caqk4G/gi8LiL34L1ENUJVFdgtIs/hDRwFpqrqFH/Vaowx5vj8OpCgqk7F23Htu+xhn8ergD7H2PddvF+frSxjK/G1KkOwnQ8E3zkF2/lA8J1TsJ0PnOQ5ifcPeWOMMebYbLgPY4wxZbKwMMYYU6ZqHxZljV8ViERkkzOe1lIRSXO7nhMlIuNEZIeI/OSzrI6IfCMi65x/a7tZ44k6xjk9KiK/Ou/TUt+x0ao6EWnijOu22hm/7W5neUC+T8c5n0B+jyJFZKGILHPO6a/O8uYissB5jz50vq1a9vGqc5+FM37VWnzGrwKGlRi/KuCIyCYgufg+lUAjIv2BHOBtVe3gLPsnkK2qTzmhXltV/+xmnSfiGOf0KJCjqs+4WdvJEJGGQENVXSwiscAi4FJgBAH4Ph3nfIYSuO+RADVUNUdEwoAfgLuBPwCfquoHIvIasExVXy3reNW9ZVGe8atMJVPV2UB2icWXAG85j9/C+z9ywDjGOQUsVc1U1cXO4/3AarzD+QTk+3Sc8wlY6pXjPA1zfhQ4C/jYWV7u96i6h0V5xq8KRApMF5FFIjLK7WIqSH1VzQTv/9hAPZfrqShjnOH5xwXKJZuSRCQJ6AosIAjepxLnAwH8HomIR0SWAjuAb4BfgD2qWuBsUu7PvOoeFuUZvyoQ9VHVbsD5wB3OJRBT9bwKtAS6AJnAs+6Wc+JEJAb4BPi9qu5zu55TVcr5BPR7pKqFqtoF73BLPYG2pW1WnmNV97Aoz/hVAUdVM5x/dwCf4f2PJNBtd64rF19f3uFyPadMVbc7/zMXAa8TYO+Tcx38E2Ciqn7qLA7Y96m08wn096iYqu4BZgK9gFrOMEpwAp951T0syjN+VUARkRpOBx0iUgPv3CA/HX+vgDAZuNF5fCPwhYu1VIjiD1XHZQTQ++R0nr4JrFbV53xWBeT7dKzzCfD3KEFEajmPo4Cz8fbFfA9c6WxW7veoWn8bCsD5KtwL/G/8qidcLumUiEgLvK0J8A7n8l6gnZOIvA8MxDsC8XbgEeBzYBLQFO8AlFepasB0GB/jnAbivbyhwCZgdPH1/qpORPoCc4AVQJGz+C94r/MH3Pt0nPMZRuC+R53wdmB78DYMJqnqY85nxAdAHWAJcL2qHirzeNU9LIwxxpStul+GMsYYUw4WFsYYY8pkYWGMMaZMFhbGGGPKZGFhjDGmTBYWxpRCRH50/k0SkWsr+Nh/Ke21jKnK7KuzxhyHiAwE7lXVISewj0dVC4+zPkdVYyqiPmMqi7UsjCmFiBSP1vkU0M+Zy+AeZ2C2p0Uk1RlcbrSz/UBnPoT38N7YhYh87gzmuLJ4QEcReQqIco430fe1xOtpEflJvPORXO1z7Jki8rGI/CwiE507jo2pNKFlb2JMtXY/Pi0L50N/r6r2EJEIYK6ITHe27Ql0UNWNzvORqprtDLWQKiKfqOr9IjLGGdytpMvx3i3cGe+d3qkiMttZ1xVoj3ccn7lAH7zzExhTKaxlYcyJORe4wRn2eQFQF2jlrFvoExQAd4nIMmA+3gErW3F8fYH3nYHrtgOzgB4+x053BrRbCiRVyNkYU07WsjDmxAhwp6pOO2qht2/jQInnZwO9VTVXRGYCkeU49rH4jt1TiP2/ayqZtSyMOb79QKzP82nAbc5w1ohIa2d035JqArudoDgd79DQxfKL9y9hNnC10y+SAPQHFlbIWRhziuyvE2OObzlQ4FxOmgD8C+8loMVOJ3MWpU9L+TXwOxFZDqzBeymq2FhguYgsVtXrfJZ/BvQGluEd5fRPqrrNCRtjXGVfnTXGGFMmuwxljDGmTBYWxhhjymRhYYwxpkwWFsYYY8pkYWGMMaZMFhbGGGPKZGFhjDGmTP8PaY+dDIREh9gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "exploration_rate_5 = unique_trajectories_5/seen_trajectories_5\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - c_puct 5\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "\n",
    "plt.plot(x, exploration_rate_5, label=\"unique/seen\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins_5 = [0.73, 0.78, 0.82, 0.89, 0.85, 0.82, 0.78, 0.87, 0.84, 0.87, 0.81, 0.89, 0.83, 0.83, 0.86, 0.85, 0.85, 0.83, 0.93, 0.86, 0.86, 0.86, 0.85, 0.88, 0.84, 0.81, 0.82, 0.75, 0.8, 0.84]\n",
      "draws_5 = [0.01, 0.03, 0.02, 0.0, 0.05, 0.01, 0.02, 0.0, 0.0, 0.0, 0.01, 0.03, 0.01, 0.03, 0.01, 0.0, 0.0, 0.01, 0.0, 0.0, 0.01, 0.03, 0.04, 0.01, 0.01, 0.01, 0.01, 0.03, 0.01, 0.04]\n",
      "losses_5 = [0.26 0.19 0.16 0.11 0.1  0.17 0.2  0.13 0.16 0.13 0.18 0.08 0.16 0.14\n",
      " 0.13 0.15 0.15 0.16 0.07 0.14 0.13 0.11 0.11 0.11 0.15 0.18 0.17 0.22\n",
      " 0.19 0.12]\n",
      "seen_trajectories_5 = [ 100.  200.  300.  400.  500.  600.  700.  800.  900. 1000. 1100. 1200.\n",
      " 1300. 1400. 1500. 1600. 1700. 1800. 1900. 2000. 2100. 2200. 2300. 2400.\n",
      " 2500. 2600. 2700. 2800. 2900. 3000.]\n",
      "unique_trajectories_5 = [ 100.  199.  296.  393.  491.  583.  675.  765.  861.  956. 1049. 1138.\n",
      " 1224. 1316. 1407. 1498. 1587. 1669. 1757. 1834. 1915. 1993. 2077. 2153.\n",
      " 2229. 2309. 2387. 2459. 2526. 2599.]\n"
     ]
    }
   ],
   "source": [
    "print(\"wins_5 =\", wins_5)\n",
    "print(\"draws_5 =\", draws_5)\n",
    "print(\"losses_5 =\", losses_5)\n",
    "print(\"seen_trajectories_5 =\", seen_trajectories_5)\n",
    "print(\"unique_trajectories_5 =\", unique_trajectories_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $c_{puct}$ = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCTS = {\n",
    "    'c_puct': 10,\n",
    "    'dir_alpha': 0.6,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 10,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 10\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 0,\n",
    "    'show_games': False\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.002,\n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 512,\n",
    "    'num_filters_value': 512,\n",
    "    'num_filters_tower': 512,\n",
    "    'num_residual_blocks': 3,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 512\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"tictactoe_c_puct_10\", \"TicTacToe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 4s 952us/step - loss: 6.7498 - value_loss: 1.0751 - policy_loss: 2.3369 - val_loss: 6.6189 - val_value_loss: 0.9454 - val_policy_loss: 2.2052\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.5430 - value_loss: 0.8599 - policy_loss: 2.1392 - val_loss: 6.5222 - val_value_loss: 0.8560 - val_policy_loss: 2.1019\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.4812 - value_loss: 0.8302 - policy_loss: 2.0459 - val_loss: 6.5233 - val_value_loss: 0.9282 - val_policy_loss: 2.0325\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.4053 - value_loss: 0.7440 - policy_loss: 1.9810 - val_loss: 6.4646 - val_value_loss: 0.8617 - val_policy_loss: 1.9821\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.3920 - value_loss: 0.7659 - policy_loss: 1.9330 - val_loss: 6.4419 - val_value_loss: 0.8556 - val_policy_loss: 1.9435\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.3390 - value_loss: 0.6970 - policy_loss: 1.8966 - val_loss: 6.3927 - val_value_loss: 0.7894 - val_policy_loss: 1.9119\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2874 - value_loss: 0.6252 - policy_loss: 1.8659 - val_loss: 6.3745 - val_value_loss: 0.7797 - val_policy_loss: 1.8859\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2793 - value_loss: 0.6334 - policy_loss: 1.8420 - val_loss: 6.3531 - val_value_loss: 0.7591 - val_policy_loss: 1.8644\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2778 - value_loss: 0.6509 - policy_loss: 1.8223 - val_loss: 6.3366 - val_value_loss: 0.7442 - val_policy_loss: 1.8467\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2422 - value_loss: 0.5966 - policy_loss: 1.8059 - val_loss: 6.3571 - val_value_loss: 0.8004 - val_policy_loss: 1.8323\n",
      "Saved model  tictactoe_c_puct_10_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.04\n",
      "Number of seen trajectories: 100\n",
      "Number of unique trajectories: 100\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.3598 - value_loss: 0.8058 - policy_loss: 1.8326 - val_loss: 6.3645 - val_value_loss: 0.8014 - val_policy_loss: 1.8468\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.3111 - value_loss: 0.7310 - policy_loss: 1.8107 - val_loss: 6.3420 - val_value_loss: 0.7706 - val_policy_loss: 1.8331\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2888 - value_loss: 0.7029 - policy_loss: 1.7947 - val_loss: 6.3372 - val_value_loss: 0.7729 - val_policy_loss: 1.8220\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2653 - value_loss: 0.6700 - policy_loss: 1.7812 - val_loss: 6.3240 - val_value_loss: 0.7578 - val_policy_loss: 1.8114\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2503 - value_loss: 0.6528 - policy_loss: 1.7692 - val_loss: 6.3196 - val_value_loss: 0.7572 - val_policy_loss: 1.8039\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2175 - value_loss: 0.5986 - policy_loss: 1.7584 - val_loss: 6.3218 - val_value_loss: 0.7696 - val_policy_loss: 1.7964\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2270 - value_loss: 0.6266 - policy_loss: 1.7500 - val_loss: 6.3021 - val_value_loss: 0.7375 - val_policy_loss: 1.7897\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1974 - value_loss: 0.5758 - policy_loss: 1.7423 - val_loss: 6.3041 - val_value_loss: 0.7477 - val_policy_loss: 1.7842\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1886 - value_loss: 0.5657 - policy_loss: 1.7354 - val_loss: 6.2903 - val_value_loss: 0.7260 - val_policy_loss: 1.7788\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1864 - value_loss: 0.5684 - policy_loss: 1.7290 - val_loss: 6.3087 - val_value_loss: 0.7687 - val_policy_loss: 1.7736\n",
      "Saved model  tictactoe_c_puct_10_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.75 - draw ratio 0.0\n",
      "Number of seen trajectories: 200\n",
      "Number of unique trajectories: 200\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 6.3629 - value_loss: 0.8922 - policy_loss: 1.7588 - val_loss: 6.3807 - val_value_loss: 0.9169 - val_policy_loss: 1.7700\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.3112 - value_loss: 0.7999 - policy_loss: 1.7484 - val_loss: 6.3486 - val_value_loss: 0.8600 - val_policy_loss: 1.7635\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2888 - value_loss: 0.7644 - policy_loss: 1.7397 - val_loss: 6.3216 - val_value_loss: 0.8114 - val_policy_loss: 1.7586\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2566 - value_loss: 0.7079 - policy_loss: 1.7324 - val_loss: 6.3260 - val_value_loss: 0.8254 - val_policy_loss: 1.7541\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2187 - value_loss: 0.6386 - policy_loss: 1.7267 - val_loss: 6.3649 - val_value_loss: 0.9071 - val_policy_loss: 1.7508\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2312 - value_loss: 0.6692 - policy_loss: 1.7215 - val_loss: 6.3175 - val_value_loss: 0.8167 - val_policy_loss: 1.7470\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1925 - value_loss: 0.5971 - policy_loss: 1.7169 - val_loss: 6.3028 - val_value_loss: 0.7910 - val_policy_loss: 1.7440\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1974 - value_loss: 0.6127 - policy_loss: 1.7119 - val_loss: 6.2909 - val_value_loss: 0.7709 - val_policy_loss: 1.7410\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2029 - value_loss: 0.6274 - policy_loss: 1.7087 - val_loss: 6.3271 - val_value_loss: 0.8467 - val_policy_loss: 1.7381\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1860 - value_loss: 0.5978 - policy_loss: 1.7051 - val_loss: 6.2765 - val_value_loss: 0.7491 - val_policy_loss: 1.7351\n",
      "Saved model  tictactoe_c_puct_10_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.71 - draw ratio 0.01\n",
      "Number of seen trajectories: 300\n",
      "Number of unique trajectories: 300\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.2879 - value_loss: 0.7684 - policy_loss: 1.7391 - val_loss: 6.2559 - val_value_loss: 0.6999 - val_policy_loss: 1.7439\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2441 - value_loss: 0.6876 - policy_loss: 1.7328 - val_loss: 6.2724 - val_value_loss: 0.7366 - val_policy_loss: 1.7408\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2120 - value_loss: 0.6288 - policy_loss: 1.7280 - val_loss: 6.2488 - val_value_loss: 0.6923 - val_policy_loss: 1.7386\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1877 - value_loss: 0.5853 - policy_loss: 1.7235 - val_loss: 6.2439 - val_value_loss: 0.6855 - val_policy_loss: 1.7363\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1743 - value_loss: 0.5630 - policy_loss: 1.7198 - val_loss: 6.2417 - val_value_loss: 0.6840 - val_policy_loss: 1.7339\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1665 - value_loss: 0.5498 - policy_loss: 1.7180 - val_loss: 6.2314 - val_value_loss: 0.6658 - val_policy_loss: 1.7323\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1569 - value_loss: 0.5350 - policy_loss: 1.7141 - val_loss: 6.2272 - val_value_loss: 0.6600 - val_policy_loss: 1.7302\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1507 - value_loss: 0.5266 - policy_loss: 1.7110 - val_loss: 6.2328 - val_value_loss: 0.6737 - val_policy_loss: 1.7284\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1618 - value_loss: 0.5513 - policy_loss: 1.7089 - val_loss: 6.2390 - val_value_loss: 0.6887 - val_policy_loss: 1.7263\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1542 - value_loss: 0.5391 - policy_loss: 1.7068 - val_loss: 6.2503 - val_value_loss: 0.7134 - val_policy_loss: 1.7249\n",
      "Saved model  tictactoe_c_puct_10_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.73 - draw ratio 0.01\n",
      "Number of seen trajectories: 400\n",
      "Number of unique trajectories: 400\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.2830 - value_loss: 0.7732 - policy_loss: 1.7307 - val_loss: 6.2519 - val_value_loss: 0.6842 - val_policy_loss: 1.7580\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2246 - value_loss: 0.6617 - policy_loss: 1.7261 - val_loss: 6.2520 - val_value_loss: 0.6866 - val_policy_loss: 1.7564\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1971 - value_loss: 0.6109 - policy_loss: 1.7226 - val_loss: 6.2359 - val_value_loss: 0.6568 - val_policy_loss: 1.7546\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1918 - value_loss: 0.6045 - policy_loss: 1.7191 - val_loss: 6.2447 - val_value_loss: 0.6764 - val_policy_loss: 1.7534\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1800 - value_loss: 0.5836 - policy_loss: 1.7169 - val_loss: 6.2317 - val_value_loss: 0.6518 - val_policy_loss: 1.7525\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1711 - value_loss: 0.5693 - policy_loss: 1.7142 - val_loss: 6.2302 - val_value_loss: 0.6511 - val_policy_loss: 1.7508\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1611 - value_loss: 0.5523 - policy_loss: 1.7118 - val_loss: 6.2292 - val_value_loss: 0.6505 - val_policy_loss: 1.7501\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1474 - value_loss: 0.5278 - policy_loss: 1.7095 - val_loss: 6.2382 - val_value_loss: 0.6710 - val_policy_loss: 1.7482\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1418 - value_loss: 0.5190 - policy_loss: 1.7077 - val_loss: 6.2460 - val_value_loss: 0.6881 - val_policy_loss: 1.7474\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1406 - value_loss: 0.5187 - policy_loss: 1.7063 - val_loss: 6.2260 - val_value_loss: 0.6498 - val_policy_loss: 1.7463\n",
      "Saved model  tictactoe_c_puct_10_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.02\n",
      "Number of seen trajectories: 500\n",
      "Number of unique trajectories: 494\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.2769 - value_loss: 0.8048 - policy_loss: 1.6933 - val_loss: 6.2595 - val_value_loss: 0.7989 - val_policy_loss: 1.6646\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2458 - value_loss: 0.7458 - policy_loss: 1.6905 - val_loss: 6.2521 - val_value_loss: 0.7853 - val_policy_loss: 1.6637\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2272 - value_loss: 0.7102 - policy_loss: 1.6892 - val_loss: 6.2465 - val_value_loss: 0.7753 - val_policy_loss: 1.6628\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2098 - value_loss: 0.6779 - policy_loss: 1.6870 - val_loss: 6.2388 - val_value_loss: 0.7608 - val_policy_loss: 1.6623\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1963 - value_loss: 0.6531 - policy_loss: 1.6851 - val_loss: 6.2390 - val_value_loss: 0.7620 - val_policy_loss: 1.6618\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1882 - value_loss: 0.6383 - policy_loss: 1.6840 - val_loss: 6.2392 - val_value_loss: 0.7632 - val_policy_loss: 1.6612\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1775 - value_loss: 0.6178 - policy_loss: 1.6833 - val_loss: 6.2292 - val_value_loss: 0.7440 - val_policy_loss: 1.6608\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1689 - value_loss: 0.6024 - policy_loss: 1.6820 - val_loss: 6.2307 - val_value_loss: 0.7478 - val_policy_loss: 1.6602\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1610 - value_loss: 0.5889 - policy_loss: 1.6800 - val_loss: 6.2286 - val_value_loss: 0.7445 - val_policy_loss: 1.6597\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1560 - value_loss: 0.5803 - policy_loss: 1.6789 - val_loss: 6.2242 - val_value_loss: 0.7368 - val_policy_loss: 1.6591\n",
      "Saved model  tictactoe_c_puct_10_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.01\n",
      "Number of seen trajectories: 600\n",
      "Number of unique trajectories: 592\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 6.2519 - value_loss: 0.7743 - policy_loss: 1.6770 - val_loss: 6.2740 - val_value_loss: 0.7810 - val_policy_loss: 1.7146\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2181 - value_loss: 0.7093 - policy_loss: 1.6747 - val_loss: 6.2651 - val_value_loss: 0.7640 - val_policy_loss: 1.7141\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1951 - value_loss: 0.6658 - policy_loss: 1.6726 - val_loss: 6.2623 - val_value_loss: 0.7597 - val_policy_loss: 1.7132\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1826 - value_loss: 0.6424 - policy_loss: 1.6713 - val_loss: 6.2532 - val_value_loss: 0.7424 - val_policy_loss: 1.7127\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1668 - value_loss: 0.6125 - policy_loss: 1.6699 - val_loss: 6.2514 - val_value_loss: 0.7397 - val_policy_loss: 1.7119\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1589 - value_loss: 0.5976 - policy_loss: 1.6693 - val_loss: 6.2465 - val_value_loss: 0.7309 - val_policy_loss: 1.7113\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1476 - value_loss: 0.5773 - policy_loss: 1.6674 - val_loss: 6.2437 - val_value_loss: 0.7261 - val_policy_loss: 1.7108\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1388 - value_loss: 0.5615 - policy_loss: 1.6658 - val_loss: 6.2395 - val_value_loss: 0.7187 - val_policy_loss: 1.7101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1323 - value_loss: 0.5495 - policy_loss: 1.6651 - val_loss: 6.2357 - val_value_loss: 0.7119 - val_policy_loss: 1.7096\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1284 - value_loss: 0.5433 - policy_loss: 1.6639 - val_loss: 6.2354 - val_value_loss: 0.7123 - val_policy_loss: 1.7090\n",
      "Saved model  tictactoe_c_puct_10_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.81 - draw ratio 0.02\n",
      "Number of seen trajectories: 700\n",
      "Number of unique trajectories: 689\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.2164 - value_loss: 0.6799 - policy_loss: 1.7036 - val_loss: 6.1688 - val_value_loss: 0.6062 - val_policy_loss: 1.6823\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1901 - value_loss: 0.6293 - policy_loss: 1.7018 - val_loss: 6.1624 - val_value_loss: 0.5949 - val_policy_loss: 1.6812\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1748 - value_loss: 0.6007 - policy_loss: 1.7003 - val_loss: 6.1588 - val_value_loss: 0.5893 - val_policy_loss: 1.6799\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1639 - value_loss: 0.5804 - policy_loss: 1.6991 - val_loss: 6.1547 - val_value_loss: 0.5823 - val_policy_loss: 1.6790\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1522 - value_loss: 0.5592 - policy_loss: 1.6972 - val_loss: 6.1542 - val_value_loss: 0.5820 - val_policy_loss: 1.6784\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1442 - value_loss: 0.5442 - policy_loss: 1.6965 - val_loss: 6.1509 - val_value_loss: 0.5766 - val_policy_loss: 1.6776\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1391 - value_loss: 0.5356 - policy_loss: 1.6952 - val_loss: 6.1495 - val_value_loss: 0.5746 - val_policy_loss: 1.6771\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1314 - value_loss: 0.5212 - policy_loss: 1.6944 - val_loss: 6.1489 - val_value_loss: 0.5743 - val_policy_loss: 1.6765\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1282 - value_loss: 0.5166 - policy_loss: 1.6931 - val_loss: 6.1465 - val_value_loss: 0.5705 - val_policy_loss: 1.6760\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1213 - value_loss: 0.5037 - policy_loss: 1.6925 - val_loss: 6.1466 - val_value_loss: 0.5714 - val_policy_loss: 1.6755\n",
      "Saved model  tictactoe_c_puct_10_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.72 - draw ratio 0.03\n",
      "Number of seen trajectories: 800\n",
      "Number of unique trajectories: 785\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2339 - value_loss: 0.7331 - policy_loss: 1.6886 - val_loss: 6.2272 - val_value_loss: 0.7246 - val_policy_loss: 1.6838\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2106 - value_loss: 0.6882 - policy_loss: 1.6872 - val_loss: 6.2220 - val_value_loss: 0.7153 - val_policy_loss: 1.6831\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1960 - value_loss: 0.6607 - policy_loss: 1.6858 - val_loss: 6.2226 - val_value_loss: 0.7172 - val_policy_loss: 1.6827\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1812 - value_loss: 0.6326 - policy_loss: 1.6846 - val_loss: 6.2185 - val_value_loss: 0.7098 - val_policy_loss: 1.6822\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1693 - value_loss: 0.6101 - policy_loss: 1.6837 - val_loss: 6.2192 - val_value_loss: 0.7120 - val_policy_loss: 1.6818\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1616 - value_loss: 0.5956 - policy_loss: 1.6831 - val_loss: 6.2154 - val_value_loss: 0.7048 - val_policy_loss: 1.6816\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1531 - value_loss: 0.5799 - policy_loss: 1.6821 - val_loss: 6.2152 - val_value_loss: 0.7052 - val_policy_loss: 1.6812\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1477 - value_loss: 0.5705 - policy_loss: 1.6809 - val_loss: 6.2155 - val_value_loss: 0.7064 - val_policy_loss: 1.6808\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1403 - value_loss: 0.5567 - policy_loss: 1.6804 - val_loss: 6.2117 - val_value_loss: 0.6995 - val_policy_loss: 1.6806\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1354 - value_loss: 0.5479 - policy_loss: 1.6796 - val_loss: 6.2114 - val_value_loss: 0.6995 - val_policy_loss: 1.6802\n",
      "Saved model  tictactoe_c_puct_10_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.75 - draw ratio 0.02\n",
      "Number of seen trajectories: 900\n",
      "Number of unique trajectories: 880\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 6.2523 - value_loss: 0.7613 - policy_loss: 1.7003 - val_loss: 6.2668 - val_value_loss: 0.7657 - val_policy_loss: 1.7251\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2221 - value_loss: 0.7031 - policy_loss: 1.6985 - val_loss: 6.2599 - val_value_loss: 0.7527 - val_policy_loss: 1.7247\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2013 - value_loss: 0.6635 - policy_loss: 1.6968 - val_loss: 6.2560 - val_value_loss: 0.7457 - val_policy_loss: 1.7242\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1886 - value_loss: 0.6385 - policy_loss: 1.6966 - val_loss: 6.2535 - val_value_loss: 0.7413 - val_policy_loss: 1.7239\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1763 - value_loss: 0.6160 - policy_loss: 1.6950 - val_loss: 6.2535 - val_value_loss: 0.7418 - val_policy_loss: 1.7236\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1670 - value_loss: 0.5987 - policy_loss: 1.6939 - val_loss: 6.2505 - val_value_loss: 0.7366 - val_policy_loss: 1.7234\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1603 - value_loss: 0.5861 - policy_loss: 1.6935 - val_loss: 6.2523 - val_value_loss: 0.7408 - val_policy_loss: 1.7230\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1533 - value_loss: 0.5728 - policy_loss: 1.6931 - val_loss: 6.2521 - val_value_loss: 0.7409 - val_policy_loss: 1.7228\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1457 - value_loss: 0.5587 - policy_loss: 1.6923 - val_loss: 6.2476 - val_value_loss: 0.7326 - val_policy_loss: 1.7224\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1407 - value_loss: 0.5499 - policy_loss: 1.6914 - val_loss: 6.2481 - val_value_loss: 0.7341 - val_policy_loss: 1.7222\n",
      "Saved model  tictactoe_c_puct_10_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.89 - draw ratio 0.01\n",
      "Number of seen trajectories: 1000\n",
      "Number of unique trajectories: 978\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2267 - value_loss: 0.6952 - policy_loss: 1.7184 - val_loss: 6.2284 - val_value_loss: 0.6946 - val_policy_loss: 1.7225\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2111 - value_loss: 0.6649 - policy_loss: 1.7176 - val_loss: 6.2235 - val_value_loss: 0.6855 - val_policy_loss: 1.7220\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2008 - value_loss: 0.6453 - policy_loss: 1.7168 - val_loss: 6.2188 - val_value_loss: 0.6766 - val_policy_loss: 1.7216\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1917 - value_loss: 0.6280 - policy_loss: 1.7160 - val_loss: 6.2159 - val_value_loss: 0.6713 - val_policy_loss: 1.7213\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1845 - value_loss: 0.6143 - policy_loss: 1.7156 - val_loss: 6.2116 - val_value_loss: 0.6632 - val_policy_loss: 1.7210\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1781 - value_loss: 0.6021 - policy_loss: 1.7152 - val_loss: 6.2092 - val_value_loss: 0.6587 - val_policy_loss: 1.7208\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1725 - value_loss: 0.5917 - policy_loss: 1.7143 - val_loss: 6.2067 - val_value_loss: 0.6541 - val_policy_loss: 1.7206\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1674 - value_loss: 0.5822 - policy_loss: 1.7139 - val_loss: 6.2053 - val_value_loss: 0.6517 - val_policy_loss: 1.7204\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1632 - value_loss: 0.5740 - policy_loss: 1.7140 - val_loss: 6.2028 - val_value_loss: 0.6469 - val_policy_loss: 1.7202\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1588 - value_loss: 0.5660 - policy_loss: 1.7132 - val_loss: 6.2024 - val_value_loss: 0.6466 - val_policy_loss: 1.7199\n",
      "Saved model  tictactoe_c_puct_10_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.02\n",
      "Number of seen trajectories: 1100\n",
      "Number of unique trajectories: 1074\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 181us/step - loss: 6.2024 - value_loss: 0.6722 - policy_loss: 1.6945 - val_loss: 6.1617 - val_value_loss: 0.6415 - val_policy_loss: 1.6438\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1876 - value_loss: 0.6434 - policy_loss: 1.6937 - val_loss: 6.1596 - val_value_loss: 0.6376 - val_policy_loss: 1.6436\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1773 - value_loss: 0.6236 - policy_loss: 1.6932 - val_loss: 6.1561 - val_value_loss: 0.6311 - val_policy_loss: 1.6433\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1677 - value_loss: 0.6053 - policy_loss: 1.6923 - val_loss: 6.1554 - val_value_loss: 0.6300 - val_policy_loss: 1.6431\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1615 - value_loss: 0.5935 - policy_loss: 1.6919 - val_loss: 6.1523 - val_value_loss: 0.6242 - val_policy_loss: 1.6429\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1538 - value_loss: 0.5785 - policy_loss: 1.6916 - val_loss: 6.1506 - val_value_loss: 0.6212 - val_policy_loss: 1.6426\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1499 - value_loss: 0.5715 - policy_loss: 1.6910 - val_loss: 6.1476 - val_value_loss: 0.6156 - val_policy_loss: 1.6425\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1439 - value_loss: 0.5602 - policy_loss: 1.6906 - val_loss: 6.1467 - val_value_loss: 0.6142 - val_policy_loss: 1.6423\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1406 - value_loss: 0.5540 - policy_loss: 1.6903 - val_loss: 6.1457 - val_value_loss: 0.6123 - val_policy_loss: 1.6422\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1351 - value_loss: 0.5440 - policy_loss: 1.6896 - val_loss: 6.1436 - val_value_loss: 0.6086 - val_policy_loss: 1.6420\n",
      "Saved model  tictactoe_c_puct_10_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.83 - draw ratio 0.02\n",
      "Number of seen trajectories: 1200\n",
      "Number of unique trajectories: 1167\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.2429 - value_loss: 0.7809 - policy_loss: 1.6683 - val_loss: 6.2334 - val_value_loss: 0.7660 - val_policy_loss: 1.6643\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2269 - value_loss: 0.7503 - policy_loss: 1.6672 - val_loss: 6.2252 - val_value_loss: 0.7502 - val_policy_loss: 1.6638\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2159 - value_loss: 0.7293 - policy_loss: 1.6663 - val_loss: 6.2206 - val_value_loss: 0.7414 - val_policy_loss: 1.6635\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2058 - value_loss: 0.7098 - policy_loss: 1.6657 - val_loss: 6.2177 - val_value_loss: 0.7362 - val_policy_loss: 1.6633\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1968 - value_loss: 0.6926 - policy_loss: 1.6649 - val_loss: 6.2153 - val_value_loss: 0.7315 - val_policy_loss: 1.6632\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1893 - value_loss: 0.6785 - policy_loss: 1.6644 - val_loss: 6.2131 - val_value_loss: 0.7274 - val_policy_loss: 1.6630\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1829 - value_loss: 0.6663 - policy_loss: 1.6639 - val_loss: 6.2100 - val_value_loss: 0.7216 - val_policy_loss: 1.6629\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1767 - value_loss: 0.6545 - policy_loss: 1.6633 - val_loss: 6.2090 - val_value_loss: 0.7200 - val_policy_loss: 1.6627\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1695 - value_loss: 0.6408 - policy_loss: 1.6628 - val_loss: 6.2059 - val_value_loss: 0.7139 - val_policy_loss: 1.6626\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1640 - value_loss: 0.6305 - policy_loss: 1.6623 - val_loss: 6.2037 - val_value_loss: 0.7099 - val_policy_loss: 1.6625\n",
      "Saved model  tictactoe_c_puct_10_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.02\n",
      "Number of seen trajectories: 1300\n",
      "Number of unique trajectories: 1264\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2560 - value_loss: 0.7970 - policy_loss: 1.6800 - val_loss: 6.2314 - val_value_loss: 0.7641 - val_policy_loss: 1.6638\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2343 - value_loss: 0.7550 - policy_loss: 1.6787 - val_loss: 6.2233 - val_value_loss: 0.7484 - val_policy_loss: 1.6634\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2215 - value_loss: 0.7305 - policy_loss: 1.6779 - val_loss: 6.2206 - val_value_loss: 0.7436 - val_policy_loss: 1.6630\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2119 - value_loss: 0.7122 - policy_loss: 1.6771 - val_loss: 6.2168 - val_value_loss: 0.7365 - val_policy_loss: 1.6627\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2033 - value_loss: 0.6955 - policy_loss: 1.6768 - val_loss: 6.2147 - val_value_loss: 0.7326 - val_policy_loss: 1.6625\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1980 - value_loss: 0.6854 - policy_loss: 1.6765 - val_loss: 6.2143 - val_value_loss: 0.7322 - val_policy_loss: 1.6622\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1910 - value_loss: 0.6719 - policy_loss: 1.6762 - val_loss: 6.2116 - val_value_loss: 0.7273 - val_policy_loss: 1.6620\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1842 - value_loss: 0.6595 - policy_loss: 1.6751 - val_loss: 6.2096 - val_value_loss: 0.7237 - val_policy_loss: 1.6618\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1794 - value_loss: 0.6502 - policy_loss: 1.6748 - val_loss: 6.2082 - val_value_loss: 0.7212 - val_policy_loss: 1.6616\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1739 - value_loss: 0.6397 - policy_loss: 1.6745 - val_loss: 6.2082 - val_value_loss: 0.7215 - val_policy_loss: 1.6614\n",
      "Saved model  tictactoe_c_puct_10_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.02\n",
      "Number of seen trajectories: 1400\n",
      "Number of unique trajectories: 1354\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 6.2543 - value_loss: 0.7896 - policy_loss: 1.6856 - val_loss: 6.2647 - val_value_loss: 0.8192 - val_policy_loss: 1.6768\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2364 - value_loss: 0.7547 - policy_loss: 1.6848 - val_loss: 6.2585 - val_value_loss: 0.8074 - val_policy_loss: 1.6765\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2217 - value_loss: 0.7266 - policy_loss: 1.6838 - val_loss: 6.2551 - val_value_loss: 0.8009 - val_policy_loss: 1.6763\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2117 - value_loss: 0.7068 - policy_loss: 1.6836 - val_loss: 6.2516 - val_value_loss: 0.7944 - val_policy_loss: 1.6761\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2003 - value_loss: 0.6857 - policy_loss: 1.6822 - val_loss: 6.2488 - val_value_loss: 0.7890 - val_policy_loss: 1.6758\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1930 - value_loss: 0.6711 - policy_loss: 1.6823 - val_loss: 6.2470 - val_value_loss: 0.7858 - val_policy_loss: 1.6756\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1854 - value_loss: 0.6563 - policy_loss: 1.6821 - val_loss: 6.2452 - val_value_loss: 0.7826 - val_policy_loss: 1.6754\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1783 - value_loss: 0.6431 - policy_loss: 1.6813 - val_loss: 6.2447 - val_value_loss: 0.7821 - val_policy_loss: 1.6752\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1729 - value_loss: 0.6332 - policy_loss: 1.6806 - val_loss: 6.2428 - val_value_loss: 0.7786 - val_policy_loss: 1.6750\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1678 - value_loss: 0.6232 - policy_loss: 1.6805 - val_loss: 6.2434 - val_value_loss: 0.7803 - val_policy_loss: 1.6748\n",
      "Saved model  tictactoe_c_puct_10_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.06\n",
      "Number of seen trajectories: 1500\n",
      "Number of unique trajectories: 1448\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2290 - value_loss: 0.7363 - policy_loss: 1.6900 - val_loss: 6.2081 - val_value_loss: 0.7168 - val_policy_loss: 1.6676\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2163 - value_loss: 0.7112 - policy_loss: 1.6896 - val_loss: 6.2023 - val_value_loss: 0.7056 - val_policy_loss: 1.6673\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2084 - value_loss: 0.6962 - policy_loss: 1.6889 - val_loss: 6.1986 - val_value_loss: 0.6984 - val_policy_loss: 1.6671\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2020 - value_loss: 0.6832 - policy_loss: 1.6892 - val_loss: 6.1958 - val_value_loss: 0.6931 - val_policy_loss: 1.6669\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1963 - value_loss: 0.6726 - policy_loss: 1.6884 - val_loss: 6.1938 - val_value_loss: 0.6894 - val_policy_loss: 1.6668\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1906 - value_loss: 0.6619 - policy_loss: 1.6879 - val_loss: 6.1924 - val_value_loss: 0.6867 - val_policy_loss: 1.6666\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1867 - value_loss: 0.6546 - policy_loss: 1.6876 - val_loss: 6.1917 - val_value_loss: 0.6856 - val_policy_loss: 1.6665\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1834 - value_loss: 0.6479 - policy_loss: 1.6877 - val_loss: 6.1896 - val_value_loss: 0.6817 - val_policy_loss: 1.6664\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1791 - value_loss: 0.6398 - policy_loss: 1.6872 - val_loss: 6.1891 - val_value_loss: 0.6809 - val_policy_loss: 1.6663\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1744 - value_loss: 0.6308 - policy_loss: 1.6869 - val_loss: 6.1888 - val_value_loss: 0.6804 - val_policy_loss: 1.6662\n",
      "Saved model  tictactoe_c_puct_10_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.03\n",
      "Number of seen trajectories: 1600\n",
      "Number of unique trajectories: 1540\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1837 - value_loss: 0.6520 - policy_loss: 1.6844 - val_loss: 6.1824 - val_value_loss: 0.6547 - val_policy_loss: 1.6791\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.1717 - value_loss: 0.6283 - policy_loss: 1.6841 - val_loss: 6.1768 - val_value_loss: 0.6436 - val_policy_loss: 1.6790\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1653 - value_loss: 0.6160 - policy_loss: 1.6836 - val_loss: 6.1740 - val_value_loss: 0.6382 - val_policy_loss: 1.6789\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1608 - value_loss: 0.6074 - policy_loss: 1.6835 - val_loss: 6.1717 - val_value_loss: 0.6339 - val_policy_loss: 1.6788\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1567 - value_loss: 0.5998 - policy_loss: 1.6829 - val_loss: 6.1695 - val_value_loss: 0.6296 - val_policy_loss: 1.6787\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1519 - value_loss: 0.5906 - policy_loss: 1.6826 - val_loss: 6.1674 - val_value_loss: 0.6256 - val_policy_loss: 1.6786\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1483 - value_loss: 0.5835 - policy_loss: 1.6826 - val_loss: 6.1659 - val_value_loss: 0.6228 - val_policy_loss: 1.6785\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1452 - value_loss: 0.5776 - policy_loss: 1.6822 - val_loss: 6.1644 - val_value_loss: 0.6200 - val_policy_loss: 1.6783\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1422 - value_loss: 0.5719 - policy_loss: 1.6820 - val_loss: 6.1630 - val_value_loss: 0.6175 - val_policy_loss: 1.6782\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1395 - value_loss: 0.5670 - policy_loss: 1.6817 - val_loss: 6.1617 - val_value_loss: 0.6150 - val_policy_loss: 1.6781\n",
      "Saved model  tictactoe_c_puct_10_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.03\n",
      "Number of seen trajectories: 1700\n",
      "Number of unique trajectories: 1634\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 184us/step - loss: 6.2061 - value_loss: 0.7049 - policy_loss: 1.6771 - val_loss: 6.2030 - val_value_loss: 0.6830 - val_policy_loss: 1.6928\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1965 - value_loss: 0.6861 - policy_loss: 1.6768 - val_loss: 6.1998 - val_value_loss: 0.6767 - val_policy_loss: 1.6927\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1877 - value_loss: 0.6689 - policy_loss: 1.6764 - val_loss: 6.1974 - val_value_loss: 0.6722 - val_policy_loss: 1.6926\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1809 - value_loss: 0.6555 - policy_loss: 1.6762 - val_loss: 6.1944 - val_value_loss: 0.6663 - val_policy_loss: 1.6925\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1747 - value_loss: 0.6439 - policy_loss: 1.6757 - val_loss: 6.1922 - val_value_loss: 0.6621 - val_policy_loss: 1.6924\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1701 - value_loss: 0.6346 - policy_loss: 1.6757 - val_loss: 6.1908 - val_value_loss: 0.6596 - val_policy_loss: 1.6923\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1656 - value_loss: 0.6256 - policy_loss: 1.6759 - val_loss: 6.1893 - val_value_loss: 0.6567 - val_policy_loss: 1.6922\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1615 - value_loss: 0.6183 - policy_loss: 1.6750 - val_loss: 6.1881 - val_value_loss: 0.6544 - val_policy_loss: 1.6921\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1568 - value_loss: 0.6092 - policy_loss: 1.6747 - val_loss: 6.1868 - val_value_loss: 0.6520 - val_policy_loss: 1.6920\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1546 - value_loss: 0.6046 - policy_loss: 1.6752 - val_loss: 6.1855 - val_value_loss: 0.6497 - val_policy_loss: 1.6920\n",
      "Saved model  tictactoe_c_puct_10_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.04\n",
      "Number of seen trajectories: 1800\n",
      "Number of unique trajectories: 1728\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 180us/step - loss: 6.2267 - value_loss: 0.7400 - policy_loss: 1.6840 - val_loss: 6.2114 - val_value_loss: 0.7261 - val_policy_loss: 1.6673\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.2132 - value_loss: 0.7140 - policy_loss: 1.6831 - val_loss: 6.2071 - val_value_loss: 0.7177 - val_policy_loss: 1.6672\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.2049 - value_loss: 0.6974 - policy_loss: 1.6831 - val_loss: 6.2036 - val_value_loss: 0.7110 - val_policy_loss: 1.6670\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1984 - value_loss: 0.6851 - policy_loss: 1.6826 - val_loss: 6.2019 - val_value_loss: 0.7078 - val_policy_loss: 1.6669\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 6.1939 - value_loss: 0.6765 - policy_loss: 1.6822 - val_loss: 6.2000 - val_value_loss: 0.7040 - val_policy_loss: 1.6668\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1884 - value_loss: 0.6656 - policy_loss: 1.6821 - val_loss: 6.1987 - val_value_loss: 0.7017 - val_policy_loss: 1.6668\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1850 - value_loss: 0.6594 - policy_loss: 1.6816 - val_loss: 6.1974 - val_value_loss: 0.6993 - val_policy_loss: 1.6667\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1811 - value_loss: 0.6513 - policy_loss: 1.6819 - val_loss: 6.1962 - val_value_loss: 0.6970 - val_policy_loss: 1.6666\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1768 - value_loss: 0.6435 - policy_loss: 1.6812 - val_loss: 6.1950 - val_value_loss: 0.6948 - val_policy_loss: 1.6665\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1743 - value_loss: 0.6385 - policy_loss: 1.6814 - val_loss: 6.1937 - val_value_loss: 0.6923 - val_policy_loss: 1.6664\n",
      "Saved model  tictactoe_c_puct_10_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.02\n",
      "Number of seen trajectories: 1900\n",
      "Number of unique trajectories: 1817\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 6.2210 - value_loss: 0.7185 - policy_loss: 1.6950 - val_loss: 6.2281 - val_value_loss: 0.7156 - val_policy_loss: 1.7119\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2108 - value_loss: 0.6979 - policy_loss: 1.6951 - val_loss: 6.2249 - val_value_loss: 0.7095 - val_policy_loss: 1.7117\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.2034 - value_loss: 0.6839 - policy_loss: 1.6944 - val_loss: 6.2221 - val_value_loss: 0.7042 - val_policy_loss: 1.7116\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1975 - value_loss: 0.6723 - policy_loss: 1.6942 - val_loss: 6.2217 - val_value_loss: 0.7037 - val_policy_loss: 1.7115\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1924 - value_loss: 0.6626 - policy_loss: 1.6939 - val_loss: 6.2207 - val_value_loss: 0.7018 - val_policy_loss: 1.7114\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1875 - value_loss: 0.6534 - policy_loss: 1.6934 - val_loss: 6.2178 - val_value_loss: 0.6962 - val_policy_loss: 1.7113\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1837 - value_loss: 0.6458 - policy_loss: 1.6934 - val_loss: 6.2186 - val_value_loss: 0.6979 - val_policy_loss: 1.7112\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1811 - value_loss: 0.6414 - policy_loss: 1.6928 - val_loss: 6.2169 - val_value_loss: 0.6948 - val_policy_loss: 1.7111\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1756 - value_loss: 0.6303 - policy_loss: 1.6928 - val_loss: 6.2186 - val_value_loss: 0.6982 - val_policy_loss: 1.7111\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1733 - value_loss: 0.6261 - policy_loss: 1.6926 - val_loss: 6.2158 - val_value_loss: 0.6927 - val_policy_loss: 1.7110\n",
      "Saved model  tictactoe_c_puct_10_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.01\n",
      "Number of seen trajectories: 2000\n",
      "Number of unique trajectories: 1908\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.1959 - value_loss: 0.6553 - policy_loss: 1.7086 - val_loss: 6.1879 - val_value_loss: 0.6367 - val_policy_loss: 1.7113\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1873 - value_loss: 0.6387 - policy_loss: 1.7081 - val_loss: 6.1836 - val_value_loss: 0.6283 - val_policy_loss: 1.7111\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1819 - value_loss: 0.6285 - policy_loss: 1.7075 - val_loss: 6.1804 - val_value_loss: 0.6220 - val_policy_loss: 1.7110\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1790 - value_loss: 0.6224 - policy_loss: 1.7078 - val_loss: 6.1779 - val_value_loss: 0.6173 - val_policy_loss: 1.7108\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1749 - value_loss: 0.6147 - policy_loss: 1.7075 - val_loss: 6.1760 - val_value_loss: 0.6135 - val_policy_loss: 1.7107\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1722 - value_loss: 0.6097 - policy_loss: 1.7072 - val_loss: 6.1742 - val_value_loss: 0.6102 - val_policy_loss: 1.7106\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1690 - value_loss: 0.6038 - policy_loss: 1.7067 - val_loss: 6.1728 - val_value_loss: 0.6075 - val_policy_loss: 1.7106\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1668 - value_loss: 0.5992 - policy_loss: 1.7068 - val_loss: 6.1717 - val_value_loss: 0.6054 - val_policy_loss: 1.7105\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1644 - value_loss: 0.5947 - policy_loss: 1.7065 - val_loss: 6.1706 - val_value_loss: 0.6033 - val_policy_loss: 1.7104\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1632 - value_loss: 0.5921 - policy_loss: 1.7068 - val_loss: 6.1695 - val_value_loss: 0.6012 - val_policy_loss: 1.7104\n",
      "Saved model  tictactoe_c_puct_10_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.02\n",
      "Number of seen trajectories: 2100\n",
      "Number of unique trajectories: 1997\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.1931 - value_loss: 0.6700 - policy_loss: 1.6888 - val_loss: 6.1885 - val_value_loss: 0.6522 - val_policy_loss: 1.6974\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 6.1880 - value_loss: 0.6600 - policy_loss: 1.6885 - val_loss: 6.1871 - val_value_loss: 0.6495 - val_policy_loss: 1.6973\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1844 - value_loss: 0.6533 - policy_loss: 1.6882 - val_loss: 6.1860 - val_value_loss: 0.6473 - val_policy_loss: 1.6973\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1815 - value_loss: 0.6470 - policy_loss: 1.6886 - val_loss: 6.1850 - val_value_loss: 0.6455 - val_policy_loss: 1.6972\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1789 - value_loss: 0.6422 - policy_loss: 1.6883 - val_loss: 6.1842 - val_value_loss: 0.6440 - val_policy_loss: 1.6972\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1755 - value_loss: 0.6361 - policy_loss: 1.6878 - val_loss: 6.1835 - val_value_loss: 0.6428 - val_policy_loss: 1.6971\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1733 - value_loss: 0.6319 - policy_loss: 1.6875 - val_loss: 6.1830 - val_value_loss: 0.6417 - val_policy_loss: 1.6971\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1713 - value_loss: 0.6277 - policy_loss: 1.6878 - val_loss: 6.1824 - val_value_loss: 0.6407 - val_policy_loss: 1.6970\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1680 - value_loss: 0.6216 - policy_loss: 1.6874 - val_loss: 6.1818 - val_value_loss: 0.6395 - val_policy_loss: 1.6970\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1666 - value_loss: 0.6189 - policy_loss: 1.6871 - val_loss: 6.1814 - val_value_loss: 0.6388 - val_policy_loss: 1.6970\n",
      "Saved model  tictactoe_c_puct_10_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.77 - draw ratio 0.05\n",
      "Number of seen trajectories: 2200\n",
      "Number of unique trajectories: 2081\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 181us/step - loss: 6.2197 - value_loss: 0.7218 - policy_loss: 1.6906 - val_loss: 6.2264 - val_value_loss: 0.7295 - val_policy_loss: 1.6963\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2140 - value_loss: 0.7108 - policy_loss: 1.6902 - val_loss: 6.2252 - val_value_loss: 0.7271 - val_policy_loss: 1.6962\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2105 - value_loss: 0.7041 - policy_loss: 1.6899 - val_loss: 6.2236 - val_value_loss: 0.7241 - val_policy_loss: 1.6961\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2072 - value_loss: 0.6979 - policy_loss: 1.6895 - val_loss: 6.2229 - val_value_loss: 0.7228 - val_policy_loss: 1.6960\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2031 - value_loss: 0.6899 - policy_loss: 1.6894 - val_loss: 6.2219 - val_value_loss: 0.7210 - val_policy_loss: 1.6960\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2000 - value_loss: 0.6835 - policy_loss: 1.6896 - val_loss: 6.2207 - val_value_loss: 0.7187 - val_policy_loss: 1.6959\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1977 - value_loss: 0.6790 - policy_loss: 1.6895 - val_loss: 6.2202 - val_value_loss: 0.7178 - val_policy_loss: 1.6958\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1949 - value_loss: 0.6739 - policy_loss: 1.6893 - val_loss: 6.2194 - val_value_loss: 0.7163 - val_policy_loss: 1.6958\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1932 - value_loss: 0.6703 - policy_loss: 1.6894 - val_loss: 6.2192 - val_value_loss: 0.7160 - val_policy_loss: 1.6957\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1898 - value_loss: 0.6639 - policy_loss: 1.6890 - val_loss: 6.2185 - val_value_loss: 0.7147 - val_policy_loss: 1.6957\n",
      "Saved model  tictactoe_c_puct_10_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.77 - draw ratio 0.01\n",
      "Number of seen trajectories: 2300\n",
      "Number of unique trajectories: 2174\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.2397 - value_loss: 0.7514 - policy_loss: 1.7012 - val_loss: 6.2432 - val_value_loss: 0.7769 - val_policy_loss: 1.6829\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2353 - value_loss: 0.7428 - policy_loss: 1.7012 - val_loss: 6.2414 - val_value_loss: 0.7735 - val_policy_loss: 1.6828\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2316 - value_loss: 0.7360 - policy_loss: 1.7005 - val_loss: 6.2399 - val_value_loss: 0.7706 - val_policy_loss: 1.6827\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2302 - value_loss: 0.7329 - policy_loss: 1.7009 - val_loss: 6.2386 - val_value_loss: 0.7682 - val_policy_loss: 1.6826\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2264 - value_loss: 0.7256 - policy_loss: 1.7006 - val_loss: 6.2374 - val_value_loss: 0.7657 - val_policy_loss: 1.6826\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2233 - value_loss: 0.7199 - policy_loss: 1.7003 - val_loss: 6.2360 - val_value_loss: 0.7631 - val_policy_loss: 1.6825\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2206 - value_loss: 0.7146 - policy_loss: 1.7002 - val_loss: 6.2351 - val_value_loss: 0.7614 - val_policy_loss: 1.6825\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2190 - value_loss: 0.7115 - policy_loss: 1.7001 - val_loss: 6.2339 - val_value_loss: 0.7590 - val_policy_loss: 1.6824\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2173 - value_loss: 0.7077 - policy_loss: 1.7005 - val_loss: 6.2329 - val_value_loss: 0.7571 - val_policy_loss: 1.6824\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2138 - value_loss: 0.7015 - policy_loss: 1.6998 - val_loss: 6.2320 - val_value_loss: 0.7553 - val_policy_loss: 1.6824\n",
      "Saved model  tictactoe_c_puct_10_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.91 - draw ratio 0.01\n",
      "Number of seen trajectories: 2400\n",
      "Number of unique trajectories: 2264\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.2112 - value_loss: 0.7017 - policy_loss: 1.6944 - val_loss: 6.1763 - val_value_loss: 0.6462 - val_policy_loss: 1.6801\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2053 - value_loss: 0.6901 - policy_loss: 1.6943 - val_loss: 6.1729 - val_value_loss: 0.6396 - val_policy_loss: 1.6800\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2016 - value_loss: 0.6830 - policy_loss: 1.6940 - val_loss: 6.1713 - val_value_loss: 0.6366 - val_policy_loss: 1.6799\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1981 - value_loss: 0.6763 - policy_loss: 1.6939 - val_loss: 6.1701 - val_value_loss: 0.6343 - val_policy_loss: 1.6798\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1951 - value_loss: 0.6703 - policy_loss: 1.6939 - val_loss: 6.1694 - val_value_loss: 0.6330 - val_policy_loss: 1.6797\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1918 - value_loss: 0.6639 - policy_loss: 1.6936 - val_loss: 6.1688 - val_value_loss: 0.6320 - val_policy_loss: 1.6797\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1893 - value_loss: 0.6593 - policy_loss: 1.6932 - val_loss: 6.1684 - val_value_loss: 0.6312 - val_policy_loss: 1.6796\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1868 - value_loss: 0.6547 - policy_loss: 1.6929 - val_loss: 6.1681 - val_value_loss: 0.6308 - val_policy_loss: 1.6795\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1842 - value_loss: 0.6495 - policy_loss: 1.6930 - val_loss: 6.1678 - val_value_loss: 0.6302 - val_policy_loss: 1.6795\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1821 - value_loss: 0.6454 - policy_loss: 1.6929 - val_loss: 6.1674 - val_value_loss: 0.6295 - val_policy_loss: 1.6794\n",
      "Saved model  tictactoe_c_puct_10_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.05\n",
      "Number of seen trajectories: 2500\n",
      "Number of unique trajectories: 2352\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 180us/step - loss: 6.1699 - value_loss: 0.6079 - policy_loss: 1.7061 - val_loss: 6.1607 - val_value_loss: 0.6250 - val_policy_loss: 1.6705\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1677 - value_loss: 0.6037 - policy_loss: 1.7059 - val_loss: 6.1601 - val_value_loss: 0.6239 - val_policy_loss: 1.6705\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1661 - value_loss: 0.6000 - policy_loss: 1.7064 - val_loss: 6.1596 - val_value_loss: 0.6229 - val_policy_loss: 1.6704\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1653 - value_loss: 0.5989 - policy_loss: 1.7059 - val_loss: 6.1590 - val_value_loss: 0.6218 - val_policy_loss: 1.6704\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1632 - value_loss: 0.5951 - policy_loss: 1.7056 - val_loss: 6.1584 - val_value_loss: 0.6208 - val_policy_loss: 1.6703\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1609 - value_loss: 0.5906 - policy_loss: 1.7056 - val_loss: 6.1578 - val_value_loss: 0.6196 - val_policy_loss: 1.6703\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1602 - value_loss: 0.5889 - policy_loss: 1.7056 - val_loss: 6.1573 - val_value_loss: 0.6187 - val_policy_loss: 1.6703\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1586 - value_loss: 0.5856 - policy_loss: 1.7060 - val_loss: 6.1569 - val_value_loss: 0.6178 - val_policy_loss: 1.6702\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1570 - value_loss: 0.5830 - policy_loss: 1.7054 - val_loss: 6.1564 - val_value_loss: 0.6170 - val_policy_loss: 1.6702\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1562 - value_loss: 0.5809 - policy_loss: 1.7058 - val_loss: 6.1560 - val_value_loss: 0.6161 - val_policy_loss: 1.6702\n",
      "Saved model  tictactoe_c_puct_10_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.0\n",
      "Number of seen trajectories: 2600\n",
      "Number of unique trajectories: 2442\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 6.2119 - value_loss: 0.7115 - policy_loss: 1.6867 - val_loss: 6.1987 - val_value_loss: 0.6943 - val_policy_loss: 1.6775\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2073 - value_loss: 0.7023 - policy_loss: 1.6868 - val_loss: 6.1963 - val_value_loss: 0.6895 - val_policy_loss: 1.6775\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2030 - value_loss: 0.6940 - policy_loss: 1.6864 - val_loss: 6.1948 - val_value_loss: 0.6866 - val_policy_loss: 1.6775\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2005 - value_loss: 0.6893 - policy_loss: 1.6861 - val_loss: 6.1938 - val_value_loss: 0.6845 - val_policy_loss: 1.6775\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1987 - value_loss: 0.6854 - policy_loss: 1.6863 - val_loss: 6.1929 - val_value_loss: 0.6828 - val_policy_loss: 1.6774\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1959 - value_loss: 0.6801 - policy_loss: 1.6862 - val_loss: 6.1922 - val_value_loss: 0.6814 - val_policy_loss: 1.6774\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1953 - value_loss: 0.6789 - policy_loss: 1.6861 - val_loss: 6.1915 - val_value_loss: 0.6800 - val_policy_loss: 1.6774\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1928 - value_loss: 0.6743 - policy_loss: 1.6858 - val_loss: 6.1909 - val_value_loss: 0.6789 - val_policy_loss: 1.6774\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1907 - value_loss: 0.6701 - policy_loss: 1.6858 - val_loss: 6.1904 - val_value_loss: 0.6779 - val_policy_loss: 1.6774\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1900 - value_loss: 0.6686 - policy_loss: 1.6860 - val_loss: 6.1899 - val_value_loss: 0.6769 - val_policy_loss: 1.6774\n",
      "Saved model  tictactoe_c_puct_10_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.75 - draw ratio 0.05\n",
      "Number of seen trajectories: 2700\n",
      "Number of unique trajectories: 2525\n",
      "iteration 27 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 6.2163 - value_loss: 0.7287 - policy_loss: 1.6784 - val_loss: 6.2314 - val_value_loss: 0.7635 - val_policy_loss: 1.6739\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2135 - value_loss: 0.7234 - policy_loss: 1.6782 - val_loss: 6.2306 - val_value_loss: 0.7619 - val_policy_loss: 1.6738\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2105 - value_loss: 0.7174 - policy_loss: 1.6782 - val_loss: 6.2298 - val_value_loss: 0.7604 - val_policy_loss: 1.6738\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2093 - value_loss: 0.7152 - policy_loss: 1.6780 - val_loss: 6.2291 - val_value_loss: 0.7590 - val_policy_loss: 1.6738\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2075 - value_loss: 0.7119 - policy_loss: 1.6777 - val_loss: 6.2285 - val_value_loss: 0.7578 - val_policy_loss: 1.6738\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2055 - value_loss: 0.7081 - policy_loss: 1.6775 - val_loss: 6.2279 - val_value_loss: 0.7568 - val_policy_loss: 1.6738\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2038 - value_loss: 0.7043 - policy_loss: 1.6780 - val_loss: 6.2273 - val_value_loss: 0.7556 - val_policy_loss: 1.6738\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2025 - value_loss: 0.7020 - policy_loss: 1.6777 - val_loss: 6.2267 - val_value_loss: 0.7544 - val_policy_loss: 1.6738\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2012 - value_loss: 0.6994 - policy_loss: 1.6777 - val_loss: 6.2263 - val_value_loss: 0.7535 - val_policy_loss: 1.6738\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1991 - value_loss: 0.6957 - policy_loss: 1.6773 - val_loss: 6.2258 - val_value_loss: 0.7525 - val_policy_loss: 1.6738\n",
      "Saved model  tictactoe_c_puct_10_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.72 - draw ratio 0.02\n",
      "Number of seen trajectories: 2800\n",
      "Number of unique trajectories: 2612\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.2155 - value_loss: 0.7067 - policy_loss: 1.6991 - val_loss: 6.2006 - val_value_loss: 0.6763 - val_policy_loss: 1.6997\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2130 - value_loss: 0.7018 - policy_loss: 1.6991 - val_loss: 6.1990 - val_value_loss: 0.6732 - val_policy_loss: 1.6996\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 172us/step - loss: 6.2100 - value_loss: 0.6960 - policy_loss: 1.6988 - val_loss: 6.1979 - val_value_loss: 0.6710 - val_policy_loss: 1.6995\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2079 - value_loss: 0.6916 - policy_loss: 1.6991 - val_loss: 6.1971 - val_value_loss: 0.6696 - val_policy_loss: 1.6994\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2053 - value_loss: 0.6871 - policy_loss: 1.6985 - val_loss: 6.1965 - val_value_loss: 0.6685 - val_policy_loss: 1.6994\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2051 - value_loss: 0.6864 - policy_loss: 1.6985 - val_loss: 6.1960 - val_value_loss: 0.6676 - val_policy_loss: 1.6993\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2026 - value_loss: 0.6815 - policy_loss: 1.6984 - val_loss: 6.1956 - val_value_loss: 0.6669 - val_policy_loss: 1.6992\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.2006 - value_loss: 0.6777 - policy_loss: 1.6985 - val_loss: 6.1954 - val_value_loss: 0.6664 - val_policy_loss: 1.6992\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1991 - value_loss: 0.6751 - policy_loss: 1.6980 - val_loss: 6.1950 - val_value_loss: 0.6659 - val_policy_loss: 1.6991\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1980 - value_loss: 0.6727 - policy_loss: 1.6982 - val_loss: 6.1947 - val_value_loss: 0.6653 - val_policy_loss: 1.6991\n",
      "Saved model  tictactoe_c_puct_10_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.87 - draw ratio 0.0\n",
      "Number of seen trajectories: 2900\n",
      "Number of unique trajectories: 2692\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_tictactoe_c_puct_10_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 3, 3, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 9)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 6.2041 - value_loss: 0.6998 - policy_loss: 1.6833 - val_loss: 6.1911 - val_value_loss: 0.6582 - val_policy_loss: 1.6990\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.2020 - value_loss: 0.6954 - policy_loss: 1.6836 - val_loss: 6.1898 - val_value_loss: 0.6555 - val_policy_loss: 1.6989\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1990 - value_loss: 0.6900 - policy_loss: 1.6831 - val_loss: 6.1885 - val_value_loss: 0.6532 - val_policy_loss: 1.6989\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1959 - value_loss: 0.6841 - policy_loss: 1.6828 - val_loss: 6.1874 - val_value_loss: 0.6510 - val_policy_loss: 1.6989\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1954 - value_loss: 0.6822 - policy_loss: 1.6836 - val_loss: 6.1864 - val_value_loss: 0.6490 - val_policy_loss: 1.6988\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1924 - value_loss: 0.6768 - policy_loss: 1.6830 - val_loss: 6.1854 - val_value_loss: 0.6471 - val_policy_loss: 1.6988\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1901 - value_loss: 0.6724 - policy_loss: 1.6828 - val_loss: 6.1845 - val_value_loss: 0.6453 - val_policy_loss: 1.6987\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1s 173us/step - loss: 6.1879 - value_loss: 0.6681 - policy_loss: 1.6828 - val_loss: 6.1837 - val_value_loss: 0.6437 - val_policy_loss: 1.6987\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1862 - value_loss: 0.6648 - policy_loss: 1.6826 - val_loss: 6.1829 - val_value_loss: 0.6423 - val_policy_loss: 1.6987\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1s 174us/step - loss: 6.1855 - value_loss: 0.6631 - policy_loss: 1.6829 - val_loss: 6.1823 - val_value_loss: 0.6410 - val_policy_loss: 1.6986\n",
      "Saved model  tictactoe_c_puct_10_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.0\n",
      "Number of seen trajectories: 3000\n",
      "Number of unique trajectories: 2782\n"
     ]
    }
   ],
   "source": [
    "wins_6, draws_6, seen_trajectories_6, unique_trajectories_6 = test_pipeline.run(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Win rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - c_puct 10\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "losses_6 = np.ones(30) - wins_6 - draws_6\n",
    "\n",
    "plt.plot(x, wins_6, label=\"win ratio\")\n",
    "plt.plot(x, draws_6, label=\"draw ratio\")\n",
    "plt.plot(x, losses_6, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "exploration_rate_6 = unique_trajectories_6/seen_trajectories_6\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - c_puct 10\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "\n",
    "plt.plot(x, exploration_rate_6, label=\"unique/seen\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins_6 = [0.74, 0.75, 0.71, 0.73, 0.78, 0.83, 0.81, 0.72, 0.75, 0.89, 0.87, 0.83, 0.76, 0.79, 0.82, 0.79, 0.82, 0.79, 0.8, 0.76, 0.8, 0.77, 0.77, 0.91, 0.82, 0.82, 0.75, 0.72, 0.87, 0.84]\n",
      "draws_6 = [0.04, 0.0, 0.01, 0.01, 0.02, 0.01, 0.02, 0.03, 0.02, 0.01, 0.02, 0.02, 0.02, 0.02, 0.06, 0.03, 0.03, 0.04, 0.02, 0.01, 0.02, 0.05, 0.01, 0.01, 0.05, 0.0, 0.05, 0.02, 0.0, 0.0]\n",
      "losses_6 = [0.22 0.25 0.28 0.26 0.2  0.16 0.17 0.25 0.23 0.1  0.11 0.15 0.22 0.19\n",
      " 0.12 0.18 0.15 0.17 0.18 0.23 0.18 0.18 0.22 0.08 0.13 0.18 0.2  0.26\n",
      " 0.13 0.16]\n",
      "seen_trajectories_6 = [ 100.  200.  300.  400.  500.  600.  700.  800.  900. 1000. 1100. 1200.\n",
      " 1300. 1400. 1500. 1600. 1700. 1800. 1900. 2000. 2100. 2200. 2300. 2400.\n",
      " 2500. 2600. 2700. 2800. 2900. 3000.]\n",
      "unique_trajectories_6 = [ 100.  200.  300.  400.  494.  592.  689.  785.  880.  978. 1074. 1167.\n",
      " 1264. 1354. 1448. 1540. 1634. 1728. 1817. 1908. 1997. 2081. 2174. 2264.\n",
      " 2352. 2442. 2525. 2612. 2692. 2782.]\n"
     ]
    }
   ],
   "source": [
    "print(\"wins_6 =\", wins_6)\n",
    "print(\"draws_6 =\", draws_6)\n",
    "print(\"losses_6 =\", losses_6)\n",
    "print(\"seen_trajectories_6 =\", seen_trajectories_6)\n",
    "print(\"unique_trajectories_6 =\", unique_trajectories_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(data, window_size):\n",
    "    return np.convolve(data, np.ones((window_size,))/window_size, mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_puct 1\n",
    "wins_1 = [0.83, 0.72, 0.87, 0.85, 0.78, 0.85, 0.8, 0.88, 0.86, 0.84, 0.86, 0.79, 0.78, 0.85, 0.8, 0.82, 0.85, 0.81, 0.74, 0.77, 0.87, 0.8, 0.8, 0.86, 0.78, 0.82, 0.77, 0.84, 0.79, 0.85]\n",
    "draws_1 = [0.02, 0.01, 0.0, 0.0, 0.01, 0.01, 0.0, 0.0, 0.01, 0.0, 0.0, 0.01, 0.01, 0.01, 0.02, 0.05, 0.01, 0.05, 0.04, 0.04, 0.01, 0.02, 0.03, 0.03, 0.02, 0.03, 0.02, 0.0, 0.02, 0.03]\n",
    "losses_1 = np.ones(30) - wins_1 -draws_1\n",
    "seen_trajectories_1 = [ 100,  200,  300,  400,  500,  600,  700,  800,  900, 1000, 1100, 1200,\n",
    " 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400,\n",
    " 2500, 2600, 2700, 2800, 2900, 3000,]\n",
    "unique_trajectories_1 = [  99,  197,  291,  386,  480,  570,  659,  753,  838, 925, 1004, 1079,\n",
    " 1164, 1244, 1326, 1407, 1482, 1564, 1634, 1710, 1778, 1849, 1913, 1984,\n",
    " 2055, 2125, 2183, 2250, 2324, 2391]\n",
    "\n",
    "# c_puct 0.5\n",
    "wins_2 = [0.78, 0.75, 0.87, 0.81, 0.8, 0.84, 0.79, 0.85, 0.79, 0.76, 0.87, 0.86, 0.77, 0.8, 0.86, 0.87, 0.85, 0.83, 0.86, 0.76, 0.84, 0.81, 0.84, 0.88, 0.82, 0.8, 0.83, 0.88, 0.89, 0.79]\n",
    "draws_2 = [0.01, 0.05, 0.02, 0.0, 0.02, 0.0, 0.02, 0.0, 0.0, 0.01, 0.01, 0.02, 0.03, 0.0, 0.01, 0.0, 0.02, 0.02, 0.01, 0.02, 0.03, 0.02, 0.07, 0.0, 0.01, 0.01, 0.02, 0.01, 0.02, 0.05]\n",
    "losses_2 = np.ones(30) - wins_2 -draws_2\n",
    "seen_trajectories_2 = [ 100,  200,  300,  400,  500,  600,  700,  800,  900, 1000, 1100, 1200,\n",
    " 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400,\n",
    " 2500, 2600, 2700, 2800, 2900, 3000]\n",
    "unique_trajectories_2 = [  99,  197,  293,  388,  476,  564,  651,  735,  822,  903,  986, 1068,\n",
    " 1143, 1213, 1286, 1366, 1449, 1527, 1599, 1679, 1754, 1825, 1891, 1960,\n",
    " 2026, 2091, 2158, 2227, 2295, 2360]\n",
    "\n",
    "# c_puct 1.5\n",
    "wins_3 = [0.82, 0.79, 0.75, 0.74, 0.82, 0.8, 0.84, 0.85, 0.75, 0.85, 0.83, 0.83, 0.84, 0.79, 0.82, 0.81, 0.7, 0.74, 0.77, 0.89, 0.85, 0.77, 0.9, 0.84, 0.7, 0.83, 0.77, 0.83, 0.8, 0.77]\n",
    "draws_3 = [0.01, 0.02, 0.01, 0.03, 0.0, 0.01, 0.01, 0.0, 0.02, 0.02, 0.0, 0.0, 0.01, 0.01, 0.0, 0.02, 0.05, 0.03, 0.04, 0.0, 0.01, 0.0, 0.01, 0.01, 0.03, 0.01, 0.03, 0.02, 0.01, 0.02]\n",
    "losses_3 = np.ones(30) - wins_3 -draws_3\n",
    "seen_trajectories_3 = [ 100,  200,  300,  400,  500,  600,  700,  800,  900, 1000, 1100, 1200,\n",
    " 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400,\n",
    " 2500, 2600, 2700, 2800, 2900, 3000]\n",
    "unique_trajectories_3 = [  99,  195,  288,  382,  474,  564,  651,  739,  824,  906,  989, 1076,\n",
    " 1158, 1237, 1315, 1388, 1462, 1537, 1608, 1675, 1744, 1817, 1890, 1952,\n",
    " 2017, 2089, 2149, 2212, 2274, 2339]\n",
    "\n",
    "# c_puct 0.1\n",
    "wins_4 = [0.71, 0.75, 0.71, 0.85, 0.78, 0.89, 0.79, 0.78, 0.74, 0.88, 0.88, 0.86, 0.83, 0.86, 0.89, 0.83, 0.87, 0.82, 0.84, 0.79, 0.83, 0.83, 0.71, 0.81, 0.85, 0.88, 0.91, 0.82, 0.87, 0.86]\n",
    "draws_4 = [0.01, 0.02, 0.01, 0.01, 0.03, 0.0, 0.01, 0.01, 0.01, 0.02, 0.01, 0.0, 0.01, 0.01, 0.0, 0.01, 0.01, 0.01, 0.01, 0.02, 0.0, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "losses_4 = np.ones(30) - wins_4 -draws_4\n",
    "seen_trajectories_4 = [ 100,  200,  300,  400,  500,  600,  700,  800,  900, 1000, 1100, 1200,\n",
    " 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400,\n",
    " 2500, 2600, 2700, 2800, 2900, 3000]\n",
    "unique_trajectories_4 = [  99,  194,  290,  380,  468,  556,  633,  710,  797,  872,  956, 1037,\n",
    " 1113, 1197, 1279, 1351, 1422, 1496, 1573, 1641, 1707, 1775, 1849, 1932,\n",
    " 2005, 2074, 2136, 2205, 2258, 2318]\n",
    "\n",
    "# c_puct 5\n",
    "wins_5 = [0.73, 0.78, 0.82, 0.89, 0.85, 0.82, 0.78, 0.87, 0.84, 0.87, 0.81, 0.89, 0.83, 0.83, 0.86, 0.85, 0.85, 0.83, 0.93, 0.86, 0.86, 0.86, 0.85, 0.88, 0.84, 0.81, 0.82, 0.75, 0.8, 0.84]\n",
    "draws_5 = [0.01, 0.03, 0.02, 0.0, 0.05, 0.01, 0.02, 0.0, 0.0, 0.0, 0.01, 0.03, 0.01, 0.03, 0.01, 0.0, 0.0, 0.01, 0.0, 0.0, 0.01, 0.03, 0.04, 0.01, 0.01, 0.01, 0.01, 0.03, 0.01, 0.04]\n",
    "losses_5 = np.ones(30) - wins_5 -draws_5\n",
    "seen_trajectories_5 = [ 100,  200,  300,  400,  500,  600,  700,  800,  900, 1000, 1100, 1200,\n",
    " 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400,\n",
    " 2500, 2600, 2700, 2800, 2900, 3000]\n",
    "unique_trajectories_5 = [ 100,  199,  296,  393,  491,  583,  675,  765,  861,  956, 1049, 1138,\n",
    " 1224, 1316, 1407, 1498, 1587, 1669, 1757, 1834, 1915, 1993, 2077, 2153,\n",
    " 2229, 2309, 2387, 2459, 2526, 2599]\n",
    "\n",
    "# c_puct 10\n",
    "wins_6 = [0.74, 0.75, 0.71, 0.73, 0.78, 0.83, 0.81, 0.72, 0.75, 0.89, 0.87, 0.83, 0.76, 0.79, 0.82, 0.79, 0.82, 0.79, 0.8, 0.76, 0.8, 0.77, 0.77, 0.91, 0.82, 0.82, 0.75, 0.72, 0.87, 0.84]\n",
    "draws_6 = [0.04, 0.0, 0.01, 0.01, 0.02, 0.01, 0.02, 0.03, 0.02, 0.01, 0.02, 0.02, 0.02, 0.02, 0.06, 0.03, 0.03, 0.04, 0.02, 0.01, 0.02, 0.05, 0.01, 0.01, 0.05, 0.0, 0.05, 0.02, 0.0, 0.0]\n",
    "losses_6 = np.ones(30) - wins_6 -draws_6\n",
    "seen_trajectories_6 = [ 100,  200,  300,  400,  500,  600,  700,  800,  900, 1000, 1100, 1200,\n",
    " 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400,\n",
    " 2500, 2600, 2700, 2800, 2900, 3000]\n",
    "unique_trajectories_6 = [ 100,  200,  300,  400,  494,  592,  689,  785,  880,  978, 1074, 1167,\n",
    " 1264, 1354, 1448, 1540, 1634, 1728, 1817, 1908, 1997, 2081, 2174, 2264,\n",
    " 2352, 2442, 2525, 2612, 2692, 2782]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_size = 1\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "\n",
    "plt.title(\"Evaluation - Win ratio\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"win ratio\")\n",
    "\n",
    "x = np.arange(30 - window_size + 1)\n",
    "\n",
    "#plt.plot(x, smooth(wins_4, window_size), label=\"c_puct 0.1\")\n",
    "#plt.plot(x, smooth(wins_2, window_size), label=\"c_puct 0.5\")\n",
    "plt.plot(x, smooth(wins_1, window_size), label=\"c_puct 1\")\n",
    "#plt.plot(x, smooth(wins_3, window_size), label=\"c_puct 1.5\")\n",
    "plt.plot(x, smooth(wins_5, window_size), label=\"c_puct 5\")\n",
    "plt.plot(x, smooth(wins_6, window_size), label=\"c_puct 10\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_rate_1 = np.array(unique_trajectories_1)/np.array(seen_trajectories_1)\n",
    "exp_rate_2 = np.array(unique_trajectories_2)/np.array(seen_trajectories_2)\n",
    "exp_rate_3 = np.array(unique_trajectories_3)/np.array(seen_trajectories_3)\n",
    "exp_rate_4 = np.array(unique_trajectories_4)/np.array(seen_trajectories_4)\n",
    "exp_rate_5 = np.array(unique_trajectories_5)/np.array(seen_trajectories_5)\n",
    "exp_rate_6 = np.array(unique_trajectories_6)/np.array(seen_trajectories_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_size = 3\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "\n",
    "plt.title(\"Evaluation - Exploration rate\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"exploration rate (unique/seen)\")\n",
    "\n",
    "x = np.arange(30 - window_size + 1)\n",
    "\n",
    "plt.plot(x, smooth(exp_rate_1, window_size), label=\"c_puct 0.1\")\n",
    "plt.plot(x, smooth(exp_rate_2, window_size), label=\"c_puct 0.5\")\n",
    "plt.plot(x, smooth(exp_rate_3, window_size), label=\"c_puct 1\")\n",
    "plt.plot(x, smooth(exp_rate_4, window_size), label=\"c_puct 1.5\")\n",
    "plt.plot(x, smooth(exp_rate_5, window_size), label=\"c_puct 5\")\n",
    "plt.plot(x, smooth(exp_rate_6, window_size), label=\"c_puct 10\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play against agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $c_{puct}$ = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_c_puct_0_1_29\n"
     ]
    }
   ],
   "source": [
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "last_model_0_1 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_c_puct_0_1\"\n",
    ")\n",
    "last_model_0_1.load(29)\n",
    "last_agent_0_1 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=last_model_0_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 1 | 0 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.5192853212356567\n",
      "policy:\n",
      " 0.0 | 0.13174253702163696 | 0.1198035404086113\n",
      " 0.12701520323753357 | 0.12559695541858673 | 0.12069827318191528\n",
      " 0.1259598731994629 | 0.12661097943782806 | 0.12257260829210281\n",
      "===========\n",
      "choose from [0 1 1 1 1 1 1 1 1] :4\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: -0.23882068693637848\n",
      "policy:\n",
      " 0.0 | 0.17151613533496857 | 0.15656057000160217\n",
      " 0.165745347738266 | 0.0 | 0.1275211125612259\n",
      " 0.17042000591754913 | 0.11256314069032669 | 0.09567373245954514\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.5937272310256958\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.21444281935691833\n",
      " 0.21471652388572693 | 0.0 | 0.1923290491104126\n",
      " 0.16784702241420746 | 0.11705442517995834 | 0.09361016750335693\n",
      "===========\n",
      "choose from [0 0 1 1 0 1 1 1 1] :2\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.8026103973388672\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.25607576966285706 | 0.0 | 0.1797827035188675\n",
      " 0.2783515751361847 | 0.17022137343883514 | 0.11556854844093323\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 1 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: -0.901354193687439\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.00859750248491764\n",
      " 0.9689044952392578 | 0.010035919956862926 | 0.012462092563509941\n",
      "===========\n",
      "choose from [0 0 0 0 0 1 1 1 1] :6\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 1 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "value: 0.5219329595565796\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.5960374474525452\n",
      " 0.0 | 0.1853393316268921 | 0.21862325072288513\n",
      "===========\n",
      "Player -1 won the game after 6 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(last_agent_0_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_c_puct_0_1_26\n"
     ]
    }
   ],
   "source": [
    "best_version = np.argmax(wins_4)\n",
    "\n",
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "best_model_0_1 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_c_puct_0_1\"\n",
    ")\n",
    "best_model_0_1.load(best_version)\n",
    "best_agent_0_1 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=best_model_0_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 1 | 0 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.42583024501800537\n",
      "policy:\n",
      " 0.0 | 0.12812471389770508 | 0.12251996248960495\n",
      " 0.12882106006145477 | 0.12094738334417343 | 0.12401995062828064\n",
      " 0.12446752935647964 | 0.1267932504415512 | 0.12430617958307266\n",
      "===========\n",
      "choose from [0 1 1 1 1 1 1 1 1] :4\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.039016954600811005\n",
      "policy:\n",
      " 0.0 | 0.17544525861740112 | 0.1521124690771103\n",
      " 0.16801856458187103 | 0.0 | 0.1232127919793129\n",
      " 0.16378118097782135 | 0.11481116712093353 | 0.10261860489845276\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.6979154944419861\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.2188824564218521\n",
      " 0.20872944593429565 | 0.0 | 0.19923417270183563\n",
      " 0.1600222885608673 | 0.11791571229696274 | 0.09521588683128357\n",
      "===========\n",
      "choose from [0 0 1 1 0 1 1 1 1] :2\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.7033112645149231\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.2579273581504822 | 0.0 | 0.16037920117378235\n",
      " 0.28729012608528137 | 0.16823652386665344 | 0.12616679072380066\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 1 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: -0.8346468210220337\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.009620961733162403\n",
      " 0.964491605758667 | 0.011330745182931423 | 0.014556722715497017\n",
      "===========\n",
      "choose from [0 0 0 0 0 1 1 1 1] :6\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 1 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "value: 0.2548157870769501\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.5463963150978088\n",
      " 0.0 | 0.19625547528266907 | 0.2573482394218445\n",
      "===========\n",
      "Player -1 won the game after 6 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(best_agent_0_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $c_{puct}$ = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_c_puct_0_5_29\n"
     ]
    }
   ],
   "source": [
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "last_model_0_5 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_c_puct_0_5\"\n",
    ")\n",
    "last_model_0_5.load(29)\n",
    "last_agent_0_5 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=last_model_0_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.12241283804178238\n",
      "policy:\n",
      " 0.12178010493516922 | 0.0 | 0.12343083322048187\n",
      " 0.12464594841003418 | 0.12881693243980408 | 0.12226851284503937\n",
      " 0.125161811709404 | 0.1254815310239792 | 0.12841425836086273\n",
      "===========\n",
      "choose from [1 0 1 1 1 1 1 1 1] :4\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.048412151634693146\n",
      "policy:\n",
      " 0.14808589220046997 | 0.0 | 0.16057300567626953\n",
      " 0.1380680352449417 | 0.0 | 0.13198889791965485\n",
      " 0.14176656305789948 | 0.13399086892604828 | 0.14552675187587738\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.7657812833786011\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.2385679930448532\n",
      " 0.12589289247989655 | 0.0 | 0.1487051248550415\n",
      " 0.19066239893436432 | 0.16206996142864227 | 0.13410162925720215\n",
      "===========\n",
      "choose from [0 0 1 1 0 1 1 1 1] :2\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.7932047247886658\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.25757476687431335 | 0.0 | 0.08987075090408325\n",
      " 0.3306224048137665 | 0.12719163298606873 | 0.1947403997182846\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 2 | 0\n",
      " 1 | 0 | 0\n",
      "-----------\n",
      "value: 0.7014656066894531\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.27033039927482605 | 0.0 | 0.33607718348503113\n",
      " 0.0 | 0.07744618505239487 | 0.31614619493484497\n",
      "===========\n",
      "choose from [0 0 0 1 0 1 0 1 1] :3\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 2 | 2 | 0\n",
      " 1 | 0 | 0\n",
      "-----------\n",
      "value: 0.7326149940490723\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.05203719064593315\n",
      " 0.0 | 0.6726069450378418 | 0.27535587549209595\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 2 | 2 | 0\n",
      " 1 | 1 | 0\n",
      "-----------\n",
      "value: -0.9592198133468628\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.9654573202133179\n",
      " 0.0 | 0.0 | 0.03454268351197243\n",
      "===========\n",
      "choose from [0 0 0 0 0 1 0 0 1] :5\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 2 | 2 | 2\n",
      " 1 | 1 | 0\n",
      "-----------\n",
      "value: -0.05845407024025917\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 1.0\n",
      "===========\n",
      "Player -1 won the game after 8 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(last_agent_0_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_c_puct_0_5_28\n"
     ]
    }
   ],
   "source": [
    "best_version = np.argmax(wins_2)\n",
    "\n",
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "best_model_0_5 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_c_puct_0_5\"\n",
    ")\n",
    "best_model_0_5.load(best_version)\n",
    "best_agent_0_5 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=best_model_0_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.14950698614120483\n",
      "policy:\n",
      " 0.12063018232584 | 0.0 | 0.12200146168470383\n",
      " 0.12308263778686523 | 0.13053321838378906 | 0.12054196745157242\n",
      " 0.1275477111339569 | 0.12604722380638123 | 0.12961557507514954\n",
      "===========\n",
      "choose from [1 0 1 1 1 1 1 1 1] :4\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.058119889348745346\n",
      "policy:\n",
      " 0.1506681740283966 | 0.0 | 0.16205400228500366\n",
      " 0.13115587830543518 | 0.0 | 0.13354700803756714\n",
      " 0.14165961742401123 | 0.13802310824394226 | 0.14289219677448273\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.831648588180542\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.241196408867836\n",
      " 0.12181387096643448 | 0.0 | 0.14537857472896576\n",
      " 0.2002832293510437 | 0.15815582871437073 | 0.13317209482192993\n",
      "===========\n",
      "choose from [0 0 1 1 0 1 1 1 1] :2\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.8136581182479858\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.23786544799804688 | 0.0 | 0.08849142491817474\n",
      " 0.33905228972435 | 0.13300620019435883 | 0.20158465206623077\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 2 | 0\n",
      " 1 | 0 | 0\n",
      "-----------\n",
      "value: 0.7587167620658875\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.27601367235183716 | 0.0 | 0.3415504992008209\n",
      " 0.0 | 0.0775614082813263 | 0.304874449968338\n",
      "===========\n",
      "choose from [0 0 0 1 0 1 0 1 1] :3\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 2 | 2 | 0\n",
      " 1 | 0 | 0\n",
      "-----------\n",
      "value: 0.7626612186431885\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.05139430984854698\n",
      " 0.0 | 0.6835516691207886 | 0.26505398750305176\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 2 | 2 | 0\n",
      " 1 | 1 | 0\n",
      "-----------\n",
      "value: -0.9544334411621094\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.9657770991325378\n",
      " 0.0 | 0.0 | 0.03422287851572037\n",
      "===========\n",
      "choose from [0 0 0 0 0 1 0 0 1] :5\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 2 | 2 | 2\n",
      " 1 | 1 | 0\n",
      "-----------\n",
      "value: -0.004661283455789089\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 1.0\n",
      "===========\n",
      "Player -1 won the game after 8 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(best_agent_0_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $c_{puct}$ = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_c_puct_1_29\n"
     ]
    }
   ],
   "source": [
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "last_model_1 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_c_puct_1\"\n",
    ")\n",
    "last_model_1.load(29)\n",
    "last_agent_1 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=last_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 1 | 0 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.4718407690525055\n",
      "policy:\n",
      " 0.0 | 0.12604078650474548 | 0.1349036991596222\n",
      " 0.12893374264240265 | 0.11616966128349304 | 0.12277014553546906\n",
      " 0.12181989848613739 | 0.12599462270736694 | 0.12336742132902145\n",
      "===========\n",
      "choose from [0 1 1 1 1 1 1 1 1] :4\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: -0.3798166811466217\n",
      "policy:\n",
      " 0.0 | 0.16440224647521973 | 0.15790627896785736\n",
      " 0.18258757889270782 | 0.0 | 0.11412227898836136\n",
      " 0.15587611496448517 | 0.11939920485019684 | 0.10570628941059113\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 1 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.6803608536720276\n",
      "policy:\n",
      " 0.0 | 0.18822447955608368 | 0.16908930242061615\n",
      " 0.0 | 0.0 | 0.09402868896722794\n",
      " 0.2003023326396942 | 0.16164655983448029 | 0.18670859932899475\n",
      "===========\n",
      "choose from [0 1 1 0 0 1 1 1 1] :6\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 1 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "value: 0.7871189117431641\n",
      "policy:\n",
      " 0.0 | 0.2210981845855713 | 0.30029720067977905\n",
      " 0.0 | 0.0 | 0.1666267365217209\n",
      " 0.0 | 0.1753300279378891 | 0.13664786517620087\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 1\n",
      " 1 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "value: 0.8158249855041504\n",
      "policy:\n",
      " 0.0 | 0.22226516902446747 | 0.0\n",
      " 0.0 | 0.0 | 0.23489895462989807\n",
      " 0.0 | 0.37323737144470215 | 0.16959841549396515\n",
      "===========\n",
      "choose from [0 1 0 0 0 1 0 1 1] :1\n",
      "===========\n",
      " 1 | 2 | 1\n",
      " 1 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "value: 0.5863916873931885\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.6305535435676575\n",
      " 0.0 | 0.18050718307495117 | 0.18893924355506897\n",
      "===========\n",
      "===========\n",
      " 1 | 2 | 1\n",
      " 1 | 2 | 1\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "value: -0.9062950611114502\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.9845175743103027 | 0.01548243872821331\n",
      "===========\n",
      "choose from [0 0 0 0 0 0 0 1 1] :7\n",
      "===========\n",
      " 1 | 2 | 1\n",
      " 1 | 2 | 1\n",
      " 2 | 2 | 0\n",
      "-----------\n",
      "value: -0.6117427349090576\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 1.0\n",
      "===========\n",
      "Player -1 won the game after 8 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(last_agent_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_c_puct_1_7\n"
     ]
    }
   ],
   "source": [
    "best_version = np.argmax(wins_1)\n",
    "\n",
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "best_model_1 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_c_puct_1\"\n",
    ")\n",
    "best_model_1.load(best_version)\n",
    "best_agent_1 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=best_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 1 | 0 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.39832669496536255\n",
      "policy:\n",
      " 0.0 | 0.12375568598508835 | 0.12282631546258926\n",
      " 0.11939848959445953 | 0.12881752848625183 | 0.12042370438575745\n",
      " 0.12500175833702087 | 0.12460236251354218 | 0.13517412543296814\n",
      "===========\n",
      "choose from [0 1 1 1 1 1 1 1 1] :4\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: -0.4403638541698456\n",
      "policy:\n",
      " 0.0 | 0.18684032559394836 | 0.15592661499977112\n",
      " 0.19526046514511108 | 0.0 | 0.11068234592676163\n",
      " 0.14949628710746765 | 0.11416713893413544 | 0.08762677013874054\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.45438674092292786\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.16148556768894196\n",
      " 0.14005549252033234 | 0.0 | 0.15611526370048523\n",
      " 0.25958317518234253 | 0.1070440411567688 | 0.17571648955345154\n",
      "===========\n",
      "choose from [0 0 1 1 0 1 1 1 1] :2\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.4443376660346985\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.3041313886642456 | 0.0 | 0.17311932146549225\n",
      " 0.2135317325592041 | 0.17143231630325317 | 0.13778522610664368\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 1 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: -0.7703574895858765\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.04252839833498001\n",
      " 0.8495484590530396 | 0.0644916445016861 | 0.04343155026435852\n",
      "===========\n",
      "choose from [0 0 0 0 0 1 1 1 1] :6\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 1 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "value: -0.7256271839141846\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.21902604401111603\n",
      " 0.0 | 0.6736075282096863 | 0.10736647993326187\n",
      "===========\n",
      "Player -1 won the game after 6 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(best_agent_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $c_{puct}$ = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_c_puct_1_5_29\n"
     ]
    }
   ],
   "source": [
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "last_model_1_5 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_c_puct_1_5\"\n",
    ")\n",
    "last_model_1_5.load(29)\n",
    "last_agent_1_5 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=last_model_1_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.403425008058548\n",
      "policy:\n",
      " 0.1272425502538681 | 0.0 | 0.12305102497339249\n",
      " 0.1262684464454651 | 0.11508801579475403 | 0.13056200742721558\n",
      " 0.12437598407268524 | 0.12765495479106903 | 0.12575706839561462\n",
      "===========\n",
      "choose from [1 0 1 1 1 1 1 1 1] :4\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.23155590891838074\n",
      "policy:\n",
      " 0.17020367085933685 | 0.0 | 0.1731155663728714\n",
      " 0.1432677060365677 | 0.0 | 0.1422891914844513\n",
      " 0.12252651900053024 | 0.12437451630830765 | 0.12422281503677368\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.8242509365081787\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.17329132556915283\n",
      " 0.16670021414756775 | 0.0 | 0.21751093864440918\n",
      " 0.21527427434921265 | 0.10762669146060944 | 0.11959653347730637\n",
      "===========\n",
      "choose from [0 0 1 1 0 1 1 1 1] :2\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.6625864505767822\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.2554599344730377 | 0.0 | 0.13291138410568237\n",
      " 0.2927890717983246 | 0.21122336387634277 | 0.10761629045009613\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 2 | 0\n",
      " 1 | 0 | 0\n",
      "-----------\n",
      "value: 0.32272276282310486\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.10794232040643692 | 0.0 | 0.36776530742645264\n",
      " 0.0 | 0.22617779672145844 | 0.2981145977973938\n",
      "===========\n",
      "choose from [0 0 0 1 0 1 0 1 1] :3\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 2 | 2 | 0\n",
      " 1 | 0 | 0\n",
      "-----------\n",
      "value: 0.633222222328186\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.09837274253368378\n",
      " 0.0 | 0.5998918414115906 | 0.30173537135124207\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 2 | 2 | 0\n",
      " 1 | 1 | 0\n",
      "-----------\n",
      "value: -0.9465801119804382\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.961860716342926\n",
      " 0.0 | 0.0 | 0.03813926875591278\n",
      "===========\n",
      "choose from [0 0 0 0 0 1 0 0 1] :5\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 2 | 2 | 2\n",
      " 1 | 1 | 0\n",
      "-----------\n",
      "value: -0.22095398604869843\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 1.0\n",
      "===========\n",
      "Player -1 won the game after 8 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(last_agent_1_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_c_puct_1_5_22\n"
     ]
    }
   ],
   "source": [
    "best_version = np.argmax(wins_3)\n",
    "\n",
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "best_model_1_5 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_c_puct_1_5\"\n",
    ")\n",
    "best_model_1_5.load(best_version)\n",
    "best_agent_1_5 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=best_model_1_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.16503317654132843\n",
      "policy:\n",
      " 0.12355843931436539 | 0.0 | 0.1230466216802597\n",
      " 0.12789300084114075 | 0.11086348444223404 | 0.13226988911628723\n",
      " 0.1266484409570694 | 0.12923240661621094 | 0.12648776173591614\n",
      "===========\n",
      "choose from [1 0 1 1 1 1 1 1 1] :4\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.6102713346481323\n",
      "policy:\n",
      " 0.1748170107603073 | 0.0 | 0.17650286853313446\n",
      " 0.13474568724632263 | 0.0 | 0.14296159148216248\n",
      " 0.12597326934337616 | 0.12677660584449768 | 0.11822301894426346\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 1\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.3052602708339691\n",
      "policy:\n",
      " 0.2210383117198944 | 0.0 | 0.0\n",
      " 0.23751738667488098 | 0.0 | 0.1573241651058197\n",
      " 0.09431099146604538 | 0.07889501750469208 | 0.21091414988040924\n",
      "===========\n",
      "choose from [1 0 0 1 0 1 1 1 1] :0\n",
      "===========\n",
      " 2 | 1 | 1\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.7808681726455688\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.11553293466567993 | 0.0 | 0.3205565810203552\n",
      " 0.14013183116912842 | 0.19405309855937958 | 0.22972556948661804\n",
      "===========\n",
      "===========\n",
      " 2 | 1 | 1\n",
      " 0 | 2 | 1\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: -0.8198919892311096\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.09381129592657089 | 0.0 | 0.0\n",
      " 0.10286249220371246 | 0.04421425610780716 | 0.7591119408607483\n",
      "===========\n",
      "choose from [0 0 0 1 0 0 1 1 1] :8\n",
      "===========\n",
      " 2 | 1 | 1\n",
      " 0 | 2 | 1\n",
      " 0 | 0 | 2\n",
      "-----------\n",
      "value: -0.5607782602310181\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.22983847558498383 | 0.0 | 0.0\n",
      " 0.31284984946250916 | 0.4573116898536682 | 0.0\n",
      "===========\n",
      "Player -1 won the game after 6 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(best_agent_1_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $c_{puct}$ = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_c_puct_5_29\n"
     ]
    }
   ],
   "source": [
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "last_model_5 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_c_puct_5\"\n",
    ")\n",
    "last_model_5.load(29)\n",
    "last_agent_5 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=last_model_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 1 | 0 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.5112273693084717\n",
      "policy:\n",
      " 0.0 | 0.12908935546875 | 0.12696082890033722\n",
      " 0.12333754450082779 | 0.127018541097641 | 0.12153360247612\n",
      " 0.1224307268857956 | 0.12451639771461487 | 0.12511302530765533\n",
      "===========\n",
      "choose from [0 1 1 1 1 1 1 1 1] :4\n",
      "===========\n",
      " 1 | 0 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: -0.3830385208129883\n",
      "policy:\n",
      " 0.0 | 0.17543098330497742 | 0.13477440178394318\n",
      " 0.15771807730197906 | 0.0 | 0.12601296603679657\n",
      " 0.1565110832452774 | 0.1225556805729866 | 0.12699678540229797\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.7234632968902588\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.1617031991481781\n",
      " 0.18445627391338348 | 0.0 | 0.20586685836315155\n",
      " 0.2201334536075592 | 0.14118757843971252 | 0.08665259182453156\n",
      "===========\n",
      "choose from [0 0 1 1 0 1 1 1 1] :2\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.5443383455276489\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.38323214650154114 | 0.0 | 0.11492326855659485\n",
      " 0.2355080395936966 | 0.1664143055677414 | 0.09992215037345886\n",
      "===========\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 1 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: -0.4177774488925934\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.06423821300268173\n",
      " 0.7306089401245117 | 0.043661437928676605 | 0.16149140894412994\n",
      "===========\n",
      "choose from [0 0 0 0 0 1 1 1 1] :6\n",
      "===========\n",
      " 1 | 1 | 2\n",
      " 1 | 2 | 0\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "value: 0.36480259895324707\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.29148027300834656\n",
      " 0.0 | 0.38168632984161377 | 0.3268333971500397\n",
      "===========\n",
      "Player -1 won the game after 6 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(last_agent_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_c_puct_5_18\n"
     ]
    }
   ],
   "source": [
    "best_version = np.argmax(wins_5)\n",
    "\n",
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "best_model_5 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_c_puct_5\"\n",
    ")\n",
    "best_model_5.load(best_version)\n",
    "best_agent_5 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=best_model_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_vs_player(best_agent_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $c_{puct}$ = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_c_puct_10_29\n"
     ]
    }
   ],
   "source": [
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "last_model_10 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_c_puct_10\"\n",
    ")\n",
    "last_model_10.load(29)\n",
    "last_agent_10 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=last_model_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.08974652737379074\n",
      "policy:\n",
      " 0.11975221335887909 | 0.0 | 0.12473759055137634\n",
      " 0.12402288615703583 | 0.13366402685642242 | 0.12119319289922714\n",
      " 0.12591516971588135 | 0.12393184006214142 | 0.12678304314613342\n",
      "===========\n",
      "choose from [1 0 1 1 1 1 1 1 1] :4\n",
      "===========\n",
      " 0 | 1 | 0\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: -0.25627315044403076\n",
      "policy:\n",
      " 0.14093030989170074 | 0.0 | 0.18181702494621277\n",
      " 0.14133617281913757 | 0.0 | 0.1457304209470749\n",
      " 0.12804195284843445 | 0.12672889232635498 | 0.1354152411222458\n",
      "===========\n",
      "===========\n",
      " 0 | 1 | 1\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.6881065368652344\n",
      "policy:\n",
      " 0.0991385355591774 | 0.0 | 0.0\n",
      " 0.20264926552772522 | 0.0 | 0.182353213429451\n",
      " 0.1929948478937149 | 0.1792798638343811 | 0.14358428120613098\n",
      "===========\n",
      "choose from [1 0 0 1 0 1 1 1 1] :0\n",
      "===========\n",
      " 2 | 1 | 1\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.45205917954444885\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.08853550255298615 | 0.0 | 0.2754504978656769\n",
      " 0.12388022243976593 | 0.18470658361911774 | 0.3274272382259369\n",
      "===========\n",
      "===========\n",
      " 2 | 1 | 1\n",
      " 0 | 2 | 0\n",
      " 0 | 0 | 1\n",
      "-----------\n",
      "value: 0.8057458400726318\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.22242966294288635 | 0.0 | 0.2846609652042389\n",
      " 0.2777177691459656 | 0.21519163250923157 | 0.0\n",
      "===========\n",
      "choose from [0 0 0 1 0 1 1 1 0] :5\n",
      "===========\n",
      " 2 | 1 | 1\n",
      " 0 | 2 | 2\n",
      " 0 | 0 | 1\n",
      "-----------\n",
      "value: 0.6225250959396362\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.18233205378055573 | 0.0 | 0.0\n",
      " 0.42960596084594727 | 0.3880619406700134 | 0.0\n",
      "===========\n",
      "===========\n",
      " 2 | 1 | 1\n",
      " 0 | 2 | 2\n",
      " 1 | 0 | 1\n",
      "-----------\n",
      "value: -0.7426813840866089\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.9499344825744629 | 0.0 | 0.0\n",
      " 0.0 | 0.05006549507379532 | 0.0\n",
      "===========\n",
      "choose from [0 0 0 1 0 0 0 1 0] :3\n",
      "===========\n",
      " 2 | 1 | 1\n",
      " 2 | 2 | 2\n",
      " 1 | 0 | 1\n",
      "-----------\n",
      "value: -0.15133053064346313\n",
      "policy:\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 1.0 | 0.0\n",
      "===========\n",
      "Player -1 won the game after 8 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(last_agent_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model tictactoe_c_puct_10_23\n"
     ]
    }
   ],
   "source": [
    "best_version = np.argmax(wins_6)\n",
    "\n",
    "position_memory = memory.PositionMemory(variant=\"TicTacToe\")\n",
    "best_model_10 = model.AZModel(\n",
    "    memory=position_memory,\n",
    "    input_shape=[3,3,3],\n",
    "    num_possible_moves=9,\n",
    "    model_id=\"tictactoe_c_puct_10\"\n",
    ")\n",
    "best_model_10.load(best_version)\n",
    "best_agent_10 = agent.AlphaZeroAgent(variant=\"TicTacToe\", model=best_model_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      " 1 | 0 | 0\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.3522714674472809\n",
      "policy:\n",
      " 0.0 | 0.12680478394031525 | 0.12331725656986237\n",
      " 0.12271157652139664 | 0.12184380739927292 | 0.12532709538936615\n",
      " 0.12168891727924347 | 0.12462539970874786 | 0.13368116319179535\n",
      "===========\n",
      "choose from [0 1 1 1 1 1 1 1 1] :2\n",
      "===========\n",
      " 1 | 0 | 2\n",
      " 0 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: -0.2785353660583496\n",
      "policy:\n",
      " 0.0 | 0.12986725568771362 | 0.0\n",
      " 0.15262804925441742 | 0.14406737685203552 | 0.14026419818401337\n",
      " 0.15870638191699982 | 0.13076439499855042 | 0.14370234310626984\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 2\n",
      " 1 | 0 | 0\n",
      " 0 | 0 | 0\n",
      "-----------\n",
      "value: 0.35749441385269165\n",
      "policy:\n",
      " 0.0 | 0.1521761566400528 | 0.0\n",
      " 0.0 | 0.18487617373466492 | 0.15081407129764557\n",
      " 0.1608162373304367 | 0.15216748416423798 | 0.19914981722831726\n",
      "===========\n",
      "choose from [0 1 0 0 1 1 1 1 1] :6\n",
      "===========\n",
      " 1 | 0 | 2\n",
      " 1 | 0 | 0\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "value: 0.5934826135635376\n",
      "policy:\n",
      " 0.0 | 0.14999115467071533 | 0.0\n",
      " 0.0 | 0.30123963952064514 | 0.20381486415863037\n",
      " 0.0 | 0.19227105379104614 | 0.152683287858963\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 2\n",
      " 1 | 1 | 0\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "value: 0.24201741814613342\n",
      "policy:\n",
      " 0.0 | 0.1364113688468933 | 0.0\n",
      " 0.0 | 0.0 | 0.18224674463272095\n",
      " 0.0 | 0.1215234249830246 | 0.5598184466362\n",
      "===========\n",
      "choose from [0 1 0 0 0 1 0 1 1] :5\n",
      "===========\n",
      " 1 | 0 | 2\n",
      " 1 | 1 | 2\n",
      " 2 | 0 | 0\n",
      "-----------\n",
      "value: -0.8337244987487793\n",
      "policy:\n",
      " 0.0 | 0.28024792671203613 | 0.0\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.09220948815345764 | 0.6275426149368286\n",
      "===========\n",
      "===========\n",
      " 1 | 0 | 2\n",
      " 1 | 1 | 2\n",
      " 2 | 0 | 1\n",
      "-----------\n",
      "value: 0.17143064737319946\n",
      "policy:\n",
      " 0.0 | 0.46275457739830017 | 0.0\n",
      " 0.0 | 0.0 | 0.0\n",
      " 0.0 | 0.5372453927993774 | 0.0\n",
      "===========\n",
      "Player 1 won the game after 7 turns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_vs_player(best_agent_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
