{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimen: TicTacToe - Number of Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCTS = {\n",
    "    'c_puct': 1.0,\n",
    "    'dir_alpha': 0.5,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 1,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 1\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 50,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 0,\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 50,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.02, \n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 256,\n",
    "    'num_filters_value': 256,\n",
    "    'num_filters_tower': 256,\n",
    "    'num_residual_blocks': 5,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 256\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"tictactoe_1_epoch\", \"TicTacToe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 3s 7ms/step - loss: 5.3722 - value_loss: 1.1022 - policy_loss: 2.5317 - val_loss: 2640813.2500 - val_value_loss: 1.8252 - val_policy_loss: 5281612.5000\n",
      "Saved model  tictactoe_1_epoch_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.34 - draw ratio 0.1\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 139us/step - loss: 14.1072 - value_loss: 1.6012 - policy_loss: 16.7814 - val_loss: 408068.2500 - val_value_loss: 1.8155 - val_policy_loss: 816119.8750\n",
      "Saved model  tictactoe_1_epoch_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.58 - draw ratio 0.02\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 144us/step - loss: 17.3070 - value_loss: 2.2592 - policy_loss: 17.5778 - val_loss: 23708.1680 - val_value_loss: 2.2136 - val_policy_loss: 47393.0859\n",
      "Saved model  tictactoe_1_epoch_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.64 - draw ratio 0.02\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 139us/step - loss: 20.3672 - value_loss: 2.2298 - policy_loss: 17.4700 - val_loss: 5896.1152 - val_value_loss: 2.3786 - val_policy_loss: 11762.2168\n",
      "Saved model  tictactoe_1_epoch_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.44 - draw ratio 0.06\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 142us/step - loss: 20.9968 - value_loss: 2.0611 - policy_loss: 12.2965 - val_loss: 1846.2225 - val_value_loss: 2.4369 - val_policy_loss: 3655.9978\n",
      "Saved model  tictactoe_1_epoch_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.34 - draw ratio 0.18\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 137us/step - loss: 22.5338 - value_loss: 2.1271 - policy_loss: 8.9304 - val_loss: 996.5909 - val_value_loss: 2.1748 - val_policy_loss: 1951.1902\n",
      "Saved model  tictactoe_1_epoch_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.72 - draw ratio 0.0\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 139us/step - loss: 24.7843 - value_loss: 2.0978 - policy_loss: 7.6537 - val_loss: 817.7913 - val_value_loss: 2.1650 - val_policy_loss: 1588.5496\n",
      "Saved model  tictactoe_1_epoch_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.52 - draw ratio 0.08\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 139us/step - loss: 26.8842 - value_loss: 2.0538 - policy_loss: 6.8468 - val_loss: 651.5361 - val_value_loss: 2.3010 - val_policy_loss: 1251.7141\n",
      "Saved model  tictactoe_1_epoch_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.5 - draw ratio 0.06\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 139us/step - loss: 28.8939 - value_loss: 1.8680 - policy_loss: 6.8628 - val_loss: 537.0795 - val_value_loss: 2.0777 - val_policy_loss: 1019.7131\n",
      "Saved model  tictactoe_1_epoch_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.36 - draw ratio 0.04\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 142us/step - loss: 30.5200 - value_loss: 1.9413 - policy_loss: 6.7304 - val_loss: 422.7488 - val_value_loss: 1.8932 - val_policy_loss: 788.7856\n",
      "Saved model  tictactoe_1_epoch_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.52 - draw ratio 0.08\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 139us/step - loss: 31.1728 - value_loss: 2.2029 - policy_loss: 5.3240 - val_loss: 284.0616 - val_value_loss: 2.2427 - val_policy_loss: 509.4206\n",
      "Saved model  tictactoe_1_epoch_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.48 - draw ratio 0.08\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 142us/step - loss: 31.8697 - value_loss: 2.1467 - policy_loss: 5.1330 - val_loss: 169.2153 - val_value_loss: 2.1165 - val_policy_loss: 278.9594\n",
      "Saved model  tictactoe_1_epoch_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.66 - draw ratio 0.02\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 139us/step - loss: 31.8490 - value_loss: 2.1785 - policy_loss: 4.1647 - val_loss: 101.8767 - val_value_loss: 1.9709 - val_policy_loss: 144.2014\n",
      "Saved model  tictactoe_1_epoch_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.5 - draw ratio 0.06\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 139us/step - loss: 31.2634 - value_loss: 1.9951 - policy_loss: 2.9506 - val_loss: 101.0492 - val_value_loss: 2.0291 - val_policy_loss: 142.8550\n",
      "Saved model  tictactoe_1_epoch_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.52 - draw ratio 0.14\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 139us/step - loss: 31.3738 - value_loss: 2.2567 - policy_loss: 3.2767 - val_loss: 78.6029 - val_value_loss: 2.5340 - val_policy_loss: 98.3300\n",
      "Saved model  tictactoe_1_epoch_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.46 - draw ratio 0.16\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 139us/step - loss: 30.7528 - value_loss: 2.1222 - policy_loss: 3.0416 - val_loss: 60.7643 - val_value_loss: 2.4563 - val_policy_loss: 64.0226\n",
      "Saved model  tictactoe_1_epoch_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.62 - draw ratio 0.12\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 139us/step - loss: 30.1723 - value_loss: 2.2494 - policy_loss: 3.0454 - val_loss: 53.6894 - val_value_loss: 2.1650 - val_policy_loss: 51.7925\n",
      "Saved model  tictactoe_1_epoch_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.36 - draw ratio 0.2\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 142us/step - loss: 29.2397 - value_loss: 2.1736 - policy_loss: 2.8845 - val_loss: 44.2135 - val_value_loss: 2.3883 - val_policy_loss: 34.5112\n",
      "Saved model  tictactoe_1_epoch_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.56 - draw ratio 0.16\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 142us/step - loss: 28.1774 - value_loss: 1.9707 - policy_loss: 2.8566 - val_loss: 41.5812 - val_value_loss: 2.3301 - val_policy_loss: 31.3963\n",
      "Saved model  tictactoe_1_epoch_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.44 - draw ratio 0.18\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 139us/step - loss: 27.0884 - value_loss: 2.1394 - policy_loss: 2.6015 - val_loss: 38.4331 - val_value_loss: 2.6019 - val_policy_loss: 27.0586\n",
      "Saved model  tictactoe_1_epoch_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.08\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 142us/step - loss: 26.0354 - value_loss: 2.1540 - policy_loss: 2.7112 - val_loss: 30.1358 - val_value_loss: 2.0291 - val_policy_loss: 13.3553\n",
      "Saved model  tictactoe_1_epoch_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.42 - draw ratio 0.18\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 142us/step - loss: 24.8223 - value_loss: 2.1369 - policy_loss: 2.6206 - val_loss: 25.7563 - val_value_loss: 2.1456 - val_policy_loss: 6.8416\n",
      "Saved model  tictactoe_1_epoch_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.4 - draw ratio 0.22\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 137us/step - loss: 23.6717 - value_loss: 2.2445 - policy_loss: 2.5735 - val_loss: 24.3132 - val_value_loss: 2.1456 - val_policy_loss: 6.3235\n",
      "Saved model  tictactoe_1_epoch_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.46 - draw ratio 0.12\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 142us/step - loss: 22.4160 - value_loss: 2.2689 - policy_loss: 2.4057 - val_loss: 21.6342 - val_value_loss: 2.0388 - val_policy_loss: 3.4165\n",
      "Saved model  tictactoe_1_epoch_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.54 - draw ratio 0.06\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 142us/step - loss: 21.1823 - value_loss: 2.1565 - policy_loss: 2.3951 - val_loss: 20.4758 - val_value_loss: 2.2233 - val_policy_loss: 3.2123\n",
      "Saved model  tictactoe_1_epoch_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.46 - draw ratio 0.16\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 137us/step - loss: 20.0609 - value_loss: 2.1687 - policy_loss: 2.4370 - val_loss: 20.0771 - val_value_loss: 1.6019 - val_policy_loss: 3.2679\n",
      "Saved model  tictactoe_1_epoch_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.48 - draw ratio 0.2\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 142us/step - loss: 19.9180 - value_loss: 2.1418 - policy_loss: 2.4100 - val_loss: 20.1387 - val_value_loss: 2.4854 - val_policy_loss: 2.7497\n",
      "Saved model  tictactoe_1_epoch_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.54 - draw ratio 0.18\n",
      "iteration 27 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 139us/step - loss: 19.7285 - value_loss: 1.9731 - policy_loss: 2.4416 - val_loss: 19.9027 - val_value_loss: 2.3883 - val_policy_loss: 2.6260\n",
      "Saved model  tictactoe_1_epoch_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.56 - draw ratio 0.16\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 139us/step - loss: 19.5778 - value_loss: 2.0171 - policy_loss: 2.3476 - val_loss: 19.9738 - val_value_loss: 2.2136 - val_policy_loss: 3.2029\n",
      "Saved model  tictactoe_1_epoch_28\n",
      "iteration 28 | evaluation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent vs random - win ratio 0.6 - draw ratio 0.16\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 142us/step - loss: 19.5463 - value_loss: 2.2103 - policy_loss: 2.3511 - val_loss: 19.5874 - val_value_loss: 1.9320 - val_policy_loss: 2.9789\n",
      "Saved model  tictactoe_1_epoch_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.64 - draw ratio 0.1\n",
      "iteration 30 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_30\n",
      "iteration 30 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 139us/step - loss: 19.5009 - value_loss: 2.3252 - policy_loss: 2.4128 - val_loss: 19.2509 - val_value_loss: 2.2718 - val_policy_loss: 2.2404\n",
      "Saved model  tictactoe_1_epoch_30\n",
      "iteration 30 | evaluation\n",
      "agent vs random - win ratio 0.72 - draw ratio 0.08\n",
      "iteration 31 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_31\n",
      "iteration 31 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 139us/step - loss: 19.2324 - value_loss: 2.1100 - policy_loss: 2.3652 - val_loss: 19.3237 - val_value_loss: 2.3592 - val_policy_loss: 2.5790\n",
      "Saved model  tictactoe_1_epoch_31\n",
      "iteration 31 | evaluation\n",
      "agent vs random - win ratio 0.56 - draw ratio 0.08\n",
      "iteration 32 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_32\n",
      "iteration 32 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 139us/step - loss: 19.0527 - value_loss: 2.0513 - policy_loss: 2.3449 - val_loss: 18.9747 - val_value_loss: 2.2039 - val_policy_loss: 2.3220\n",
      "Saved model  tictactoe_1_epoch_32\n",
      "iteration 32 | evaluation\n",
      "agent vs random - win ratio 0.66 - draw ratio 0.08\n",
      "iteration 33 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_33\n",
      "iteration 33 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 139us/step - loss: 18.9761 - value_loss: 2.2445 - policy_loss: 2.2842 - val_loss: 18.9772 - val_value_loss: 2.1650 - val_policy_loss: 2.6563\n",
      "Saved model  tictactoe_1_epoch_33\n",
      "iteration 33 | evaluation\n",
      "agent vs random - win ratio 0.6 - draw ratio 0.14\n",
      "iteration 34 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_34\n",
      "iteration 34 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 139us/step - loss: 18.7624 - value_loss: 2.1589 - policy_loss: 2.2328 - val_loss: 18.7159 - val_value_loss: 2.3495 - val_policy_loss: 2.2439\n",
      "Saved model  tictactoe_1_epoch_34\n",
      "iteration 34 | evaluation\n",
      "agent vs random - win ratio 0.68 - draw ratio 0.08\n",
      "iteration 35 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_35\n",
      "iteration 35 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 139us/step - loss: 18.5596 - value_loss: 2.0391 - policy_loss: 2.2417 - val_loss: 18.5912 - val_value_loss: 2.3592 - val_policy_loss: 2.2830\n",
      "Saved model  tictactoe_1_epoch_35\n",
      "iteration 35 | evaluation\n",
      "agent vs random - win ratio 0.66 - draw ratio 0.08\n",
      "iteration 36 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_36\n",
      "iteration 36 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 142us/step - loss: 18.4622 - value_loss: 2.1491 - policy_loss: 2.2350 - val_loss: 18.3427 - val_value_loss: 2.0874 - val_policy_loss: 2.3591\n",
      "Saved model  tictactoe_1_epoch_36\n",
      "iteration 36 | evaluation\n",
      "agent vs random - win ratio 0.68 - draw ratio 0.06\n",
      "iteration 37 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_37\n",
      "iteration 37 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 142us/step - loss: 18.4006 - value_loss: 2.2787 - policy_loss: 2.2835 - val_loss: 18.1619 - val_value_loss: 2.0583 - val_policy_loss: 2.3303\n",
      "Saved model  tictactoe_1_epoch_37\n",
      "iteration 37 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.04\n",
      "iteration 38 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_38\n",
      "iteration 38 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 142us/step - loss: 18.1414 - value_loss: 2.1443 - policy_loss: 2.2032 - val_loss: 17.8076 - val_value_loss: 1.7282 - val_policy_loss: 2.2576\n",
      "Saved model  tictactoe_1_epoch_38\n",
      "iteration 38 | evaluation\n",
      "agent vs random - win ratio 0.64 - draw ratio 0.04\n",
      "iteration 39 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_39\n",
      "iteration 39 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 149us/step - loss: 17.9517 - value_loss: 2.0807 - policy_loss: 2.1932 - val_loss: 17.8641 - val_value_loss: 2.1359 - val_policy_loss: 2.2704\n",
      "Saved model  tictactoe_1_epoch_39\n",
      "iteration 39 | evaluation\n",
      "agent vs random - win ratio 0.68 - draw ratio 0.08\n",
      "iteration 40 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_40\n",
      "iteration 40 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 157us/step - loss: 17.8452 - value_loss: 2.1736 - policy_loss: 2.1948 - val_loss: 17.6137 - val_value_loss: 2.0194 - val_policy_loss: 2.1948\n",
      "Saved model  tictactoe_1_epoch_40\n",
      "iteration 40 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.02\n",
      "iteration 41 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_41\n",
      "iteration 41 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 139us/step - loss: 17.7641 - value_loss: 2.3130 - policy_loss: 2.2021 - val_loss: 17.5175 - val_value_loss: 2.1359 - val_policy_loss: 2.1956\n",
      "Saved model  tictactoe_1_epoch_41\n",
      "iteration 41 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.02\n",
      "iteration 42 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_42\n",
      "iteration 42 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 139us/step - loss: 17.5092 - value_loss: 2.0831 - policy_loss: 2.2317 - val_loss: 17.4199 - val_value_loss: 2.2233 - val_policy_loss: 2.2234\n",
      "Saved model  tictactoe_1_epoch_42\n",
      "iteration 42 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.08\n",
      "iteration 43 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_43\n",
      "iteration 43 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 142us/step - loss: 17.3399 - value_loss: 2.0954 - policy_loss: 2.1912 - val_loss: 17.2771 - val_value_loss: 2.2621 - val_policy_loss: 2.2096\n",
      "Saved model  tictactoe_1_epoch_43\n",
      "iteration 43 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.02\n",
      "iteration 44 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_44\n",
      "iteration 44 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 142us/step - loss: 17.2666 - value_loss: 2.2274 - policy_loss: 2.2233 - val_loss: 17.2543 - val_value_loss: 2.5340 - val_policy_loss: 2.2027\n",
      "Saved model  tictactoe_1_epoch_44\n",
      "iteration 44 | evaluation\n",
      "agent vs random - win ratio 0.72 - draw ratio 0.02\n",
      "iteration 45 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_45\n",
      "iteration 45 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 142us/step - loss: 17.0242 - value_loss: 2.0782 - policy_loss: 2.1982 - val_loss: 16.9087 - val_value_loss: 2.1553 - val_policy_loss: 2.2006\n",
      "Saved model  tictactoe_1_epoch_45\n",
      "iteration 45 | evaluation\n",
      "agent vs random - win ratio 0.64 - draw ratio 0.04\n",
      "iteration 46 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_46\n",
      "iteration 46 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 139us/step - loss: 16.9239 - value_loss: 2.1956 - policy_loss: 2.1907 - val_loss: 16.8498 - val_value_loss: 2.3495 - val_policy_loss: 2.1987\n",
      "Saved model  tictactoe_1_epoch_46\n",
      "iteration 46 | evaluation\n",
      "agent vs random - win ratio 0.64 - draw ratio 0.02\n",
      "iteration 47 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_47\n",
      "iteration 47 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 142us/step - loss: 16.6696 - value_loss: 1.9878 - policy_loss: 2.2001 - val_loss: 16.7214 - val_value_loss: 2.4078 - val_policy_loss: 2.1932\n",
      "Saved model  tictactoe_1_epoch_47\n",
      "iteration 47 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.0\n",
      "iteration 48 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_48\n",
      "iteration 48 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 139us/step - loss: 16.4667 - value_loss: 1.9046 - policy_loss: 2.1869 - val_loss: 16.3687 - val_value_loss: 1.9806 - val_policy_loss: 2.2236\n",
      "Saved model  tictactoe_1_epoch_48\n",
      "iteration 48 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.02\n",
      "iteration 49 | self-play\n",
      "saving memory position_memory_tictactoe_1_epoch_ep_49\n",
      "iteration 49 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/1\n",
      "409/409 [==============================] - 0s 144us/step - loss: 16.4803 - value_loss: 2.2274 - policy_loss: 2.2001 - val_loss: 16.1736 - val_value_loss: 1.9320 - val_policy_loss: 2.1897\n",
      "Saved model  tictactoe_1_epoch_49\n",
      "iteration 49 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.0\n"
     ]
    }
   ],
   "source": [
    "wins_1, draws_1 = test_pipeline.run(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(50)\n",
    "losses_1 = np.ones(50) - wins_1 - draws_1\n",
    "# no_loss = np.zeros(50) + wins +draws\n",
    "\n",
    "plt.plot(x, wins_1, label=\"win ratio\")\n",
    "plt.plot(x, draws_1, label=\"draw ratio\")\n",
    "#plt.plot(x, no_loss, label=\"no loss ratio\")\n",
    "plt.plot(x, losses_1, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34, 0.58, 0.64, 0.44, 0.34, 0.72, 0.52, 0.5, 0.36, 0.52, 0.48, 0.66, 0.5, 0.52, 0.46, 0.62, 0.36, 0.56, 0.44, 0.7, 0.42, 0.4, 0.46, 0.54, 0.46, 0.48, 0.54, 0.56, 0.6, 0.64, 0.72, 0.56, 0.66, 0.6, 0.68, 0.66, 0.68, 0.8, 0.64, 0.68, 0.76, 0.76, 0.76, 0.8, 0.72, 0.64, 0.64, 0.74, 0.7, 0.7]\n",
      "[0.1, 0.02, 0.02, 0.06, 0.18, 0.0, 0.08, 0.06, 0.04, 0.08, 0.08, 0.02, 0.06, 0.14, 0.16, 0.12, 0.2, 0.16, 0.18, 0.08, 0.18, 0.22, 0.12, 0.06, 0.16, 0.2, 0.18, 0.16, 0.16, 0.1, 0.08, 0.08, 0.08, 0.14, 0.08, 0.08, 0.06, 0.04, 0.04, 0.08, 0.02, 0.02, 0.08, 0.02, 0.02, 0.04, 0.02, 0.0, 0.02, 0.0]\n",
      "[0.56 0.4  0.34 0.5  0.48 0.28 0.4  0.44 0.6  0.4  0.44 0.32 0.44 0.34\n",
      " 0.38 0.26 0.44 0.28 0.38 0.22 0.4  0.38 0.42 0.4  0.38 0.32 0.28 0.28\n",
      " 0.24 0.26 0.2  0.36 0.26 0.26 0.24 0.26 0.26 0.16 0.32 0.24 0.22 0.22\n",
      " 0.16 0.18 0.26 0.32 0.34 0.26 0.28 0.3 ]\n"
     ]
    }
   ],
   "source": [
    "print(wins_1)\n",
    "print(draws_1)\n",
    "print(losses_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" These dictionarys set most of the relevant settings and hyperparameters for the program. \"\"\"\n",
    "\n",
    "MCTS = {\n",
    "    'c_puct': 1.0,\n",
    "    'dir_alpha': 0.5,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 1,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 3\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 50,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 0,\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 50,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.02, \n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 256,\n",
    "    'num_filters_value': 256,\n",
    "    'num_filters_tower': 256,\n",
    "    'num_residual_blocks': 5,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 256\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"tictactoe_3_epochs\", \"TicTacToe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 3s 7ms/step - loss: 5.3762 - value_loss: 1.0056 - policy_loss: 2.6297 - val_loss: 5217160.5000 - val_value_loss: 1.6311 - val_policy_loss: 10434306.0000\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 12.2074 - value_loss: 1.5355 - policy_loss: 13.0508 - val_loss: 161275.4375 - val_value_loss: 1.6311 - val_policy_loss: 322534.1250\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 15.7142 - value_loss: 1.5355 - policy_loss: 14.7806 - val_loss: 22108.3281 - val_value_loss: 1.6311 - val_policy_loss: 44193.5547\n",
      "Saved model  tictactoe_3_epochs_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.54 - draw ratio 0.08\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 19.3708 - value_loss: 1.8289 - policy_loss: 15.4490 - val_loss: 9560.6885 - val_value_loss: 1.8641 - val_policy_loss: 19091.5039\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 21.0247 - value_loss: 1.8289 - policy_loss: 12.2141 - val_loss: 3117.8518 - val_value_loss: 1.8641 - val_policy_loss: 6199.6226\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 149us/step - loss: 22.2922 - value_loss: 1.8289 - policy_loss: 8.5386 - val_loss: 2136.4968 - val_value_loss: 1.8641 - val_policy_loss: 4231.3438\n",
      "Saved model  tictactoe_3_epochs_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.38 - draw ratio 0.14\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 25.5017 - value_loss: 1.7702 - policy_loss: 9.4480 - val_loss: 1252.6384 - val_value_loss: 1.6019 - val_policy_loss: 2459.1479\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 26.6716 - value_loss: 1.7702 - policy_loss: 7.0463 - val_loss: 809.1135 - val_value_loss: 1.6019 - val_policy_loss: 1568.2300\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 152us/step - loss: 27.8102 - value_loss: 1.7702 - policy_loss: 5.4552 - val_loss: 727.7041 - val_value_loss: 1.6019 - val_policy_loss: 1402.4406\n",
      "Saved model  tictactoe_3_epochs_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.54 - draw ratio 0.06\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 29.3216 - value_loss: 1.8484 - policy_loss: 5.4290 - val_loss: 416.0408 - val_value_loss: 1.7379 - val_policy_loss: 776.8640\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 30.0313 - value_loss: 1.8484 - policy_loss: 4.7344 - val_loss: 289.6076 - val_value_loss: 1.7379 - val_policy_loss: 522.6600\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 30.2096 - value_loss: 1.8484 - policy_loss: 3.7535 - val_loss: 199.8929 - val_value_loss: 1.7379 - val_policy_loss: 342.6030\n",
      "Saved model  tictactoe_3_epochs_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.66 - draw ratio 0.1\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 30.3749 - value_loss: 1.8680 - policy_loss: 3.4369 - val_loss: 166.9298 - val_value_loss: 1.9903 - val_policy_loss: 276.4221\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 30.3888 - value_loss: 1.8680 - policy_loss: 3.4623 - val_loss: 142.4122 - val_value_loss: 1.9903 - val_policy_loss: 227.9185\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 30.0877 - value_loss: 1.8680 - policy_loss: 3.3918 - val_loss: 110.4806 - val_value_loss: 1.9903 - val_policy_loss: 165.0373\n",
      "Saved model  tictactoe_3_epochs_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.54 - draw ratio 0.06\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 29.6125 - value_loss: 1.8117 - policy_loss: 3.4795 - val_loss: 83.1038 - val_value_loss: 1.2816 - val_policy_loss: 112.3397\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 149us/step - loss: 28.7523 - value_loss: 1.8117 - policy_loss: 3.1065 - val_loss: 56.6695 - val_value_loss: 1.2816 - val_policy_loss: 61.1051\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 152us/step - loss: 27.8354 - value_loss: 1.8117 - policy_loss: 2.9067 - val_loss: 47.3426 - val_value_loss: 1.2816 - val_policy_loss: 44.3026\n",
      "Saved model  tictactoe_3_epochs_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.5 - draw ratio 0.14\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 26.7439 - value_loss: 1.7042 - policy_loss: 2.6826 - val_loss: 35.2137 - val_value_loss: 1.8350 - val_policy_loss: 21.5000\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 25.6260 - value_loss: 1.7042 - policy_loss: 2.4552 - val_loss: 31.8661 - val_value_loss: 1.8350 - val_policy_loss: 16.9189\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 24.5987 - value_loss: 1.7042 - policy_loss: 2.5149 - val_loss: 28.1335 - val_value_loss: 1.8350 - val_policy_loss: 11.6297\n",
      "Saved model  tictactoe_3_epochs_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.48 - draw ratio 0.2\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 23.6683 - value_loss: 1.7971 - policy_loss: 2.7372 - val_loss: 23.6350 - val_value_loss: 1.9417 - val_policy_loss: 4.7269\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 152us/step - loss: 22.4778 - value_loss: 1.7971 - policy_loss: 2.5572 - val_loss: 21.9626 - val_value_loss: 1.9417 - val_policy_loss: 3.5778\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 152us/step - loss: 21.3417 - value_loss: 1.7971 - policy_loss: 2.4808 - val_loss: 20.7194 - val_value_loss: 1.9417 - val_policy_loss: 3.2577\n",
      "Saved model  tictactoe_3_epochs_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.48 - draw ratio 0.12\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 20.2929 - value_loss: 1.9095 - policy_loss: 2.4369 - val_loss: 19.5062 - val_value_loss: 1.6699 - val_policy_loss: 3.2223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 19.2390 - value_loss: 1.9095 - policy_loss: 2.4483 - val_loss: 18.2285 - val_value_loss: 1.6699 - val_policy_loss: 2.7234\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 18.2018 - value_loss: 1.9095 - policy_loss: 2.4303 - val_loss: 17.1033 - val_value_loss: 1.6699 - val_policy_loss: 2.4545\n",
      "Saved model  tictactoe_3_epochs_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.44 - draw ratio 0.12\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 149us/step - loss: 17.1621 - value_loss: 1.8826 - policy_loss: 2.3594 - val_loss: 16.1894 - val_value_loss: 1.9223 - val_policy_loss: 2.2727\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 152us/step - loss: 16.2138 - value_loss: 1.8826 - policy_loss: 2.3612 - val_loss: 15.2656 - val_value_loss: 1.9223 - val_policy_loss: 2.2353\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 149us/step - loss: 15.3152 - value_loss: 1.8826 - policy_loss: 2.3743 - val_loss: 14.3961 - val_value_loss: 1.9223 - val_policy_loss: 2.2161\n",
      "Saved model  tictactoe_3_epochs_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.56 - draw ratio 0.1\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 14.3693 - value_loss: 1.6406 - policy_loss: 2.4442 - val_loss: 13.4662 - val_value_loss: 1.6796 - val_policy_loss: 2.2270\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 13.5413 - value_loss: 1.6406 - policy_loss: 2.4163 - val_loss: 12.6887 - val_value_loss: 1.6796 - val_policy_loss: 2.2079\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 12.7604 - value_loss: 1.6406 - policy_loss: 2.3903 - val_loss: 11.9627 - val_value_loss: 1.6796 - val_policy_loss: 2.2008\n",
      "Saved model  tictactoe_3_epochs_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.58 - draw ratio 0.08\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 154us/step - loss: 11.9995 - value_loss: 1.6039 - policy_loss: 2.3500 - val_loss: 11.3499 - val_value_loss: 1.8155 - val_policy_loss: 2.1954\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 157us/step - loss: 11.3106 - value_loss: 1.6039 - policy_loss: 2.3285 - val_loss: 10.7144 - val_value_loss: 1.8155 - val_policy_loss: 2.1955\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 149us/step - loss: 10.6655 - value_loss: 1.6039 - policy_loss: 2.3094 - val_loss: 10.1196 - val_value_loss: 1.8155 - val_policy_loss: 2.1955\n",
      "Saved model  tictactoe_3_epochs_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.58 - draw ratio 0.06\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 10.0721 - value_loss: 1.6430 - policy_loss: 2.2731 - val_loss: 9.4924 - val_value_loss: 1.6699 - val_policy_loss: 2.1979\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 9.5076 - value_loss: 1.6430 - policy_loss: 2.2550 - val_loss: 8.9746 - val_value_loss: 1.6699 - val_policy_loss: 2.1979\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 8.9811 - value_loss: 1.6430 - policy_loss: 2.2379 - val_loss: 8.4922 - val_value_loss: 1.6699 - val_policy_loss: 2.1980\n",
      "Saved model  tictactoe_3_epochs_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.04\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 8.4951 - value_loss: 1.6601 - policy_loss: 2.2136 - val_loss: 8.1589 - val_value_loss: 1.9029 - val_policy_loss: 2.1964\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 8.0492 - value_loss: 1.6601 - policy_loss: 2.2196 - val_loss: 7.7411 - val_value_loss: 1.9029 - val_policy_loss: 2.1963\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 7.6316 - value_loss: 1.6601 - policy_loss: 2.2200 - val_loss: 7.3529 - val_value_loss: 1.9029 - val_policy_loss: 2.1963\n",
      "Saved model  tictactoe_3_epochs_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.04\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 7.2801 - value_loss: 1.7311 - policy_loss: 2.2224 - val_loss: 6.9736 - val_value_loss: 1.8641 - val_policy_loss: 2.1972\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 6.9198 - value_loss: 1.7311 - policy_loss: 2.2226 - val_loss: 6.6391 - val_value_loss: 1.8641 - val_policy_loss: 2.1972\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 6.5901 - value_loss: 1.7311 - policy_loss: 2.2321 - val_loss: 6.3285 - val_value_loss: 1.8641 - val_policy_loss: 2.1971\n",
      "Saved model  tictactoe_3_epochs_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.02\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 6.3005 - value_loss: 1.7090 - policy_loss: 2.2961 - val_loss: 5.8256 - val_value_loss: 1.4369 - val_policy_loss: 2.1953\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 6.0022 - value_loss: 1.7090 - policy_loss: 2.2763 - val_loss: 5.5581 - val_value_loss: 1.4369 - val_policy_loss: 2.1951\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 5.7151 - value_loss: 1.7090 - policy_loss: 2.2367 - val_loss: 5.3103 - val_value_loss: 1.4369 - val_policy_loss: 2.1948\n",
      "Saved model  tictactoe_3_epochs_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.02\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 5.3997 - value_loss: 1.6137 - policy_loss: 2.1968 - val_loss: 5.3493 - val_value_loss: 1.9709 - val_policy_loss: 2.1980\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 5.1697 - value_loss: 1.6137 - policy_loss: 2.1959 - val_loss: 5.1363 - val_value_loss: 1.9709 - val_policy_loss: 2.1979\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 4.9571 - value_loss: 1.6137 - policy_loss: 2.1967 - val_loss: 4.9385 - val_value_loss: 1.9709 - val_policy_loss: 2.1979\n",
      "Saved model  tictactoe_3_epochs_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.08\n",
      "iteration 17 | self-play\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving memory position_memory_tictactoe_3_epochs_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 4.8286 - value_loss: 1.7286 - policy_loss: 2.2203 - val_loss: 4.5222 - val_value_loss: 1.5049 - val_policy_loss: 2.1982\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 4.6384 - value_loss: 1.7286 - policy_loss: 2.2067 - val_loss: 4.3520 - val_value_loss: 1.5049 - val_policy_loss: 2.1981\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 4.4614 - value_loss: 1.7286 - policy_loss: 2.1931 - val_loss: 4.1942 - val_value_loss: 1.5049 - val_policy_loss: 2.1981\n",
      "Saved model  tictactoe_3_epochs_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.02\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 4.2777 - value_loss: 1.6650 - policy_loss: 2.2049 - val_loss: 4.1101 - val_value_loss: 1.6311 - val_policy_loss: 2.1969\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 4.1231 - value_loss: 1.6650 - policy_loss: 2.1891 - val_loss: 3.9743 - val_value_loss: 1.6311 - val_policy_loss: 2.1969\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 3.9852 - value_loss: 1.6650 - policy_loss: 2.1849 - val_loss: 3.8482 - val_value_loss: 1.6311 - val_policy_loss: 2.1970\n",
      "Saved model  tictactoe_3_epochs_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.0\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 152us/step - loss: 3.9664 - value_loss: 1.8655 - policy_loss: 2.1989 - val_loss: 3.6975 - val_value_loss: 1.5631 - val_policy_loss: 2.1975\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 149us/step - loss: 3.8429 - value_loss: 1.8655 - policy_loss: 2.1859 - val_loss: 3.5887 - val_value_loss: 1.5631 - val_policy_loss: 2.1974\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 149us/step - loss: 3.7327 - value_loss: 1.8655 - policy_loss: 2.1831 - val_loss: 3.4874 - val_value_loss: 1.5631 - val_policy_loss: 2.1973\n",
      "Saved model  tictactoe_3_epochs_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.0\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 3.5302 - value_loss: 1.6381 - policy_loss: 2.2079 - val_loss: 3.3293 - val_value_loss: 1.4369 - val_policy_loss: 2.1958\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 155us/step - loss: 3.4281 - value_loss: 1.6377 - policy_loss: 2.1926 - val_loss: 3.2418 - val_value_loss: 1.4369 - val_policy_loss: 2.1957\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 3.3145 - value_loss: 1.5972 - policy_loss: 2.1807 - val_loss: 3.5651 - val_value_loss: 2.2292 - val_policy_loss: 2.1956\n",
      "Saved model  tictactoe_3_epochs_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.08\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 152us/step - loss: 3.4803 - value_loss: 2.0551 - policy_loss: 2.2002 - val_loss: 3.4698 - val_value_loss: 2.1389 - val_policy_loss: 2.1974\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 159us/step - loss: 2.9352 - value_loss: 1.0761 - policy_loss: 2.1912 - val_loss: 3.4372 - val_value_loss: 2.1282 - val_policy_loss: 2.1974\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 159us/step - loss: 2.8454 - value_loss: 0.9550 - policy_loss: 2.1870 - val_loss: 2.9639 - val_value_loss: 1.2086 - val_policy_loss: 2.1973\n",
      "Saved model  tictactoe_3_epochs_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.08\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.9078 - value_loss: 1.0930 - policy_loss: 2.2008 - val_loss: 2.8408 - val_value_loss: 0.9871 - val_policy_loss: 2.1931\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.8446 - value_loss: 1.0030 - policy_loss: 2.1847 - val_loss: 2.8196 - val_value_loss: 0.9687 - val_policy_loss: 2.1931\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 149us/step - loss: 2.8261 - value_loss: 0.9925 - policy_loss: 2.1823 - val_loss: 2.9140 - val_value_loss: 1.1935 - val_policy_loss: 2.1931\n",
      "Saved model  tictactoe_3_epochs_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.02\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.9089 - value_loss: 1.1838 - policy_loss: 2.1927 - val_loss: 2.7605 - val_value_loss: 0.9297 - val_policy_loss: 2.1971\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 154us/step - loss: 2.7630 - value_loss: 0.9466 - policy_loss: 2.1854 - val_loss: 2.6960 - val_value_loss: 0.8581 - val_policy_loss: 2.1973\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 149us/step - loss: 2.7090 - value_loss: 0.9062 - policy_loss: 2.1752 - val_loss: 2.6666 - val_value_loss: 0.8638 - val_policy_loss: 2.1974\n",
      "Saved model  tictactoe_3_epochs_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.06\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 154us/step - loss: 2.6889 - value_loss: 0.8893 - policy_loss: 2.2165 - val_loss: 2.6672 - val_value_loss: 0.9343 - val_policy_loss: 2.1979\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 154us/step - loss: 2.6231 - value_loss: 0.8396 - policy_loss: 2.2044 - val_loss: 2.6315 - val_value_loss: 0.9374 - val_policy_loss: 2.1979\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 149us/step - loss: 2.5595 - value_loss: 0.7901 - policy_loss: 2.2012 - val_loss: 2.5823 - val_value_loss: 0.9169 - val_policy_loss: 2.1978\n",
      "Saved model  tictactoe_3_epochs_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.02\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.4733 - value_loss: 0.6992 - policy_loss: 2.1976 - val_loss: 2.5365 - val_value_loss: 0.8348 - val_policy_loss: 2.1975\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.4624 - value_loss: 0.6928 - policy_loss: 2.1913 - val_loss: 2.5379 - val_value_loss: 0.8482 - val_policy_loss: 2.1975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 141us/step - loss: 2.5197 - value_loss: 0.8223 - policy_loss: 2.1870 - val_loss: 2.5142 - val_value_loss: 0.8133 - val_policy_loss: 2.1975\n",
      "Saved model  tictactoe_3_epochs_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.02\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.5688 - value_loss: 0.9253 - policy_loss: 2.1947 - val_loss: 2.5046 - val_value_loss: 0.8048 - val_policy_loss: 2.2005\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 149us/step - loss: 2.5599 - value_loss: 0.9208 - policy_loss: 2.1951 - val_loss: 2.4954 - val_value_loss: 0.8009 - val_policy_loss: 2.2005\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.5502 - value_loss: 0.9167 - policy_loss: 2.1944 - val_loss: 2.4887 - val_value_loss: 0.8028 - val_policy_loss: 2.2005\n",
      "Saved model  tictactoe_3_epochs_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.0\n",
      "iteration 27 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.5065 - value_loss: 0.8429 - policy_loss: 2.1961 - val_loss: 2.4537 - val_value_loss: 0.7496 - val_policy_loss: 2.1997\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.4960 - value_loss: 0.8397 - policy_loss: 2.1943 - val_loss: 2.4468 - val_value_loss: 0.7525 - val_policy_loss: 2.1997\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.4841 - value_loss: 0.8349 - policy_loss: 2.1918 - val_loss: 2.4399 - val_value_loss: 0.7558 - val_policy_loss: 2.1997\n",
      "Saved model  tictactoe_3_epochs_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.0\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.4475 - value_loss: 0.7818 - policy_loss: 2.1888 - val_loss: 2.4244 - val_value_loss: 0.7414 - val_policy_loss: 2.2004\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 152us/step - loss: 2.4348 - value_loss: 0.7750 - policy_loss: 2.1875 - val_loss: 2.4157 - val_value_loss: 0.7418 - val_policy_loss: 2.2004\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.4224 - value_loss: 0.7690 - policy_loss: 2.1865 - val_loss: 2.4062 - val_value_loss: 0.7407 - val_policy_loss: 2.2004\n",
      "Saved model  tictactoe_3_epochs_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.08\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.3733 - value_loss: 0.6786 - policy_loss: 2.1966 - val_loss: 2.4310 - val_value_loss: 0.8130 - val_policy_loss: 2.1956\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.3598 - value_loss: 0.6713 - policy_loss: 2.1950 - val_loss: 2.4215 - val_value_loss: 0.8122 - val_policy_loss: 2.1956\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.3447 - value_loss: 0.6651 - policy_loss: 2.1890 - val_loss: 2.4115 - val_value_loss: 0.8102 - val_policy_loss: 2.1956\n",
      "Saved model  tictactoe_3_epochs_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.0\n",
      "iteration 30 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_30\n",
      "iteration 30 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 154us/step - loss: 2.3274 - value_loss: 0.6482 - policy_loss: 2.1894 - val_loss: 2.3980 - val_value_loss: 0.8010 - val_policy_loss: 2.1958\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 152us/step - loss: 2.3168 - value_loss: 0.6430 - policy_loss: 2.1914 - val_loss: 2.3880 - val_value_loss: 0.7990 - val_policy_loss: 2.1958\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 134us/step - loss: 2.3070 - value_loss: 0.6394 - policy_loss: 2.1932 - val_loss: 2.3785 - val_value_loss: 0.7977 - val_policy_loss: 2.1958\n",
      "Saved model  tictactoe_3_epochs_30\n",
      "iteration 30 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.08\n",
      "iteration 31 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_31\n",
      "iteration 31 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.3119 - value_loss: 0.6453 - policy_loss: 2.2150 - val_loss: 2.4022 - val_value_loss: 0.8619 - val_policy_loss: 2.1967\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.2988 - value_loss: 0.6428 - policy_loss: 2.2090 - val_loss: 2.3924 - val_value_loss: 0.8598 - val_policy_loss: 2.1967\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.2848 - value_loss: 0.6413 - policy_loss: 2.1999 - val_loss: 2.3832 - val_value_loss: 0.8588 - val_policy_loss: 2.1966\n",
      "Saved model  tictactoe_3_epochs_31\n",
      "iteration 31 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.02\n",
      "iteration 32 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_32\n",
      "iteration 32 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.3443 - value_loss: 0.7835 - policy_loss: 2.1941 - val_loss: 2.3866 - val_value_loss: 0.8844 - val_policy_loss: 2.1949\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.3319 - value_loss: 0.7716 - policy_loss: 2.1983 - val_loss: 2.3790 - val_value_loss: 0.8859 - val_policy_loss: 2.1949\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.3209 - value_loss: 0.7649 - policy_loss: 2.1996 - val_loss: 2.3716 - val_value_loss: 0.8878 - val_policy_loss: 2.1948\n",
      "Saved model  tictactoe_3_epochs_32\n",
      "iteration 32 | evaluation\n",
      "agent vs random - win ratio 0.68 - draw ratio 0.02\n",
      "iteration 33 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_33\n",
      "iteration 33 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.3528 - value_loss: 0.8571 - policy_loss: 2.1880 - val_loss: 2.3038 - val_value_loss: 0.7700 - val_policy_loss: 2.1934\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 149us/step - loss: 2.3405 - value_loss: 0.8525 - policy_loss: 2.1841 - val_loss: 2.2970 - val_value_loss: 0.7723 - val_policy_loss: 2.1934\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.3283 - value_loss: 0.8477 - policy_loss: 2.1806 - val_loss: 2.2902 - val_value_loss: 0.7743 - val_policy_loss: 2.1933\n",
      "Saved model  tictactoe_3_epochs_33\n",
      "iteration 33 | evaluation\n",
      "agent vs random - win ratio 0.68 - draw ratio 0.06\n",
      "iteration 34 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_34\n",
      "iteration 34 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.3005 - value_loss: 0.7941 - policy_loss: 2.1942 - val_loss: 2.2957 - val_value_loss: 0.7985 - val_policy_loss: 2.1955\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.2923 - value_loss: 0.7904 - policy_loss: 2.1967 - val_loss: 2.2903 - val_value_loss: 0.8025 - val_policy_loss: 2.1955\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.2818 - value_loss: 0.7849 - policy_loss: 2.1961 - val_loss: 2.2843 - val_value_loss: 0.8051 - val_policy_loss: 2.1955\n",
      "Saved model  tictactoe_3_epochs_34\n",
      "iteration 34 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.04\n",
      "iteration 35 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_35\n",
      "iteration 35 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.2903 - value_loss: 0.8224 - policy_loss: 2.1903 - val_loss: 2.2698 - val_value_loss: 0.7920 - val_policy_loss: 2.1940\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.2767 - value_loss: 0.8104 - policy_loss: 2.1893 - val_loss: 2.2632 - val_value_loss: 0.7926 - val_policy_loss: 2.1939\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.2658 - value_loss: 0.8017 - policy_loss: 2.1900 - val_loss: 2.2565 - val_value_loss: 0.7929 - val_policy_loss: 2.1939\n",
      "Saved model  tictactoe_3_epochs_35\n",
      "iteration 35 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.04\n",
      "iteration 36 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_36\n",
      "iteration 36 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.2664 - value_loss: 0.8048 - policy_loss: 2.2016 - val_loss: 2.2968 - val_value_loss: 0.8830 - val_policy_loss: 2.1978\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.2560 - value_loss: 0.7998 - policy_loss: 2.1993 - val_loss: 2.2897 - val_value_loss: 0.8819 - val_policy_loss: 2.1978\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.2461 - value_loss: 0.7971 - policy_loss: 2.1954 - val_loss: 2.2823 - val_value_loss: 0.8802 - val_policy_loss: 2.1978\n",
      "Saved model  tictactoe_3_epochs_36\n",
      "iteration 36 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.06\n",
      "iteration 37 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_37\n",
      "iteration 37 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.2219 - value_loss: 0.7538 - policy_loss: 2.2034 - val_loss: 2.2559 - val_value_loss: 0.8402 - val_policy_loss: 2.1978\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.2118 - value_loss: 0.7483 - policy_loss: 2.2016 - val_loss: 2.2509 - val_value_loss: 0.8429 - val_policy_loss: 2.1978\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.2000 - value_loss: 0.7430 - policy_loss: 2.1960 - val_loss: 2.2467 - val_value_loss: 0.8471 - val_policy_loss: 2.1978\n",
      "Saved model  tictactoe_3_epochs_37\n",
      "iteration 37 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.0\n",
      "iteration 38 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_38\n",
      "iteration 38 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 152us/step - loss: 2.2353 - value_loss: 0.8344 - policy_loss: 2.1877 - val_loss: 2.2404 - val_value_loss: 0.8486 - val_policy_loss: 2.1959\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.2215 - value_loss: 0.8161 - policy_loss: 2.1905 - val_loss: 2.2384 - val_value_loss: 0.8566 - val_policy_loss: 2.1959\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 154us/step - loss: 2.2081 - value_loss: 0.8003 - policy_loss: 2.1915 - val_loss: 2.2372 - val_value_loss: 0.8658 - val_policy_loss: 2.1959\n",
      "Saved model  tictactoe_3_epochs_38\n",
      "iteration 38 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.04\n",
      "iteration 39 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_39\n",
      "iteration 39 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 154us/step - loss: 2.1892 - value_loss: 0.7692 - policy_loss: 2.1964 - val_loss: 2.2282 - val_value_loss: 0.8575 - val_policy_loss: 2.1978\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 156us/step - loss: 2.1846 - value_loss: 0.7718 - policy_loss: 2.1962 - val_loss: 2.2232 - val_value_loss: 0.8589 - val_policy_loss: 2.1978\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 159us/step - loss: 2.1773 - value_loss: 0.7701 - policy_loss: 2.1947 - val_loss: 2.2179 - val_value_loss: 0.8596 - val_policy_loss: 2.1978\n",
      "Saved model  tictactoe_3_epochs_39\n",
      "iteration 39 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.04\n",
      "iteration 40 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_40\n",
      "iteration 40 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.1508 - value_loss: 0.7245 - policy_loss: 2.1987 - val_loss: 2.2129 - val_value_loss: 0.8632 - val_policy_loss: 2.1953\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.1382 - value_loss: 0.7137 - policy_loss: 2.1954 - val_loss: 2.2074 - val_value_loss: 0.8630 - val_policy_loss: 2.1953\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.1256 - value_loss: 0.7032 - policy_loss: 2.1914 - val_loss: 2.2019 - val_value_loss: 0.8627 - val_policy_loss: 2.1953\n",
      "Saved model  tictactoe_3_epochs_40\n",
      "iteration 40 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.02\n",
      "iteration 41 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_41\n",
      "iteration 41 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.1485 - value_loss: 0.7549 - policy_loss: 2.1962 - val_loss: 2.1620 - val_value_loss: 0.7923 - val_policy_loss: 2.1963\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.1452 - value_loss: 0.7577 - policy_loss: 2.1972 - val_loss: 2.1554 - val_value_loss: 0.7895 - val_policy_loss: 2.1963\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.1370 - value_loss: 0.7545 - policy_loss: 2.1946 - val_loss: 2.1495 - val_value_loss: 0.7880 - val_policy_loss: 2.1963\n",
      "Saved model  tictactoe_3_epochs_41\n",
      "iteration 41 | evaluation\n",
      "agent vs random - win ratio 0.68 - draw ratio 0.08\n",
      "iteration 42 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_42\n",
      "iteration 42 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.1418 - value_loss: 0.7697 - policy_loss: 2.1994 - val_loss: 2.1599 - val_value_loss: 0.8243 - val_policy_loss: 2.1911\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 140us/step - loss: 2.1265 - value_loss: 0.7545 - policy_loss: 2.1941 - val_loss: 2.1547 - val_value_loss: 0.8241 - val_policy_loss: 2.1911\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.1170 - value_loss: 0.7464 - policy_loss: 2.1934 - val_loss: 2.1500 - val_value_loss: 0.8246 - val_policy_loss: 2.1910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_3_epochs_42\n",
      "iteration 42 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.0\n",
      "iteration 43 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_43\n",
      "iteration 43 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.0946 - value_loss: 0.7204 - policy_loss: 2.1843 - val_loss: 2.1614 - val_value_loss: 0.8591 - val_policy_loss: 2.1890\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.0913 - value_loss: 0.7236 - policy_loss: 2.1842 - val_loss: 2.1566 - val_value_loss: 0.8592 - val_policy_loss: 2.1889\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.0850 - value_loss: 0.7227 - policy_loss: 2.1821 - val_loss: 2.1518 - val_value_loss: 0.8591 - val_policy_loss: 2.1888\n",
      "Saved model  tictactoe_3_epochs_43\n",
      "iteration 43 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.02\n",
      "iteration 44 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_44\n",
      "iteration 44 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.0926 - value_loss: 0.7476 - policy_loss: 2.1819 - val_loss: 2.0974 - val_value_loss: 0.7550 - val_policy_loss: 2.1935\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 152us/step - loss: 2.0804 - value_loss: 0.7349 - policy_loss: 2.1797 - val_loss: 2.0931 - val_value_loss: 0.7556 - val_policy_loss: 2.1934\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.0664 - value_loss: 0.7194 - policy_loss: 2.1762 - val_loss: 2.0889 - val_value_loss: 0.7563 - val_policy_loss: 2.1934\n",
      "Saved model  tictactoe_3_epochs_44\n",
      "iteration 44 | evaluation\n",
      "agent vs random - win ratio 0.72 - draw ratio 0.02\n",
      "iteration 45 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_45\n",
      "iteration 45 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.0975 - value_loss: 0.7881 - policy_loss: 2.1786 - val_loss: 2.1340 - val_value_loss: 0.8527 - val_policy_loss: 2.1958\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.0894 - value_loss: 0.7839 - policy_loss: 2.1753 - val_loss: 2.1326 - val_value_loss: 0.8585 - val_policy_loss: 2.1958\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.0800 - value_loss: 0.7767 - policy_loss: 2.1724 - val_loss: 2.1316 - val_value_loss: 0.8652 - val_policy_loss: 2.1958\n",
      "Saved model  tictactoe_3_epochs_45\n",
      "iteration 45 | evaluation\n",
      "agent vs random - win ratio 0.72 - draw ratio 0.06\n",
      "iteration 46 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_46\n",
      "iteration 46 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.0841 - value_loss: 0.7988 - policy_loss: 2.1672 - val_loss: 2.1292 - val_value_loss: 0.8697 - val_policy_loss: 2.1950\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.0792 - value_loss: 0.7972 - policy_loss: 2.1674 - val_loss: 2.1264 - val_value_loss: 0.8722 - val_policy_loss: 2.1950\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.0726 - value_loss: 0.7925 - policy_loss: 2.1673 - val_loss: 2.1216 - val_value_loss: 0.8709 - val_policy_loss: 2.1949\n",
      "Saved model  tictactoe_3_epochs_46\n",
      "iteration 46 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.04\n",
      "iteration 47 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_47\n",
      "iteration 47 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.0449 - value_loss: 0.7304 - policy_loss: 2.1820 - val_loss: 2.1253 - val_value_loss: 0.8846 - val_policy_loss: 2.1966\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 149us/step - loss: 2.0365 - value_loss: 0.7236 - policy_loss: 2.1801 - val_loss: 2.1183 - val_value_loss: 0.8786 - val_policy_loss: 2.1966\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.0287 - value_loss: 0.7204 - policy_loss: 2.1755 - val_loss: 2.1117 - val_value_loss: 0.8732 - val_policy_loss: 2.1966\n",
      "Saved model  tictactoe_3_epochs_47\n",
      "iteration 47 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.06\n",
      "iteration 48 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_48\n",
      "iteration 48 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.0651 - value_loss: 0.7776 - policy_loss: 2.1990 - val_loss: 2.1275 - val_value_loss: 0.9134 - val_policy_loss: 2.1958\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.0546 - value_loss: 0.7723 - policy_loss: 2.1911 - val_loss: 2.1233 - val_value_loss: 0.9127 - val_policy_loss: 2.1958\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.0413 - value_loss: 0.7609 - policy_loss: 2.1834 - val_loss: 2.1194 - val_value_loss: 0.9123 - val_policy_loss: 2.1957\n",
      "Saved model  tictactoe_3_epochs_48\n",
      "iteration 48 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.02\n",
      "iteration 49 | self-play\n",
      "saving memory position_memory_tictactoe_3_epochs_ep_49\n",
      "iteration 49 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.1094 - value_loss: 0.8700 - policy_loss: 2.2179 - val_loss: 2.1143 - val_value_loss: 0.9099 - val_policy_loss: 2.1953\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.0947 - value_loss: 0.8574 - policy_loss: 2.2086 - val_loss: 2.1144 - val_value_loss: 0.9174 - val_policy_loss: 2.1953\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.0784 - value_loss: 0.8478 - policy_loss: 2.1930 - val_loss: 2.1138 - val_value_loss: 0.9232 - val_policy_loss: 2.1953\n",
      "Saved model  tictactoe_3_epochs_49\n",
      "iteration 49 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.1\n"
     ]
    }
   ],
   "source": [
    "wins_2, draws_2 = test_pipeline.run(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(50)\n",
    "losses_2 = np.ones(50) - wins_2 - draws_2\n",
    "# no_loss = np.zeros(50) + wins +draws\n",
    "\n",
    "plt.plot(x, wins_2, label=\"win ratio\")\n",
    "plt.plot(x, draws_2, label=\"draw ratio\")\n",
    "#plt.plot(x, no_loss, label=\"no loss ratio\")\n",
    "plt.plot(x, losses_2, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54, 0.38, 0.54, 0.66, 0.54, 0.5, 0.48, 0.48, 0.44, 0.56, 0.58, 0.58, 0.74, 0.8, 0.78, 0.76, 0.78, 0.8, 0.86, 0.88, 0.82, 0.76, 0.82, 0.8, 0.86, 0.78, 0.82, 0.8, 0.78, 0.78, 0.7, 0.78, 0.68, 0.68, 0.76, 0.84, 0.74, 0.82, 0.86, 0.8, 0.74, 0.68, 0.8, 0.84, 0.72, 0.72, 0.76, 0.76, 0.78, 0.78]\n",
      "[0.08, 0.14, 0.06, 0.1, 0.06, 0.14, 0.2, 0.12, 0.12, 0.1, 0.08, 0.06, 0.04, 0.04, 0.02, 0.02, 0.08, 0.02, 0.0, 0.0, 0.08, 0.08, 0.02, 0.06, 0.02, 0.02, 0.0, 0.0, 0.08, 0.0, 0.08, 0.02, 0.02, 0.06, 0.04, 0.04, 0.06, 0.0, 0.04, 0.04, 0.02, 0.08, 0.0, 0.02, 0.02, 0.06, 0.04, 0.06, 0.02, 0.1]\n",
      "[0.38 0.48 0.4  0.24 0.4  0.36 0.32 0.4  0.44 0.34 0.34 0.36 0.22 0.16\n",
      " 0.2  0.22 0.14 0.18 0.14 0.12 0.1  0.16 0.16 0.14 0.12 0.2  0.18 0.2\n",
      " 0.14 0.22 0.22 0.2  0.3  0.26 0.2  0.12 0.2  0.18 0.1  0.16 0.24 0.24\n",
      " 0.2  0.14 0.26 0.22 0.2  0.18 0.2  0.12]\n"
     ]
    }
   ],
   "source": [
    "print(wins_2)\n",
    "print(draws_2)\n",
    "print(losses_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" These dictionarys set most of the relevant settings and hyperparameters for the program. \"\"\"\n",
    "\n",
    "MCTS = {\n",
    "    'c_puct': 1.0,\n",
    "    'dir_alpha': 0.5,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 1,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 5\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 50,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 0,\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 50,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.02, \n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 256,\n",
    "    'num_filters_value': 256,\n",
    "    'num_filters_tower': 256,\n",
    "    'num_residual_blocks': 5,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 256\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"tictactoe_5_epochs\", \"TicTacToe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 3s 7ms/step - loss: 5.7187 - value_loss: 1.5816 - policy_loss: 2.7375 - val_loss: 12547629.0000 - val_value_loss: 2.1650 - val_policy_loss: 25095254.0000\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 13.2735 - value_loss: 2.0954 - policy_loss: 14.6284 - val_loss: 247860.5625 - val_value_loss: 2.1650 - val_policy_loss: 495703.9375\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 16.3445 - value_loss: 2.0954 - policy_loss: 15.5690 - val_loss: 18779.3379 - val_value_loss: 2.1650 - val_policy_loss: 37535.2344\n",
      "Saved model  tictactoe_5_epochs_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.62 - draw ratio 0.02\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 18.5279 - value_loss: 2.2200 - policy_loss: 13.5597 - val_loss: 4283.0366 - val_value_loss: 2.1165 - val_policy_loss: 8536.3154\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 20.8880 - value_loss: 2.2200 - policy_loss: 11.9151 - val_loss: 2213.2556 - val_value_loss: 2.1165 - val_policy_loss: 4390.8125\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 22.4250 - value_loss: 2.2200 - policy_loss: 9.0482 - val_loss: 1224.3206 - val_value_loss: 2.1165 - val_policy_loss: 2407.7366\n",
      "Saved model  tictactoe_5_epochs_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.54 - draw ratio 0.02\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 23.9991 - value_loss: 2.1785 - policy_loss: 7.0318 - val_loss: 397.3095 - val_value_loss: 2.2427 - val_policy_loss: 749.2770\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 154us/step - loss: 24.2217 - value_loss: 2.1785 - policy_loss: 3.1657 - val_loss: 478.7592 - val_value_loss: 2.2427 - val_policy_loss: 908.8159\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 154us/step - loss: 26.2502 - value_loss: 2.1785 - policy_loss: 3.8621 - val_loss: 488.3121 - val_value_loss: 2.2427 - val_policy_loss: 925.5032\n",
      "Saved model  tictactoe_5_epochs_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.5 - draw ratio 0.08\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 27.9538 - value_loss: 2.0636 - policy_loss: 4.9656 - val_loss: 408.1678 - val_value_loss: 1.9515 - val_policy_loss: 763.9651\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 28.8445 - value_loss: 2.0636 - policy_loss: 5.2062 - val_loss: 323.9867 - val_value_loss: 1.9515 - val_policy_loss: 594.8433\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 29.1243 - value_loss: 2.0636 - policy_loss: 5.0062 - val_loss: 297.5944 - val_value_loss: 1.9515 - val_policy_loss: 541.9823\n",
      "Saved model  tictactoe_5_epochs_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.5 - draw ratio 0.04\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 29.5649 - value_loss: 2.1663 - policy_loss: 5.7085 - val_loss: 217.3432 - val_value_loss: 2.0485 - val_policy_loss: 381.9048\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 28.9303 - value_loss: 2.1663 - policy_loss: 4.9614 - val_loss: 157.0240 - val_value_loss: 2.0485 - val_policy_loss: 262.2839\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 28.4242 - value_loss: 2.1663 - policy_loss: 4.9665 - val_loss: 123.0908 - val_value_loss: 2.0485 - val_policy_loss: 195.8313\n",
      "Saved model  tictactoe_5_epochs_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.52 - draw ratio 0.1\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 27.9342 - value_loss: 2.2274 - policy_loss: 5.3393 - val_loss: 76.7436 - val_value_loss: 2.0777 - val_policy_loss: 104.8347\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 26.5909 - value_loss: 2.2274 - policy_loss: 4.3795 - val_loss: 48.5924 - val_value_loss: 2.0777 - val_policy_loss: 50.4868\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 25.1895 - value_loss: 2.2274 - policy_loss: 3.5313 - val_loss: 32.4167 - val_value_loss: 2.0777 - val_policy_loss: 20.2437\n",
      "Saved model  tictactoe_5_epochs_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.56 - draw ratio 0.14\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 157us/step - loss: 24.0922 - value_loss: 2.2078 - policy_loss: 3.4646 - val_loss: 29.3919 - val_value_loss: 2.2621 - val_policy_loss: 16.2122\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 152us/step - loss: 23.0767 - value_loss: 2.2078 - policy_loss: 3.6361 - val_loss: 25.2025 - val_value_loss: 2.2621 - val_policy_loss: 10.0877\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 152us/step - loss: 21.9162 - value_loss: 2.2078 - policy_loss: 3.5694 - val_loss: 21.5824 - val_value_loss: 2.2621 - val_policy_loss: 5.1130\n",
      "Saved model  tictactoe_5_epochs_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.54 - draw ratio 0.02\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 156us/step - loss: 20.4507 - value_loss: 2.1516 - policy_loss: 2.9601 - val_loss: 20.0205 - val_value_loss: 2.1553 - val_policy_loss: 4.3388\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 19.3266 - value_loss: 2.1516 - policy_loss: 2.9550 - val_loss: 18.4329 - val_value_loss: 2.1553 - val_policy_loss: 3.3574\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 18.2576 - value_loss: 2.1516 - policy_loss: 3.0105 - val_loss: 17.0122 - val_value_loss: 2.1553 - val_policy_loss: 2.6421\n",
      "Saved model  tictactoe_5_epochs_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.04\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 17.0485 - value_loss: 2.0709 - policy_loss: 2.7993 - val_loss: 15.8315 - val_value_loss: 2.2524 - val_policy_loss: 2.2272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 16.0076 - value_loss: 2.0709 - policy_loss: 2.7610 - val_loss: 14.8404 - val_value_loss: 2.2524 - val_policy_loss: 2.1943\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 15.0270 - value_loss: 2.0709 - policy_loss: 2.7489 - val_loss: 13.9147 - val_value_loss: 2.2524 - val_policy_loss: 2.1903\n",
      "Saved model  tictactoe_5_epochs_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.66 - draw ratio 0.08\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 161us/step - loss: 14.1564 - value_loss: 2.1369 - policy_loss: 2.7893 - val_loss: 12.8570 - val_value_loss: 1.8738 - val_policy_loss: 2.1942\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 154us/step - loss: 13.2235 - value_loss: 2.1369 - policy_loss: 2.6641 - val_loss: 12.0408 - val_value_loss: 1.8738 - val_policy_loss: 2.1938\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 159us/step - loss: 12.3315 - value_loss: 2.1369 - policy_loss: 2.5120 - val_loss: 11.2785 - val_value_loss: 1.8738 - val_policy_loss: 2.1939\n",
      "Saved model  tictactoe_5_epochs_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.06\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 11.5829 - value_loss: 2.1687 - policy_loss: 2.5077 - val_loss: 10.5787 - val_value_loss: 1.8932 - val_policy_loss: 2.1945\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 10.8120 - value_loss: 2.1687 - policy_loss: 2.3857 - val_loss: 9.9197 - val_value_loss: 1.8932 - val_policy_loss: 2.1946\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 134us/step - loss: 10.1203 - value_loss: 2.1687 - policy_loss: 2.3203 - val_loss: 9.3098 - val_value_loss: 1.8932 - val_policy_loss: 2.1946\n",
      "Saved model  tictactoe_5_epochs_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.06\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 9.3514 - value_loss: 1.9218 - policy_loss: 2.2494 - val_loss: 8.6893 - val_value_loss: 1.7767 - val_policy_loss: 2.1967\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 148us/step - loss: 8.8139 - value_loss: 1.9218 - policy_loss: 2.3009 - val_loss: 8.1696 - val_value_loss: 1.7767 - val_policy_loss: 2.1967\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 8.3046 - value_loss: 1.9218 - policy_loss: 2.3216 - val_loss: 7.6909 - val_value_loss: 1.7767 - val_policy_loss: 2.1966\n",
      "Saved model  tictactoe_5_epochs_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.02\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 7.8216 - value_loss: 1.8631 - policy_loss: 2.3717 - val_loss: 7.5622 - val_value_loss: 2.3981 - val_policy_loss: 2.1994\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 7.3631 - value_loss: 1.8631 - policy_loss: 2.3362 - val_loss: 7.1570 - val_value_loss: 2.3981 - val_policy_loss: 2.1993\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 149us/step - loss: 6.9373 - value_loss: 1.8631 - policy_loss: 2.2949 - val_loss: 6.7849 - val_value_loss: 2.3981 - val_policy_loss: 2.1991\n",
      "Saved model  tictactoe_5_epochs_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.12\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 6.7294 - value_loss: 2.2029 - policy_loss: 2.2832 - val_loss: 6.3171 - val_value_loss: 2.1456 - val_policy_loss: 2.1980\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 6.3718 - value_loss: 2.2029 - policy_loss: 2.2501 - val_loss: 6.0048 - val_value_loss: 2.1456 - val_policy_loss: 2.1978\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 6.0376 - value_loss: 2.2029 - policy_loss: 2.2063 - val_loss: 5.7187 - val_value_loss: 2.1456 - val_policy_loss: 2.1976\n",
      "Saved model  tictactoe_5_epochs_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.72 - draw ratio 0.04\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 154us/step - loss: 5.8017 - value_loss: 2.2861 - policy_loss: 2.2231 - val_loss: 5.2866 - val_value_loss: 1.8058 - val_policy_loss: 2.1970\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 154us/step - loss: 5.5414 - value_loss: 2.2861 - policy_loss: 2.2264 - val_loss: 5.0462 - val_value_loss: 1.8058 - val_policy_loss: 2.1969\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 143us/step - loss: 5.2994 - value_loss: 2.2861 - policy_loss: 2.2230 - val_loss: 4.8255 - val_value_loss: 1.8058 - val_policy_loss: 2.1968\n",
      "Saved model  tictactoe_5_epochs_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.08\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 4.9205 - value_loss: 1.9853 - policy_loss: 2.2073 - val_loss: 4.6826 - val_value_loss: 1.9223 - val_policy_loss: 2.1993\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 148us/step - loss: 4.7135 - value_loss: 1.9853 - policy_loss: 2.1981 - val_loss: 4.4966 - val_value_loss: 1.9223 - val_policy_loss: 2.1993\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 4.5262 - value_loss: 1.9853 - policy_loss: 2.1954 - val_loss: 4.3256 - val_value_loss: 1.9223 - val_policy_loss: 2.1992\n",
      "Saved model  tictactoe_5_epochs_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.02\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 149us/step - loss: 4.3802 - value_loss: 2.0391 - policy_loss: 2.1917 - val_loss: 4.2509 - val_value_loss: 2.0874 - val_policy_loss: 2.1990\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 155us/step - loss: 4.2141 - value_loss: 2.0391 - policy_loss: 2.1737 - val_loss: 4.1068 - val_value_loss: 2.0874 - val_policy_loss: 2.1990\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 4.0656 - value_loss: 2.0391 - policy_loss: 2.1649 - val_loss: 3.9744 - val_value_loss: 2.0874 - val_policy_loss: 2.1990\n",
      "Saved model  tictactoe_5_epochs_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.0\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 4.1071 - value_loss: 2.3301 - policy_loss: 2.2218 - val_loss: 3.9194 - val_value_loss: 2.2233 - val_policy_loss: 2.1961\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 3.9686 - value_loss: 2.3301 - policy_loss: 2.1879 - val_loss: 3.8086 - val_value_loss: 2.2233 - val_policy_loss: 2.1962\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 3.9704 - value_loss: 2.3301 - policy_loss: 2.4130 - val_loss: 3.7988 - val_value_loss: 2.2233 - val_policy_loss: 2.1963\n",
      "Saved model  tictactoe_5_epochs_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.02\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 3.8306 - value_loss: 2.2689 - policy_loss: 2.2141 - val_loss: 3.8863 - val_value_loss: 2.1165 - val_policy_loss: 2.1983\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 3.9657 - value_loss: 2.2689 - policy_loss: 2.2048 - val_loss: 4.1133 - val_value_loss: 2.1165 - val_policy_loss: 2.1983\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 4.1927 - value_loss: 2.2689 - policy_loss: 2.2046 - val_loss: 4.3721 - val_value_loss: 2.1165 - val_policy_loss: 2.1983\n",
      "Saved model  tictactoe_5_epochs_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.08\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 4.4125 - value_loss: 2.1834 - policy_loss: 2.2121 - val_loss: 4.6030 - val_value_loss: 2.0874 - val_policy_loss: 2.1962\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 156us/step - loss: 4.6475 - value_loss: 2.1834 - policy_loss: 2.1892 - val_loss: 4.8066 - val_value_loss: 2.0874 - val_policy_loss: 2.1962\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 149us/step - loss: 4.8433 - value_loss: 2.1834 - policy_loss: 2.1737 - val_loss: 4.9499 - val_value_loss: 2.0874 - val_policy_loss: 2.1968\n",
      "Saved model  tictactoe_5_epochs_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.04\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 4.9644 - value_loss: 2.1027 - policy_loss: 2.2105 - val_loss: 5.0215 - val_value_loss: 2.0971 - val_policy_loss: 2.1784\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 5.0272 - value_loss: 2.1027 - policy_loss: 2.1842 - val_loss: 5.0316 - val_value_loss: 2.0971 - val_policy_loss: 2.1750\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 132us/step - loss: 5.0389 - value_loss: 2.1027 - policy_loss: 2.1840 - val_loss: 4.9859 - val_value_loss: 2.0971 - val_policy_loss: 2.1740\n",
      "Saved model  tictactoe_5_epochs_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.04\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 5.0653 - value_loss: 2.2127 - policy_loss: 2.2171 - val_loss: 4.9384 - val_value_loss: 2.1456 - val_policy_loss: 2.2137\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 4.9618 - value_loss: 2.2127 - policy_loss: 2.1934 - val_loss: 4.8122 - val_value_loss: 2.1456 - val_policy_loss: 2.2142\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 134us/step - loss: 4.8362 - value_loss: 2.2127 - policy_loss: 2.1951 - val_loss: 4.6601 - val_value_loss: 2.1456 - val_policy_loss: 2.2107\n",
      "Saved model  tictactoe_5_epochs_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.08\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 4.6609 - value_loss: 2.1391 - policy_loss: 2.2189 - val_loss: 4.4866 - val_value_loss: 2.1456 - val_policy_loss: 2.1924\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 148us/step - loss: 4.4798 - value_loss: 2.1236 - policy_loss: 2.2009 - val_loss: 4.3207 - val_value_loss: 2.1456 - val_policy_loss: 2.1928\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 146us/step - loss: 4.1324 - value_loss: 1.7694 - policy_loss: 2.1926 - val_loss: 4.1563 - val_value_loss: 2.1235 - val_policy_loss: 2.1933\n",
      "Saved model  tictactoe_5_epochs_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.1\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 3.6890 - value_loss: 1.1552 - policy_loss: 2.2270 - val_loss: 3.4595 - val_value_loss: 0.9878 - val_policy_loss: 2.1979\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 3.6665 - value_loss: 1.3817 - policy_loss: 2.2178 - val_loss: 3.7368 - val_value_loss: 1.7198 - val_policy_loss: 2.1972\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 3.3166 - value_loss: 0.8631 - policy_loss: 2.2134 - val_loss: 3.6989 - val_value_loss: 1.7464 - val_policy_loss: 2.1969\n",
      "Saved model  tictactoe_5_epochs_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.06\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 3.3560 - value_loss: 1.0038 - policy_loss: 2.2539 - val_loss: 3.6574 - val_value_loss: 1.7274 - val_policy_loss: 2.1982\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 3.3044 - value_loss: 1.0079 - policy_loss: 2.2117 - val_loss: 3.6313 - val_value_loss: 1.7267 - val_policy_loss: 2.1983\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 3.2385 - value_loss: 0.9458 - policy_loss: 2.1935 - val_loss: 3.6021 - val_value_loss: 1.7209 - val_policy_loss: 2.1985\n",
      "Saved model  tictactoe_5_epochs_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.9 - draw ratio 0.04\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 3.2486 - value_loss: 0.9965 - policy_loss: 2.2160 - val_loss: 3.6309 - val_value_loss: 1.7849 - val_policy_loss: 2.2014\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 3.2416 - value_loss: 0.9922 - policy_loss: 2.2154 - val_loss: 3.5858 - val_value_loss: 1.7104 - val_policy_loss: 2.2014\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 3.2297 - value_loss: 0.9869 - policy_loss: 2.2127 - val_loss: 3.4925 - val_value_loss: 1.5453 - val_policy_loss: 2.2014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model  tictactoe_5_epochs_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.02\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 3.1997 - value_loss: 0.9440 - policy_loss: 2.2171 - val_loss: 3.3829 - val_value_loss: 1.3575 - val_policy_loss: 2.1965\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 145us/step - loss: 3.1871 - value_loss: 0.9484 - policy_loss: 2.2140 - val_loss: 3.2606 - val_value_loss: 1.1441 - val_policy_loss: 2.1965\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 135us/step - loss: 3.1726 - value_loss: 0.9544 - policy_loss: 2.2102 - val_loss: 3.1699 - val_value_loss: 0.9978 - val_policy_loss: 2.1965\n",
      "Saved model  tictactoe_5_epochs_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.02\n",
      "iteration 27 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 3.1788 - value_loss: 1.0059 - policy_loss: 2.2060 - val_loss: 3.1359 - val_value_loss: 0.9692 - val_policy_loss: 2.1948\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 3.1580 - value_loss: 1.0071 - policy_loss: 2.2011 - val_loss: 3.1147 - val_value_loss: 0.9672 - val_policy_loss: 2.1948\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 134us/step - loss: 3.1331 - value_loss: 1.0040 - policy_loss: 2.1948 - val_loss: 3.0985 - val_value_loss: 0.9772 - val_policy_loss: 2.1948\n",
      "Saved model  tictactoe_5_epochs_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.02\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 3.1133 - value_loss: 1.0019 - policy_loss: 2.1997 - val_loss: 3.0466 - val_value_loss: 0.9138 - val_policy_loss: 2.1980\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 3.0936 - value_loss: 1.0038 - policy_loss: 2.2021 - val_loss: 3.0277 - val_value_loss: 0.9212 - val_policy_loss: 2.1980\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 3.0681 - value_loss: 0.9991 - policy_loss: 2.2009 - val_loss: 3.0069 - val_value_loss: 0.9254 - val_policy_loss: 2.1980\n",
      "Saved model  tictactoe_5_epochs_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.04\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 3.0582 - value_loss: 1.0280 - policy_loss: 2.1982 - val_loss: 3.0084 - val_value_loss: 0.9795 - val_policy_loss: 2.1933\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 3.0310 - value_loss: 1.0206 - policy_loss: 2.1975 - val_loss: 2.9845 - val_value_loss: 0.9780 - val_policy_loss: 2.1933\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.9909 - value_loss: 0.9883 - policy_loss: 2.1959 - val_loss: 2.9610 - val_value_loss: 0.9774 - val_policy_loss: 2.1933\n",
      "Saved model  tictactoe_5_epochs_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.68 - draw ratio 0.1\n",
      "iteration 30 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_30\n",
      "iteration 30 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.9684 - value_loss: 0.9677 - policy_loss: 2.2177 - val_loss: 2.9228 - val_value_loss: 0.9455 - val_policy_loss: 2.1943\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.9386 - value_loss: 0.9577 - policy_loss: 2.2139 - val_loss: 2.9014 - val_value_loss: 0.9480 - val_policy_loss: 2.1943\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.9141 - value_loss: 0.9596 - policy_loss: 2.2081 - val_loss: 2.8798 - val_value_loss: 0.9495 - val_policy_loss: 2.1943\n",
      "Saved model  tictactoe_5_epochs_30\n",
      "iteration 30 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.04\n",
      "iteration 31 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_31\n",
      "iteration 31 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.8833 - value_loss: 0.9422 - policy_loss: 2.2086 - val_loss: 2.8589 - val_value_loss: 0.9535 - val_policy_loss: 2.1924\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.8581 - value_loss: 0.9363 - policy_loss: 2.2079 - val_loss: 2.8385 - val_value_loss: 0.9556 - val_policy_loss: 2.1924\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.8338 - value_loss: 0.9328 - policy_loss: 2.2058 - val_loss: 2.8182 - val_value_loss: 0.9569 - val_policy_loss: 2.1923\n",
      "Saved model  tictactoe_5_epochs_31\n",
      "iteration 31 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.04\n",
      "iteration 32 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_32\n",
      "iteration 32 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 157us/step - loss: 2.8020 - value_loss: 0.9145 - policy_loss: 2.2025 - val_loss: 2.7907 - val_value_loss: 0.9402 - val_policy_loss: 2.1953\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 154us/step - loss: 2.7801 - value_loss: 0.9159 - policy_loss: 2.1984 - val_loss: 2.7703 - val_value_loss: 0.9396 - val_policy_loss: 2.1953\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.7581 - value_loss: 0.9157 - policy_loss: 2.1947 - val_loss: 2.7503 - val_value_loss: 0.9388 - val_policy_loss: 2.1953\n",
      "Saved model  tictactoe_5_epochs_32\n",
      "iteration 32 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.08\n",
      "iteration 33 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_33\n",
      "iteration 33 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.7405 - value_loss: 0.9155 - policy_loss: 2.1990 - val_loss: 2.7093 - val_value_loss: 0.8973 - val_policy_loss: 2.1932\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.7212 - value_loss: 0.9149 - policy_loss: 2.1993 - val_loss: 2.6902 - val_value_loss: 0.8964 - val_policy_loss: 2.1932\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.7023 - value_loss: 0.9139 - policy_loss: 2.1998 - val_loss: 2.6715 - val_value_loss: 0.8954 - val_policy_loss: 2.1932\n",
      "Saved model  tictactoe_5_epochs_33\n",
      "iteration 33 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.02\n",
      "iteration 34 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_34\n",
      "iteration 34 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 154us/step - loss: 2.6926 - value_loss: 0.9268 - policy_loss: 2.2040 - val_loss: 2.6716 - val_value_loss: 0.9311 - val_policy_loss: 2.1933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.6743 - value_loss: 0.9260 - policy_loss: 2.2038 - val_loss: 2.6550 - val_value_loss: 0.9327 - val_policy_loss: 2.1933\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.6561 - value_loss: 0.9258 - policy_loss: 2.2023 - val_loss: 2.6380 - val_value_loss: 0.9325 - val_policy_loss: 2.1933\n",
      "Saved model  tictactoe_5_epochs_34\n",
      "iteration 34 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.06\n",
      "iteration 35 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_35\n",
      "iteration 35 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.6201 - value_loss: 0.8873 - policy_loss: 2.2026 - val_loss: 2.6263 - val_value_loss: 0.9377 - val_policy_loss: 2.1977\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.6006 - value_loss: 0.8845 - policy_loss: 2.1995 - val_loss: 2.6110 - val_value_loss: 0.9391 - val_policy_loss: 2.1977\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.5804 - value_loss: 0.8809 - policy_loss: 2.1949 - val_loss: 2.5958 - val_value_loss: 0.9402 - val_policy_loss: 2.1977\n",
      "Saved model  tictactoe_5_epochs_35\n",
      "iteration 35 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.1\n",
      "iteration 36 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_36\n",
      "iteration 36 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.5754 - value_loss: 0.8951 - policy_loss: 2.2018 - val_loss: 2.5866 - val_value_loss: 0.9556 - val_policy_loss: 2.1944\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.5581 - value_loss: 0.8896 - policy_loss: 2.2033 - val_loss: 2.5710 - val_value_loss: 0.9540 - val_policy_loss: 2.1944\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.5389 - value_loss: 0.8802 - policy_loss: 2.2042 - val_loss: 2.5566 - val_value_loss: 0.9541 - val_policy_loss: 2.1944\n",
      "Saved model  tictactoe_5_epochs_36\n",
      "iteration 36 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.02\n",
      "iteration 37 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_37\n",
      "iteration 37 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.5654 - value_loss: 0.9703 - policy_loss: 2.1959 - val_loss: 2.5375 - val_value_loss: 0.9443 - val_policy_loss: 2.1940\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.5479 - value_loss: 0.9639 - policy_loss: 2.1952 - val_loss: 2.5230 - val_value_loss: 0.9428 - val_policy_loss: 2.1940\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.5284 - value_loss: 0.9532 - policy_loss: 2.1943 - val_loss: 2.5080 - val_value_loss: 0.9392 - val_policy_loss: 2.1940\n",
      "Saved model  tictactoe_5_epochs_37\n",
      "iteration 37 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.06\n",
      "iteration 38 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_38\n",
      "iteration 38 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.5096 - value_loss: 0.9357 - policy_loss: 2.2007 - val_loss: 2.4863 - val_value_loss: 0.9226 - val_policy_loss: 2.1930\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.4879 - value_loss: 0.9199 - policy_loss: 2.1989 - val_loss: 2.4713 - val_value_loss: 0.9177 - val_policy_loss: 2.1930\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 127us/step - loss: 2.4683 - value_loss: 0.9104 - policy_loss: 2.1942 - val_loss: 2.4573 - val_value_loss: 0.9139 - val_policy_loss: 2.1930\n",
      "Saved model  tictactoe_5_epochs_38\n",
      "iteration 38 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.1\n",
      "iteration 39 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_39\n",
      "iteration 39 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.4482 - value_loss: 0.8835 - policy_loss: 2.2052 - val_loss: 2.4517 - val_value_loss: 0.9220 - val_policy_loss: 2.1975\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.4305 - value_loss: 0.8713 - policy_loss: 2.2057 - val_loss: 2.4355 - val_value_loss: 0.9128 - val_policy_loss: 2.1975\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.4151 - value_loss: 0.8652 - policy_loss: 2.2043 - val_loss: 2.4214 - val_value_loss: 0.9070 - val_policy_loss: 2.1975\n",
      "Saved model  tictactoe_5_epochs_39\n",
      "iteration 39 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.06\n",
      "iteration 40 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_40\n",
      "iteration 40 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.4636 - value_loss: 0.9957 - policy_loss: 2.1933 - val_loss: 2.4344 - val_value_loss: 0.9556 - val_policy_loss: 2.1970\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.4506 - value_loss: 0.9932 - policy_loss: 2.1919 - val_loss: 2.4147 - val_value_loss: 0.9380 - val_policy_loss: 2.1971\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.4328 - value_loss: 0.9823 - policy_loss: 2.1890 - val_loss: 2.3935 - val_value_loss: 0.9169 - val_policy_loss: 2.1971\n",
      "Saved model  tictactoe_5_epochs_40\n",
      "iteration 40 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.06\n",
      "iteration 41 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_41\n",
      "iteration 41 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.3494 - value_loss: 0.8378 - policy_loss: 2.1881 - val_loss: 2.3829 - val_value_loss: 0.9182 - val_policy_loss: 2.1954\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 152us/step - loss: 2.3415 - value_loss: 0.8423 - policy_loss: 2.1884 - val_loss: 2.3733 - val_value_loss: 0.9196 - val_policy_loss: 2.1954\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.3313 - value_loss: 0.8426 - policy_loss: 2.1882 - val_loss: 2.3652 - val_value_loss: 0.9234 - val_policy_loss: 2.1954\n",
      "Saved model  tictactoe_5_epochs_41\n",
      "iteration 41 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.0\n",
      "iteration 42 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_42\n",
      "iteration 42 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.3309 - value_loss: 0.8515 - policy_loss: 2.1986 - val_loss: 2.3314 - val_value_loss: 0.8781 - val_policy_loss: 2.1928\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.3170 - value_loss: 0.8431 - policy_loss: 2.1991 - val_loss: 2.3150 - val_value_loss: 0.8647 - val_policy_loss: 2.1928\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.3031 - value_loss: 0.8359 - policy_loss: 2.1978 - val_loss: 2.2982 - val_value_loss: 0.8500 - val_policy_loss: 2.1928\n",
      "Saved model  tictactoe_5_epochs_42\n",
      "iteration 42 | evaluation\n",
      "agent vs random - win ratio 0.9 - draw ratio 0.04\n",
      "iteration 43 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_43\n",
      "iteration 43 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.2847 - value_loss: 0.8171 - policy_loss: 2.1988 - val_loss: 2.2921 - val_value_loss: 0.8567 - val_policy_loss: 2.1925\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.2723 - value_loss: 0.8122 - policy_loss: 2.1975 - val_loss: 2.2823 - val_value_loss: 0.8555 - val_policy_loss: 2.1925\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.2602 - value_loss: 0.8077 - policy_loss: 2.1961 - val_loss: 2.2749 - val_value_loss: 0.8585 - val_policy_loss: 2.1925\n",
      "Saved model  tictactoe_5_epochs_43\n",
      "iteration 43 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.02\n",
      "iteration 44 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_44\n",
      "iteration 44 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.2463 - value_loss: 0.8034 - policy_loss: 2.1905 - val_loss: 2.2559 - val_value_loss: 0.8335 - val_policy_loss: 2.1968\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.2745 - value_loss: 0.8782 - policy_loss: 2.1893 - val_loss: 2.2514 - val_value_loss: 0.8412 - val_policy_loss: 2.1968\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.2294 - value_loss: 0.8065 - policy_loss: 2.1876 - val_loss: 2.2423 - val_value_loss: 0.8390 - val_policy_loss: 2.1968\n",
      "Saved model  tictactoe_5_epochs_44\n",
      "iteration 44 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.0\n",
      "iteration 45 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_45\n",
      "iteration 45 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.2425 - value_loss: 0.8376 - policy_loss: 2.1986 - val_loss: 2.2245 - val_value_loss: 0.8217 - val_policy_loss: 2.1939\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.2277 - value_loss: 0.8239 - policy_loss: 2.1980 - val_loss: 2.2173 - val_value_loss: 0.8221 - val_policy_loss: 2.1939\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.2209 - value_loss: 0.8273 - policy_loss: 2.1957 - val_loss: 2.2161 - val_value_loss: 0.8337 - val_policy_loss: 2.1939\n",
      "Saved model  tictactoe_5_epochs_45\n",
      "iteration 45 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.1\n",
      "iteration 46 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_46\n",
      "iteration 46 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.2096 - value_loss: 0.8284 - policy_loss: 2.1862 - val_loss: 2.2445 - val_value_loss: 0.9010 - val_policy_loss: 2.1971\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.2018 - value_loss: 0.8265 - policy_loss: 2.1863 - val_loss: 2.2401 - val_value_loss: 0.9056 - val_policy_loss: 2.1970\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.1880 - value_loss: 0.8146 - policy_loss: 2.1838 - val_loss: 2.2315 - val_value_loss: 0.9014 - val_policy_loss: 2.1970\n",
      "Saved model  tictactoe_5_epochs_46\n",
      "iteration 46 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.08\n",
      "iteration 47 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_47\n",
      "iteration 47 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.2090 - value_loss: 0.8569 - policy_loss: 2.1967 - val_loss: 2.2441 - val_value_loss: 0.9354 - val_policy_loss: 2.2012\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.2047 - value_loss: 0.8600 - policy_loss: 2.1978 - val_loss: 2.2382 - val_value_loss: 0.9365 - val_policy_loss: 2.2012\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.1987 - value_loss: 0.8620 - policy_loss: 2.1967 - val_loss: 2.2367 - val_value_loss: 0.9463 - val_policy_loss: 2.2012\n",
      "Saved model  tictactoe_5_epochs_47\n",
      "iteration 47 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.02\n",
      "iteration 48 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_48\n",
      "iteration 48 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.1719 - value_loss: 0.8168 - policy_loss: 2.2012 - val_loss: 2.2037 - val_value_loss: 0.8992 - val_policy_loss: 2.1950\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.1578 - value_loss: 0.8043 - policy_loss: 2.1981 - val_loss: 2.2163 - val_value_loss: 0.9370 - val_policy_loss: 2.1950\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.1513 - value_loss: 0.8085 - policy_loss: 2.1937 - val_loss: 2.2132 - val_value_loss: 0.9433 - val_policy_loss: 2.1950\n",
      "Saved model  tictactoe_5_epochs_48\n",
      "iteration 48 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.0\n",
      "iteration 49 | self-play\n",
      "saving memory position_memory_tictactoe_5_epochs_ep_49\n",
      "iteration 49 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.1443 - value_loss: 0.7962 - policy_loss: 2.2043 - val_loss: 2.2070 - val_value_loss: 0.9417 - val_policy_loss: 2.1968\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.1278 - value_loss: 0.7760 - policy_loss: 2.2041 - val_loss: 2.1895 - val_value_loss: 0.9189 - val_policy_loss: 2.1967\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.1216 - value_loss: 0.7794 - policy_loss: 2.2005 - val_loss: 2.1836 - val_value_loss: 0.9193 - val_policy_loss: 2.1967\n",
      "Saved model  tictactoe_5_epochs_49\n",
      "iteration 49 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.04\n"
     ]
    }
   ],
   "source": [
    "wins_3, draws_3 = test_pipeline.run(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(50)\n",
    "losses_3 = np.ones(50) - wins_3 - draws_3\n",
    "# no_loss = np.zeros(50) + wins +draws\n",
    "\n",
    "plt.plot(x, wins_3, label=\"win ratio\")\n",
    "plt.plot(x, draws_3, label=\"draw ratio\")\n",
    "#plt.plot(x, no_loss, label=\"no loss ratio\")\n",
    "plt.plot(x, losses_3, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62, 0.54, 0.5, 0.5, 0.52, 0.56, 0.54, 0.76, 0.66, 0.7, 0.7, 0.8, 0.76, 0.72, 0.7, 0.7, 0.82, 0.76, 0.7, 0.8, 0.86, 0.74, 0.82, 0.82, 0.9, 0.8, 0.74, 0.82, 0.8, 0.68, 0.84, 0.8, 0.74, 0.76, 0.74, 0.76, 0.84, 0.84, 0.74, 0.88, 0.82, 0.86, 0.9, 0.8, 0.84, 0.76, 0.76, 0.78, 0.84, 0.82]\n",
      "[0.02, 0.02, 0.08, 0.04, 0.1, 0.14, 0.02, 0.04, 0.08, 0.06, 0.06, 0.02, 0.12, 0.04, 0.08, 0.02, 0.0, 0.02, 0.08, 0.04, 0.04, 0.08, 0.1, 0.06, 0.04, 0.02, 0.02, 0.02, 0.04, 0.1, 0.04, 0.04, 0.08, 0.02, 0.06, 0.1, 0.02, 0.06, 0.1, 0.06, 0.06, 0.0, 0.04, 0.02, 0.0, 0.1, 0.08, 0.02, 0.0, 0.04]\n",
      "[0.36 0.44 0.42 0.46 0.38 0.3  0.44 0.2  0.26 0.24 0.24 0.18 0.12 0.24\n",
      " 0.22 0.28 0.18 0.22 0.22 0.16 0.1  0.18 0.08 0.12 0.06 0.18 0.24 0.16\n",
      " 0.16 0.22 0.12 0.16 0.18 0.22 0.2  0.14 0.14 0.1  0.16 0.06 0.12 0.14\n",
      " 0.06 0.18 0.16 0.14 0.16 0.2  0.16 0.14]\n"
     ]
    }
   ],
   "source": [
    "print(wins_3)\n",
    "print(draws_3)\n",
    "print(losses_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" These dictionarys set most of the relevant settings and hyperparameters for the program. \"\"\"\n",
    "\n",
    "MCTS = {\n",
    "    'c_puct': 1.0,\n",
    "    'dir_alpha': 0.5,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 1,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 10\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 50,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 0,\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 50,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.02, \n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 256,\n",
    "    'num_filters_value': 256,\n",
    "    'num_filters_tower': 256,\n",
    "    'num_residual_blocks': 5,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 256\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"tictactoe_10_epochs\",\"TicTacToe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 3s 7ms/step - loss: 5.7002 - value_loss: 1.6800 - policy_loss: 2.6066 - val_loss: 4532007.5000 - val_value_loss: 1.8058 - val_policy_loss: 9064000.0000\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 149us/step - loss: 13.6432 - value_loss: 1.6748 - policy_loss: 15.6972 - val_loss: 51748.4805 - val_value_loss: 1.8058 - val_policy_loss: 103479.6953\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 16.1901 - value_loss: 1.6748 - policy_loss: 15.2486 - val_loss: 8464.1729 - val_value_loss: 1.8058 - val_policy_loss: 16904.3281\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 18.4831 - value_loss: 1.6748 - policy_loss: 13.0803 - val_loss: 6441.0073 - val_value_loss: 1.8058 - val_policy_loss: 12850.9365\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 21.6651 - value_loss: 1.6748 - policy_loss: 12.3818 - val_loss: 3742.6372 - val_value_loss: 1.8058 - val_policy_loss: 7447.3403\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 25.0939 - value_loss: 1.6748 - policy_loss: 12.3845 - val_loss: 2890.1125 - val_value_loss: 1.8058 - val_policy_loss: 5735.9365\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 28.4061 - value_loss: 1.6748 - policy_loss: 12.6539 - val_loss: 2299.4348 - val_value_loss: 1.8058 - val_policy_loss: 4548.8838\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 31.1186 - value_loss: 1.6748 - policy_loss: 12.3819 - val_loss: 1062.6295 - val_value_loss: 1.8058 - val_policy_loss: 2070.3135\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 31.3645 - value_loss: 1.6748 - policy_loss: 7.9145 - val_loss: 975.1869 - val_value_loss: 1.8058 - val_policy_loss: 1891.2430\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 33.5481 - value_loss: 1.6748 - policy_loss: 8.0966 - val_loss: 923.0212 - val_value_loss: 1.8058 - val_policy_loss: 1783.5215\n",
      "Saved model  tictactoe_10_epochs_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.46 - draw ratio 0.1\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 34.7562 - value_loss: 1.4939 - policy_loss: 7.3032 - val_loss: 648.7933 - val_value_loss: 1.7379 - val_policy_loss: 1232.5148\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 149us/step - loss: 35.6406 - value_loss: 1.4939 - policy_loss: 6.4531 - val_loss: 415.7208 - val_value_loss: 1.7379 - val_policy_loss: 764.4744\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 143us/step - loss: 36.1269 - value_loss: 1.4939 - policy_loss: 5.5306 - val_loss: 326.8849 - val_value_loss: 1.7379 - val_policy_loss: 585.5704\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 141us/step - loss: 36.4961 - value_loss: 1.4939 - policy_loss: 5.0367 - val_loss: 175.3104 - val_value_loss: 1.7379 - val_policy_loss: 281.7921\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 140us/step - loss: 36.1935 - value_loss: 1.4939 - policy_loss: 3.8022 - val_loss: 145.1781 - val_value_loss: 1.7379 - val_policy_loss: 221.4313\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 36.0522 - value_loss: 1.4939 - policy_loss: 3.4236 - val_loss: 119.8560 - val_value_loss: 1.7379 - val_policy_loss: 171.1593\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 35.9209 - value_loss: 1.4939 - policy_loss: 3.5331 - val_loss: 104.9759 - val_value_loss: 1.7379 - val_policy_loss: 142.1693\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 35.5376 - value_loss: 1.4939 - policy_loss: 3.5368 - val_loss: 79.7721 - val_value_loss: 1.7379 - val_policy_loss: 92.8671\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 34.8604 - value_loss: 1.4939 - policy_loss: 3.2875 - val_loss: 62.4033 - val_value_loss: 1.7379 - val_policy_loss: 59.5111\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 34.0481 - value_loss: 1.4939 - policy_loss: 3.0447 - val_loss: 52.8088 - val_value_loss: 1.7379 - val_policy_loss: 41.9296\n",
      "Saved model  tictactoe_10_epochs_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.44 - draw ratio 0.14\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 33.3898 - value_loss: 1.7995 - policy_loss: 3.0300 - val_loss: 47.0162 - val_value_loss: 1.6408 - val_policy_loss: 32.2266\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 149us/step - loss: 32.4736 - value_loss: 1.7995 - policy_loss: 2.9826 - val_loss: 39.4709 - val_value_loss: 1.6408 - val_policy_loss: 19.0564\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 147us/step - loss: 31.4059 - value_loss: 1.7995 - policy_loss: 2.7678 - val_loss: 34.3965 - val_value_loss: 1.6408 - val_policy_loss: 10.9262\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 147us/step - loss: 30.3297 - value_loss: 1.7995 - policy_loss: 2.6339 - val_loss: 31.8358 - val_value_loss: 1.6408 - val_policy_loss: 7.8890\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 29.3292 - value_loss: 1.7995 - policy_loss: 2.7171 - val_loss: 29.4724 - val_value_loss: 1.6408 - val_policy_loss: 5.2848\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 28.2689 - value_loss: 1.7995 - policy_loss: 2.7191 - val_loss: 27.4100 - val_value_loss: 1.6408 - val_policy_loss: 3.2979\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 27.1396 - value_loss: 1.7995 - policy_loss: 2.5983 - val_loss: 25.9184 - val_value_loss: 1.6408 - val_policy_loss: 2.4480\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 26.0140 - value_loss: 1.7995 - policy_loss: 2.4804 - val_loss: 24.7865 - val_value_loss: 1.6408 - val_policy_loss: 2.2968\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 24.9710 - value_loss: 1.7995 - policy_loss: 2.5072 - val_loss: 23.7174 - val_value_loss: 1.6408 - val_policy_loss: 2.2388\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 23.9303 - value_loss: 1.7995 - policy_loss: 2.5058 - val_loss: 22.6825 - val_value_loss: 1.6408 - val_policy_loss: 2.2065\n",
      "Saved model  tictactoe_10_epochs_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.02\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 22.8965 - value_loss: 1.6504 - policy_loss: 2.6250 - val_loss: 21.7614 - val_value_loss: 1.7670 - val_policy_loss: 2.2251\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 147us/step - loss: 21.8369 - value_loss: 1.6504 - policy_loss: 2.4926 - val_loss: 20.7831 - val_value_loss: 1.7670 - val_policy_loss: 2.1985\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 20.8376 - value_loss: 1.6504 - policy_loss: 2.4242 - val_loss: 19.8464 - val_value_loss: 1.7670 - val_policy_loss: 2.1936\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 19.8784 - value_loss: 1.6504 - policy_loss: 2.3743 - val_loss: 18.9444 - val_value_loss: 1.7670 - val_policy_loss: 2.1935\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 18.9642 - value_loss: 1.6504 - policy_loss: 2.3497 - val_loss: 18.0761 - val_value_loss: 1.7670 - val_policy_loss: 2.1935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 18.0692 - value_loss: 1.6504 - policy_loss: 2.2963 - val_loss: 17.2427 - val_value_loss: 1.7670 - val_policy_loss: 2.1933\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 17.2487 - value_loss: 1.6504 - policy_loss: 2.3220 - val_loss: 16.4446 - val_value_loss: 1.7670 - val_policy_loss: 2.1931\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 16.4690 - value_loss: 1.6504 - policy_loss: 2.3584 - val_loss: 15.6821 - val_value_loss: 1.7670 - val_policy_loss: 2.1930\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 15.7031 - value_loss: 1.6504 - policy_loss: 2.3515 - val_loss: 14.9551 - val_value_loss: 1.7670 - val_policy_loss: 2.1928\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 14.9651 - value_loss: 1.6504 - policy_loss: 2.3294 - val_loss: 14.2634 - val_value_loss: 1.7670 - val_policy_loss: 2.1927\n",
      "Saved model  tictactoe_10_epochs_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.04\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 14.4219 - value_loss: 1.7311 - policy_loss: 2.5457 - val_loss: 13.5694 - val_value_loss: 1.6893 - val_policy_loss: 2.1973\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 13.7608 - value_loss: 1.7311 - policy_loss: 2.5383 - val_loss: 12.9434 - val_value_loss: 1.6893 - val_policy_loss: 2.1971\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 140us/step - loss: 13.0947 - value_loss: 1.7311 - policy_loss: 2.4580 - val_loss: 12.3537 - val_value_loss: 1.6893 - val_policy_loss: 2.1970\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 12.4602 - value_loss: 1.7311 - policy_loss: 2.3683 - val_loss: 11.7976 - val_value_loss: 1.6893 - val_policy_loss: 2.1969\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 11.8903 - value_loss: 1.7311 - policy_loss: 2.3406 - val_loss: 11.2724 - val_value_loss: 1.6893 - val_policy_loss: 2.1969\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 11.3613 - value_loss: 1.7311 - policy_loss: 2.3328 - val_loss: 10.7757 - val_value_loss: 1.6893 - val_policy_loss: 2.1968\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 10.8354 - value_loss: 1.7311 - policy_loss: 2.2745 - val_loss: 10.3057 - val_value_loss: 1.6893 - val_policy_loss: 2.1968\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 10.3683 - value_loss: 1.7311 - policy_loss: 2.2802 - val_loss: 9.8605 - val_value_loss: 1.6893 - val_policy_loss: 2.1968\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 9.9349 - value_loss: 1.7311 - policy_loss: 2.3038 - val_loss: 9.4384 - val_value_loss: 1.6893 - val_policy_loss: 2.1968\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 9.5123 - value_loss: 1.7311 - policy_loss: 2.3029 - val_loss: 9.0382 - val_value_loss: 1.6893 - val_policy_loss: 2.1968\n",
      "Saved model  tictactoe_10_epochs_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.04\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 9.0938 - value_loss: 1.7408 - policy_loss: 2.2565 - val_loss: 8.6449 - val_value_loss: 1.6602 - val_policy_loss: 2.1981\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 8.6855 - value_loss: 1.7408 - policy_loss: 2.1987 - val_loss: 8.2859 - val_value_loss: 1.6602 - val_policy_loss: 2.1982\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 140us/step - loss: 8.3270 - value_loss: 1.7408 - policy_loss: 2.1998 - val_loss: 7.9465 - val_value_loss: 1.6602 - val_policy_loss: 2.1983\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 7.9817 - value_loss: 1.7408 - policy_loss: 2.1880 - val_loss: 7.6255 - val_value_loss: 1.6602 - val_policy_loss: 2.1983\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 133us/step - loss: 7.6686 - value_loss: 1.7408 - policy_loss: 2.2038 - val_loss: 7.3220 - val_value_loss: 1.6602 - val_policy_loss: 2.1984\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 7.3634 - value_loss: 1.7408 - policy_loss: 2.2005 - val_loss: 7.0354 - val_value_loss: 1.6602 - val_policy_loss: 2.1984\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 7.0734 - value_loss: 1.7408 - policy_loss: 2.1937 - val_loss: 6.7649 - val_value_loss: 1.6602 - val_policy_loss: 2.1985\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 6.8038 - value_loss: 1.7408 - policy_loss: 2.1957 - val_loss: 6.5095 - val_value_loss: 1.6602 - val_policy_loss: 2.1985\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 138us/step - loss: 6.5419 - value_loss: 1.7408 - policy_loss: 2.1827 - val_loss: 6.2685 - val_value_loss: 1.6602 - val_policy_loss: 2.1986\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 6.3016 - value_loss: 1.7408 - policy_loss: 2.1841 - val_loss: 6.0412 - val_value_loss: 1.6602 - val_policy_loss: 2.1986\n",
      "Saved model  tictactoe_10_epochs_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.04\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 149us/step - loss: 5.9934 - value_loss: 1.5452 - policy_loss: 2.2181 - val_loss: 5.8846 - val_value_loss: 1.7767 - val_policy_loss: 2.1979\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 149us/step - loss: 5.7753 - value_loss: 1.5452 - policy_loss: 2.2108 - val_loss: 5.6825 - val_value_loss: 1.7767 - val_policy_loss: 2.1979\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 149us/step - loss: 5.5658 - value_loss: 1.5452 - policy_loss: 2.1960 - val_loss: 5.4922 - val_value_loss: 1.7767 - val_policy_loss: 2.1980\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 5.3694 - value_loss: 1.5452 - policy_loss: 2.1839 - val_loss: 5.3130 - val_value_loss: 1.7767 - val_policy_loss: 2.1980\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 5.1906 - value_loss: 1.5452 - policy_loss: 2.1847 - val_loss: 5.1441 - val_value_loss: 1.7767 - val_policy_loss: 2.1980\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 5.0196 - value_loss: 1.5452 - policy_loss: 2.1804 - val_loss: 4.9848 - val_value_loss: 1.7767 - val_policy_loss: 2.1980\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 4.8572 - value_loss: 1.5452 - policy_loss: 2.1743 - val_loss: 4.8345 - val_value_loss: 1.7767 - val_policy_loss: 2.1981\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 4.7060 - value_loss: 1.5452 - policy_loss: 2.1725 - val_loss: 4.6927 - val_value_loss: 1.7767 - val_policy_loss: 2.1981\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 4.5612 - value_loss: 1.5452 - policy_loss: 2.1665 - val_loss: 4.5588 - val_value_loss: 1.7767 - val_policy_loss: 2.1981\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 4.4242 - value_loss: 1.5452 - policy_loss: 2.1603 - val_loss: 4.4324 - val_value_loss: 1.7767 - val_policy_loss: 2.1981\n",
      "Saved model  tictactoe_10_epochs_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.04\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 4.3900 - value_loss: 1.6553 - policy_loss: 2.2347 - val_loss: 4.2708 - val_value_loss: 1.6893 - val_policy_loss: 2.2003\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 4.2601 - value_loss: 1.6553 - policy_loss: 2.2130 - val_loss: 4.1588 - val_value_loss: 1.6893 - val_policy_loss: 2.2003\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 4.1358 - value_loss: 1.6553 - policy_loss: 2.1883 - val_loss: 4.0536 - val_value_loss: 1.6893 - val_policy_loss: 2.2003\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 4.0181 - value_loss: 1.6553 - policy_loss: 2.1635 - val_loss: 3.9544 - val_value_loss: 1.6893 - val_policy_loss: 2.2003\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 3.9293 - value_loss: 1.6553 - policy_loss: 2.1841 - val_loss: 3.8605 - val_value_loss: 1.6893 - val_policy_loss: 2.2002\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 3.8233 - value_loss: 1.6553 - policy_loss: 2.1599 - val_loss: 3.7715 - val_value_loss: 1.6893 - val_policy_loss: 2.2002\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 3.7327 - value_loss: 1.6553 - policy_loss: 2.1565 - val_loss: 3.6873 - val_value_loss: 1.6893 - val_policy_loss: 2.2002\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 3.6457 - value_loss: 1.6553 - policy_loss: 2.1510 - val_loss: 3.6074 - val_value_loss: 1.6893 - val_policy_loss: 2.2001\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 3.5587 - value_loss: 1.6553 - policy_loss: 2.1368 - val_loss: 3.5318 - val_value_loss: 1.6893 - val_policy_loss: 2.2001\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 3.4851 - value_loss: 1.6553 - policy_loss: 2.1407 - val_loss: 3.4599 - val_value_loss: 1.6893 - val_policy_loss: 2.2001\n",
      "Saved model  tictactoe_10_epochs_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.04\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 3.3510 - value_loss: 1.4988 - policy_loss: 2.1728 - val_loss: 3.4048 - val_value_loss: 1.7184 - val_policy_loss: 2.1973\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 3.2779 - value_loss: 1.4988 - policy_loss: 2.1632 - val_loss: 3.3399 - val_value_loss: 1.7184 - val_policy_loss: 2.1972\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 3.2078 - value_loss: 1.4988 - policy_loss: 2.1528 - val_loss: 3.2783 - val_value_loss: 1.7184 - val_policy_loss: 2.1972\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 3.1417 - value_loss: 1.4988 - policy_loss: 2.1436 - val_loss: 3.2199 - val_value_loss: 1.7184 - val_policy_loss: 2.1971\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 3.0817 - value_loss: 1.4988 - policy_loss: 2.1403 - val_loss: 3.1644 - val_value_loss: 1.7184 - val_policy_loss: 2.1970\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 3.0216 - value_loss: 1.4988 - policy_loss: 2.1310 - val_loss: 3.1118 - val_value_loss: 1.7184 - val_policy_loss: 2.1970\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 2.9652 - value_loss: 1.4988 - policy_loss: 2.1235 - val_loss: 3.0620 - val_value_loss: 1.7184 - val_policy_loss: 2.1969\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 2.9105 - value_loss: 1.4988 - policy_loss: 2.1136 - val_loss: 3.0148 - val_value_loss: 1.7184 - val_policy_loss: 2.1969\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 2.8583 - value_loss: 1.4988 - policy_loss: 2.1035 - val_loss: 2.9703 - val_value_loss: 1.7184 - val_policy_loss: 2.1968\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 2.8206 - value_loss: 1.4988 - policy_loss: 2.1171 - val_loss: 2.9287 - val_value_loss: 1.7184 - val_policy_loss: 2.1968\n",
      "Saved model  tictactoe_10_epochs_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.02\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.8253 - value_loss: 1.4963 - policy_loss: 2.2121 - val_loss: 2.9919 - val_value_loss: 1.9223 - val_policy_loss: 2.1946\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.7817 - value_loss: 1.4963 - policy_loss: 2.2001 - val_loss: 2.9594 - val_value_loss: 1.9223 - val_policy_loss: 2.1946\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.7372 - value_loss: 1.4963 - policy_loss: 2.1762 - val_loss: 2.9310 - val_value_loss: 1.9223 - val_policy_loss: 2.1947\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.6988 - value_loss: 1.4963 - policy_loss: 2.1562 - val_loss: 2.9045 - val_value_loss: 1.9223 - val_policy_loss: 2.1947\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.6641 - value_loss: 1.4963 - policy_loss: 2.1399 - val_loss: 2.8787 - val_value_loss: 1.9223 - val_policy_loss: 2.1948\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 2.6363 - value_loss: 1.4963 - policy_loss: 2.1358 - val_loss: 2.8528 - val_value_loss: 1.9223 - val_policy_loss: 2.1948\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 2.6028 - value_loss: 1.4963 - policy_loss: 2.1209 - val_loss: 2.8265 - val_value_loss: 1.9223 - val_policy_loss: 2.1949\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 2.5732 - value_loss: 1.4961 - policy_loss: 2.1145 - val_loss: 2.8000 - val_value_loss: 1.9223 - val_policy_loss: 2.1949\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 2.5422 - value_loss: 1.4930 - policy_loss: 2.1087 - val_loss: 2.7561 - val_value_loss: 1.8855 - val_policy_loss: 2.1949\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 2.4333 - value_loss: 1.3433 - policy_loss: 2.0914 - val_loss: 2.7928 - val_value_loss: 1.9223 - val_policy_loss: 2.1949\n",
      "Saved model  tictactoe_10_epochs_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.92 - draw ratio 0.04\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.6293 - value_loss: 1.6039 - policy_loss: 2.1865 - val_loss: 2.8526 - val_value_loss: 1.8738 - val_policy_loss: 2.1916\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.7085 - value_loss: 1.6039 - policy_loss: 2.1732 - val_loss: 2.9754 - val_value_loss: 1.8738 - val_policy_loss: 2.1915\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 2.8187 - value_loss: 1.6039 - policy_loss: 2.1480 - val_loss: 3.1098 - val_value_loss: 1.8738 - val_policy_loss: 2.1915\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 2.9546 - value_loss: 1.6039 - policy_loss: 2.1510 - val_loss: 3.2370 - val_value_loss: 1.8738 - val_policy_loss: 2.1914\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 3.0771 - value_loss: 1.6039 - policy_loss: 2.1414 - val_loss: 3.3456 - val_value_loss: 1.8738 - val_policy_loss: 2.1913\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 3.1773 - value_loss: 1.6039 - policy_loss: 2.1247 - val_loss: 3.4298 - val_value_loss: 1.8738 - val_policy_loss: 2.1913\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 3.2627 - value_loss: 1.6039 - policy_loss: 2.1270 - val_loss: 3.4879 - val_value_loss: 1.8738 - val_policy_loss: 2.1912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 3.3133 - value_loss: 1.6039 - policy_loss: 2.1120 - val_loss: 3.5212 - val_value_loss: 1.8738 - val_policy_loss: 2.1912\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 3.3402 - value_loss: 1.6039 - policy_loss: 2.0990 - val_loss: 3.5328 - val_value_loss: 1.8738 - val_policy_loss: 2.1912\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 3.3470 - value_loss: 1.6039 - policy_loss: 2.0896 - val_loss: 3.5259 - val_value_loss: 1.8738 - val_policy_loss: 2.1912\n",
      "Saved model  tictactoe_10_epochs_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.06\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 147us/step - loss: 3.4722 - value_loss: 1.7751 - policy_loss: 2.1825 - val_loss: 3.4244 - val_value_loss: 1.7087 - val_policy_loss: 2.1953\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 147us/step - loss: 3.4490 - value_loss: 1.7751 - policy_loss: 2.1781 - val_loss: 3.3934 - val_value_loss: 1.7087 - val_policy_loss: 2.1954\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 3.4043 - value_loss: 1.7751 - policy_loss: 2.1509 - val_loss: 3.3562 - val_value_loss: 1.7087 - val_policy_loss: 2.1954\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 3.3449 - value_loss: 1.7751 - policy_loss: 2.1065 - val_loss: 3.3146 - val_value_loss: 1.7087 - val_policy_loss: 2.1954\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 3.2979 - value_loss: 1.7751 - policy_loss: 2.0957 - val_loss: 3.2697 - val_value_loss: 1.7087 - val_policy_loss: 2.1955\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 3.2378 - value_loss: 1.7751 - policy_loss: 2.0653 - val_loss: 3.2229 - val_value_loss: 1.7087 - val_policy_loss: 2.1955\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 3.1835 - value_loss: 1.7751 - policy_loss: 2.0506 - val_loss: 3.1751 - val_value_loss: 1.7087 - val_policy_loss: 2.1956\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 3.1292 - value_loss: 1.7751 - policy_loss: 2.0374 - val_loss: 3.1270 - val_value_loss: 1.7087 - val_policy_loss: 2.1956\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 136us/step - loss: 3.0832 - value_loss: 1.7751 - policy_loss: 2.0416 - val_loss: 3.0802 - val_value_loss: 1.7087 - val_policy_loss: 2.1957\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 3.0951 - value_loss: 1.7751 - policy_loss: 2.1591 - val_loss: 3.0359 - val_value_loss: 1.7087 - val_policy_loss: 2.1957\n",
      "Saved model  tictactoe_10_epochs_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.08\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.9911 - value_loss: 1.7115 - policy_loss: 2.1035 - val_loss: 2.9435 - val_value_loss: 1.6019 - val_policy_loss: 2.1986\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.9481 - value_loss: 1.7115 - policy_loss: 2.0984 - val_loss: 2.9054 - val_value_loss: 1.6019 - val_policy_loss: 2.1986\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.8991 - value_loss: 1.7115 - policy_loss: 2.0764 - val_loss: 2.8689 - val_value_loss: 1.6019 - val_policy_loss: 2.1986\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.8517 - value_loss: 1.7115 - policy_loss: 2.0546 - val_loss: 2.8331 - val_value_loss: 1.6019 - val_policy_loss: 2.1986\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.8101 - value_loss: 1.7115 - policy_loss: 2.0431 - val_loss: 2.7975 - val_value_loss: 1.6019 - val_policy_loss: 2.1986\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 2.7682 - value_loss: 1.7115 - policy_loss: 2.0304 - val_loss: 2.7620 - val_value_loss: 1.6019 - val_policy_loss: 2.1986\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 2.7271 - value_loss: 1.7115 - policy_loss: 2.0192 - val_loss: 2.7269 - val_value_loss: 1.6019 - val_policy_loss: 2.1986\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 2.6831 - value_loss: 1.7115 - policy_loss: 2.0014 - val_loss: 2.6927 - val_value_loss: 1.6019 - val_policy_loss: 2.1986\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 2.6424 - value_loss: 1.7115 - policy_loss: 1.9883 - val_loss: 2.6599 - val_value_loss: 1.6019 - val_policy_loss: 2.1986\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 2.6034 - value_loss: 1.7115 - policy_loss: 1.9761 - val_loss: 2.6286 - val_value_loss: 1.6019 - val_policy_loss: 2.1987\n",
      "Saved model  tictactoe_10_epochs_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.04\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 152us/step - loss: 2.5801 - value_loss: 1.6748 - policy_loss: 2.0287 - val_loss: 2.5871 - val_value_loss: 1.5825 - val_policy_loss: 2.1929\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.5419 - value_loss: 1.6748 - policy_loss: 2.0102 - val_loss: 2.5611 - val_value_loss: 1.5825 - val_policy_loss: 2.1928\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.5153 - value_loss: 1.6748 - policy_loss: 2.0089 - val_loss: 2.5392 - val_value_loss: 1.5825 - val_policy_loss: 2.1928\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.4902 - value_loss: 1.6748 - policy_loss: 2.0026 - val_loss: 2.5203 - val_value_loss: 1.5825 - val_policy_loss: 2.1928\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 2.4561 - value_loss: 1.6748 - policy_loss: 1.9722 - val_loss: 2.5041 - val_value_loss: 1.5825 - val_policy_loss: 2.1928\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.4478 - value_loss: 1.6748 - policy_loss: 1.9879 - val_loss: 2.4906 - val_value_loss: 1.5825 - val_policy_loss: 2.1927\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 2.4428 - value_loss: 1.6748 - policy_loss: 2.0049 - val_loss: 2.4799 - val_value_loss: 1.5825 - val_policy_loss: 2.1926\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 2.3970 - value_loss: 1.6748 - policy_loss: 1.9345 - val_loss: 2.4711 - val_value_loss: 1.5825 - val_policy_loss: 2.1926\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 2.3877 - value_loss: 1.6748 - policy_loss: 1.9336 - val_loss: 2.4619 - val_value_loss: 1.5825 - val_policy_loss: 2.1926\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 2.3525 - value_loss: 1.6748 - policy_loss: 1.8815 - val_loss: 2.4515 - val_value_loss: 1.5825 - val_policy_loss: 2.1926\n",
      "Saved model  tictactoe_10_epochs_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.02\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.3345 - value_loss: 1.5550 - policy_loss: 1.9861 - val_loss: 2.4564 - val_value_loss: 1.6019 - val_policy_loss: 2.2062\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.2950 - value_loss: 1.5550 - policy_loss: 1.9304 - val_loss: 2.4439 - val_value_loss: 1.6019 - val_policy_loss: 2.2061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.2600 - value_loss: 1.5550 - policy_loss: 1.8851 - val_loss: 2.4306 - val_value_loss: 1.6019 - val_policy_loss: 2.2060\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.2353 - value_loss: 1.5550 - policy_loss: 1.8623 - val_loss: 2.4164 - val_value_loss: 1.6019 - val_policy_loss: 2.2059\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.2136 - value_loss: 1.5550 - policy_loss: 1.8473 - val_loss: 2.4020 - val_value_loss: 1.6019 - val_policy_loss: 2.2058\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.2152 - value_loss: 1.5550 - policy_loss: 1.8791 - val_loss: 2.3884 - val_value_loss: 1.6019 - val_policy_loss: 2.2058\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 2.1934 - value_loss: 1.5550 - policy_loss: 1.8627 - val_loss: 2.3760 - val_value_loss: 1.6019 - val_policy_loss: 2.2057\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 2.1583 - value_loss: 1.5550 - policy_loss: 1.8171 - val_loss: 2.3647 - val_value_loss: 1.6019 - val_policy_loss: 2.2056\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 2.1301 - value_loss: 1.5550 - policy_loss: 1.7834 - val_loss: 2.3541 - val_value_loss: 1.6019 - val_policy_loss: 2.2055\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.1023 - value_loss: 1.5550 - policy_loss: 1.7488 - val_loss: 2.3437 - val_value_loss: 1.6019 - val_policy_loss: 2.2053\n",
      "Saved model  tictactoe_10_epochs_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.04\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.2470 - value_loss: 1.7090 - policy_loss: 1.9048 - val_loss: 2.4230 - val_value_loss: 1.7864 - val_policy_loss: 2.1998\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.2161 - value_loss: 1.7090 - policy_loss: 1.8634 - val_loss: 2.4136 - val_value_loss: 1.7864 - val_policy_loss: 2.1996\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.1842 - value_loss: 1.7090 - policy_loss: 1.8183 - val_loss: 2.4047 - val_value_loss: 1.7864 - val_policy_loss: 2.1994\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 2.1720 - value_loss: 1.7090 - policy_loss: 1.8114 - val_loss: 2.3960 - val_value_loss: 1.7864 - val_policy_loss: 2.1991\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 2.1580 - value_loss: 1.7090 - policy_loss: 1.8004 - val_loss: 2.3873 - val_value_loss: 1.7864 - val_policy_loss: 2.1988\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 2.1307 - value_loss: 1.7090 - policy_loss: 1.7630 - val_loss: 2.3787 - val_value_loss: 1.7864 - val_policy_loss: 2.1984\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 2.1130 - value_loss: 1.7090 - policy_loss: 1.7444 - val_loss: 2.3697 - val_value_loss: 1.7864 - val_policy_loss: 2.1980\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 2.1041 - value_loss: 1.7090 - policy_loss: 1.7442 - val_loss: 2.3602 - val_value_loss: 1.7864 - val_policy_loss: 2.1975\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 2.0855 - value_loss: 1.7090 - policy_loss: 1.7257 - val_loss: 2.3505 - val_value_loss: 1.7864 - val_policy_loss: 2.1971\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 2.0797 - value_loss: 1.7090 - policy_loss: 1.7330 - val_loss: 2.3408 - val_value_loss: 1.7864 - val_policy_loss: 2.1966\n",
      "Saved model  tictactoe_10_epochs_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.0\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.0971 - value_loss: 1.6870 - policy_loss: 1.8087 - val_loss: 2.2571 - val_value_loss: 1.6408 - val_policy_loss: 2.1901\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.1220 - value_loss: 1.6870 - policy_loss: 1.8736 - val_loss: 2.2530 - val_value_loss: 1.6408 - val_policy_loss: 2.1899\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 2.1151 - value_loss: 1.6870 - policy_loss: 1.8677 - val_loss: 2.2537 - val_value_loss: 1.6408 - val_policy_loss: 2.1896\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.0789 - value_loss: 1.6870 - policy_loss: 1.7938 - val_loss: 2.2574 - val_value_loss: 1.6408 - val_policy_loss: 2.1893\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 2.0906 - value_loss: 1.6870 - policy_loss: 1.8093 - val_loss: 2.2629 - val_value_loss: 1.6408 - val_policy_loss: 2.1885\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 2.0831 - value_loss: 1.6870 - policy_loss: 1.7827 - val_loss: 2.2699 - val_value_loss: 1.6408 - val_policy_loss: 2.1879\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 2.0583 - value_loss: 1.6870 - policy_loss: 1.7184 - val_loss: 2.2762 - val_value_loss: 1.6408 - val_policy_loss: 2.1872\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 2.0585 - value_loss: 1.6870 - policy_loss: 1.7057 - val_loss: 2.2793 - val_value_loss: 1.6408 - val_policy_loss: 2.1867\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 2.0455 - value_loss: 1.6870 - policy_loss: 1.6729 - val_loss: 2.2786 - val_value_loss: 1.6408 - val_policy_loss: 2.1862\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 2.0368 - value_loss: 1.6870 - policy_loss: 1.6562 - val_loss: 2.2741 - val_value_loss: 1.6408 - val_policy_loss: 2.1857\n",
      "Saved model  tictactoe_10_epochs_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.06\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.1916 - value_loss: 1.8337 - policy_loss: 1.8277 - val_loss: 2.2766 - val_value_loss: 1.6602 - val_policy_loss: 2.1828\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.2751 - value_loss: 1.8337 - policy_loss: 2.0063 - val_loss: 2.2748 - val_value_loss: 1.6602 - val_policy_loss: 2.1823\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.2248 - value_loss: 1.8337 - policy_loss: 1.9088 - val_loss: 2.2810 - val_value_loss: 1.6602 - val_policy_loss: 2.1817\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 151us/step - loss: 2.2072 - value_loss: 1.8337 - policy_loss: 1.8606 - val_loss: 2.2910 - val_value_loss: 1.6602 - val_policy_loss: 2.1806\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.1956 - value_loss: 1.8337 - policy_loss: 1.8163 - val_loss: 2.3003 - val_value_loss: 1.6602 - val_policy_loss: 2.1790\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.1880 - value_loss: 1.8337 - policy_loss: 1.7809 - val_loss: 2.3057 - val_value_loss: 1.6602 - val_policy_loss: 2.1774\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.1944 - value_loss: 1.8337 - policy_loss: 1.7811 - val_loss: 2.3059 - val_value_loss: 1.6602 - val_policy_loss: 2.1758\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 2.1766 - value_loss: 1.8337 - policy_loss: 1.7437 - val_loss: 2.3007 - val_value_loss: 1.6602 - val_policy_loss: 2.1740\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 2.1656 - value_loss: 1.8337 - policy_loss: 1.7302 - val_loss: 2.2911 - val_value_loss: 1.6602 - val_policy_loss: 2.1726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.1507 - value_loss: 1.8337 - policy_loss: 1.7182 - val_loss: 2.2786 - val_value_loss: 1.6602 - val_policy_loss: 2.1723\n",
      "Saved model  tictactoe_10_epochs_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.02\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.0866 - value_loss: 1.6822 - policy_loss: 1.7663 - val_loss: 2.2299 - val_value_loss: 1.5922 - val_policy_loss: 2.1708\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.0524 - value_loss: 1.6822 - policy_loss: 1.7256 - val_loss: 2.2158 - val_value_loss: 1.5922 - val_policy_loss: 2.1708\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 2.0162 - value_loss: 1.6822 - policy_loss: 1.6816 - val_loss: 2.2028 - val_value_loss: 1.5922 - val_policy_loss: 2.1713\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 133us/step - loss: 1.9986 - value_loss: 1.6822 - policy_loss: 1.6731 - val_loss: 2.1906 - val_value_loss: 1.5922 - val_policy_loss: 2.1711\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.9834 - value_loss: 1.6822 - policy_loss: 1.6669 - val_loss: 2.1795 - val_value_loss: 1.5922 - val_policy_loss: 2.1712\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.9635 - value_loss: 1.6822 - policy_loss: 1.6492 - val_loss: 2.1694 - val_value_loss: 1.5922 - val_policy_loss: 2.1707\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.9434 - value_loss: 1.6822 - policy_loss: 1.6288 - val_loss: 2.1599 - val_value_loss: 1.5922 - val_policy_loss: 2.1701\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 1.9360 - value_loss: 1.6822 - policy_loss: 1.6324 - val_loss: 2.1507 - val_value_loss: 1.5922 - val_policy_loss: 2.1695\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.9388 - value_loss: 1.6822 - policy_loss: 1.6558 - val_loss: 2.1424 - val_value_loss: 1.5922 - val_policy_loss: 2.1692\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 128us/step - loss: 1.9317 - value_loss: 1.6822 - policy_loss: 1.6579 - val_loss: 2.1368 - val_value_loss: 1.5922 - val_policy_loss: 2.1697\n",
      "Saved model  tictactoe_10_epochs_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.02\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.1475 - value_loss: 1.8020 - policy_loss: 1.9813 - val_loss: 2.2490 - val_value_loss: 1.7961 - val_policy_loss: 2.1841\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.1371 - value_loss: 1.8020 - policy_loss: 1.9545 - val_loss: 2.2637 - val_value_loss: 1.7961 - val_policy_loss: 2.1826\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.1346 - value_loss: 1.8020 - policy_loss: 1.9186 - val_loss: 2.2883 - val_value_loss: 1.7961 - val_policy_loss: 2.1801\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.1242 - value_loss: 1.8020 - policy_loss: 1.8459 - val_loss: 2.3178 - val_value_loss: 1.7961 - val_policy_loss: 2.1760\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.1390 - value_loss: 1.8020 - policy_loss: 1.8127 - val_loss: 2.3446 - val_value_loss: 1.7961 - val_policy_loss: 2.1722\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.1502 - value_loss: 1.8020 - policy_loss: 1.7777 - val_loss: 2.3642 - val_value_loss: 1.7961 - val_policy_loss: 2.1692\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 2.1579 - value_loss: 1.8020 - policy_loss: 1.7508 - val_loss: 2.3742 - val_value_loss: 1.7961 - val_policy_loss: 2.1667\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 2.1624 - value_loss: 1.8020 - policy_loss: 1.7372 - val_loss: 2.3743 - val_value_loss: 1.7961 - val_policy_loss: 2.1641\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 2.1530 - value_loss: 1.8020 - policy_loss: 1.7157 - val_loss: 2.3658 - val_value_loss: 1.7961 - val_policy_loss: 2.1615\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 2.1389 - value_loss: 1.8020 - policy_loss: 1.7017 - val_loss: 2.3514 - val_value_loss: 1.7961 - val_policy_loss: 2.1594\n",
      "Saved model  tictactoe_10_epochs_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.02\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.1246 - value_loss: 1.6675 - policy_loss: 1.8345 - val_loss: 2.3595 - val_value_loss: 1.8641 - val_policy_loss: 2.1425\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.0830 - value_loss: 1.6675 - policy_loss: 1.7862 - val_loss: 2.3401 - val_value_loss: 1.8641 - val_policy_loss: 2.1408\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.0592 - value_loss: 1.6675 - policy_loss: 1.7757 - val_loss: 2.3215 - val_value_loss: 1.8641 - val_policy_loss: 2.1395\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.0487 - value_loss: 1.6675 - policy_loss: 1.7905 - val_loss: 2.3045 - val_value_loss: 1.8641 - val_policy_loss: 2.1385\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.0191 - value_loss: 1.6675 - policy_loss: 1.7645 - val_loss: 2.2902 - val_value_loss: 1.8641 - val_policy_loss: 2.1394\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.9909 - value_loss: 1.6675 - policy_loss: 1.7375 - val_loss: 2.2779 - val_value_loss: 1.8641 - val_policy_loss: 2.1414\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 1.9808 - value_loss: 1.6675 - policy_loss: 1.7438 - val_loss: 2.2668 - val_value_loss: 1.8641 - val_policy_loss: 2.1434\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 1.9631 - value_loss: 1.6675 - policy_loss: 1.7328 - val_loss: 2.2565 - val_value_loss: 1.8641 - val_policy_loss: 2.1442\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.9468 - value_loss: 1.6675 - policy_loss: 1.7214 - val_loss: 2.2465 - val_value_loss: 1.8641 - val_policy_loss: 2.1443\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.9323 - value_loss: 1.6675 - policy_loss: 1.7123 - val_loss: 2.2369 - val_value_loss: 1.8641 - val_policy_loss: 2.1444\n",
      "Saved model  tictactoe_10_epochs_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.0\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.0007 - value_loss: 1.7971 - policy_loss: 1.7391 - val_loss: 2.3135 - val_value_loss: 2.0194 - val_policy_loss: 2.1589\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 1.9718 - value_loss: 1.7971 - policy_loss: 1.6980 - val_loss: 2.3074 - val_value_loss: 2.0194 - val_policy_loss: 2.1594\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.9768 - value_loss: 1.7970 - policy_loss: 1.7206 - val_loss: 2.3035 - val_value_loss: 2.0194 - val_policy_loss: 2.1595\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 1.9578 - value_loss: 1.7969 - policy_loss: 1.6908 - val_loss: 2.3017 - val_value_loss: 2.0194 - val_policy_loss: 2.1590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.9547 - value_loss: 1.7962 - policy_loss: 1.6883 - val_loss: 2.3006 - val_value_loss: 2.0194 - val_policy_loss: 2.1578\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.9425 - value_loss: 1.7883 - policy_loss: 1.6726 - val_loss: 2.3020 - val_value_loss: 2.0188 - val_policy_loss: 2.1569\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.6430 - value_loss: 1.2069 - policy_loss: 1.6506 - val_loss: 1.7692 - val_value_loss: 0.9037 - val_policy_loss: 2.1579\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.9641 - value_loss: 1.7263 - policy_loss: 1.7251 - val_loss: 2.0223 - val_value_loss: 1.2836 - val_policy_loss: 2.1596\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 1.7894 - value_loss: 1.1805 - policy_loss: 1.7969 - val_loss: 2.0007 - val_value_loss: 1.0230 - val_policy_loss: 2.1593\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.8147 - value_loss: 0.9848 - policy_loss: 1.8254 - val_loss: 2.2555 - val_value_loss: 1.2649 - val_policy_loss: 2.1559\n",
      "Saved model  tictactoe_10_epochs_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.08\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.0197 - value_loss: 1.0179 - policy_loss: 1.9312 - val_loss: 2.2010 - val_value_loss: 0.8925 - val_policy_loss: 2.1358\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.1283 - value_loss: 0.9513 - policy_loss: 1.9316 - val_loss: 2.3189 - val_value_loss: 0.8714 - val_policy_loss: 2.1269\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.2193 - value_loss: 0.8977 - policy_loss: 1.9012 - val_loss: 2.4870 - val_value_loss: 0.9914 - val_policy_loss: 2.1180\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.3811 - value_loss: 1.0476 - policy_loss: 1.8501 - val_loss: 2.8312 - val_value_loss: 1.5141 - val_policy_loss: 2.1084\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.8091 - value_loss: 1.7393 - policy_loss: 1.8390 - val_loss: 2.9039 - val_value_loss: 1.5443 - val_policy_loss: 2.0959\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 2.8660 - value_loss: 1.7364 - policy_loss: 1.8280 - val_loss: 2.9286 - val_value_loss: 1.5336 - val_policy_loss: 2.0767\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 2.8588 - value_loss: 1.6653 - policy_loss: 1.8052 - val_loss: 2.7944 - val_value_loss: 1.2561 - val_policy_loss: 2.0521\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 2.5907 - value_loss: 1.1197 - policy_loss: 1.7811 - val_loss: 2.7559 - val_value_loss: 1.1949 - val_policy_loss: 2.0358\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 2.5690 - value_loss: 1.0660 - policy_loss: 1.7909 - val_loss: 2.5571 - val_value_loss: 0.8293 - val_policy_loss: 2.0294\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 2.4369 - value_loss: 0.8192 - policy_loss: 1.7992 - val_loss: 2.6060 - val_value_loss: 0.9740 - val_policy_loss: 2.0218\n",
      "Saved model  tictactoe_10_epochs_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.02\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.6076 - value_loss: 0.8234 - policy_loss: 2.1755 - val_loss: 2.5441 - val_value_loss: 0.9191 - val_policy_loss: 2.0029\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.3830 - value_loss: 0.8022 - policy_loss: 1.7975 - val_loss: 2.5204 - val_value_loss: 0.9326 - val_policy_loss: 1.9973\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.3255 - value_loss: 0.7754 - policy_loss: 1.7649 - val_loss: 2.4336 - val_value_loss: 0.8133 - val_policy_loss: 1.9886\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.2909 - value_loss: 0.7630 - policy_loss: 1.7535 - val_loss: 2.4709 - val_value_loss: 0.9289 - val_policy_loss: 1.9747\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.2701 - value_loss: 0.7596 - policy_loss: 1.7423 - val_loss: 2.3965 - val_value_loss: 0.8239 - val_policy_loss: 1.9530\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.2217 - value_loss: 0.6956 - policy_loss: 1.7318 - val_loss: 2.3957 - val_value_loss: 0.8600 - val_policy_loss: 1.9436\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 2.1773 - value_loss: 0.6428 - policy_loss: 1.7241 - val_loss: 2.3782 - val_value_loss: 0.8754 - val_policy_loss: 1.9351\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 2.1349 - value_loss: 0.6165 - policy_loss: 1.7073 - val_loss: 2.3009 - val_value_loss: 0.7851 - val_policy_loss: 1.9143\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 2.1793 - value_loss: 0.7106 - policy_loss: 1.7456 - val_loss: 2.3141 - val_value_loss: 0.8396 - val_policy_loss: 1.9133\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 2.1213 - value_loss: 0.6581 - policy_loss: 1.7091 - val_loss: 2.3011 - val_value_loss: 0.8442 - val_policy_loss: 1.9022\n",
      "Saved model  tictactoe_10_epochs_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.06\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 152us/step - loss: 2.4006 - value_loss: 0.9177 - policy_loss: 2.0277 - val_loss: 2.2890 - val_value_loss: 0.8045 - val_policy_loss: 1.9256\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 146us/step - loss: 2.2860 - value_loss: 0.7792 - policy_loss: 1.9448 - val_loss: 2.3256 - val_value_loss: 0.8569 - val_policy_loss: 1.9342\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 2.5202 - value_loss: 1.0669 - policy_loss: 2.1133 - val_loss: 2.3212 - val_value_loss: 0.8262 - val_policy_loss: 1.9240\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 2.2286 - value_loss: 0.7382 - policy_loss: 1.8267 - val_loss: 2.3580 - val_value_loss: 0.8495 - val_policy_loss: 1.9305\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 2.2275 - value_loss: 0.7419 - policy_loss: 1.7772 - val_loss: 2.3905 - val_value_loss: 0.8942 - val_policy_loss: 1.9129\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 2.2325 - value_loss: 0.7336 - policy_loss: 1.7574 - val_loss: 2.3753 - val_value_loss: 0.8614 - val_policy_loss: 1.8856\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.2366 - value_loss: 0.6827 - policy_loss: 1.7869 - val_loss: 2.3873 - val_value_loss: 0.8714 - val_policy_loss: 1.8813\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.2126 - value_loss: 0.6397 - policy_loss: 1.7635 - val_loss: 2.3998 - val_value_loss: 0.8895 - val_policy_loss: 1.8899\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 2.2230 - value_loss: 0.6726 - policy_loss: 1.7532 - val_loss: 2.3813 - val_value_loss: 0.8735 - val_policy_loss: 1.8867\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 2.2907 - value_loss: 0.7687 - policy_loss: 1.8102 - val_loss: 2.4310 - val_value_loss: 1.0166 - val_policy_loss: 1.8627\n",
      "Saved model  tictactoe_10_epochs_24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.06\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 2.6967 - value_loss: 1.5248 - policy_loss: 1.8859 - val_loss: 2.4247 - val_value_loss: 1.0606 - val_policy_loss: 1.8114\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.6019 - value_loss: 1.4142 - policy_loss: 1.8122 - val_loss: 2.4000 - val_value_loss: 1.0234 - val_policy_loss: 1.8106\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 2.4952 - value_loss: 1.2480 - policy_loss: 1.7765 - val_loss: 2.3662 - val_value_loss: 0.9736 - val_policy_loss: 1.8094\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 2.3892 - value_loss: 1.0652 - policy_loss: 1.7638 - val_loss: 2.3271 - val_value_loss: 0.9179 - val_policy_loss: 1.8074\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 2.3112 - value_loss: 0.9373 - policy_loss: 1.7562 - val_loss: 2.2848 - val_value_loss: 0.8591 - val_policy_loss: 1.8053\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 125us/step - loss: 2.2685 - value_loss: 0.8815 - policy_loss: 1.7503 - val_loss: 2.2472 - val_value_loss: 0.8120 - val_policy_loss: 1.8038\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 125us/step - loss: 2.2507 - value_loss: 0.8773 - policy_loss: 1.7454 - val_loss: 2.2152 - val_value_loss: 0.7792 - val_policy_loss: 1.8018\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 2.2315 - value_loss: 0.8731 - policy_loss: 1.7405 - val_loss: 2.1876 - val_value_loss: 0.7580 - val_policy_loss: 1.7993\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 2.2050 - value_loss: 0.8568 - policy_loss: 1.7352 - val_loss: 2.1635 - val_value_loss: 0.7464 - val_policy_loss: 1.7960\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 2.1743 - value_loss: 0.8339 - policy_loss: 1.7301 - val_loss: 2.1419 - val_value_loss: 0.7414 - val_policy_loss: 1.7923\n",
      "Saved model  tictactoe_10_epochs_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.02\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.2692 - value_loss: 0.9611 - policy_loss: 1.8271 - val_loss: 2.2142 - val_value_loss: 0.8821 - val_policy_loss: 1.8319\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 2.1600 - value_loss: 0.8451 - policy_loss: 1.7605 - val_loss: 2.1925 - val_value_loss: 0.8796 - val_policy_loss: 1.8264\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.1234 - value_loss: 0.8178 - policy_loss: 1.7499 - val_loss: 2.1717 - val_value_loss: 0.8766 - val_policy_loss: 1.8228\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 147us/step - loss: 2.0890 - value_loss: 0.7981 - policy_loss: 1.7358 - val_loss: 2.1537 - val_value_loss: 0.8765 - val_policy_loss: 1.8215\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 149us/step - loss: 2.0606 - value_loss: 0.7833 - policy_loss: 1.7285 - val_loss: 2.1374 - val_value_loss: 0.8768 - val_policy_loss: 1.8229\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 2.0341 - value_loss: 0.7697 - policy_loss: 1.7234 - val_loss: 2.1226 - val_value_loss: 0.8777 - val_policy_loss: 1.8261\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 2.0083 - value_loss: 0.7567 - policy_loss: 1.7184 - val_loss: 2.1092 - val_value_loss: 0.8795 - val_policy_loss: 1.8308\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 1.9817 - value_loss: 0.7425 - policy_loss: 1.7128 - val_loss: 2.0968 - val_value_loss: 0.8818 - val_policy_loss: 1.8362\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.9547 - value_loss: 0.7260 - policy_loss: 1.7079 - val_loss: 2.0846 - val_value_loss: 0.8842 - val_policy_loss: 1.8414\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.9296 - value_loss: 0.7117 - policy_loss: 1.7039 - val_loss: 2.0720 - val_value_loss: 0.8859 - val_policy_loss: 1.8459\n",
      "Saved model  tictactoe_10_epochs_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.08\n",
      "iteration 27 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 1.9918 - value_loss: 0.8328 - policy_loss: 1.7386 - val_loss: 1.9765 - val_value_loss: 0.8017 - val_policy_loss: 1.7697\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 143us/step - loss: 1.9703 - value_loss: 0.8270 - policy_loss: 1.7321 - val_loss: 1.9610 - val_value_loss: 0.7993 - val_policy_loss: 1.7713\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 1.9447 - value_loss: 0.8164 - policy_loss: 1.7214 - val_loss: 1.9453 - val_value_loss: 0.7966 - val_policy_loss: 1.7719\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 1.9166 - value_loss: 0.8019 - policy_loss: 1.7091 - val_loss: 1.9297 - val_value_loss: 0.7938 - val_policy_loss: 1.7718\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.8884 - value_loss: 0.7855 - policy_loss: 1.6974 - val_loss: 1.9144 - val_value_loss: 0.7912 - val_policy_loss: 1.7714\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.8622 - value_loss: 0.7698 - policy_loss: 1.6885 - val_loss: 1.8999 - val_value_loss: 0.7891 - val_policy_loss: 1.7711\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.8375 - value_loss: 0.7547 - policy_loss: 1.6808 - val_loss: 1.8861 - val_value_loss: 0.7874 - val_policy_loss: 1.7711\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.8170 - value_loss: 0.7457 - policy_loss: 1.6747 - val_loss: 1.8735 - val_value_loss: 0.7863 - val_policy_loss: 1.7720\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.7939 - value_loss: 0.7310 - policy_loss: 1.6680 - val_loss: 1.8625 - val_value_loss: 0.7860 - val_policy_loss: 1.7734\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 1.7756 - value_loss: 0.7206 - policy_loss: 1.6649 - val_loss: 1.8525 - val_value_loss: 0.7858 - val_policy_loss: 1.7750\n",
      "Saved model  tictactoe_10_epochs_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.0\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.9127 - value_loss: 0.8770 - policy_loss: 1.8043 - val_loss: 1.9518 - val_value_loss: 0.9390 - val_policy_loss: 1.8408\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 1.8735 - value_loss: 0.8593 - policy_loss: 1.7640 - val_loss: 1.9409 - val_value_loss: 0.9345 - val_policy_loss: 1.8427\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 140us/step - loss: 1.8414 - value_loss: 0.8413 - policy_loss: 1.7369 - val_loss: 1.9305 - val_value_loss: 0.9299 - val_policy_loss: 1.8448\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 1.8148 - value_loss: 0.8262 - policy_loss: 1.7171 - val_loss: 1.9205 - val_value_loss: 0.9255 - val_policy_loss: 1.8467\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.7920 - value_loss: 0.8135 - policy_loss: 1.7017 - val_loss: 1.9109 - val_value_loss: 0.9213 - val_policy_loss: 1.8484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.7766 - value_loss: 0.8007 - policy_loss: 1.7006 - val_loss: 1.9010 - val_value_loss: 0.9165 - val_policy_loss: 1.8498\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.7631 - value_loss: 0.7903 - policy_loss: 1.7003 - val_loss: 1.8908 - val_value_loss: 0.9108 - val_policy_loss: 1.8512\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.7423 - value_loss: 0.7729 - policy_loss: 1.6920 - val_loss: 1.8803 - val_value_loss: 0.9044 - val_policy_loss: 1.8519\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 1.7210 - value_loss: 0.7572 - policy_loss: 1.6805 - val_loss: 1.8694 - val_value_loss: 0.8975 - val_policy_loss: 1.8523\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 1.7058 - value_loss: 0.7413 - policy_loss: 1.6812 - val_loss: 1.8589 - val_value_loss: 0.8908 - val_policy_loss: 1.8526\n",
      "Saved model  tictactoe_10_epochs_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.0\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 149us/step - loss: 1.7410 - value_loss: 0.7376 - policy_loss: 1.7700 - val_loss: 1.8227 - val_value_loss: 0.8801 - val_policy_loss: 1.8055\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 152us/step - loss: 1.6963 - value_loss: 0.7125 - policy_loss: 1.7203 - val_loss: 1.8147 - val_value_loss: 0.8776 - val_policy_loss: 1.8062\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 1.6651 - value_loss: 0.6864 - policy_loss: 1.6981 - val_loss: 1.8079 - val_value_loss: 0.8760 - val_policy_loss: 1.8077\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.6449 - value_loss: 0.6620 - policy_loss: 1.6958 - val_loss: 1.8017 - val_value_loss: 0.8751 - val_policy_loss: 1.8095\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 1.6260 - value_loss: 0.6405 - policy_loss: 1.6925 - val_loss: 1.7959 - val_value_loss: 0.8745 - val_policy_loss: 1.8113\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.6053 - value_loss: 0.6200 - policy_loss: 1.6847 - val_loss: 1.7903 - val_value_loss: 0.8739 - val_policy_loss: 1.8133\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.5868 - value_loss: 0.5989 - policy_loss: 1.6812 - val_loss: 1.7849 - val_value_loss: 0.8735 - val_policy_loss: 1.8151\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.5688 - value_loss: 0.5798 - policy_loss: 1.6765 - val_loss: 1.7797 - val_value_loss: 0.8734 - val_policy_loss: 1.8167\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 138us/step - loss: 1.5523 - value_loss: 0.5652 - policy_loss: 1.6699 - val_loss: 1.7744 - val_value_loss: 0.8728 - val_policy_loss: 1.8182\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 1.5401 - value_loss: 0.5537 - policy_loss: 1.6688 - val_loss: 1.7689 - val_value_loss: 0.8717 - val_policy_loss: 1.8197\n",
      "Saved model  tictactoe_10_epochs_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.0\n",
      "iteration 30 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_30\n",
      "iteration 30 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.6998 - value_loss: 0.8147 - policy_loss: 1.7387 - val_loss: 1.7522 - val_value_loss: 0.8270 - val_policy_loss: 1.8425\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 1.6785 - value_loss: 0.7919 - policy_loss: 1.7302 - val_loss: 1.7467 - val_value_loss: 0.8281 - val_policy_loss: 1.8415\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 1.6416 - value_loss: 0.7363 - policy_loss: 1.7232 - val_loss: 1.7413 - val_value_loss: 0.8294 - val_policy_loss: 1.8403\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 1.6147 - value_loss: 0.6974 - policy_loss: 1.7190 - val_loss: 1.7368 - val_value_loss: 0.8315 - val_policy_loss: 1.8394\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.5981 - value_loss: 0.6776 - policy_loss: 1.7160 - val_loss: 1.7327 - val_value_loss: 0.8339 - val_policy_loss: 1.8388\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.5807 - value_loss: 0.6541 - policy_loss: 1.7144 - val_loss: 1.7291 - val_value_loss: 0.8364 - val_policy_loss: 1.8387\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 1.5619 - value_loss: 0.6273 - policy_loss: 1.7132 - val_loss: 1.7256 - val_value_loss: 0.8385 - val_policy_loss: 1.8388\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.5402 - value_loss: 0.5962 - policy_loss: 1.7102 - val_loss: 1.7221 - val_value_loss: 0.8398 - val_policy_loss: 1.8393\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.5247 - value_loss: 0.5759 - policy_loss: 1.7085 - val_loss: 1.7184 - val_value_loss: 0.8402 - val_policy_loss: 1.8402\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.5092 - value_loss: 0.5561 - policy_loss: 1.7057 - val_loss: 1.7146 - val_value_loss: 0.8399 - val_policy_loss: 1.8411\n",
      "Saved model  tictactoe_10_epochs_30\n",
      "iteration 30 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.08\n",
      "iteration 31 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_31\n",
      "iteration 31 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 154us/step - loss: 1.6069 - value_loss: 0.7662 - policy_loss: 1.6993 - val_loss: 1.7360 - val_value_loss: 0.8373 - val_policy_loss: 1.8945\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 147us/step - loss: 1.5598 - value_loss: 0.6877 - policy_loss: 1.6918 - val_loss: 1.7308 - val_value_loss: 0.8341 - val_policy_loss: 1.8951\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 149us/step - loss: 1.5381 - value_loss: 0.6557 - policy_loss: 1.6882 - val_loss: 1.7257 - val_value_loss: 0.8309 - val_policy_loss: 1.8957\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 149us/step - loss: 1.5212 - value_loss: 0.6335 - policy_loss: 1.6840 - val_loss: 1.7211 - val_value_loss: 0.8282 - val_policy_loss: 1.8962\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.5028 - value_loss: 0.6097 - policy_loss: 1.6780 - val_loss: 1.7171 - val_value_loss: 0.8265 - val_policy_loss: 1.8967\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.4856 - value_loss: 0.5892 - policy_loss: 1.6710 - val_loss: 1.7138 - val_value_loss: 0.8257 - val_policy_loss: 1.8973\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 133us/step - loss: 1.4667 - value_loss: 0.5646 - policy_loss: 1.6644 - val_loss: 1.7113 - val_value_loss: 0.8261 - val_policy_loss: 1.8981\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 129us/step - loss: 1.4472 - value_loss: 0.5365 - policy_loss: 1.6596 - val_loss: 1.7095 - val_value_loss: 0.8275 - val_policy_loss: 1.8992\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.4318 - value_loss: 0.5152 - policy_loss: 1.6561 - val_loss: 1.7081 - val_value_loss: 0.8294 - val_policy_loss: 1.9002\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 1.4149 - value_loss: 0.4908 - policy_loss: 1.6524 - val_loss: 1.7069 - val_value_loss: 0.8315 - val_policy_loss: 1.9013\n",
      "Saved model  tictactoe_10_epochs_31\n",
      "iteration 31 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.06\n",
      "iteration 32 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_32\n",
      "iteration 32 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 1.5939 - value_loss: 0.8204 - policy_loss: 1.6863 - val_loss: 1.6630 - val_value_loss: 0.7825 - val_policy_loss: 1.8682\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.5602 - value_loss: 0.7653 - policy_loss: 1.6799 - val_loss: 1.6630 - val_value_loss: 0.7866 - val_policy_loss: 1.8695\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.5238 - value_loss: 0.7060 - policy_loss: 1.6718 - val_loss: 1.6626 - val_value_loss: 0.7894 - val_policy_loss: 1.8711\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.5035 - value_loss: 0.6742 - policy_loss: 1.6682 - val_loss: 1.6612 - val_value_loss: 0.7902 - val_policy_loss: 1.8727\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.4856 - value_loss: 0.6462 - policy_loss: 1.6655 - val_loss: 1.6595 - val_value_loss: 0.7903 - val_policy_loss: 1.8741\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 1.4706 - value_loss: 0.6242 - policy_loss: 1.6623 - val_loss: 1.6584 - val_value_loss: 0.7915 - val_policy_loss: 1.8754\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.4568 - value_loss: 0.6040 - policy_loss: 1.6597 - val_loss: 1.6581 - val_value_loss: 0.7943 - val_policy_loss: 1.8766\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 1.4421 - value_loss: 0.5822 - policy_loss: 1.6567 - val_loss: 1.6581 - val_value_loss: 0.7980 - val_policy_loss: 1.8775\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 1.4257 - value_loss: 0.5562 - policy_loss: 1.6545 - val_loss: 1.6577 - val_value_loss: 0.8012 - val_policy_loss: 1.8780\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 125us/step - loss: 1.4133 - value_loss: 0.5388 - policy_loss: 1.6517 - val_loss: 1.6569 - val_value_loss: 0.8040 - val_policy_loss: 1.8782\n",
      "Saved model  tictactoe_10_epochs_32\n",
      "iteration 32 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.04\n",
      "iteration 33 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_33\n",
      "iteration 33 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.5985 - value_loss: 0.9005 - policy_loss: 1.6650 - val_loss: 1.6673 - val_value_loss: 0.8231 - val_policy_loss: 1.8846\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 1.5538 - value_loss: 0.8228 - policy_loss: 1.6578 - val_loss: 1.6663 - val_value_loss: 0.8258 - val_policy_loss: 1.8847\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 1.5137 - value_loss: 0.7511 - policy_loss: 1.6541 - val_loss: 1.6660 - val_value_loss: 0.8294 - val_policy_loss: 1.8847\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.4838 - value_loss: 0.6965 - policy_loss: 1.6532 - val_loss: 1.6659 - val_value_loss: 0.8329 - val_policy_loss: 1.8848\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.4608 - value_loss: 0.6546 - policy_loss: 1.6530 - val_loss: 1.6658 - val_value_loss: 0.8359 - val_policy_loss: 1.8850\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 1.4444 - value_loss: 0.6273 - policy_loss: 1.6509 - val_loss: 1.6658 - val_value_loss: 0.8386 - val_policy_loss: 1.8855\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.4256 - value_loss: 0.5961 - policy_loss: 1.6477 - val_loss: 1.6660 - val_value_loss: 0.8412 - val_policy_loss: 1.8863\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.4030 - value_loss: 0.5561 - policy_loss: 1.6455 - val_loss: 1.6662 - val_value_loss: 0.8436 - val_policy_loss: 1.8871\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 1.3861 - value_loss: 0.5263 - policy_loss: 1.6441 - val_loss: 1.6666 - val_value_loss: 0.8464 - val_policy_loss: 1.8875\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.3723 - value_loss: 0.5018 - policy_loss: 1.6435 - val_loss: 1.6674 - val_value_loss: 0.8501 - val_policy_loss: 1.8876\n",
      "Saved model  tictactoe_10_epochs_33\n",
      "iteration 33 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.02\n",
      "iteration 34 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_34\n",
      "iteration 34 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.6306 - value_loss: 0.9528 - policy_loss: 1.7113 - val_loss: 1.6906 - val_value_loss: 0.9609 - val_policy_loss: 1.8260\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 1.5339 - value_loss: 0.8175 - policy_loss: 1.6559 - val_loss: 1.6852 - val_value_loss: 0.9520 - val_policy_loss: 1.8256\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 1.4913 - value_loss: 0.7379 - policy_loss: 1.6519 - val_loss: 1.6775 - val_value_loss: 0.9381 - val_policy_loss: 1.8248\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 1.4663 - value_loss: 0.6865 - policy_loss: 1.6541 - val_loss: 1.6737 - val_value_loss: 0.9312 - val_policy_loss: 1.8240\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 1.4456 - value_loss: 0.6471 - policy_loss: 1.6518 - val_loss: 1.6743 - val_value_loss: 0.9324 - val_policy_loss: 1.8235\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 1.4263 - value_loss: 0.6115 - policy_loss: 1.6483 - val_loss: 1.6763 - val_value_loss: 0.9357 - val_policy_loss: 1.8232\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 1.4127 - value_loss: 0.5859 - policy_loss: 1.6459 - val_loss: 1.6779 - val_value_loss: 0.9382 - val_policy_loss: 1.8232\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.3975 - value_loss: 0.5581 - policy_loss: 1.6425 - val_loss: 1.6791 - val_value_loss: 0.9393 - val_policy_loss: 1.8238\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 1.3876 - value_loss: 0.5388 - policy_loss: 1.6413 - val_loss: 1.6814 - val_value_loss: 0.9421 - val_policy_loss: 1.8251\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 1.3687 - value_loss: 0.5045 - policy_loss: 1.6373 - val_loss: 1.6839 - val_value_loss: 0.9452 - val_policy_loss: 1.8268\n",
      "Saved model  tictactoe_10_epochs_34\n",
      "iteration 34 | evaluation\n",
      "agent vs random - win ratio 0.94 - draw ratio 0.0\n",
      "iteration 35 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_35\n",
      "iteration 35 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 154us/step - loss: 1.5510 - value_loss: 0.8042 - policy_loss: 1.7021 - val_loss: 1.7035 - val_value_loss: 0.9158 - val_policy_loss: 1.8961\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 150us/step - loss: 1.5045 - value_loss: 0.7210 - policy_loss: 1.6928 - val_loss: 1.7009 - val_value_loss: 0.9110 - val_policy_loss: 1.8966\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 147us/step - loss: 1.4580 - value_loss: 0.6353 - policy_loss: 1.6864 - val_loss: 1.6989 - val_value_loss: 0.9074 - val_policy_loss: 1.8968\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 1.4254 - value_loss: 0.5780 - policy_loss: 1.6792 - val_loss: 1.6987 - val_value_loss: 0.9077 - val_policy_loss: 1.8969\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 1.4033 - value_loss: 0.5364 - policy_loss: 1.6774 - val_loss: 1.7005 - val_value_loss: 0.9119 - val_policy_loss: 1.8969\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 1.3890 - value_loss: 0.5085 - policy_loss: 1.6773 - val_loss: 1.7040 - val_value_loss: 0.9200 - val_policy_loss: 1.8970\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 1.3749 - value_loss: 0.4818 - policy_loss: 1.6767 - val_loss: 1.7076 - val_value_loss: 0.9282 - val_policy_loss: 1.8970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 1.3640 - value_loss: 0.4632 - policy_loss: 1.6748 - val_loss: 1.7095 - val_value_loss: 0.9337 - val_policy_loss: 1.8969\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.3533 - value_loss: 0.4463 - policy_loss: 1.6719 - val_loss: 1.7104 - val_value_loss: 0.9375 - val_policy_loss: 1.8968\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 1.3423 - value_loss: 0.4291 - policy_loss: 1.6690 - val_loss: 1.7108 - val_value_loss: 0.9407 - val_policy_loss: 1.8967\n",
      "Saved model  tictactoe_10_epochs_35\n",
      "iteration 35 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.0\n",
      "iteration 36 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_36\n",
      "iteration 36 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.5861 - value_loss: 0.8745 - policy_loss: 1.7135 - val_loss: 1.7073 - val_value_loss: 0.9569 - val_policy_loss: 1.8765\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 149us/step - loss: 1.5414 - value_loss: 0.7931 - policy_loss: 1.7084 - val_loss: 1.7066 - val_value_loss: 0.9597 - val_policy_loss: 1.8754\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 149us/step - loss: 1.4969 - value_loss: 0.7113 - policy_loss: 1.7044 - val_loss: 1.7050 - val_value_loss: 0.9605 - val_policy_loss: 1.8744\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 147us/step - loss: 1.4776 - value_loss: 0.6801 - policy_loss: 1.7000 - val_loss: 1.7026 - val_value_loss: 0.9597 - val_policy_loss: 1.8737\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 1.4538 - value_loss: 0.6405 - policy_loss: 1.6952 - val_loss: 1.6994 - val_value_loss: 0.9565 - val_policy_loss: 1.8736\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 1.4250 - value_loss: 0.5902 - policy_loss: 1.6911 - val_loss: 1.6957 - val_value_loss: 0.9520 - val_policy_loss: 1.8739\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.4045 - value_loss: 0.5557 - policy_loss: 1.6878 - val_loss: 1.6927 - val_value_loss: 0.9483 - val_policy_loss: 1.8745\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.3876 - value_loss: 0.5272 - policy_loss: 1.6855 - val_loss: 1.6902 - val_value_loss: 0.9457 - val_policy_loss: 1.8752\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.3806 - value_loss: 0.5169 - policy_loss: 1.6847 - val_loss: 1.6877 - val_value_loss: 0.9434 - val_policy_loss: 1.8757\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.3732 - value_loss: 0.5065 - policy_loss: 1.6836 - val_loss: 1.6855 - val_value_loss: 0.9421 - val_policy_loss: 1.8760\n",
      "Saved model  tictactoe_10_epochs_36\n",
      "iteration 36 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.04\n",
      "iteration 37 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_37\n",
      "iteration 37 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 145us/step - loss: 1.5070 - value_loss: 0.7810 - policy_loss: 1.6801 - val_loss: 1.7027 - val_value_loss: 0.9643 - val_policy_loss: 1.8919\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 148us/step - loss: 1.4641 - value_loss: 0.7082 - policy_loss: 1.6708 - val_loss: 1.6984 - val_value_loss: 0.9595 - val_policy_loss: 1.8918\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 149us/step - loss: 1.4252 - value_loss: 0.6385 - policy_loss: 1.6665 - val_loss: 1.6940 - val_value_loss: 0.9537 - val_policy_loss: 1.8922\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 1.3977 - value_loss: 0.5902 - policy_loss: 1.6633 - val_loss: 1.6895 - val_value_loss: 0.9471 - val_policy_loss: 1.8932\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 1.3785 - value_loss: 0.5577 - policy_loss: 1.6607 - val_loss: 1.6859 - val_value_loss: 0.9420 - val_policy_loss: 1.8943\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.3679 - value_loss: 0.5387 - policy_loss: 1.6616 - val_loss: 1.6840 - val_value_loss: 0.9405 - val_policy_loss: 1.8950\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 1.3537 - value_loss: 0.5169 - policy_loss: 1.6580 - val_loss: 1.6831 - val_value_loss: 0.9415 - val_policy_loss: 1.8953\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 1.3426 - value_loss: 0.4976 - policy_loss: 1.6581 - val_loss: 1.6825 - val_value_loss: 0.9434 - val_policy_loss: 1.8952\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.3311 - value_loss: 0.4793 - policy_loss: 1.6566 - val_loss: 1.6818 - val_value_loss: 0.9456 - val_policy_loss: 1.8948\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 1.3167 - value_loss: 0.4562 - policy_loss: 1.6539 - val_loss: 1.6816 - val_value_loss: 0.9486 - val_policy_loss: 1.8944\n",
      "Saved model  tictactoe_10_epochs_37\n",
      "iteration 37 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.02\n",
      "iteration 38 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_38\n",
      "iteration 38 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.5843 - value_loss: 0.9302 - policy_loss: 1.7182 - val_loss: 1.6305 - val_value_loss: 0.8713 - val_policy_loss: 1.8730\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 147us/step - loss: 1.5390 - value_loss: 0.8508 - policy_loss: 1.7105 - val_loss: 1.6276 - val_value_loss: 0.8692 - val_policy_loss: 1.8727\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 1.4872 - value_loss: 0.7578 - policy_loss: 1.7034 - val_loss: 1.6248 - val_value_loss: 0.8671 - val_policy_loss: 1.8722\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.4555 - value_loss: 0.7001 - policy_loss: 1.7005 - val_loss: 1.6229 - val_value_loss: 0.8664 - val_policy_loss: 1.8715\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 1.4333 - value_loss: 0.6604 - policy_loss: 1.6982 - val_loss: 1.6218 - val_value_loss: 0.8670 - val_policy_loss: 1.8708\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.4105 - value_loss: 0.6213 - policy_loss: 1.6940 - val_loss: 1.6219 - val_value_loss: 0.8696 - val_policy_loss: 1.8701\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.3907 - value_loss: 0.5860 - policy_loss: 1.6913 - val_loss: 1.6236 - val_value_loss: 0.8749 - val_policy_loss: 1.8699\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.3725 - value_loss: 0.5537 - policy_loss: 1.6887 - val_loss: 1.6262 - val_value_loss: 0.8813 - val_policy_loss: 1.8699\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.3568 - value_loss: 0.5271 - policy_loss: 1.6854 - val_loss: 1.6284 - val_value_loss: 0.8867 - val_policy_loss: 1.8704\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.3434 - value_loss: 0.5014 - policy_loss: 1.6856 - val_loss: 1.6305 - val_value_loss: 0.8914 - val_policy_loss: 1.8711\n",
      "Saved model  tictactoe_10_epochs_38\n",
      "iteration 38 | evaluation\n",
      "agent vs random - win ratio 0.9 - draw ratio 0.02\n",
      "iteration 39 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_39\n",
      "iteration 39 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 1.4564 - value_loss: 0.7313 - policy_loss: 1.6832 - val_loss: 1.6253 - val_value_loss: 0.9067 - val_policy_loss: 1.8472\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 1.3886 - value_loss: 0.6060 - policy_loss: 1.6744 - val_loss: 1.6233 - val_value_loss: 0.9046 - val_policy_loss: 1.8467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 1.3657 - value_loss: 0.5666 - policy_loss: 1.6695 - val_loss: 1.6201 - val_value_loss: 0.8997 - val_policy_loss: 1.8465\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 147us/step - loss: 1.3385 - value_loss: 0.5184 - policy_loss: 1.6645 - val_loss: 1.6178 - val_value_loss: 0.8961 - val_policy_loss: 1.8466\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 1.3195 - value_loss: 0.4839 - policy_loss: 1.6621 - val_loss: 1.6168 - val_value_loss: 0.8951 - val_policy_loss: 1.8466\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.3062 - value_loss: 0.4602 - policy_loss: 1.6604 - val_loss: 1.6173 - val_value_loss: 0.8968 - val_policy_loss: 1.8468\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 1.2968 - value_loss: 0.4448 - policy_loss: 1.6578 - val_loss: 1.6187 - val_value_loss: 0.9003 - val_policy_loss: 1.8471\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.2881 - value_loss: 0.4317 - policy_loss: 1.6545 - val_loss: 1.6204 - val_value_loss: 0.9045 - val_policy_loss: 1.8475\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.2779 - value_loss: 0.4154 - policy_loss: 1.6516 - val_loss: 1.6225 - val_value_loss: 0.9095 - val_policy_loss: 1.8482\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.2694 - value_loss: 0.4011 - policy_loss: 1.6504 - val_loss: 1.6253 - val_value_loss: 0.9158 - val_policy_loss: 1.8492\n",
      "Saved model  tictactoe_10_epochs_39\n",
      "iteration 39 | evaluation\n",
      "agent vs random - win ratio 0.92 - draw ratio 0.0\n",
      "iteration 40 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_40\n",
      "iteration 40 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 1.4321 - value_loss: 0.7036 - policy_loss: 1.6750 - val_loss: 1.6071 - val_value_loss: 0.9271 - val_policy_loss: 1.8040\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 1.3911 - value_loss: 0.6314 - policy_loss: 1.6678 - val_loss: 1.6075 - val_value_loss: 0.9302 - val_policy_loss: 1.8042\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 1.3491 - value_loss: 0.5617 - policy_loss: 1.6559 - val_loss: 1.6080 - val_value_loss: 0.9331 - val_policy_loss: 1.8047\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.3279 - value_loss: 0.5263 - policy_loss: 1.6513 - val_loss: 1.6073 - val_value_loss: 0.9330 - val_policy_loss: 1.8057\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 1.3168 - value_loss: 0.5050 - policy_loss: 1.6526 - val_loss: 1.6059 - val_value_loss: 0.9311 - val_policy_loss: 1.8071\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 1.3049 - value_loss: 0.4844 - policy_loss: 1.6519 - val_loss: 1.6053 - val_value_loss: 0.9310 - val_policy_loss: 1.8083\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.2905 - value_loss: 0.4655 - policy_loss: 1.6442 - val_loss: 1.6064 - val_value_loss: 0.9354 - val_policy_loss: 1.8085\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.2812 - value_loss: 0.4440 - policy_loss: 1.6495 - val_loss: 1.6073 - val_value_loss: 0.9403 - val_policy_loss: 1.8079\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 1.2658 - value_loss: 0.4254 - policy_loss: 1.6397 - val_loss: 1.6066 - val_value_loss: 0.9427 - val_policy_loss: 1.8067\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 1.2569 - value_loss: 0.4079 - policy_loss: 1.6421 - val_loss: 1.6051 - val_value_loss: 0.9435 - val_policy_loss: 1.8056\n",
      "Saved model  tictactoe_10_epochs_40\n",
      "iteration 40 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.02\n",
      "iteration 41 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_41\n",
      "iteration 41 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.4277 - value_loss: 0.7428 - policy_loss: 1.6514 - val_loss: 1.6224 - val_value_loss: 0.9526 - val_policy_loss: 1.8341\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 1.3933 - value_loss: 0.6819 - policy_loss: 1.6465 - val_loss: 1.6136 - val_value_loss: 0.9391 - val_policy_loss: 1.8329\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 147us/step - loss: 1.3577 - value_loss: 0.6181 - policy_loss: 1.6422 - val_loss: 1.6084 - val_value_loss: 0.9325 - val_policy_loss: 1.8319\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 147us/step - loss: 1.3274 - value_loss: 0.5624 - policy_loss: 1.6400 - val_loss: 1.6064 - val_value_loss: 0.9317 - val_policy_loss: 1.8313\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 147us/step - loss: 1.3044 - value_loss: 0.5206 - policy_loss: 1.6384 - val_loss: 1.6053 - val_value_loss: 0.9317 - val_policy_loss: 1.8313\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 138us/step - loss: 1.2882 - value_loss: 0.4925 - policy_loss: 1.6362 - val_loss: 1.6039 - val_value_loss: 0.9301 - val_policy_loss: 1.8321\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 1.2767 - value_loss: 0.4732 - policy_loss: 1.6346 - val_loss: 1.6023 - val_value_loss: 0.9274 - val_policy_loss: 1.8336\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 1.2656 - value_loss: 0.4530 - policy_loss: 1.6346 - val_loss: 1.6018 - val_value_loss: 0.9267 - val_policy_loss: 1.8352\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 133us/step - loss: 1.2555 - value_loss: 0.4351 - policy_loss: 1.6342 - val_loss: 1.6035 - val_value_loss: 0.9309 - val_policy_loss: 1.8366\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 133us/step - loss: 1.2452 - value_loss: 0.4184 - policy_loss: 1.6323 - val_loss: 1.6070 - val_value_loss: 0.9391 - val_policy_loss: 1.8375\n",
      "Saved model  tictactoe_10_epochs_41\n",
      "iteration 41 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.04\n",
      "iteration 42 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_42\n",
      "iteration 42 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.4215 - value_loss: 0.6955 - policy_loss: 1.7102 - val_loss: 1.5754 - val_value_loss: 0.8477 - val_policy_loss: 1.8679\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 148us/step - loss: 1.3820 - value_loss: 0.6310 - policy_loss: 1.6980 - val_loss: 1.5744 - val_value_loss: 0.8479 - val_policy_loss: 1.8679\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 147us/step - loss: 1.3514 - value_loss: 0.5788 - policy_loss: 1.6912 - val_loss: 1.5725 - val_value_loss: 0.8460 - val_policy_loss: 1.8680\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 153us/step - loss: 1.3210 - value_loss: 0.5241 - policy_loss: 1.6868 - val_loss: 1.5707 - val_value_loss: 0.8435 - val_policy_loss: 1.8683\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 143us/step - loss: 1.3006 - value_loss: 0.4888 - policy_loss: 1.6828 - val_loss: 1.5691 - val_value_loss: 0.8409 - val_policy_loss: 1.8688\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.2845 - value_loss: 0.4592 - policy_loss: 1.6814 - val_loss: 1.5679 - val_value_loss: 0.8395 - val_policy_loss: 1.8689\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.2748 - value_loss: 0.4415 - policy_loss: 1.6806 - val_loss: 1.5673 - val_value_loss: 0.8393 - val_policy_loss: 1.8686\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 131us/step - loss: 1.2622 - value_loss: 0.4187 - policy_loss: 1.6790 - val_loss: 1.5669 - val_value_loss: 0.8398 - val_policy_loss: 1.8684\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 128us/step - loss: 1.2494 - value_loss: 0.3950 - policy_loss: 1.6780 - val_loss: 1.5669 - val_value_loss: 0.8408 - val_policy_loss: 1.8681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 1.2437 - value_loss: 0.3849 - policy_loss: 1.6776 - val_loss: 1.5674 - val_value_loss: 0.8430 - val_policy_loss: 1.8679\n",
      "Saved model  tictactoe_10_epochs_42\n",
      "iteration 42 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.02\n",
      "iteration 43 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_43\n",
      "iteration 43 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 1.3968 - value_loss: 0.6787 - policy_loss: 1.6909 - val_loss: 1.5690 - val_value_loss: 0.7987 - val_policy_loss: 1.9163\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 1.3255 - value_loss: 0.5420 - policy_loss: 1.6860 - val_loss: 1.5679 - val_value_loss: 0.7974 - val_policy_loss: 1.9156\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 1.3036 - value_loss: 0.5073 - policy_loss: 1.6770 - val_loss: 1.5690 - val_value_loss: 0.8005 - val_policy_loss: 1.9144\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.2724 - value_loss: 0.4516 - policy_loss: 1.6702 - val_loss: 1.5717 - val_value_loss: 0.8068 - val_policy_loss: 1.9126\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.2595 - value_loss: 0.4281 - policy_loss: 1.6668 - val_loss: 1.5749 - val_value_loss: 0.8136 - val_policy_loss: 1.9110\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 1.2420 - value_loss: 0.3956 - policy_loss: 1.6633 - val_loss: 1.5776 - val_value_loss: 0.8183 - val_policy_loss: 1.9104\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.2416 - value_loss: 0.3947 - policy_loss: 1.6620 - val_loss: 1.5794 - val_value_loss: 0.8202 - val_policy_loss: 1.9113\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.2286 - value_loss: 0.3721 - policy_loss: 1.6576 - val_loss: 1.5807 - val_value_loss: 0.8209 - val_policy_loss: 1.9126\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.2203 - value_loss: 0.3549 - policy_loss: 1.6577 - val_loss: 1.5817 - val_value_loss: 0.8219 - val_policy_loss: 1.9133\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.2162 - value_loss: 0.3480 - policy_loss: 1.6561 - val_loss: 1.5834 - val_value_loss: 0.8258 - val_policy_loss: 1.9132\n",
      "Saved model  tictactoe_10_epochs_43\n",
      "iteration 43 | evaluation\n",
      "agent vs random - win ratio 0.84 - draw ratio 0.02\n",
      "iteration 44 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_44\n",
      "iteration 44 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.3638 - value_loss: 0.6406 - policy_loss: 1.6592 - val_loss: 1.6234 - val_value_loss: 0.8811 - val_policy_loss: 1.9388\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 1.3303 - value_loss: 0.5800 - policy_loss: 1.6538 - val_loss: 1.6263 - val_value_loss: 0.8887 - val_policy_loss: 1.9385\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.2962 - value_loss: 0.5178 - policy_loss: 1.6492 - val_loss: 1.6287 - val_value_loss: 0.8953 - val_policy_loss: 1.9383\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.2759 - value_loss: 0.4835 - policy_loss: 1.6446 - val_loss: 1.6265 - val_value_loss: 0.8921 - val_policy_loss: 1.9389\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 1.2509 - value_loss: 0.4404 - policy_loss: 1.6393 - val_loss: 1.6240 - val_value_loss: 0.8883 - val_policy_loss: 1.9394\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.2359 - value_loss: 0.4158 - policy_loss: 1.6356 - val_loss: 1.6235 - val_value_loss: 0.8892 - val_policy_loss: 1.9394\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.2241 - value_loss: 0.3964 - policy_loss: 1.6333 - val_loss: 1.6240 - val_value_loss: 0.8924 - val_policy_loss: 1.9391\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.2142 - value_loss: 0.3792 - policy_loss: 1.6327 - val_loss: 1.6244 - val_value_loss: 0.8953 - val_policy_loss: 1.9390\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 1.2041 - value_loss: 0.3613 - policy_loss: 1.6323 - val_loss: 1.6240 - val_value_loss: 0.8964 - val_policy_loss: 1.9392\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 125us/step - loss: 1.1939 - value_loss: 0.3438 - policy_loss: 1.6317 - val_loss: 1.6235 - val_value_loss: 0.8974 - val_policy_loss: 1.9397\n",
      "Saved model  tictactoe_10_epochs_44\n",
      "iteration 44 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.06\n",
      "iteration 45 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_45\n",
      "iteration 45 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 149us/step - loss: 1.3800 - value_loss: 0.7128 - policy_loss: 1.6372 - val_loss: 1.6196 - val_value_loss: 0.9405 - val_policy_loss: 1.8916\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 149us/step - loss: 1.3028 - value_loss: 0.5644 - policy_loss: 1.6340 - val_loss: 1.6132 - val_value_loss: 0.9319 - val_policy_loss: 1.8897\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 153us/step - loss: 1.2704 - value_loss: 0.5106 - policy_loss: 1.6254 - val_loss: 1.6086 - val_value_loss: 0.9268 - val_policy_loss: 1.8874\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 142us/step - loss: 1.2550 - value_loss: 0.4792 - policy_loss: 1.6278 - val_loss: 1.6056 - val_value_loss: 0.9244 - val_policy_loss: 1.8855\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 1.2286 - value_loss: 0.4368 - policy_loss: 1.6190 - val_loss: 1.6039 - val_value_loss: 0.9240 - val_policy_loss: 1.8838\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 1.2130 - value_loss: 0.4056 - policy_loss: 1.6205 - val_loss: 1.6018 - val_value_loss: 0.9225 - val_policy_loss: 1.8823\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 1.2032 - value_loss: 0.3898 - policy_loss: 1.6178 - val_loss: 1.6001 - val_value_loss: 0.9216 - val_policy_loss: 1.8810\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 133us/step - loss: 1.1959 - value_loss: 0.3763 - policy_loss: 1.6178 - val_loss: 1.6005 - val_value_loss: 0.9248 - val_policy_loss: 1.8798\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.1876 - value_loss: 0.3632 - policy_loss: 1.6157 - val_loss: 1.6040 - val_value_loss: 0.9343 - val_policy_loss: 1.8787\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 1.1773 - value_loss: 0.3465 - policy_loss: 1.6132 - val_loss: 1.6104 - val_value_loss: 0.9496 - val_policy_loss: 1.8780\n",
      "Saved model  tictactoe_10_epochs_45\n",
      "iteration 45 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.04\n",
      "iteration 46 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_46\n",
      "iteration 46 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 149us/step - loss: 1.5122 - value_loss: 0.9683 - policy_loss: 1.6628 - val_loss: 1.6386 - val_value_loss: 1.0540 - val_policy_loss: 1.8321\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 150us/step - loss: 1.4452 - value_loss: 0.8407 - policy_loss: 1.6586 - val_loss: 1.6406 - val_value_loss: 1.0598 - val_policy_loss: 1.8322\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.3968 - value_loss: 0.7496 - policy_loss: 1.6548 - val_loss: 1.6335 - val_value_loss: 1.0472 - val_policy_loss: 1.8320\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 1.3701 - value_loss: 0.6989 - policy_loss: 1.6535 - val_loss: 1.6210 - val_value_loss: 1.0232 - val_policy_loss: 1.8321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 1.3512 - value_loss: 0.6652 - policy_loss: 1.6505 - val_loss: 1.6106 - val_value_loss: 1.0023 - val_policy_loss: 1.8330\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 1.3398 - value_loss: 0.6449 - policy_loss: 1.6490 - val_loss: 1.6061 - val_value_loss: 0.9928 - val_policy_loss: 1.8343\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 1.3265 - value_loss: 0.6195 - policy_loss: 1.6484 - val_loss: 1.6074 - val_value_loss: 0.9951 - val_policy_loss: 1.8355\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.3099 - value_loss: 0.5880 - policy_loss: 1.6476 - val_loss: 1.6122 - val_value_loss: 1.0047 - val_policy_loss: 1.8363\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.2946 - value_loss: 0.5590 - policy_loss: 1.6468 - val_loss: 1.6181 - val_value_loss: 1.0168 - val_policy_loss: 1.8367\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 1.2805 - value_loss: 0.5320 - policy_loss: 1.6465 - val_loss: 1.6240 - val_value_loss: 1.0295 - val_policy_loss: 1.8369\n",
      "Saved model  tictactoe_10_epochs_46\n",
      "iteration 46 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.0\n",
      "iteration 47 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_47\n",
      "iteration 47 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.4472 - value_loss: 0.8026 - policy_loss: 1.7102 - val_loss: 1.6584 - val_value_loss: 1.0880 - val_policy_loss: 1.8483\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 1.4137 - value_loss: 0.7587 - policy_loss: 1.6883 - val_loss: 1.6626 - val_value_loss: 1.0982 - val_policy_loss: 1.8478\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 1.3829 - value_loss: 0.7130 - policy_loss: 1.6736 - val_loss: 1.6645 - val_value_loss: 1.1038 - val_policy_loss: 1.8471\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 147us/step - loss: 1.3584 - value_loss: 0.6715 - policy_loss: 1.6673 - val_loss: 1.6645 - val_value_loss: 1.1057 - val_policy_loss: 1.8464\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 1.3430 - value_loss: 0.6437 - policy_loss: 1.6654 - val_loss: 1.6637 - val_value_loss: 1.1059 - val_policy_loss: 1.8456\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.3233 - value_loss: 0.6115 - policy_loss: 1.6594 - val_loss: 1.6627 - val_value_loss: 1.1053 - val_policy_loss: 1.8451\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 1.3049 - value_loss: 0.5798 - policy_loss: 1.6552 - val_loss: 1.6629 - val_value_loss: 1.1062 - val_policy_loss: 1.8456\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.2983 - value_loss: 0.5685 - policy_loss: 1.6541 - val_loss: 1.6642 - val_value_loss: 1.1083 - val_policy_loss: 1.8468\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 1.2832 - value_loss: 0.5403 - policy_loss: 1.6527 - val_loss: 1.6655 - val_value_loss: 1.1102 - val_policy_loss: 1.8482\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.2724 - value_loss: 0.5198 - policy_loss: 1.6526 - val_loss: 1.6694 - val_value_loss: 1.1175 - val_policy_loss: 1.8497\n",
      "Saved model  tictactoe_10_epochs_47\n",
      "iteration 47 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.0\n",
      "iteration 48 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_48\n",
      "iteration 48 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 149us/step - loss: 1.3768 - value_loss: 0.7380 - policy_loss: 1.6439 - val_loss: 1.6299 - val_value_loss: 1.0504 - val_policy_loss: 1.8387\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 151us/step - loss: 1.3345 - value_loss: 0.6662 - policy_loss: 1.6321 - val_loss: 1.6264 - val_value_loss: 1.0440 - val_policy_loss: 1.8390\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.2998 - value_loss: 0.6052 - policy_loss: 1.6246 - val_loss: 1.6172 - val_value_loss: 1.0263 - val_policy_loss: 1.8387\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 137us/step - loss: 1.2747 - value_loss: 0.5671 - policy_loss: 1.6128 - val_loss: 1.6104 - val_value_loss: 1.0141 - val_policy_loss: 1.8374\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 134us/step - loss: 1.2561 - value_loss: 0.5339 - policy_loss: 1.6088 - val_loss: 1.6079 - val_value_loss: 1.0102 - val_policy_loss: 1.8361\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 131us/step - loss: 1.2466 - value_loss: 0.5147 - policy_loss: 1.6089 - val_loss: 1.6073 - val_value_loss: 1.0095 - val_policy_loss: 1.8351\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 128us/step - loss: 1.2294 - value_loss: 0.4830 - policy_loss: 1.6060 - val_loss: 1.6084 - val_value_loss: 1.0121 - val_policy_loss: 1.8346\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 133us/step - loss: 1.2167 - value_loss: 0.4598 - policy_loss: 1.6034 - val_loss: 1.6135 - val_value_loss: 1.0222 - val_policy_loss: 1.8345\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 135us/step - loss: 1.2052 - value_loss: 0.4388 - policy_loss: 1.6012 - val_loss: 1.6217 - val_value_loss: 1.0379 - val_policy_loss: 1.8350\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.1941 - value_loss: 0.4175 - policy_loss: 1.6004 - val_loss: 1.6302 - val_value_loss: 1.0542 - val_policy_loss: 1.8360\n",
      "Saved model  tictactoe_10_epochs_48\n",
      "iteration 48 | evaluation\n",
      "agent vs random - win ratio 0.88 - draw ratio 0.0\n",
      "iteration 49 | self-play\n",
      "saving memory position_memory_tictactoe_10_epochs_ep_49\n",
      "iteration 49 | optimization\n",
      "num_positions: 512\n",
      "model_X shape: (512, 3, 3, 3)\n",
      "model_y_outcomes: (512,)\n",
      "model_y_probabilities: (512, 9)\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 0s 139us/step - loss: 1.4728 - value_loss: 0.9183 - policy_loss: 1.6572 - val_loss: 1.5591 - val_value_loss: 0.9350 - val_policy_loss: 1.8136\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 0s 154us/step - loss: 1.4047 - value_loss: 0.7888 - policy_loss: 1.6511 - val_loss: 1.5568 - val_value_loss: 0.9312 - val_policy_loss: 1.8134\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 0s 147us/step - loss: 1.3615 - value_loss: 0.7063 - policy_loss: 1.6476 - val_loss: 1.5553 - val_value_loss: 0.9291 - val_policy_loss: 1.8125\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 0s 144us/step - loss: 1.3238 - value_loss: 0.6330 - policy_loss: 1.6455 - val_loss: 1.5533 - val_value_loss: 0.9256 - val_policy_loss: 1.8115\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 0s 132us/step - loss: 1.3018 - value_loss: 0.5897 - policy_loss: 1.6444 - val_loss: 1.5515 - val_value_loss: 0.9219 - val_policy_loss: 1.8110\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.2805 - value_loss: 0.5490 - policy_loss: 1.6420 - val_loss: 1.5487 - val_value_loss: 0.9155 - val_policy_loss: 1.8110\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 1.2654 - value_loss: 0.5192 - policy_loss: 1.6406 - val_loss: 1.5463 - val_value_loss: 0.9094 - val_policy_loss: 1.8115\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 0s 130us/step - loss: 1.2557 - value_loss: 0.5002 - policy_loss: 1.6393 - val_loss: 1.5471 - val_value_loss: 0.9093 - val_policy_loss: 1.8124\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 0s 127us/step - loss: 1.2426 - value_loss: 0.4748 - policy_loss: 1.6379 - val_loss: 1.5520 - val_value_loss: 0.9173 - val_policy_loss: 1.8136\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 0s 125us/step - loss: 1.2291 - value_loss: 0.4482 - policy_loss: 1.6369 - val_loss: 1.5594 - val_value_loss: 0.9309 - val_policy_loss: 1.8146\n",
      "Saved model  tictactoe_10_epochs_49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 49 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.46,\n",
       "  0.44,\n",
       "  0.74,\n",
       "  0.74,\n",
       "  0.7,\n",
       "  0.82,\n",
       "  0.78,\n",
       "  0.78,\n",
       "  0.82,\n",
       "  0.92,\n",
       "  0.8,\n",
       "  0.76,\n",
       "  0.8,\n",
       "  0.78,\n",
       "  0.76,\n",
       "  0.82,\n",
       "  0.78,\n",
       "  0.74,\n",
       "  0.86,\n",
       "  0.84,\n",
       "  0.84,\n",
       "  0.84,\n",
       "  0.86,\n",
       "  0.74,\n",
       "  0.78,\n",
       "  0.8,\n",
       "  0.8,\n",
       "  0.76,\n",
       "  0.78,\n",
       "  0.84,\n",
       "  0.8,\n",
       "  0.78,\n",
       "  0.86,\n",
       "  0.78,\n",
       "  0.94,\n",
       "  0.88,\n",
       "  0.86,\n",
       "  0.86,\n",
       "  0.9,\n",
       "  0.92,\n",
       "  0.8,\n",
       "  0.86,\n",
       "  0.86,\n",
       "  0.84,\n",
       "  0.86,\n",
       "  0.74,\n",
       "  0.88,\n",
       "  0.8,\n",
       "  0.88,\n",
       "  0.78],\n",
       " [0.1,\n",
       "  0.14,\n",
       "  0.02,\n",
       "  0.04,\n",
       "  0.04,\n",
       "  0.04,\n",
       "  0.04,\n",
       "  0.04,\n",
       "  0.02,\n",
       "  0.04,\n",
       "  0.06,\n",
       "  0.08,\n",
       "  0.04,\n",
       "  0.02,\n",
       "  0.04,\n",
       "  0.0,\n",
       "  0.06,\n",
       "  0.02,\n",
       "  0.02,\n",
       "  0.02,\n",
       "  0.0,\n",
       "  0.08,\n",
       "  0.02,\n",
       "  0.06,\n",
       "  0.06,\n",
       "  0.02,\n",
       "  0.08,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.08,\n",
       "  0.06,\n",
       "  0.04,\n",
       "  0.02,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.04,\n",
       "  0.02,\n",
       "  0.02,\n",
       "  0.0,\n",
       "  0.02,\n",
       "  0.04,\n",
       "  0.02,\n",
       "  0.02,\n",
       "  0.06,\n",
       "  0.04,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.08])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pipeline.run(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wins_4=[0.46, 0.44, 0.74, 0.74, 0.7, 0.82, 0.78, 0.78, 0.82, 0.92, 0.8, 0.76, 0.8, 0.78, 0.76, 0.82, 0.78, 0.74, 0.86,\n",
    "        0.84, 0.84, 0.84, 0.86, 0.74, 0.78, 0.8, 0.8, 0.76, 0.78, 0.84, 0.8, 0.78, 0.86, 0.78, 0.94, 0.88, 0.86, 0.86,\n",
    "        0.9, 0.92, 0.8, 0.86, 0.86, 0.84, 0.86, 0.74, 0.88, 0.8, 0.88, 0.78]\n",
    "\n",
    "draws_4=[0.1, 0.14, 0.02, 0.04, 0.04, 0.04, 0.04, 0.04, 0.02, 0.04, 0.06, 0.08, 0.04, 0.02, 0.04, 0.0, 0.06, 0.02,\n",
    "         0.02, 0.02, 0.0, 0.08, 0.02, 0.06, 0.06, 0.02, 0.08, 0.0, 0.0, 0.0, 0.08, 0.06, 0.04, 0.02, 0.0, 0.0, 0.04,\n",
    "         0.02, 0.02, 0.0, 0.02, 0.04, 0.02, 0.02, 0.06, 0.04, 0.0, 0.0, 0.0, 0.08]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(50)\n",
    "losses_4 = np.ones(50) - wins_4 - draws_4\n",
    "# no_loss = np.zeros(50) + wins +draws\n",
    "\n",
    "plt.plot(x, wins_4, label=\"win ratio\")\n",
    "plt.plot(x, draws_4, label=\"draw ratio\")\n",
    "#plt.plot(x, no_loss, label=\"no loss ratio\")\n",
    "plt.plot(x, losses_4, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46, 0.44, 0.74, 0.74, 0.7, 0.82, 0.78, 0.78, 0.82, 0.92, 0.8, 0.76, 0.8, 0.78, 0.76, 0.82, 0.78, 0.74, 0.86, 0.84, 0.84, 0.84, 0.86, 0.74, 0.78, 0.8, 0.8, 0.76, 0.78, 0.84, 0.8, 0.78, 0.86, 0.78, 0.94, 0.88, 0.86, 0.86, 0.9, 0.92, 0.8, 0.86, 0.86, 0.84, 0.86, 0.74, 0.88, 0.8, 0.88, 0.78]\n",
      "[0.1, 0.14, 0.02, 0.04, 0.04, 0.04, 0.04, 0.04, 0.02, 0.04, 0.06, 0.08, 0.04, 0.02, 0.04, 0.0, 0.06, 0.02, 0.02, 0.02, 0.0, 0.08, 0.02, 0.06, 0.06, 0.02, 0.08, 0.0, 0.0, 0.0, 0.08, 0.06, 0.04, 0.02, 0.0, 0.0, 0.04, 0.02, 0.02, 0.0, 0.02, 0.04, 0.02, 0.02, 0.06, 0.04, 0.0, 0.0, 0.0, 0.08]\n",
      "[0.44 0.42 0.24 0.22 0.26 0.14 0.18 0.18 0.16 0.04 0.14 0.16 0.16 0.2\n",
      " 0.2  0.18 0.16 0.24 0.12 0.14 0.16 0.08 0.12 0.2  0.16 0.18 0.12 0.24\n",
      " 0.22 0.16 0.12 0.16 0.1  0.2  0.06 0.12 0.1  0.12 0.08 0.08 0.18 0.1\n",
      " 0.12 0.14 0.08 0.22 0.12 0.2  0.12 0.14]\n"
     ]
    }
   ],
   "source": [
    "print(wins_4)\n",
    "print(draws_4)\n",
    "print(losses_4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
