{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: ConnectFour - Number of simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from pipeline import Pipeline, agent_vs_player, agent_vs_agent\n",
    "import memory\n",
    "import model\n",
    "import agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCTS = {\n",
    "    'c_puct': 1,\n",
    "    'dir_alpha': 0.6,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 10,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 10\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 1,\n",
    "    'temperature': 0,\n",
    "    'show_games': False\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 1,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.002,\n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 512,\n",
    "    'num_filters_value': 512,\n",
    "    'num_filters_tower': 512,\n",
    "    'num_residual_blocks': 3,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 512\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"connectfour_num_sim_1\", \"Connect4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (3962, 6, 7, 3)\n",
      "model_y_outcomes: (3962,)\n",
      "model_y_probabilities: (3962, 7)\n",
      "Train on 3169 samples, validate on 793 samples\n",
      "Epoch 1/10\n",
      "3169/3169 [==============================] - 5s 2ms/step - loss: 6.8956 - value_loss: 1.3716 - policy_loss: 2.1874 - val_loss: 7.0266 - val_value_loss: 1.6463 - val_policy_loss: 2.1751\n",
      "Epoch 2/10\n",
      "3169/3169 [==============================] - 1s 461us/step - loss: 6.7268 - value_loss: 1.1516 - policy_loss: 2.0704 - val_loss: 6.8167 - val_value_loss: 1.2565 - val_policy_loss: 2.1456\n",
      "Epoch 3/10\n",
      "3169/3169 [==============================] - 1s 459us/step - loss: 6.5753 - value_loss: 0.9032 - policy_loss: 2.0164 - val_loss: 6.9379 - val_value_loss: 1.4749 - val_policy_loss: 2.1702\n",
      "Epoch 4/10\n",
      "3169/3169 [==============================] - 1s 461us/step - loss: 6.4956 - value_loss: 0.7894 - policy_loss: 1.9714 - val_loss: 6.9346 - val_value_loss: 1.5093 - val_policy_loss: 2.1299\n",
      "Epoch 5/10\n",
      "3169/3169 [==============================] - 1s 460us/step - loss: 6.4465 - value_loss: 0.7329 - policy_loss: 1.9301 - val_loss: 7.0781 - val_value_loss: 1.7494 - val_policy_loss: 2.1773\n",
      "Epoch 6/10\n",
      "3169/3169 [==============================] - 1s 460us/step - loss: 6.4897 - value_loss: 0.8438 - policy_loss: 1.9062 - val_loss: 6.9183 - val_value_loss: 1.4984 - val_policy_loss: 2.1094\n",
      "Epoch 7/10\n",
      "3169/3169 [==============================] - 1s 460us/step - loss: 6.3580 - value_loss: 0.6122 - policy_loss: 1.8750 - val_loss: 6.9331 - val_value_loss: 1.4883 - val_policy_loss: 2.1495\n",
      "Epoch 8/10\n",
      "3169/3169 [==============================] - 1s 461us/step - loss: 6.3419 - value_loss: 0.6086 - policy_loss: 1.8470 - val_loss: 6.9027 - val_value_loss: 1.4678 - val_policy_loss: 2.1097\n",
      "Epoch 9/10\n",
      "3169/3169 [==============================] - 1s 461us/step - loss: 6.3272 - value_loss: 0.6049 - policy_loss: 1.8220 - val_loss: 6.8562 - val_value_loss: 1.3646 - val_policy_loss: 2.1205\n",
      "Epoch 10/10\n",
      "3169/3169 [==============================] - 1s 461us/step - loss: 6.2672 - value_loss: 0.4988 - policy_loss: 1.8086 - val_loss: 6.8348 - val_value_loss: 1.3253 - val_policy_loss: 2.1175\n",
      "Saved model  connectfour_num_sim_1_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.67 - draw ratio 0.0\n",
      "Number of seen trajectories: 100\n",
      "Number of unique trajectories: 100\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4611 - value_loss: 0.7617 - policy_loss: 1.9341 - val_loss: 6.4605 - val_value_loss: 0.7684 - val_policy_loss: 1.9266\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4928 - value_loss: 0.8848 - policy_loss: 1.8750 - val_loss: 6.4693 - val_value_loss: 0.8091 - val_policy_loss: 1.9042\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4052 - value_loss: 0.7558 - policy_loss: 1.8294 - val_loss: 6.4741 - val_value_loss: 0.8308 - val_policy_loss: 1.8927\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3695 - value_loss: 0.7173 - policy_loss: 1.7972 - val_loss: 6.3968 - val_value_loss: 0.6798 - val_policy_loss: 1.8897\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.2894 - value_loss: 0.5891 - policy_loss: 1.7659 - val_loss: 6.4142 - val_value_loss: 0.7305 - val_policy_loss: 1.8745\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2280 - value_loss: 0.4968 - policy_loss: 1.7360 - val_loss: 6.3673 - val_value_loss: 0.6457 - val_policy_loss: 1.8661\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.1911 - value_loss: 0.4509 - policy_loss: 1.7089 - val_loss: 6.3477 - val_value_loss: 0.6135 - val_policy_loss: 1.8597\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.1545 - value_loss: 0.3979 - policy_loss: 1.6892 - val_loss: 6.3502 - val_value_loss: 0.6285 - val_policy_loss: 1.8503\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.1583 - value_loss: 0.4310 - policy_loss: 1.6644 - val_loss: 6.3526 - val_value_loss: 0.6420 - val_policy_loss: 1.8423\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.1287 - value_loss: 0.3906 - policy_loss: 1.6461 - val_loss: 6.3399 - val_value_loss: 0.6174 - val_policy_loss: 1.8422\n",
      "Saved model  connectfour_num_sim_1_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.51 - draw ratio 0.0\n",
      "Number of seen trajectories: 200\n",
      "Number of unique trajectories: 200\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5330 - value_loss: 0.9369 - policy_loss: 1.9093 - val_loss: 6.4041 - val_value_loss: 0.7119 - val_policy_loss: 1.8767\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3683 - value_loss: 0.6627 - policy_loss: 1.8546 - val_loss: 6.4046 - val_value_loss: 0.7217 - val_policy_loss: 1.8686\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3757 - value_loss: 0.7169 - policy_loss: 1.8158 - val_loss: 6.4188 - val_value_loss: 0.7558 - val_policy_loss: 1.8635\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3212 - value_loss: 0.6454 - policy_loss: 1.7789 - val_loss: 6.3803 - val_value_loss: 0.6897 - val_policy_loss: 1.8531\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2816 - value_loss: 0.5974 - policy_loss: 1.7484 - val_loss: 6.3617 - val_value_loss: 0.6648 - val_policy_loss: 1.8417\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.2245 - value_loss: 0.5099 - policy_loss: 1.7224 - val_loss: 6.3309 - val_value_loss: 0.6122 - val_policy_loss: 1.8332\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.1578 - value_loss: 0.3964 - policy_loss: 1.7032 - val_loss: 6.3264 - val_value_loss: 0.6011 - val_policy_loss: 1.8359\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.1298 - value_loss: 0.3677 - policy_loss: 1.6764 - val_loss: 6.3059 - val_value_loss: 0.5671 - val_policy_loss: 1.8297\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.1139 - value_loss: 0.3566 - policy_loss: 1.6564 - val_loss: 6.3452 - val_value_loss: 0.6578 - val_policy_loss: 1.8181\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.1118 - value_loss: 0.3759 - policy_loss: 1.6334 - val_loss: 6.3045 - val_value_loss: 0.5744 - val_policy_loss: 1.8208\n",
      "Saved model  connectfour_num_sim_1_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.62 - draw ratio 0.0\n",
      "Number of seen trajectories: 300\n",
      "Number of unique trajectories: 300\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 456us/step - loss: 6.4730 - value_loss: 0.8239 - policy_loss: 1.9085 - val_loss: 6.4882 - val_value_loss: 0.8984 - val_policy_loss: 1.8649\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4326 - value_loss: 0.8021 - policy_loss: 1.8502 - val_loss: 6.4886 - val_value_loss: 0.9141 - val_policy_loss: 1.8507\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3733 - value_loss: 0.7301 - policy_loss: 1.8042 - val_loss: 6.4410 - val_value_loss: 0.8358 - val_policy_loss: 1.8344\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3038 - value_loss: 0.6323 - policy_loss: 1.7638 - val_loss: 6.4199 - val_value_loss: 0.7895 - val_policy_loss: 1.8391\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2392 - value_loss: 0.5350 - policy_loss: 1.7324 - val_loss: 6.3464 - val_value_loss: 0.6732 - val_policy_loss: 1.8091\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.1820 - value_loss: 0.4536 - policy_loss: 1.7001 - val_loss: 6.3308 - val_value_loss: 0.6502 - val_policy_loss: 1.8015\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.1498 - value_loss: 0.4125 - policy_loss: 1.6776 - val_loss: 6.3098 - val_value_loss: 0.6186 - val_policy_loss: 1.7917\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.1215 - value_loss: 0.3839 - policy_loss: 1.6501 - val_loss: 6.3040 - val_value_loss: 0.6142 - val_policy_loss: 1.7853\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.1124 - value_loss: 0.3849 - policy_loss: 1.6316 - val_loss: 6.3298 - val_value_loss: 0.6702 - val_policy_loss: 1.7814\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.1086 - value_loss: 0.3981 - policy_loss: 1.6112 - val_loss: 6.2853 - val_value_loss: 0.5929 - val_policy_loss: 1.7704\n",
      "Saved model  connectfour_num_sim_1_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.54 - draw ratio 0.0\n",
      "Number of seen trajectories: 400\n",
      "Number of unique trajectories: 400\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4825 - value_loss: 0.8538 - policy_loss: 1.9041 - val_loss: 6.4606 - val_value_loss: 0.8396 - val_policy_loss: 1.8749\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4468 - value_loss: 0.8348 - policy_loss: 1.8523 - val_loss: 6.4399 - val_value_loss: 0.8075 - val_policy_loss: 1.8662\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3471 - value_loss: 0.6776 - policy_loss: 1.8109 - val_loss: 6.4314 - val_value_loss: 0.8067 - val_policy_loss: 1.8506\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3002 - value_loss: 0.6233 - policy_loss: 1.7719 - val_loss: 6.4016 - val_value_loss: 0.7614 - val_policy_loss: 1.8371\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2514 - value_loss: 0.5582 - policy_loss: 1.7401 - val_loss: 6.3818 - val_value_loss: 0.7316 - val_policy_loss: 1.8279\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2291 - value_loss: 0.5450 - policy_loss: 1.7094 - val_loss: 6.3735 - val_value_loss: 0.7215 - val_policy_loss: 1.8221\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.1736 - value_loss: 0.4574 - policy_loss: 1.6866 - val_loss: 6.3365 - val_value_loss: 0.6569 - val_policy_loss: 1.8133\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.1329 - value_loss: 0.4040 - policy_loss: 1.6593 - val_loss: 6.3203 - val_value_loss: 0.6354 - val_policy_loss: 1.8029\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.1321 - value_loss: 0.4252 - policy_loss: 1.6371 - val_loss: 6.3227 - val_value_loss: 0.6459 - val_policy_loss: 1.7978\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.1027 - value_loss: 0.3844 - policy_loss: 1.6197 - val_loss: 6.3082 - val_value_loss: 0.6247 - val_policy_loss: 1.7908\n",
      "Saved model  connectfour_num_sim_1_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.5 - draw ratio 0.0\n",
      "Number of seen trajectories: 500\n",
      "Number of unique trajectories: 500\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4198 - value_loss: 0.7459 - policy_loss: 1.8929 - val_loss: 6.3976 - val_value_loss: 0.6966 - val_policy_loss: 1.8979\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3591 - value_loss: 0.6547 - policy_loss: 1.8629 - val_loss: 6.3803 - val_value_loss: 0.6690 - val_policy_loss: 1.8913\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3094 - value_loss: 0.5860 - policy_loss: 1.8327 - val_loss: 6.3689 - val_value_loss: 0.6508 - val_policy_loss: 1.8870\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2776 - value_loss: 0.5436 - policy_loss: 1.8119 - val_loss: 6.3562 - val_value_loss: 0.6330 - val_policy_loss: 1.8798\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2475 - value_loss: 0.5063 - policy_loss: 1.7893 - val_loss: 6.3469 - val_value_loss: 0.6200 - val_policy_loss: 1.8745\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2238 - value_loss: 0.4780 - policy_loss: 1.7703 - val_loss: 6.3386 - val_value_loss: 0.6094 - val_policy_loss: 1.8688\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2037 - value_loss: 0.4567 - policy_loss: 1.7519 - val_loss: 6.3323 - val_value_loss: 0.5998 - val_policy_loss: 1.8662\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.1884 - value_loss: 0.4390 - policy_loss: 1.7393 - val_loss: 6.3252 - val_value_loss: 0.5906 - val_policy_loss: 1.8615\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.1670 - value_loss: 0.4168 - policy_loss: 1.7189 - val_loss: 6.3208 - val_value_loss: 0.5850 - val_policy_loss: 1.8586\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.1533 - value_loss: 0.4030 - policy_loss: 1.7057 - val_loss: 6.3138 - val_value_loss: 0.5781 - val_policy_loss: 1.8518\n",
      "Saved model  connectfour_num_sim_1_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.63 - draw ratio 0.0\n",
      "Number of seen trajectories: 600\n",
      "Number of unique trajectories: 600\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4489 - value_loss: 0.7950 - policy_loss: 1.9052 - val_loss: 6.4296 - val_value_loss: 0.7467 - val_policy_loss: 1.9150\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3823 - value_loss: 0.6952 - policy_loss: 1.8720 - val_loss: 6.4069 - val_value_loss: 0.7109 - val_policy_loss: 1.9058\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3293 - value_loss: 0.6195 - policy_loss: 1.8423 - val_loss: 6.3930 - val_value_loss: 0.6904 - val_policy_loss: 1.8990\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2883 - value_loss: 0.5647 - policy_loss: 1.8152 - val_loss: 6.3790 - val_value_loss: 0.6711 - val_policy_loss: 1.8904\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2552 - value_loss: 0.5216 - policy_loss: 1.7926 - val_loss: 6.3661 - val_value_loss: 0.6503 - val_policy_loss: 1.8858\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2348 - value_loss: 0.4956 - policy_loss: 1.7780 - val_loss: 6.3546 - val_value_loss: 0.6338 - val_policy_loss: 1.8795\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2056 - value_loss: 0.4622 - policy_loss: 1.7534 - val_loss: 6.3457 - val_value_loss: 0.6250 - val_policy_loss: 1.8709\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.1837 - value_loss: 0.4386 - policy_loss: 1.7334 - val_loss: 6.3393 - val_value_loss: 0.6126 - val_policy_loss: 1.8708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.1709 - value_loss: 0.4274 - policy_loss: 1.7195 - val_loss: 6.3332 - val_value_loss: 0.6082 - val_policy_loss: 1.8634\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.1511 - value_loss: 0.4077 - policy_loss: 1.6998 - val_loss: 6.3260 - val_value_loss: 0.5973 - val_policy_loss: 1.8603\n",
      "Saved model  connectfour_num_sim_1_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.58 - draw ratio 0.0\n",
      "Number of seen trajectories: 700\n",
      "Number of unique trajectories: 700\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4651 - value_loss: 0.8047 - policy_loss: 1.9311 - val_loss: 6.4425 - val_value_loss: 0.7710 - val_policy_loss: 1.9198\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3970 - value_loss: 0.7058 - policy_loss: 1.8941 - val_loss: 6.4280 - val_value_loss: 0.7528 - val_policy_loss: 1.9094\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3468 - value_loss: 0.6344 - policy_loss: 1.8655 - val_loss: 6.4014 - val_value_loss: 0.7118 - val_policy_loss: 1.8974\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3058 - value_loss: 0.5801 - policy_loss: 1.8382 - val_loss: 6.3921 - val_value_loss: 0.7003 - val_policy_loss: 1.8907\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2692 - value_loss: 0.5360 - policy_loss: 1.8093 - val_loss: 6.3810 - val_value_loss: 0.6810 - val_policy_loss: 1.8881\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2423 - value_loss: 0.5023 - policy_loss: 1.7896 - val_loss: 6.3721 - val_value_loss: 0.6724 - val_policy_loss: 1.8792\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2165 - value_loss: 0.4703 - policy_loss: 1.7704 - val_loss: 6.3593 - val_value_loss: 0.6509 - val_policy_loss: 1.8754\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.1910 - value_loss: 0.4422 - policy_loss: 1.7477 - val_loss: 6.3497 - val_value_loss: 0.6370 - val_policy_loss: 1.8706\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.1750 - value_loss: 0.4263 - policy_loss: 1.7320 - val_loss: 6.3423 - val_value_loss: 0.6280 - val_policy_loss: 1.8651\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.1553 - value_loss: 0.4047 - policy_loss: 1.7144 - val_loss: 6.3357 - val_value_loss: 0.6211 - val_policy_loss: 1.8591\n",
      "Saved model  connectfour_num_sim_1_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.56 - draw ratio 0.0\n",
      "Number of seen trajectories: 800\n",
      "Number of unique trajectories: 800\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4630 - value_loss: 0.8267 - policy_loss: 1.9081 - val_loss: 6.4615 - val_value_loss: 0.8663 - val_policy_loss: 1.8658\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3917 - value_loss: 0.7223 - policy_loss: 1.8703 - val_loss: 6.4394 - val_value_loss: 0.8325 - val_policy_loss: 1.8556\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3344 - value_loss: 0.6380 - policy_loss: 1.8403 - val_loss: 6.4201 - val_value_loss: 0.7975 - val_policy_loss: 1.8524\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2986 - value_loss: 0.5932 - policy_loss: 1.8138 - val_loss: 6.4024 - val_value_loss: 0.7716 - val_policy_loss: 1.8433\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2586 - value_loss: 0.5391 - policy_loss: 1.7882 - val_loss: 6.3888 - val_value_loss: 0.7530 - val_policy_loss: 1.8349\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2320 - value_loss: 0.5049 - policy_loss: 1.7695 - val_loss: 6.3806 - val_value_loss: 0.7468 - val_policy_loss: 1.8252\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2133 - value_loss: 0.4908 - policy_loss: 1.7466 - val_loss: 6.3640 - val_value_loss: 0.7139 - val_policy_loss: 1.8251\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.1856 - value_loss: 0.4529 - policy_loss: 1.7295 - val_loss: 6.3604 - val_value_loss: 0.7161 - val_policy_loss: 1.8161\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.1613 - value_loss: 0.4251 - policy_loss: 1.7090 - val_loss: 6.3458 - val_value_loss: 0.6935 - val_policy_loss: 1.8098\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 459us/step - loss: 6.1451 - value_loss: 0.4097 - policy_loss: 1.6922 - val_loss: 6.3433 - val_value_loss: 0.6892 - val_policy_loss: 1.8093\n",
      "Saved model  connectfour_num_sim_1_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.61 - draw ratio 0.0\n",
      "Number of seen trajectories: 900\n",
      "Number of unique trajectories: 900\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4521 - value_loss: 0.8238 - policy_loss: 1.8926 - val_loss: 6.4375 - val_value_loss: 0.7831 - val_policy_loss: 1.9041\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3893 - value_loss: 0.7329 - policy_loss: 1.8581 - val_loss: 6.4116 - val_value_loss: 0.7408 - val_policy_loss: 1.8950\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3303 - value_loss: 0.6460 - policy_loss: 1.8274 - val_loss: 6.3973 - val_value_loss: 0.7213 - val_policy_loss: 1.8862\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2937 - value_loss: 0.5965 - policy_loss: 1.8040 - val_loss: 6.3785 - val_value_loss: 0.6924 - val_policy_loss: 1.8779\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2540 - value_loss: 0.5426 - policy_loss: 1.7787 - val_loss: 6.3763 - val_value_loss: 0.6929 - val_policy_loss: 1.8734\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2228 - value_loss: 0.5045 - policy_loss: 1.7549 - val_loss: 6.3688 - val_value_loss: 0.6754 - val_policy_loss: 1.8761\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2038 - value_loss: 0.4862 - policy_loss: 1.7355 - val_loss: 6.3611 - val_value_loss: 0.6724 - val_policy_loss: 1.8640\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.1820 - value_loss: 0.4593 - policy_loss: 1.7191 - val_loss: 6.3470 - val_value_loss: 0.6484 - val_policy_loss: 1.8601\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.1619 - value_loss: 0.4383 - policy_loss: 1.7001 - val_loss: 6.3549 - val_value_loss: 0.6700 - val_policy_loss: 1.8546\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.1500 - value_loss: 0.4291 - policy_loss: 1.6859 - val_loss: 6.3439 - val_value_loss: 0.6532 - val_policy_loss: 1.8498\n",
      "Saved model  connectfour_num_sim_1_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.53 - draw ratio 0.0\n",
      "Number of seen trajectories: 1000\n",
      "Number of unique trajectories: 1000\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 456us/step - loss: 6.4529 - value_loss: 0.8267 - policy_loss: 1.8944 - val_loss: 6.4547 - val_value_loss: 0.8309 - val_policy_loss: 1.8939\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4107 - value_loss: 0.7618 - policy_loss: 1.8751 - val_loss: 6.4392 - val_value_loss: 0.8067 - val_policy_loss: 1.8873\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3770 - value_loss: 0.7123 - policy_loss: 1.8573 - val_loss: 6.4273 - val_value_loss: 0.7892 - val_policy_loss: 1.8811\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3498 - value_loss: 0.6744 - policy_loss: 1.8411 - val_loss: 6.4173 - val_value_loss: 0.7734 - val_policy_loss: 1.8770\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3257 - value_loss: 0.6401 - policy_loss: 1.8272 - val_loss: 6.4080 - val_value_loss: 0.7592 - val_policy_loss: 1.8729\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3044 - value_loss: 0.6103 - policy_loss: 1.8146 - val_loss: 6.4000 - val_value_loss: 0.7485 - val_policy_loss: 1.8676\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2819 - value_loss: 0.5814 - policy_loss: 1.7985 - val_loss: 6.3919 - val_value_loss: 0.7367 - val_policy_loss: 1.8635\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2640 - value_loss: 0.5573 - policy_loss: 1.7872 - val_loss: 6.3854 - val_value_loss: 0.7278 - val_policy_loss: 1.8595\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2495 - value_loss: 0.5400 - policy_loss: 1.7755 - val_loss: 6.3791 - val_value_loss: 0.7191 - val_policy_loss: 1.8556\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2345 - value_loss: 0.5209 - policy_loss: 1.7649 - val_loss: 6.3736 - val_value_loss: 0.7116 - val_policy_loss: 1.8524\n",
      "Saved model  connectfour_num_sim_1_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.63 - draw ratio 0.0\n",
      "Number of seen trajectories: 1100\n",
      "Number of unique trajectories: 1100\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4979 - value_loss: 0.8773 - policy_loss: 1.9354 - val_loss: 6.4901 - val_value_loss: 0.8633 - val_policy_loss: 1.9339\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4505 - value_loss: 0.8019 - policy_loss: 1.9162 - val_loss: 6.4738 - val_value_loss: 0.8349 - val_policy_loss: 1.9299\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4138 - value_loss: 0.7452 - policy_loss: 1.8997 - val_loss: 6.4596 - val_value_loss: 0.8117 - val_policy_loss: 1.9248\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3812 - value_loss: 0.6957 - policy_loss: 1.8841 - val_loss: 6.4491 - val_value_loss: 0.7956 - val_policy_loss: 1.9200\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3500 - value_loss: 0.6478 - policy_loss: 1.8698 - val_loss: 6.4403 - val_value_loss: 0.7814 - val_policy_loss: 1.9169\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3280 - value_loss: 0.6173 - policy_loss: 1.8565 - val_loss: 6.4257 - val_value_loss: 0.7570 - val_policy_loss: 1.9122\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3078 - value_loss: 0.5875 - policy_loss: 1.8459 - val_loss: 6.4183 - val_value_loss: 0.7449 - val_policy_loss: 1.9096\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2878 - value_loss: 0.5613 - policy_loss: 1.8323 - val_loss: 6.4092 - val_value_loss: 0.7311 - val_policy_loss: 1.9053\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2709 - value_loss: 0.5382 - policy_loss: 1.8217 - val_loss: 6.4010 - val_value_loss: 0.7204 - val_policy_loss: 1.8999\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2545 - value_loss: 0.5157 - policy_loss: 1.8117 - val_loss: 6.3950 - val_value_loss: 0.7097 - val_policy_loss: 1.8988\n",
      "Saved model  connectfour_num_sim_1_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.52 - draw ratio 0.0\n",
      "Number of seen trajectories: 1200\n",
      "Number of unique trajectories: 1200\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.5003 - value_loss: 0.8823 - policy_loss: 1.9368 - val_loss: 6.5219 - val_value_loss: 0.8958 - val_policy_loss: 1.9666\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4583 - value_loss: 0.8165 - policy_loss: 1.9187 - val_loss: 6.5040 - val_value_loss: 0.8686 - val_policy_loss: 1.9581\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4173 - value_loss: 0.7534 - policy_loss: 1.9000 - val_loss: 6.4864 - val_value_loss: 0.8396 - val_policy_loss: 1.9521\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3876 - value_loss: 0.7092 - policy_loss: 1.8850 - val_loss: 6.4758 - val_value_loss: 0.8242 - val_policy_loss: 1.9464\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3594 - value_loss: 0.6675 - policy_loss: 1.8704 - val_loss: 6.4597 - val_value_loss: 0.7998 - val_policy_loss: 1.9389\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3323 - value_loss: 0.6291 - policy_loss: 1.8548 - val_loss: 6.4536 - val_value_loss: 0.7918 - val_policy_loss: 1.9348\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3127 - value_loss: 0.6019 - policy_loss: 1.8429 - val_loss: 6.4424 - val_value_loss: 0.7748 - val_policy_loss: 1.9295\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2935 - value_loss: 0.5750 - policy_loss: 1.8316 - val_loss: 6.4344 - val_value_loss: 0.7623 - val_policy_loss: 1.9263\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2786 - value_loss: 0.5574 - policy_loss: 1.8197 - val_loss: 6.4277 - val_value_loss: 0.7519 - val_policy_loss: 1.9233\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2547 - value_loss: 0.5243 - policy_loss: 1.8050 - val_loss: 6.4188 - val_value_loss: 0.7390 - val_policy_loss: 1.9187\n",
      "Saved model  connectfour_num_sim_1_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.43 - draw ratio 0.0\n",
      "Number of seen trajectories: 1300\n",
      "Number of unique trajectories: 1300\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 456us/step - loss: 6.5191 - value_loss: 0.9235 - policy_loss: 1.9349 - val_loss: 6.5038 - val_value_loss: 0.8934 - val_policy_loss: 1.9345\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4680 - value_loss: 0.8388 - policy_loss: 1.9176 - val_loss: 6.4809 - val_value_loss: 0.8544 - val_policy_loss: 1.9278\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4241 - value_loss: 0.7687 - policy_loss: 1.8999 - val_loss: 6.4637 - val_value_loss: 0.8266 - val_policy_loss: 1.9215\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3895 - value_loss: 0.7157 - policy_loss: 1.8839 - val_loss: 6.4524 - val_value_loss: 0.8061 - val_policy_loss: 1.9193\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3641 - value_loss: 0.6806 - policy_loss: 1.8684 - val_loss: 6.4397 - val_value_loss: 0.7869 - val_policy_loss: 1.9133\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3372 - value_loss: 0.6392 - policy_loss: 1.8562 - val_loss: 6.4281 - val_value_loss: 0.7687 - val_policy_loss: 1.9086\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3160 - value_loss: 0.6116 - policy_loss: 1.8415 - val_loss: 6.4198 - val_value_loss: 0.7556 - val_policy_loss: 1.9052\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2901 - value_loss: 0.5740 - policy_loss: 1.8274 - val_loss: 6.4127 - val_value_loss: 0.7462 - val_policy_loss: 1.9006\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2743 - value_loss: 0.5526 - policy_loss: 1.8175 - val_loss: 6.4040 - val_value_loss: 0.7329 - val_policy_loss: 1.8968\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2614 - value_loss: 0.5376 - policy_loss: 1.8068 - val_loss: 6.3995 - val_value_loss: 0.7286 - val_policy_loss: 1.8921\n",
      "Saved model  connectfour_num_sim_1_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.55 - draw ratio 0.0\n",
      "Number of seen trajectories: 1400\n",
      "Number of unique trajectories: 1400\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 457us/step - loss: 6.4610 - value_loss: 0.8130 - policy_loss: 1.9307 - val_loss: 6.4717 - val_value_loss: 0.8511 - val_policy_loss: 1.9142\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 461us/step - loss: 6.4121 - value_loss: 0.7338 - policy_loss: 1.9124 - val_loss: 6.4545 - val_value_loss: 0.8259 - val_policy_loss: 1.9051\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 459us/step - loss: 6.3753 - value_loss: 0.6776 - policy_loss: 1.8951 - val_loss: 6.4366 - val_value_loss: 0.7970 - val_policy_loss: 1.8984\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 458us/step - loss: 6.3466 - value_loss: 0.6353 - policy_loss: 1.8801 - val_loss: 6.4261 - val_value_loss: 0.7797 - val_policy_loss: 1.8949\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 456us/step - loss: 6.3220 - value_loss: 0.5977 - policy_loss: 1.8687 - val_loss: 6.4151 - val_value_loss: 0.7647 - val_policy_loss: 1.8881\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.3036 - value_loss: 0.5734 - policy_loss: 1.8564 - val_loss: 6.4072 - val_value_loss: 0.7532 - val_policy_loss: 1.8839\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2765 - value_loss: 0.5363 - policy_loss: 1.8394 - val_loss: 6.3981 - val_value_loss: 0.7396 - val_policy_loss: 1.8795\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2610 - value_loss: 0.5165 - policy_loss: 1.8284 - val_loss: 6.3921 - val_value_loss: 0.7318 - val_policy_loss: 1.8754\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2462 - value_loss: 0.4974 - policy_loss: 1.8180 - val_loss: 6.3847 - val_value_loss: 0.7218 - val_policy_loss: 1.8708\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2322 - value_loss: 0.4812 - policy_loss: 1.8065 - val_loss: 6.3781 - val_value_loss: 0.7130 - val_policy_loss: 1.8666\n",
      "Saved model  connectfour_num_sim_1_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.57 - draw ratio 0.0\n",
      "Number of seen trajectories: 1500\n",
      "Number of unique trajectories: 1500\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4920 - value_loss: 0.8791 - policy_loss: 1.9282 - val_loss: 6.4877 - val_value_loss: 0.8693 - val_policy_loss: 1.9295\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4630 - value_loss: 0.8317 - policy_loss: 1.9177 - val_loss: 6.4743 - val_value_loss: 0.8468 - val_policy_loss: 1.9252\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4377 - value_loss: 0.7911 - policy_loss: 1.9079 - val_loss: 6.4636 - val_value_loss: 0.8292 - val_policy_loss: 1.9216\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4176 - value_loss: 0.7586 - policy_loss: 1.9002 - val_loss: 6.4549 - val_value_loss: 0.8154 - val_policy_loss: 1.9179\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3982 - value_loss: 0.7281 - policy_loss: 1.8921 - val_loss: 6.4492 - val_value_loss: 0.8079 - val_policy_loss: 1.9142\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3815 - value_loss: 0.7019 - policy_loss: 1.8848 - val_loss: 6.4376 - val_value_loss: 0.7887 - val_policy_loss: 1.9103\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3645 - value_loss: 0.6758 - policy_loss: 1.8770 - val_loss: 6.4312 - val_value_loss: 0.7779 - val_policy_loss: 1.9083\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3493 - value_loss: 0.6545 - policy_loss: 1.8681 - val_loss: 6.4257 - val_value_loss: 0.7698 - val_policy_loss: 1.9056\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3369 - value_loss: 0.6361 - policy_loss: 1.8618 - val_loss: 6.4197 - val_value_loss: 0.7601 - val_policy_loss: 1.9032\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3248 - value_loss: 0.6189 - policy_loss: 1.8548 - val_loss: 6.4151 - val_value_loss: 0.7536 - val_policy_loss: 1.9007\n",
      "Saved model  connectfour_num_sim_1_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.6 - draw ratio 0.0\n",
      "Number of seen trajectories: 1600\n",
      "Number of unique trajectories: 1600\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 456us/step - loss: 6.5474 - value_loss: 0.9789 - policy_loss: 1.9401 - val_loss: 6.5288 - val_value_loss: 0.9530 - val_policy_loss: 1.9288\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5178 - value_loss: 0.9298 - policy_loss: 1.9300 - val_loss: 6.5167 - val_value_loss: 0.9315 - val_policy_loss: 1.9262\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4910 - value_loss: 0.8853 - policy_loss: 1.9211 - val_loss: 6.5065 - val_value_loss: 0.9136 - val_policy_loss: 1.9238\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4673 - value_loss: 0.8457 - policy_loss: 1.9133 - val_loss: 6.4995 - val_value_loss: 0.9019 - val_policy_loss: 1.9216\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4466 - value_loss: 0.8133 - policy_loss: 1.9044 - val_loss: 6.4894 - val_value_loss: 0.8846 - val_policy_loss: 1.9187\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4299 - value_loss: 0.7847 - policy_loss: 1.8997 - val_loss: 6.4827 - val_value_loss: 0.8731 - val_policy_loss: 1.9169\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4115 - value_loss: 0.7578 - policy_loss: 1.8898 - val_loss: 6.4749 - val_value_loss: 0.8594 - val_policy_loss: 1.9151\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3937 - value_loss: 0.7300 - policy_loss: 1.8821 - val_loss: 6.4688 - val_value_loss: 0.8493 - val_policy_loss: 1.9132\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3801 - value_loss: 0.7087 - policy_loss: 1.8764 - val_loss: 6.4636 - val_value_loss: 0.8411 - val_policy_loss: 1.9110\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3658 - value_loss: 0.6878 - policy_loss: 1.8686 - val_loss: 6.4572 - val_value_loss: 0.8300 - val_policy_loss: 1.9093\n",
      "Saved model  connectfour_num_sim_1_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.65 - draw ratio 0.0\n",
      "Number of seen trajectories: 1700\n",
      "Number of unique trajectories: 1700\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 456us/step - loss: 6.5394 - value_loss: 0.9643 - policy_loss: 1.9395 - val_loss: 6.5413 - val_value_loss: 0.9748 - val_policy_loss: 1.9328\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5107 - value_loss: 0.9172 - policy_loss: 1.9293 - val_loss: 6.5266 - val_value_loss: 0.9503 - val_policy_loss: 1.9281\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4844 - value_loss: 0.8729 - policy_loss: 1.9212 - val_loss: 6.5149 - val_value_loss: 0.9312 - val_policy_loss: 1.9237\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4631 - value_loss: 0.8390 - policy_loss: 1.9124 - val_loss: 6.5057 - val_value_loss: 0.9164 - val_policy_loss: 1.9204\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4410 - value_loss: 0.8032 - policy_loss: 1.9042 - val_loss: 6.4993 - val_value_loss: 0.9061 - val_policy_loss: 1.9178\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4209 - value_loss: 0.7705 - policy_loss: 1.8967 - val_loss: 6.4892 - val_value_loss: 0.8894 - val_policy_loss: 1.9144\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4033 - value_loss: 0.7435 - policy_loss: 1.8886 - val_loss: 6.4816 - val_value_loss: 0.8766 - val_policy_loss: 1.9121\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3860 - value_loss: 0.7168 - policy_loss: 1.8807 - val_loss: 6.4767 - val_value_loss: 0.8700 - val_policy_loss: 1.9091\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3707 - value_loss: 0.6931 - policy_loss: 1.8740 - val_loss: 6.4704 - val_value_loss: 0.8594 - val_policy_loss: 1.9072\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3579 - value_loss: 0.6742 - policy_loss: 1.8674 - val_loss: 6.4645 - val_value_loss: 0.8503 - val_policy_loss: 1.9044\n",
      "Saved model  connectfour_num_sim_1_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.62 - draw ratio 0.0\n",
      "Number of seen trajectories: 1800\n",
      "Number of unique trajectories: 1800\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 456us/step - loss: 6.5530 - value_loss: 0.9886 - policy_loss: 1.9432 - val_loss: 6.5577 - val_value_loss: 0.9886 - val_policy_loss: 1.9527\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5192 - value_loss: 0.9313 - policy_loss: 1.9330 - val_loss: 6.5450 - val_value_loss: 0.9660 - val_policy_loss: 1.9499\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4915 - value_loss: 0.8852 - policy_loss: 1.9238 - val_loss: 6.5330 - val_value_loss: 0.9458 - val_policy_loss: 1.9462\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4664 - value_loss: 0.8435 - policy_loss: 1.9153 - val_loss: 6.5220 - val_value_loss: 0.9274 - val_policy_loss: 1.9427\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4460 - value_loss: 0.8107 - policy_loss: 1.9073 - val_loss: 6.5123 - val_value_loss: 0.9107 - val_policy_loss: 1.9401\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4243 - value_loss: 0.7757 - policy_loss: 1.8991 - val_loss: 6.5041 - val_value_loss: 0.8974 - val_policy_loss: 1.9370\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4066 - value_loss: 0.7489 - policy_loss: 1.8907 - val_loss: 6.4953 - val_value_loss: 0.8823 - val_policy_loss: 1.9346\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3926 - value_loss: 0.7274 - policy_loss: 1.8842 - val_loss: 6.4881 - val_value_loss: 0.8698 - val_policy_loss: 1.9328\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3774 - value_loss: 0.7028 - policy_loss: 1.8784 - val_loss: 6.4811 - val_value_loss: 0.8587 - val_policy_loss: 1.9301\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3612 - value_loss: 0.6782 - policy_loss: 1.8707 - val_loss: 6.4746 - val_value_loss: 0.8476 - val_policy_loss: 1.9282\n",
      "Saved model  connectfour_num_sim_1_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.56 - draw ratio 0.0\n",
      "Number of seen trajectories: 1900\n",
      "Number of unique trajectories: 1900\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.5095 - value_loss: 0.9205 - policy_loss: 1.9250 - val_loss: 6.4871 - val_value_loss: 0.8858 - val_policy_loss: 1.9151\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4761 - value_loss: 0.8639 - policy_loss: 1.9150 - val_loss: 6.4748 - val_value_loss: 0.8657 - val_policy_loss: 1.9107\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4520 - value_loss: 0.8251 - policy_loss: 1.9055 - val_loss: 6.4665 - val_value_loss: 0.8529 - val_policy_loss: 1.9069\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4296 - value_loss: 0.7892 - policy_loss: 1.8968 - val_loss: 6.4561 - val_value_loss: 0.8351 - val_policy_loss: 1.9040\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4108 - value_loss: 0.7595 - policy_loss: 1.8890 - val_loss: 6.4471 - val_value_loss: 0.8203 - val_policy_loss: 1.9009\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3920 - value_loss: 0.7321 - policy_loss: 1.8789 - val_loss: 6.4409 - val_value_loss: 0.8103 - val_policy_loss: 1.8986\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3776 - value_loss: 0.7101 - policy_loss: 1.8722 - val_loss: 6.4329 - val_value_loss: 0.7970 - val_policy_loss: 1.8960\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3617 - value_loss: 0.6871 - policy_loss: 1.8636 - val_loss: 6.4272 - val_value_loss: 0.7874 - val_policy_loss: 1.8942\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3496 - value_loss: 0.6697 - policy_loss: 1.8569 - val_loss: 6.4216 - val_value_loss: 0.7777 - val_policy_loss: 1.8929\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3384 - value_loss: 0.6527 - policy_loss: 1.8513 - val_loss: 6.4152 - val_value_loss: 0.7678 - val_policy_loss: 1.8901\n",
      "Saved model  connectfour_num_sim_1_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.6 - draw ratio 0.0\n",
      "Number of seen trajectories: 2000\n",
      "Number of unique trajectories: 2000\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 2s 456us/step - loss: 6.4843 - value_loss: 0.8816 - policy_loss: 1.9144 - val_loss: 6.5144 - val_value_loss: 0.9401 - val_policy_loss: 1.9160\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4706 - value_loss: 0.8601 - policy_loss: 1.9085 - val_loss: 6.5085 - val_value_loss: 0.9307 - val_policy_loss: 1.9137\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4576 - value_loss: 0.8376 - policy_loss: 1.9050 - val_loss: 6.5031 - val_value_loss: 0.9223 - val_policy_loss: 1.9114\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4461 - value_loss: 0.8203 - policy_loss: 1.8995 - val_loss: 6.4983 - val_value_loss: 0.9145 - val_policy_loss: 1.9097\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4348 - value_loss: 0.8025 - policy_loss: 1.8946 - val_loss: 6.4940 - val_value_loss: 0.9075 - val_policy_loss: 1.9080\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4231 - value_loss: 0.7842 - policy_loss: 1.8897 - val_loss: 6.4900 - val_value_loss: 0.9012 - val_policy_loss: 1.9063\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4154 - value_loss: 0.7719 - policy_loss: 1.8866 - val_loss: 6.4859 - val_value_loss: 0.8949 - val_policy_loss: 1.9047\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4047 - value_loss: 0.7560 - policy_loss: 1.8811 - val_loss: 6.4823 - val_value_loss: 0.8893 - val_policy_loss: 1.9029\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3960 - value_loss: 0.7423 - policy_loss: 1.8775 - val_loss: 6.4785 - val_value_loss: 0.8831 - val_policy_loss: 1.9015\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3895 - value_loss: 0.7324 - policy_loss: 1.8743 - val_loss: 6.4754 - val_value_loss: 0.8785 - val_policy_loss: 1.9001\n",
      "Saved model  connectfour_num_sim_1_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.53 - draw ratio 0.0\n",
      "Number of seen trajectories: 2100\n",
      "Number of unique trajectories: 2100\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.5319 - value_loss: 0.9602 - policy_loss: 1.9314 - val_loss: 6.4987 - val_value_loss: 0.9396 - val_policy_loss: 1.8856\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5164 - value_loss: 0.9356 - policy_loss: 1.9252 - val_loss: 6.4912 - val_value_loss: 0.9265 - val_policy_loss: 1.8838\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5026 - value_loss: 0.9133 - policy_loss: 1.9199 - val_loss: 6.4849 - val_value_loss: 0.9156 - val_policy_loss: 1.8823\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4899 - value_loss: 0.8924 - policy_loss: 1.9154 - val_loss: 6.4789 - val_value_loss: 0.9047 - val_policy_loss: 1.8812\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4754 - value_loss: 0.8692 - policy_loss: 1.9095 - val_loss: 6.4743 - val_value_loss: 0.8966 - val_policy_loss: 1.8800\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4649 - value_loss: 0.8524 - policy_loss: 1.9054 - val_loss: 6.4689 - val_value_loss: 0.8871 - val_policy_loss: 1.8787\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4546 - value_loss: 0.8352 - policy_loss: 1.9021 - val_loss: 6.4637 - val_value_loss: 0.8777 - val_policy_loss: 1.8779\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4441 - value_loss: 0.8187 - policy_loss: 1.8976 - val_loss: 6.4593 - val_value_loss: 0.8698 - val_policy_loss: 1.8769\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4339 - value_loss: 0.8021 - policy_loss: 1.8938 - val_loss: 6.4549 - val_value_loss: 0.8621 - val_policy_loss: 1.8759\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4232 - value_loss: 0.7836 - policy_loss: 1.8910 - val_loss: 6.4503 - val_value_loss: 0.8540 - val_policy_loss: 1.8749\n",
      "Saved model  connectfour_num_sim_1_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.54 - draw ratio 0.0\n",
      "Number of seen trajectories: 2200\n",
      "Number of unique trajectories: 2200\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5697 - value_loss: 1.0281 - policy_loss: 1.9395 - val_loss: 6.5765 - val_value_loss: 1.0439 - val_policy_loss: 1.9373\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5500 - value_loss: 0.9944 - policy_loss: 1.9339 - val_loss: 6.5703 - val_value_loss: 1.0326 - val_policy_loss: 1.9363\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5345 - value_loss: 0.9688 - policy_loss: 1.9284 - val_loss: 6.5640 - val_value_loss: 1.0209 - val_policy_loss: 1.9355\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5199 - value_loss: 0.9440 - policy_loss: 1.9242 - val_loss: 6.5577 - val_value_loss: 1.0094 - val_policy_loss: 1.9344\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5099 - value_loss: 0.9276 - policy_loss: 1.9206 - val_loss: 6.5506 - val_value_loss: 0.9962 - val_policy_loss: 1.9333\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4954 - value_loss: 0.9046 - policy_loss: 1.9147 - val_loss: 6.5455 - val_value_loss: 0.9873 - val_policy_loss: 1.9321\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4854 - value_loss: 0.8882 - policy_loss: 1.9110 - val_loss: 6.5411 - val_value_loss: 0.9796 - val_policy_loss: 1.9311\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4748 - value_loss: 0.8704 - policy_loss: 1.9078 - val_loss: 6.5346 - val_value_loss: 0.9680 - val_policy_loss: 1.9298\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4644 - value_loss: 0.8541 - policy_loss: 1.9031 - val_loss: 6.5295 - val_value_loss: 0.9591 - val_policy_loss: 1.9285\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4546 - value_loss: 0.8378 - policy_loss: 1.9000 - val_loss: 6.5253 - val_value_loss: 0.9519 - val_policy_loss: 1.9274\n",
      "Saved model  connectfour_num_sim_1_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.47 - draw ratio 0.0\n",
      "Number of seen trajectories: 2300\n",
      "Number of unique trajectories: 2300\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.5865 - value_loss: 1.0500 - policy_loss: 1.9517 - val_loss: 6.5818 - val_value_loss: 1.0435 - val_policy_loss: 1.9487\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5676 - value_loss: 1.0197 - policy_loss: 1.9443 - val_loss: 6.5745 - val_value_loss: 1.0314 - val_policy_loss: 1.9463\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5537 - value_loss: 0.9954 - policy_loss: 1.9408 - val_loss: 6.5670 - val_value_loss: 1.0184 - val_policy_loss: 1.9443\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5381 - value_loss: 0.9710 - policy_loss: 1.9339 - val_loss: 6.5595 - val_value_loss: 1.0055 - val_policy_loss: 1.9424\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5248 - value_loss: 0.9487 - policy_loss: 1.9297 - val_loss: 6.5526 - val_value_loss: 0.9936 - val_policy_loss: 1.9404\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5119 - value_loss: 0.9275 - policy_loss: 1.9252 - val_loss: 6.5469 - val_value_loss: 0.9840 - val_policy_loss: 1.9386\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4987 - value_loss: 0.9062 - policy_loss: 1.9201 - val_loss: 6.5415 - val_value_loss: 0.9752 - val_policy_loss: 1.9368\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4869 - value_loss: 0.8876 - policy_loss: 1.9151 - val_loss: 6.5356 - val_value_loss: 0.9653 - val_policy_loss: 1.9349\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4768 - value_loss: 0.8715 - policy_loss: 1.9110 - val_loss: 6.5309 - val_value_loss: 0.9573 - val_policy_loss: 1.9335\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4656 - value_loss: 0.8532 - policy_loss: 1.9069 - val_loss: 6.5255 - val_value_loss: 0.9480 - val_policy_loss: 1.9320\n",
      "Saved model  connectfour_num_sim_1_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.62 - draw ratio 0.0\n",
      "Number of seen trajectories: 2400\n",
      "Number of unique trajectories: 2400\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.5723 - value_loss: 1.0355 - policy_loss: 1.9382 - val_loss: 6.5671 - val_value_loss: 1.0406 - val_policy_loss: 1.9226\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5533 - value_loss: 1.0025 - policy_loss: 1.9332 - val_loss: 6.5589 - val_value_loss: 1.0259 - val_policy_loss: 1.9211\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5363 - value_loss: 0.9743 - policy_loss: 1.9275 - val_loss: 6.5517 - val_value_loss: 1.0131 - val_policy_loss: 1.9194\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5227 - value_loss: 0.9509 - policy_loss: 1.9238 - val_loss: 6.5451 - val_value_loss: 1.0015 - val_policy_loss: 1.9179\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5098 - value_loss: 0.9289 - policy_loss: 1.9200 - val_loss: 6.5387 - val_value_loss: 0.9901 - val_policy_loss: 1.9165\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4964 - value_loss: 0.9067 - policy_loss: 1.9155 - val_loss: 6.5328 - val_value_loss: 0.9797 - val_policy_loss: 1.9152\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4815 - value_loss: 0.8820 - policy_loss: 1.9104 - val_loss: 6.5275 - val_value_loss: 0.9707 - val_policy_loss: 1.9137\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4695 - value_loss: 0.8622 - policy_loss: 1.9062 - val_loss: 6.5223 - val_value_loss: 0.9613 - val_policy_loss: 1.9126\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4588 - value_loss: 0.8445 - policy_loss: 1.9026 - val_loss: 6.5174 - val_value_loss: 0.9529 - val_policy_loss: 1.9112\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4474 - value_loss: 0.8255 - policy_loss: 1.8988 - val_loss: 6.5125 - val_value_loss: 0.9444 - val_policy_loss: 1.9100\n",
      "Saved model  connectfour_num_sim_1_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.56 - draw ratio 0.0\n",
      "Number of seen trajectories: 2500\n",
      "Number of unique trajectories: 2500\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.5628 - value_loss: 1.0194 - policy_loss: 1.9357 - val_loss: 6.5634 - val_value_loss: 1.0436 - val_policy_loss: 1.9126\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5547 - value_loss: 1.0066 - policy_loss: 1.9323 - val_loss: 6.5594 - val_value_loss: 1.0363 - val_policy_loss: 1.9119\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5455 - value_loss: 0.9914 - policy_loss: 1.9290 - val_loss: 6.5557 - val_value_loss: 1.0295 - val_policy_loss: 1.9114\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5364 - value_loss: 0.9751 - policy_loss: 1.9272 - val_loss: 6.5521 - val_value_loss: 1.0231 - val_policy_loss: 1.9107\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5289 - value_loss: 0.9625 - policy_loss: 1.9248 - val_loss: 6.5490 - val_value_loss: 1.0173 - val_policy_loss: 1.9102\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5221 - value_loss: 0.9517 - policy_loss: 1.9221 - val_loss: 6.5463 - val_value_loss: 1.0124 - val_policy_loss: 1.9097\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5148 - value_loss: 0.9388 - policy_loss: 1.9203 - val_loss: 6.5432 - val_value_loss: 1.0068 - val_policy_loss: 1.9092\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.5073 - value_loss: 0.9270 - policy_loss: 1.9172 - val_loss: 6.5403 - val_value_loss: 1.0015 - val_policy_loss: 1.9086\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.5016 - value_loss: 0.9174 - policy_loss: 1.9154 - val_loss: 6.5377 - val_value_loss: 0.9969 - val_policy_loss: 1.9080\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4965 - value_loss: 0.9088 - policy_loss: 1.9139 - val_loss: 6.5354 - val_value_loss: 0.9929 - val_policy_loss: 1.9075\n",
      "Saved model  connectfour_num_sim_1_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.56 - draw ratio 0.0\n",
      "Number of seen trajectories: 2600\n",
      "Number of unique trajectories: 2600\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5640 - value_loss: 1.0162 - policy_loss: 1.9415 - val_loss: 6.5767 - val_value_loss: 1.0402 - val_policy_loss: 1.9428\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5549 - value_loss: 1.0015 - policy_loss: 1.9380 - val_loss: 6.5711 - val_value_loss: 1.0298 - val_policy_loss: 1.9419\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5472 - value_loss: 0.9878 - policy_loss: 1.9362 - val_loss: 6.5659 - val_value_loss: 1.0204 - val_policy_loss: 1.9411\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5391 - value_loss: 0.9743 - policy_loss: 1.9337 - val_loss: 6.5617 - val_value_loss: 1.0127 - val_policy_loss: 1.9403\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5307 - value_loss: 0.9603 - policy_loss: 1.9310 - val_loss: 6.5574 - val_value_loss: 1.0050 - val_policy_loss: 1.9395\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5266 - value_loss: 0.9536 - policy_loss: 1.9294 - val_loss: 6.5532 - val_value_loss: 0.9975 - val_policy_loss: 1.9387\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5162 - value_loss: 0.9352 - policy_loss: 1.9269 - val_loss: 6.5491 - val_value_loss: 0.9900 - val_policy_loss: 1.9380\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5112 - value_loss: 0.9280 - policy_loss: 1.9242 - val_loss: 6.5453 - val_value_loss: 0.9831 - val_policy_loss: 1.9372\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5031 - value_loss: 0.9144 - policy_loss: 1.9217 - val_loss: 6.5416 - val_value_loss: 0.9766 - val_policy_loss: 1.9365\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4971 - value_loss: 0.9038 - policy_loss: 1.9203 - val_loss: 6.5381 - val_value_loss: 0.9702 - val_policy_loss: 1.9358\n",
      "Saved model  connectfour_num_sim_1_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.42 - draw ratio 0.0\n",
      "Number of seen trajectories: 2700\n",
      "Number of unique trajectories: 2700\n",
      "iteration 27 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.5732 - value_loss: 1.0333 - policy_loss: 1.9431 - val_loss: 6.5612 - val_value_loss: 1.0275 - val_policy_loss: 1.9248\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5648 - value_loss: 1.0193 - policy_loss: 1.9401 - val_loss: 6.5567 - val_value_loss: 1.0194 - val_policy_loss: 1.9239\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5557 - value_loss: 1.0037 - policy_loss: 1.9376 - val_loss: 6.5529 - val_value_loss: 1.0125 - val_policy_loss: 1.9232\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5489 - value_loss: 0.9918 - policy_loss: 1.9358 - val_loss: 6.5494 - val_value_loss: 1.0063 - val_policy_loss: 1.9224\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5420 - value_loss: 0.9797 - policy_loss: 1.9342 - val_loss: 6.5460 - val_value_loss: 1.0003 - val_policy_loss: 1.9217\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5342 - value_loss: 0.9671 - policy_loss: 1.9314 - val_loss: 6.5428 - val_value_loss: 0.9947 - val_policy_loss: 1.9209\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5254 - value_loss: 0.9526 - policy_loss: 1.9283 - val_loss: 6.5398 - val_value_loss: 0.9894 - val_policy_loss: 1.9202\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5208 - value_loss: 0.9448 - policy_loss: 1.9268 - val_loss: 6.5369 - val_value_loss: 0.9843 - val_policy_loss: 1.9196\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5136 - value_loss: 0.9325 - policy_loss: 1.9247 - val_loss: 6.5342 - val_value_loss: 0.9795 - val_policy_loss: 1.9189\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5064 - value_loss: 0.9209 - policy_loss: 1.9219 - val_loss: 6.5313 - val_value_loss: 0.9745 - val_policy_loss: 1.9182\n",
      "Saved model  connectfour_num_sim_1_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.48 - draw ratio 0.0\n",
      "Number of seen trajectories: 2800\n",
      "Number of unique trajectories: 2800\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5838 - value_loss: 1.0382 - policy_loss: 1.9594 - val_loss: 6.5737 - val_value_loss: 1.0416 - val_policy_loss: 1.9358\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5726 - value_loss: 1.0206 - policy_loss: 1.9547 - val_loss: 6.5695 - val_value_loss: 1.0344 - val_policy_loss: 1.9348\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5630 - value_loss: 1.0042 - policy_loss: 1.9518 - val_loss: 6.5661 - val_value_loss: 1.0286 - val_policy_loss: 1.9337\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5552 - value_loss: 0.9921 - policy_loss: 1.9484 - val_loss: 6.5628 - val_value_loss: 1.0231 - val_policy_loss: 1.9327\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5473 - value_loss: 0.9791 - policy_loss: 1.9456 - val_loss: 6.5595 - val_value_loss: 1.0173 - val_policy_loss: 1.9318\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5400 - value_loss: 0.9660 - policy_loss: 1.9442 - val_loss: 6.5564 - val_value_loss: 1.0121 - val_policy_loss: 1.9309\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5341 - value_loss: 0.9566 - policy_loss: 1.9418 - val_loss: 6.5532 - val_value_loss: 1.0066 - val_policy_loss: 1.9301\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5272 - value_loss: 0.9451 - policy_loss: 1.9395 - val_loss: 6.5504 - val_value_loss: 1.0018 - val_policy_loss: 1.9293\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5223 - value_loss: 0.9379 - policy_loss: 1.9370 - val_loss: 6.5472 - val_value_loss: 0.9962 - val_policy_loss: 1.9285\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5177 - value_loss: 0.9299 - policy_loss: 1.9357 - val_loss: 6.5446 - val_value_loss: 0.9918 - val_policy_loss: 1.9276\n",
      "Saved model  connectfour_num_sim_1_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.53 - draw ratio 0.0\n",
      "Number of seen trajectories: 2900\n",
      "Number of unique trajectories: 2900\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_1_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.5736 - value_loss: 1.0531 - policy_loss: 1.9244 - val_loss: 6.5839 - val_value_loss: 1.0623 - val_policy_loss: 1.9358\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5636 - value_loss: 1.0357 - policy_loss: 1.9218 - val_loss: 6.5786 - val_value_loss: 1.0531 - val_policy_loss: 1.9345\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5560 - value_loss: 1.0232 - policy_loss: 1.9192 - val_loss: 6.5738 - val_value_loss: 1.0446 - val_policy_loss: 1.9335\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5481 - value_loss: 1.0103 - policy_loss: 1.9163 - val_loss: 6.5694 - val_value_loss: 1.0366 - val_policy_loss: 1.9325\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5413 - value_loss: 0.9992 - policy_loss: 1.9138 - val_loss: 6.5655 - val_value_loss: 1.0298 - val_policy_loss: 1.9316\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5349 - value_loss: 0.9886 - policy_loss: 1.9115 - val_loss: 6.5619 - val_value_loss: 1.0235 - val_policy_loss: 1.9307\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5260 - value_loss: 0.9745 - policy_loss: 1.9080 - val_loss: 6.5583 - val_value_loss: 1.0172 - val_policy_loss: 1.9299\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5205 - value_loss: 0.9647 - policy_loss: 1.9066 - val_loss: 6.5548 - val_value_loss: 1.0111 - val_policy_loss: 1.9291\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5131 - value_loss: 0.9525 - policy_loss: 1.9042 - val_loss: 6.5514 - val_value_loss: 1.0050 - val_policy_loss: 1.9283\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5070 - value_loss: 0.9424 - policy_loss: 1.9020 - val_loss: 6.5482 - val_value_loss: 0.9992 - val_policy_loss: 1.9276\n",
      "Saved model  connectfour_num_sim_1_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.65 - draw ratio 0.0\n",
      "Number of seen trajectories: 3000\n",
      "Number of unique trajectories: 3000\n"
     ]
    }
   ],
   "source": [
    "wins_1, draws_1, seen_trajectories_1, unique_trajectories_1 = test_pipeline.run(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - 1 simulation\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "losses_1 = np.ones(30) - wins_1 - draws_1\n",
    "\n",
    "plt.plot(x, wins_1, label=\"win ratio\")\n",
    "plt.plot(x, draws_1, label=\"draw ratio\")\n",
    "plt.plot(x, losses_1, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "exploration_rate_1 = unique_trajectories_1/seen_trajectories_1\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - 1 simulation\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "\n",
    "plt.plot(x, exploration_rate_1, label=\"unique/seen\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins_1 = [0.67, 0.51, 0.62, 0.54, 0.5, 0.63, 0.58, 0.56, 0.61, 0.53, 0.63, 0.52, 0.43, 0.55, 0.57, 0.6, 0.65, 0.62, 0.56, 0.6, 0.53, 0.54, 0.47, 0.62, 0.56, 0.56, 0.42, 0.48, 0.53, 0.65]\n",
      "draws_1 = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "seen_trajectories_1 = [ 100.  200.  300.  400.  500.  600.  700.  800.  900. 1000. 1100. 1200.\n",
      " 1300. 1400. 1500. 1600. 1700. 1800. 1900. 2000. 2100. 2200. 2300. 2400.\n",
      " 2500. 2600. 2700. 2800. 2900. 3000.]\n",
      "unique_trajectories_1 = [ 100.  200.  300.  400.  500.  600.  700.  800.  900. 1000. 1100. 1200.\n",
      " 1300. 1400. 1500. 1600. 1700. 1800. 1900. 2000. 2100. 2200. 2300. 2400.\n",
      " 2500. 2600. 2700. 2800. 2900. 3000.]\n"
     ]
    }
   ],
   "source": [
    "print(\"wins_1 =\",wins_1)\n",
    "print(\"draws_1 =\",draws_1)\n",
    "print(\"seen_trajectories_1 =\", seen_trajectories_1)\n",
    "print(\"unique_trajectories_1 =\", unique_trajectories_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCTS = {\n",
    "    'c_puct': 1,\n",
    "    'dir_alpha': 0.6,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 10,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 10\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 5,\n",
    "    'temperature': 0,\n",
    "    'show_games': False\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 5,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.002,\n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 512,\n",
    "    'num_filters_value': 512,\n",
    "    'num_filters_tower': 512,\n",
    "    'num_residual_blocks': 3,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 512\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"connectfour_num_sim_5\", \"Connect4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (3010, 6, 7, 3)\n",
      "model_y_outcomes: (3010,)\n",
      "model_y_probabilities: (3010, 7)\n",
      "Train on 2408 samples, validate on 602 samples\n",
      "Epoch 1/10\n",
      "2408/2408 [==============================] - 5s 2ms/step - loss: 6.8313 - value_loss: 1.2732 - policy_loss: 2.1540 - val_loss: 6.9646 - val_value_loss: 1.6093 - val_policy_loss: 2.0847\n",
      "Epoch 2/10\n",
      "2408/2408 [==============================] - 1s 463us/step - loss: 6.6964 - value_loss: 1.0887 - policy_loss: 2.0691 - val_loss: 7.0982 - val_value_loss: 1.8944 - val_policy_loss: 2.0673\n",
      "Epoch 3/10\n",
      "2408/2408 [==============================] - 1s 457us/step - loss: 6.6831 - value_loss: 1.0940 - policy_loss: 2.0377 - val_loss: 6.7595 - val_value_loss: 1.2271 - val_policy_loss: 2.0578\n",
      "Epoch 4/10\n",
      "2408/2408 [==============================] - 1s 457us/step - loss: 6.7146 - value_loss: 1.1764 - policy_loss: 2.0186 - val_loss: 6.9061 - val_value_loss: 1.5291 - val_policy_loss: 2.0492\n",
      "Epoch 5/10\n",
      "2408/2408 [==============================] - 1s 457us/step - loss: 6.5773 - value_loss: 0.9235 - policy_loss: 1.9973 - val_loss: 7.0380 - val_value_loss: 1.7953 - val_policy_loss: 2.0473\n",
      "Epoch 6/10\n",
      "2408/2408 [==============================] - 1s 457us/step - loss: 6.4837 - value_loss: 0.7501 - policy_loss: 1.9840 - val_loss: 6.9345 - val_value_loss: 1.5866 - val_policy_loss: 2.0493\n",
      "Epoch 7/10\n",
      "2408/2408 [==============================] - 1s 458us/step - loss: 6.4973 - value_loss: 0.7921 - policy_loss: 1.9698 - val_loss: 6.7648 - val_value_loss: 1.2525 - val_policy_loss: 2.0446\n",
      "Epoch 8/10\n",
      "2408/2408 [==============================] - 1s 459us/step - loss: 6.4999 - value_loss: 0.8093 - policy_loss: 1.9580 - val_loss: 6.7265 - val_value_loss: 1.1770 - val_policy_loss: 2.0439\n",
      "Epoch 9/10\n",
      "2408/2408 [==============================] - 1s 459us/step - loss: 6.4897 - value_loss: 0.7988 - policy_loss: 1.9484 - val_loss: 6.7739 - val_value_loss: 1.2747 - val_policy_loss: 2.0413\n",
      "Epoch 10/10\n",
      "2408/2408 [==============================] - 1s 459us/step - loss: 6.3250 - value_loss: 0.4822 - policy_loss: 1.9361 - val_loss: 6.8767 - val_value_loss: 1.4821 - val_policy_loss: 2.0398\n",
      "Saved model  connectfour_num_sim_5_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.72 - draw ratio 0.0\n",
      "Number of seen trajectories: 100\n",
      "Number of unique trajectories: 100\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.6435 - value_loss: 1.0612 - policy_loss: 1.9948 - val_loss: 6.4800 - val_value_loss: 0.7481 - val_policy_loss: 1.9812\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5413 - value_loss: 0.8900 - policy_loss: 1.9621 - val_loss: 6.4980 - val_value_loss: 0.8031 - val_policy_loss: 1.9628\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5217 - value_loss: 0.8766 - policy_loss: 1.9370 - val_loss: 6.5639 - val_value_loss: 0.9417 - val_policy_loss: 1.9567\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4707 - value_loss: 0.7961 - policy_loss: 1.9162 - val_loss: 6.5111 - val_value_loss: 0.8476 - val_policy_loss: 1.9458\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4034 - value_loss: 0.6806 - policy_loss: 1.8977 - val_loss: 6.4810 - val_value_loss: 0.7952 - val_policy_loss: 1.9388\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3936 - value_loss: 0.6768 - policy_loss: 1.8826 - val_loss: 6.4164 - val_value_loss: 0.6719 - val_policy_loss: 1.9334\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3031 - value_loss: 0.5097 - policy_loss: 1.8693 - val_loss: 6.3965 - val_value_loss: 0.6413 - val_policy_loss: 1.9248\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2498 - value_loss: 0.4163 - policy_loss: 1.8568 - val_loss: 6.3699 - val_value_loss: 0.5958 - val_policy_loss: 1.9178\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3408 - value_loss: 0.6087 - policy_loss: 1.8470 - val_loss: 6.3527 - val_value_loss: 0.5672 - val_policy_loss: 1.9127\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2163 - value_loss: 0.3728 - policy_loss: 1.8345 - val_loss: 6.3390 - val_value_loss: 0.5448 - val_policy_loss: 1.9083\n",
      "Saved model  connectfour_num_sim_5_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.55 - draw ratio 0.0\n",
      "Number of seen trajectories: 200\n",
      "Number of unique trajectories: 200\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 457us/step - loss: 6.5064 - value_loss: 0.8205 - policy_loss: 1.9677 - val_loss: 6.5318 - val_value_loss: 0.8828 - val_policy_loss: 1.9566\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5266 - value_loss: 0.8860 - policy_loss: 1.9432 - val_loss: 6.4362 - val_value_loss: 0.6958 - val_policy_loss: 1.9530\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3796 - value_loss: 0.6124 - policy_loss: 1.9235 - val_loss: 6.5273 - val_value_loss: 0.8897 - val_policy_loss: 1.9420\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4127 - value_loss: 0.6957 - policy_loss: 1.9070 - val_loss: 6.5160 - val_value_loss: 0.8748 - val_policy_loss: 1.9350\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3657 - value_loss: 0.6161 - policy_loss: 1.8934 - val_loss: 6.4330 - val_value_loss: 0.7134 - val_policy_loss: 1.9311\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3251 - value_loss: 0.5508 - policy_loss: 1.8781 - val_loss: 6.4564 - val_value_loss: 0.7647 - val_policy_loss: 1.9270\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3150 - value_loss: 0.5438 - policy_loss: 1.8654 - val_loss: 6.3713 - val_value_loss: 0.6029 - val_policy_loss: 1.9193\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2399 - value_loss: 0.4046 - policy_loss: 1.8551 - val_loss: 6.3543 - val_value_loss: 0.5739 - val_policy_loss: 1.9150\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2261 - value_loss: 0.3884 - policy_loss: 1.8444 - val_loss: 6.3582 - val_value_loss: 0.5850 - val_policy_loss: 1.9124\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2327 - value_loss: 0.4124 - policy_loss: 1.8343 - val_loss: 6.3551 - val_value_loss: 0.5845 - val_policy_loss: 1.9072\n",
      "Saved model  connectfour_num_sim_5_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.68 - draw ratio 0.0\n",
      "Number of seen trajectories: 300\n",
      "Number of unique trajectories: 300\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.4927 - value_loss: 0.8232 - policy_loss: 1.9440 - val_loss: 6.5743 - val_value_loss: 0.9706 - val_policy_loss: 1.9603\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4981 - value_loss: 0.8598 - policy_loss: 1.9190 - val_loss: 6.5554 - val_value_loss: 0.9381 - val_policy_loss: 1.9555\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4178 - value_loss: 0.7186 - policy_loss: 1.9002 - val_loss: 6.4686 - val_value_loss: 0.7745 - val_policy_loss: 1.9462\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3246 - value_loss: 0.5513 - policy_loss: 1.8817 - val_loss: 6.4478 - val_value_loss: 0.7406 - val_policy_loss: 1.9392\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3768 - value_loss: 0.6713 - policy_loss: 1.8667 - val_loss: 6.4866 - val_value_loss: 0.8180 - val_policy_loss: 1.9401\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3091 - value_loss: 0.5514 - policy_loss: 1.8519 - val_loss: 6.4457 - val_value_loss: 0.7449 - val_policy_loss: 1.9321\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2568 - value_loss: 0.4591 - policy_loss: 1.8401 - val_loss: 6.4093 - val_value_loss: 0.6812 - val_policy_loss: 1.9235\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2384 - value_loss: 0.4340 - policy_loss: 1.8292 - val_loss: 6.4513 - val_value_loss: 0.7719 - val_policy_loss: 1.9174\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2519 - value_loss: 0.4748 - policy_loss: 1.8160 - val_loss: 6.4131 - val_value_loss: 0.6978 - val_policy_loss: 1.9157\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2082 - value_loss: 0.3937 - policy_loss: 1.8104 - val_loss: 6.3995 - val_value_loss: 0.6710 - val_policy_loss: 1.9160\n",
      "Saved model  connectfour_num_sim_5_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.59 - draw ratio 0.0\n",
      "Number of seen trajectories: 400\n",
      "Number of unique trajectories: 400\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.5205 - value_loss: 0.8803 - policy_loss: 1.9491 - val_loss: 6.4818 - val_value_loss: 0.8220 - val_policy_loss: 1.9303\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4147 - value_loss: 0.6945 - policy_loss: 1.9238 - val_loss: 6.4484 - val_value_loss: 0.7603 - val_policy_loss: 1.9259\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3939 - value_loss: 0.6741 - policy_loss: 1.9034 - val_loss: 6.4717 - val_value_loss: 0.8192 - val_policy_loss: 1.9143\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3273 - value_loss: 0.5590 - policy_loss: 1.8858 - val_loss: 6.4399 - val_value_loss: 0.7619 - val_policy_loss: 1.9086\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3382 - value_loss: 0.5967 - policy_loss: 1.8707 - val_loss: 6.4124 - val_value_loss: 0.7131 - val_policy_loss: 1.9030\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2661 - value_loss: 0.4657 - policy_loss: 1.8580 - val_loss: 6.3859 - val_value_loss: 0.6673 - val_policy_loss: 1.8964\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2448 - value_loss: 0.4378 - policy_loss: 1.8439 - val_loss: 6.3807 - val_value_loss: 0.6611 - val_policy_loss: 1.8929\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2434 - value_loss: 0.4454 - policy_loss: 1.8343 - val_loss: 6.3742 - val_value_loss: 0.6552 - val_policy_loss: 1.8865\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2214 - value_loss: 0.4146 - policy_loss: 1.8218 - val_loss: 6.3550 - val_value_loss: 0.6200 - val_policy_loss: 1.8839\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.1911 - value_loss: 0.3652 - policy_loss: 1.8112 - val_loss: 6.3493 - val_value_loss: 0.6129 - val_policy_loss: 1.8802\n",
      "Saved model  connectfour_num_sim_5_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.57 - draw ratio 0.0\n",
      "Number of seen trajectories: 500\n",
      "Number of unique trajectories: 500\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4794 - value_loss: 0.8114 - policy_loss: 1.9420 - val_loss: 6.4726 - val_value_loss: 0.8057 - val_policy_loss: 1.9345\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4233 - value_loss: 0.7148 - policy_loss: 1.9269 - val_loss: 6.4486 - val_value_loss: 0.7629 - val_policy_loss: 1.9294\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3831 - value_loss: 0.6480 - policy_loss: 1.9136 - val_loss: 6.4359 - val_value_loss: 0.7426 - val_policy_loss: 1.9246\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3540 - value_loss: 0.6003 - policy_loss: 1.9033 - val_loss: 6.4213 - val_value_loss: 0.7183 - val_policy_loss: 1.9201\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3279 - value_loss: 0.5595 - policy_loss: 1.8921 - val_loss: 6.4110 - val_value_loss: 0.7021 - val_policy_loss: 1.9160\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3070 - value_loss: 0.5271 - policy_loss: 1.8832 - val_loss: 6.4021 - val_value_loss: 0.6881 - val_policy_loss: 1.9126\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2905 - value_loss: 0.5023 - policy_loss: 1.8753 - val_loss: 6.3925 - val_value_loss: 0.6727 - val_policy_loss: 1.9091\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2769 - value_loss: 0.4839 - policy_loss: 1.8669 - val_loss: 6.3903 - val_value_loss: 0.6712 - val_policy_loss: 1.9065\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2634 - value_loss: 0.4636 - policy_loss: 1.8604 - val_loss: 6.3829 - val_value_loss: 0.6597 - val_policy_loss: 1.9036\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2456 - value_loss: 0.4373 - policy_loss: 1.8515 - val_loss: 6.3773 - val_value_loss: 0.6510 - val_policy_loss: 1.9014\n",
      "Saved model  connectfour_num_sim_5_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.59 - draw ratio 0.0\n",
      "Number of seen trajectories: 600\n",
      "Number of unique trajectories: 600\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 456us/step - loss: 6.4669 - value_loss: 0.8102 - policy_loss: 1.9214 - val_loss: 6.4684 - val_value_loss: 0.8081 - val_policy_loss: 1.9267\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4129 - value_loss: 0.7157 - policy_loss: 1.9083 - val_loss: 6.4517 - val_value_loss: 0.7806 - val_policy_loss: 1.9213\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3761 - value_loss: 0.6550 - policy_loss: 1.8958 - val_loss: 6.4376 - val_value_loss: 0.7570 - val_policy_loss: 1.9170\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3449 - value_loss: 0.6041 - policy_loss: 1.8846 - val_loss: 6.4272 - val_value_loss: 0.7387 - val_policy_loss: 1.9148\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3206 - value_loss: 0.5647 - policy_loss: 1.8758 - val_loss: 6.4182 - val_value_loss: 0.7230 - val_policy_loss: 1.9128\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2985 - value_loss: 0.5298 - policy_loss: 1.8666 - val_loss: 6.4106 - val_value_loss: 0.7116 - val_policy_loss: 1.9092\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2810 - value_loss: 0.5041 - policy_loss: 1.8578 - val_loss: 6.4016 - val_value_loss: 0.6968 - val_policy_loss: 1.9063\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2711 - value_loss: 0.4908 - policy_loss: 1.8515 - val_loss: 6.3990 - val_value_loss: 0.6939 - val_policy_loss: 1.9044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2496 - value_loss: 0.4579 - policy_loss: 1.8417 - val_loss: 6.4002 - val_value_loss: 0.7001 - val_policy_loss: 1.9008\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2397 - value_loss: 0.4445 - policy_loss: 1.8358 - val_loss: 6.3877 - val_value_loss: 0.6770 - val_policy_loss: 1.8994\n",
      "Saved model  connectfour_num_sim_5_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.64 - draw ratio 0.0\n",
      "Number of seen trajectories: 700\n",
      "Number of unique trajectories: 700\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4740 - value_loss: 0.8306 - policy_loss: 1.9185 - val_loss: 6.4654 - val_value_loss: 0.8211 - val_policy_loss: 1.9109\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4156 - value_loss: 0.7278 - policy_loss: 1.9048 - val_loss: 6.4574 - val_value_loss: 0.8086 - val_policy_loss: 1.9078\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3711 - value_loss: 0.6505 - policy_loss: 1.8934 - val_loss: 6.4419 - val_value_loss: 0.7810 - val_policy_loss: 1.9046\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3363 - value_loss: 0.5926 - policy_loss: 1.8821 - val_loss: 6.4309 - val_value_loss: 0.7623 - val_policy_loss: 1.9019\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3159 - value_loss: 0.5613 - policy_loss: 1.8730 - val_loss: 6.4326 - val_value_loss: 0.7682 - val_policy_loss: 1.8995\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2978 - value_loss: 0.5343 - policy_loss: 1.8642 - val_loss: 6.4182 - val_value_loss: 0.7424 - val_policy_loss: 1.8969\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2740 - value_loss: 0.4945 - policy_loss: 1.8565 - val_loss: 6.4104 - val_value_loss: 0.7311 - val_policy_loss: 1.8929\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2566 - value_loss: 0.4684 - policy_loss: 1.8481 - val_loss: 6.4079 - val_value_loss: 0.7281 - val_policy_loss: 1.8913\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2424 - value_loss: 0.4480 - policy_loss: 1.8405 - val_loss: 6.4012 - val_value_loss: 0.7175 - val_policy_loss: 1.8888\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2311 - value_loss: 0.4328 - policy_loss: 1.8334 - val_loss: 6.4000 - val_value_loss: 0.7180 - val_policy_loss: 1.8861\n",
      "Saved model  connectfour_num_sim_5_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.69 - draw ratio 0.0\n",
      "Number of seen trajectories: 800\n",
      "Number of unique trajectories: 800\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4699 - value_loss: 0.8400 - policy_loss: 1.9041 - val_loss: 6.4603 - val_value_loss: 0.8095 - val_policy_loss: 1.9156\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4167 - value_loss: 0.7481 - policy_loss: 1.8899 - val_loss: 6.4367 - val_value_loss: 0.7671 - val_policy_loss: 1.9112\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3746 - value_loss: 0.6756 - policy_loss: 1.8786 - val_loss: 6.4256 - val_value_loss: 0.7498 - val_policy_loss: 1.9065\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3398 - value_loss: 0.6166 - policy_loss: 1.8684 - val_loss: 6.4109 - val_value_loss: 0.7247 - val_policy_loss: 1.9026\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3130 - value_loss: 0.5733 - policy_loss: 1.8584 - val_loss: 6.4008 - val_value_loss: 0.7088 - val_policy_loss: 1.8987\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2901 - value_loss: 0.5368 - policy_loss: 1.8493 - val_loss: 6.3910 - val_value_loss: 0.6917 - val_policy_loss: 1.8965\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2716 - value_loss: 0.5092 - policy_loss: 1.8403 - val_loss: 6.3817 - val_value_loss: 0.6775 - val_policy_loss: 1.8924\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2576 - value_loss: 0.4879 - policy_loss: 1.8338 - val_loss: 6.3800 - val_value_loss: 0.6768 - val_policy_loss: 1.8900\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2463 - value_loss: 0.4734 - policy_loss: 1.8261 - val_loss: 6.3738 - val_value_loss: 0.6667 - val_policy_loss: 1.8881\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2397 - value_loss: 0.4669 - policy_loss: 1.8197 - val_loss: 6.3777 - val_value_loss: 0.6782 - val_policy_loss: 1.8846\n",
      "Saved model  connectfour_num_sim_5_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.62 - draw ratio 0.0\n",
      "Number of seen trajectories: 900\n",
      "Number of unique trajectories: 900\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4705 - value_loss: 0.8468 - policy_loss: 1.9018 - val_loss: 6.4553 - val_value_loss: 0.8206 - val_policy_loss: 1.8977\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4096 - value_loss: 0.7396 - policy_loss: 1.8876 - val_loss: 6.4399 - val_value_loss: 0.7959 - val_policy_loss: 1.8920\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3708 - value_loss: 0.6737 - policy_loss: 1.8760 - val_loss: 6.4352 - val_value_loss: 0.7894 - val_policy_loss: 1.8894\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3409 - value_loss: 0.6245 - policy_loss: 1.8659 - val_loss: 6.4187 - val_value_loss: 0.7586 - val_policy_loss: 1.8876\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3105 - value_loss: 0.5753 - policy_loss: 1.8545 - val_loss: 6.4049 - val_value_loss: 0.7329 - val_policy_loss: 1.8859\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2914 - value_loss: 0.5463 - policy_loss: 1.8457 - val_loss: 6.3988 - val_value_loss: 0.7244 - val_policy_loss: 1.8825\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2621 - value_loss: 0.4969 - policy_loss: 1.8368 - val_loss: 6.3889 - val_value_loss: 0.7075 - val_policy_loss: 1.8800\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2489 - value_loss: 0.4792 - policy_loss: 1.8284 - val_loss: 6.3976 - val_value_loss: 0.7278 - val_policy_loss: 1.8775\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2385 - value_loss: 0.4650 - policy_loss: 1.8220 - val_loss: 6.3906 - val_value_loss: 0.7158 - val_policy_loss: 1.8758\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2258 - value_loss: 0.4471 - policy_loss: 1.8150 - val_loss: 6.3724 - val_value_loss: 0.6823 - val_policy_loss: 1.8732\n",
      "Saved model  connectfour_num_sim_5_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.75 - draw ratio 0.0\n",
      "Number of seen trajectories: 1000\n",
      "Number of unique trajectories: 1000\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.4592 - value_loss: 0.8432 - policy_loss: 1.8859 - val_loss: 6.4684 - val_value_loss: 0.8634 - val_policy_loss: 1.8844\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4209 - value_loss: 0.7742 - policy_loss: 1.8784 - val_loss: 6.4472 - val_value_loss: 0.8240 - val_policy_loss: 1.8813\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3884 - value_loss: 0.7164 - policy_loss: 1.8714 - val_loss: 6.4382 - val_value_loss: 0.8095 - val_policy_loss: 1.8781\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3643 - value_loss: 0.6742 - policy_loss: 1.8655 - val_loss: 6.4296 - val_value_loss: 0.7946 - val_policy_loss: 1.8758\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3419 - value_loss: 0.6367 - policy_loss: 1.8585 - val_loss: 6.4174 - val_value_loss: 0.7726 - val_policy_loss: 1.8738\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3256 - value_loss: 0.6089 - policy_loss: 1.8539 - val_loss: 6.4084 - val_value_loss: 0.7572 - val_policy_loss: 1.8711\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3078 - value_loss: 0.5797 - policy_loss: 1.8477 - val_loss: 6.4074 - val_value_loss: 0.7574 - val_policy_loss: 1.8693\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2946 - value_loss: 0.5574 - policy_loss: 1.8436 - val_loss: 6.3987 - val_value_loss: 0.7420 - val_policy_loss: 1.8674\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2803 - value_loss: 0.5352 - policy_loss: 1.8374 - val_loss: 6.3916 - val_value_loss: 0.7295 - val_policy_loss: 1.8659\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2743 - value_loss: 0.5265 - policy_loss: 1.8343 - val_loss: 6.3893 - val_value_loss: 0.7275 - val_policy_loss: 1.8633\n",
      "Saved model  connectfour_num_sim_5_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.68 - draw ratio 0.0\n",
      "Number of seen trajectories: 1100\n",
      "Number of unique trajectories: 1100\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 456us/step - loss: 6.4643 - value_loss: 0.8568 - policy_loss: 1.8842 - val_loss: 6.4572 - val_value_loss: 0.8512 - val_policy_loss: 1.8755\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4282 - value_loss: 0.7942 - policy_loss: 1.8746 - val_loss: 6.4458 - val_value_loss: 0.8317 - val_policy_loss: 1.8724\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4022 - value_loss: 0.7484 - policy_loss: 1.8687 - val_loss: 6.4325 - val_value_loss: 0.8077 - val_policy_loss: 1.8701\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3761 - value_loss: 0.7038 - policy_loss: 1.8612 - val_loss: 6.4259 - val_value_loss: 0.7976 - val_policy_loss: 1.8670\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3525 - value_loss: 0.6631 - policy_loss: 1.8550 - val_loss: 6.4170 - val_value_loss: 0.7819 - val_policy_loss: 1.8652\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3350 - value_loss: 0.6339 - policy_loss: 1.8492 - val_loss: 6.4131 - val_value_loss: 0.7763 - val_policy_loss: 1.8632\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3238 - value_loss: 0.6166 - policy_loss: 1.8444 - val_loss: 6.4010 - val_value_loss: 0.7551 - val_policy_loss: 1.8603\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3041 - value_loss: 0.5829 - policy_loss: 1.8387 - val_loss: 6.3908 - val_value_loss: 0.7372 - val_policy_loss: 1.8581\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2883 - value_loss: 0.5572 - policy_loss: 1.8331 - val_loss: 6.3838 - val_value_loss: 0.7255 - val_policy_loss: 1.8560\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2788 - value_loss: 0.5427 - policy_loss: 1.8288 - val_loss: 6.3813 - val_value_loss: 0.7223 - val_policy_loss: 1.8543\n",
      "Saved model  connectfour_num_sim_5_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.64 - draw ratio 0.0\n",
      "Number of seen trajectories: 1200\n",
      "Number of unique trajectories: 1200\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4509 - value_loss: 0.8519 - policy_loss: 1.8639 - val_loss: 6.4269 - val_value_loss: 0.8119 - val_policy_loss: 1.8559\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4100 - value_loss: 0.7782 - policy_loss: 1.8560 - val_loss: 6.4149 - val_value_loss: 0.7902 - val_policy_loss: 1.8538\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3802 - value_loss: 0.7251 - policy_loss: 1.8497 - val_loss: 6.4089 - val_value_loss: 0.7796 - val_policy_loss: 1.8525\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3555 - value_loss: 0.6810 - policy_loss: 1.8444 - val_loss: 6.3999 - val_value_loss: 0.7633 - val_policy_loss: 1.8510\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3365 - value_loss: 0.6477 - policy_loss: 1.8399 - val_loss: 6.3923 - val_value_loss: 0.7498 - val_policy_loss: 1.8495\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3156 - value_loss: 0.6126 - policy_loss: 1.8334 - val_loss: 6.3902 - val_value_loss: 0.7476 - val_policy_loss: 1.8477\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2995 - value_loss: 0.5846 - policy_loss: 1.8293 - val_loss: 6.3825 - val_value_loss: 0.7337 - val_policy_loss: 1.8463\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.2854 - value_loss: 0.5618 - policy_loss: 1.8241 - val_loss: 6.3788 - val_value_loss: 0.7285 - val_policy_loss: 1.8444\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.2757 - value_loss: 0.5460 - policy_loss: 1.8206 - val_loss: 6.3757 - val_value_loss: 0.7232 - val_policy_loss: 1.8435\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2613 - value_loss: 0.5232 - policy_loss: 1.8148 - val_loss: 6.3707 - val_value_loss: 0.7153 - val_policy_loss: 1.8417\n",
      "Saved model  connectfour_num_sim_5_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.0\n",
      "Number of seen trajectories: 1300\n",
      "Number of unique trajectories: 1300\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.4223 - value_loss: 0.8180 - policy_loss: 1.8422 - val_loss: 6.4333 - val_value_loss: 0.8418 - val_policy_loss: 1.8405\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3861 - value_loss: 0.7529 - policy_loss: 1.8351 - val_loss: 6.4213 - val_value_loss: 0.8203 - val_policy_loss: 1.8382\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3597 - value_loss: 0.7061 - policy_loss: 1.8292 - val_loss: 6.4073 - val_value_loss: 0.7940 - val_policy_loss: 1.8367\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3350 - value_loss: 0.6630 - policy_loss: 1.8231 - val_loss: 6.3982 - val_value_loss: 0.7776 - val_policy_loss: 1.8349\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3147 - value_loss: 0.6276 - policy_loss: 1.8181 - val_loss: 6.3874 - val_value_loss: 0.7580 - val_policy_loss: 1.8331\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2972 - value_loss: 0.5972 - policy_loss: 1.8135 - val_loss: 6.3836 - val_value_loss: 0.7521 - val_policy_loss: 1.8316\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2821 - value_loss: 0.5725 - policy_loss: 1.8082 - val_loss: 6.3734 - val_value_loss: 0.7333 - val_policy_loss: 1.8301\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2716 - value_loss: 0.5554 - policy_loss: 1.8045 - val_loss: 6.3694 - val_value_loss: 0.7270 - val_policy_loss: 1.8286\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2575 - value_loss: 0.5323 - policy_loss: 1.7996 - val_loss: 6.3673 - val_value_loss: 0.7237 - val_policy_loss: 1.8278\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2444 - value_loss: 0.5116 - policy_loss: 1.7942 - val_loss: 6.3598 - val_value_loss: 0.7102 - val_policy_loss: 1.8265\n",
      "Saved model  connectfour_num_sim_5_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.65 - draw ratio 0.0\n",
      "Number of seen trajectories: 1400\n",
      "Number of unique trajectories: 1399\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4378 - value_loss: 0.8611 - policy_loss: 1.8318 - val_loss: 6.4022 - val_value_loss: 0.8077 - val_policy_loss: 1.8141\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3976 - value_loss: 0.7890 - policy_loss: 1.8237 - val_loss: 6.3893 - val_value_loss: 0.7835 - val_policy_loss: 1.8126\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3674 - value_loss: 0.7356 - policy_loss: 1.8167 - val_loss: 6.3777 - val_value_loss: 0.7633 - val_policy_loss: 1.8097\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3422 - value_loss: 0.6913 - policy_loss: 1.8107 - val_loss: 6.3689 - val_value_loss: 0.7470 - val_policy_loss: 1.8086\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3212 - value_loss: 0.6553 - policy_loss: 1.8049 - val_loss: 6.3618 - val_value_loss: 0.7352 - val_policy_loss: 1.8065\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3037 - value_loss: 0.6254 - policy_loss: 1.8000 - val_loss: 6.3541 - val_value_loss: 0.7213 - val_policy_loss: 1.8050\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2895 - value_loss: 0.6025 - policy_loss: 1.7947 - val_loss: 6.3478 - val_value_loss: 0.7109 - val_policy_loss: 1.8030\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2706 - value_loss: 0.5691 - policy_loss: 1.7904 - val_loss: 6.3420 - val_value_loss: 0.7017 - val_policy_loss: 1.8008\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2604 - value_loss: 0.5535 - policy_loss: 1.7858 - val_loss: 6.3428 - val_value_loss: 0.7047 - val_policy_loss: 1.7994\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2534 - value_loss: 0.5440 - policy_loss: 1.7816 - val_loss: 6.3339 - val_value_loss: 0.6891 - val_policy_loss: 1.7974\n",
      "Saved model  connectfour_num_sim_5_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.64 - draw ratio 0.0\n",
      "Number of seen trajectories: 1500\n",
      "Number of unique trajectories: 1499\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.4333 - value_loss: 0.8614 - policy_loss: 1.8240 - val_loss: 6.4397 - val_value_loss: 0.8781 - val_policy_loss: 1.8202\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4095 - value_loss: 0.8182 - policy_loss: 1.8197 - val_loss: 6.4268 - val_value_loss: 0.8542 - val_policy_loss: 1.8183\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3912 - value_loss: 0.7854 - policy_loss: 1.8160 - val_loss: 6.4175 - val_value_loss: 0.8371 - val_policy_loss: 1.8169\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3746 - value_loss: 0.7548 - policy_loss: 1.8135 - val_loss: 6.4098 - val_value_loss: 0.8231 - val_policy_loss: 1.8157\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3594 - value_loss: 0.7274 - policy_loss: 1.8105 - val_loss: 6.4019 - val_value_loss: 0.8088 - val_policy_loss: 1.8142\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3471 - value_loss: 0.7058 - policy_loss: 1.8076 - val_loss: 6.3923 - val_value_loss: 0.7907 - val_policy_loss: 1.8131\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3318 - value_loss: 0.6788 - policy_loss: 1.8041 - val_loss: 6.3863 - val_value_loss: 0.7802 - val_policy_loss: 1.8118\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3206 - value_loss: 0.6597 - policy_loss: 1.8008 - val_loss: 6.3804 - val_value_loss: 0.7694 - val_policy_loss: 1.8107\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3112 - value_loss: 0.6431 - policy_loss: 1.7987 - val_loss: 6.3761 - val_value_loss: 0.7620 - val_policy_loss: 1.8097\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3003 - value_loss: 0.6242 - policy_loss: 1.7959 - val_loss: 6.3705 - val_value_loss: 0.7519 - val_policy_loss: 1.8086\n",
      "Saved model  connectfour_num_sim_5_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.68 - draw ratio 0.0\n",
      "Number of seen trajectories: 1600\n",
      "Number of unique trajectories: 1599\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.4431 - value_loss: 0.9061 - policy_loss: 1.7998 - val_loss: 6.4311 - val_value_loss: 0.8875 - val_policy_loss: 1.7944\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4216 - value_loss: 0.8682 - policy_loss: 1.7946 - val_loss: 6.4275 - val_value_loss: 0.8820 - val_policy_loss: 1.7927\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4018 - value_loss: 0.8328 - policy_loss: 1.7905 - val_loss: 6.4176 - val_value_loss: 0.8642 - val_policy_loss: 1.7909\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 456us/step - loss: 6.3853 - value_loss: 0.8036 - policy_loss: 1.7868 - val_loss: 6.4114 - val_value_loss: 0.8531 - val_policy_loss: 1.7897\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 457us/step - loss: 6.3702 - value_loss: 0.7774 - policy_loss: 1.7829 - val_loss: 6.4068 - val_value_loss: 0.8451 - val_policy_loss: 1.7884\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 457us/step - loss: 6.3538 - value_loss: 0.7484 - policy_loss: 1.7792 - val_loss: 6.4020 - val_value_loss: 0.8369 - val_policy_loss: 1.7871\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 460us/step - loss: 6.3409 - value_loss: 0.7262 - policy_loss: 1.7757 - val_loss: 6.3970 - val_value_loss: 0.8281 - val_policy_loss: 1.7860\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 456us/step - loss: 6.3287 - value_loss: 0.7044 - policy_loss: 1.7732 - val_loss: 6.3925 - val_value_loss: 0.8202 - val_policy_loss: 1.7849\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 458us/step - loss: 6.3165 - value_loss: 0.6836 - policy_loss: 1.7697 - val_loss: 6.3913 - val_value_loss: 0.8191 - val_policy_loss: 1.7838\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 458us/step - loss: 6.3058 - value_loss: 0.6654 - policy_loss: 1.7665 - val_loss: 6.3863 - val_value_loss: 0.8102 - val_policy_loss: 1.7827\n",
      "Saved model  connectfour_num_sim_5_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.0\n",
      "Number of seen trajectories: 1700\n",
      "Number of unique trajectories: 1699\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4492 - value_loss: 0.9480 - policy_loss: 1.7708 - val_loss: 6.4485 - val_value_loss: 0.9250 - val_policy_loss: 1.7925\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4255 - value_loss: 0.9047 - policy_loss: 1.7669 - val_loss: 6.4395 - val_value_loss: 0.9085 - val_policy_loss: 1.7910\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4052 - value_loss: 0.8678 - policy_loss: 1.7633 - val_loss: 6.4313 - val_value_loss: 0.8935 - val_policy_loss: 1.7898\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3858 - value_loss: 0.8331 - policy_loss: 1.7591 - val_loss: 6.4259 - val_value_loss: 0.8839 - val_policy_loss: 1.7887\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3720 - value_loss: 0.8083 - policy_loss: 1.7563 - val_loss: 6.4190 - val_value_loss: 0.8711 - val_policy_loss: 1.7877\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3577 - value_loss: 0.7822 - policy_loss: 1.7542 - val_loss: 6.4136 - val_value_loss: 0.8613 - val_policy_loss: 1.7868\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3436 - value_loss: 0.7574 - policy_loss: 1.7507 - val_loss: 6.4083 - val_value_loss: 0.8516 - val_policy_loss: 1.7860\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3325 - value_loss: 0.7376 - policy_loss: 1.7484 - val_loss: 6.4046 - val_value_loss: 0.8451 - val_policy_loss: 1.7852\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3221 - value_loss: 0.7194 - policy_loss: 1.7460 - val_loss: 6.4002 - val_value_loss: 0.8371 - val_policy_loss: 1.7844\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3092 - value_loss: 0.6961 - policy_loss: 1.7434 - val_loss: 6.3963 - val_value_loss: 0.8302 - val_policy_loss: 1.7837\n",
      "Saved model  connectfour_num_sim_5_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.65 - draw ratio 0.0\n",
      "Number of seen trajectories: 1800\n",
      "Number of unique trajectories: 1798\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4527 - value_loss: 0.9737 - policy_loss: 1.7529 - val_loss: 6.4448 - val_value_loss: 0.9565 - val_policy_loss: 1.7545\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4282 - value_loss: 0.9297 - policy_loss: 1.7480 - val_loss: 6.4338 - val_value_loss: 0.9359 - val_policy_loss: 1.7529\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4064 - value_loss: 0.8895 - policy_loss: 1.7447 - val_loss: 6.4248 - val_value_loss: 0.9196 - val_policy_loss: 1.7515\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3860 - value_loss: 0.8527 - policy_loss: 1.7407 - val_loss: 6.4208 - val_value_loss: 0.9130 - val_policy_loss: 1.7501\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3692 - value_loss: 0.8221 - policy_loss: 1.7378 - val_loss: 6.4092 - val_value_loss: 0.8913 - val_policy_loss: 1.7487\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3509 - value_loss: 0.7884 - policy_loss: 1.7350 - val_loss: 6.4040 - val_value_loss: 0.8820 - val_policy_loss: 1.7476\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3392 - value_loss: 0.7677 - policy_loss: 1.7323 - val_loss: 6.3977 - val_value_loss: 0.8712 - val_policy_loss: 1.7460\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3201 - value_loss: 0.7335 - policy_loss: 1.7284 - val_loss: 6.3943 - val_value_loss: 0.8655 - val_policy_loss: 1.7449\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3081 - value_loss: 0.7129 - policy_loss: 1.7252 - val_loss: 6.3863 - val_value_loss: 0.8509 - val_policy_loss: 1.7437\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2988 - value_loss: 0.6958 - policy_loss: 1.7238 - val_loss: 6.3835 - val_value_loss: 0.8465 - val_policy_loss: 1.7425\n",
      "Saved model  connectfour_num_sim_5_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.69 - draw ratio 0.0\n",
      "Number of seen trajectories: 1900\n",
      "Number of unique trajectories: 1898\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.4542 - value_loss: 0.9829 - policy_loss: 1.7476 - val_loss: 6.4341 - val_value_loss: 0.9552 - val_policy_loss: 1.7351\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4287 - value_loss: 0.9363 - policy_loss: 1.7432 - val_loss: 6.4241 - val_value_loss: 0.9371 - val_policy_loss: 1.7332\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4073 - value_loss: 0.8967 - policy_loss: 1.7402 - val_loss: 6.4148 - val_value_loss: 0.9200 - val_policy_loss: 1.7318\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3840 - value_loss: 0.8548 - policy_loss: 1.7354 - val_loss: 6.4049 - val_value_loss: 0.9017 - val_policy_loss: 1.7304\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 456us/step - loss: 6.3697 - value_loss: 0.8288 - policy_loss: 1.7331 - val_loss: 6.3985 - val_value_loss: 0.8903 - val_policy_loss: 1.7291\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 458us/step - loss: 6.3508 - value_loss: 0.7949 - policy_loss: 1.7291 - val_loss: 6.3926 - val_value_loss: 0.8799 - val_policy_loss: 1.7279\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 459us/step - loss: 6.3356 - value_loss: 0.7685 - policy_loss: 1.7253 - val_loss: 6.3846 - val_value_loss: 0.8651 - val_policy_loss: 1.7268\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3218 - value_loss: 0.7433 - policy_loss: 1.7230 - val_loss: 6.3803 - val_value_loss: 0.8575 - val_policy_loss: 1.7258\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3092 - value_loss: 0.7210 - policy_loss: 1.7201 - val_loss: 6.3740 - val_value_loss: 0.8458 - val_policy_loss: 1.7249\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2975 - value_loss: 0.7005 - policy_loss: 1.7174 - val_loss: 6.3701 - val_value_loss: 0.8390 - val_policy_loss: 1.7240\n",
      "Saved model  connectfour_num_sim_5_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.61 - draw ratio 0.0\n",
      "Number of seen trajectories: 2000\n",
      "Number of unique trajectories: 1998\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.4192 - value_loss: 0.9358 - policy_loss: 1.7253 - val_loss: 6.4145 - val_value_loss: 0.9252 - val_policy_loss: 1.7267\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4053 - value_loss: 0.9105 - policy_loss: 1.7230 - val_loss: 6.4087 - val_value_loss: 0.9151 - val_policy_loss: 1.7252\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3945 - value_loss: 0.8904 - policy_loss: 1.7216 - val_loss: 6.4025 - val_value_loss: 0.9039 - val_policy_loss: 1.7241\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3846 - value_loss: 0.8725 - policy_loss: 1.7196 - val_loss: 6.3974 - val_value_loss: 0.8948 - val_policy_loss: 1.7230\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3735 - value_loss: 0.8526 - policy_loss: 1.7173 - val_loss: 6.3923 - val_value_loss: 0.8857 - val_policy_loss: 1.7220\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3639 - value_loss: 0.8359 - policy_loss: 1.7149 - val_loss: 6.3877 - val_value_loss: 0.8773 - val_policy_loss: 1.7211\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3542 - value_loss: 0.8179 - policy_loss: 1.7137 - val_loss: 6.3837 - val_value_loss: 0.8702 - val_policy_loss: 1.7203\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3468 - value_loss: 0.8046 - policy_loss: 1.7121 - val_loss: 6.3800 - val_value_loss: 0.8635 - val_policy_loss: 1.7196\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3394 - value_loss: 0.7915 - policy_loss: 1.7105 - val_loss: 6.3759 - val_value_loss: 0.8562 - val_policy_loss: 1.7188\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3319 - value_loss: 0.7778 - policy_loss: 1.7093 - val_loss: 6.3726 - val_value_loss: 0.8504 - val_policy_loss: 1.7182\n",
      "Saved model  connectfour_num_sim_5_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.57 - draw ratio 0.0\n",
      "Number of seen trajectories: 2100\n",
      "Number of unique trajectories: 2098\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.4286 - value_loss: 0.9683 - policy_loss: 1.7121 - val_loss: 6.4048 - val_value_loss: 0.9254 - val_policy_loss: 1.7074\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4147 - value_loss: 0.9430 - policy_loss: 1.7097 - val_loss: 6.3991 - val_value_loss: 0.9153 - val_policy_loss: 1.7062\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4016 - value_loss: 0.9197 - policy_loss: 1.7069 - val_loss: 6.3937 - val_value_loss: 0.9055 - val_policy_loss: 1.7052\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3904 - value_loss: 0.8987 - policy_loss: 1.7054 - val_loss: 6.3892 - val_value_loss: 0.8974 - val_policy_loss: 1.7043\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3795 - value_loss: 0.8787 - policy_loss: 1.7037 - val_loss: 6.3851 - val_value_loss: 0.8903 - val_policy_loss: 1.7034\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3695 - value_loss: 0.8606 - policy_loss: 1.7019 - val_loss: 6.3802 - val_value_loss: 0.8813 - val_policy_loss: 1.7025\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3607 - value_loss: 0.8443 - policy_loss: 1.7006 - val_loss: 6.3770 - val_value_loss: 0.8758 - val_policy_loss: 1.7018\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3501 - value_loss: 0.8247 - policy_loss: 1.6992 - val_loss: 6.3733 - val_value_loss: 0.8692 - val_policy_loss: 1.7010\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3418 - value_loss: 0.8099 - policy_loss: 1.6973 - val_loss: 6.3697 - val_value_loss: 0.8628 - val_policy_loss: 1.7003\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3331 - value_loss: 0.7946 - policy_loss: 1.6951 - val_loss: 6.3656 - val_value_loss: 0.8552 - val_policy_loss: 1.6996\n",
      "Saved model  connectfour_num_sim_5_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.62 - draw ratio 0.0\n",
      "Number of seen trajectories: 2200\n",
      "Number of unique trajectories: 2198\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4017 - value_loss: 0.9440 - policy_loss: 1.6831 - val_loss: 6.4050 - val_value_loss: 0.9480 - val_policy_loss: 1.6856\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3872 - value_loss: 0.9173 - policy_loss: 1.6807 - val_loss: 6.3990 - val_value_loss: 0.9376 - val_policy_loss: 1.6841\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3759 - value_loss: 0.8968 - policy_loss: 1.6788 - val_loss: 6.3940 - val_value_loss: 0.9288 - val_policy_loss: 1.6829\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3630 - value_loss: 0.8739 - policy_loss: 1.6760 - val_loss: 6.3891 - val_value_loss: 0.9202 - val_policy_loss: 1.6818\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3531 - value_loss: 0.8552 - policy_loss: 1.6749 - val_loss: 6.3844 - val_value_loss: 0.9118 - val_policy_loss: 1.6808\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3410 - value_loss: 0.8332 - policy_loss: 1.6727 - val_loss: 6.3801 - val_value_loss: 0.9043 - val_policy_loss: 1.6799\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3330 - value_loss: 0.8176 - policy_loss: 1.6723 - val_loss: 6.3759 - val_value_loss: 0.8967 - val_policy_loss: 1.6791\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3237 - value_loss: 0.8016 - policy_loss: 1.6698 - val_loss: 6.3719 - val_value_loss: 0.8895 - val_policy_loss: 1.6783\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3122 - value_loss: 0.7808 - policy_loss: 1.6677 - val_loss: 6.3682 - val_value_loss: 0.8828 - val_policy_loss: 1.6776\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3038 - value_loss: 0.7657 - policy_loss: 1.6660 - val_loss: 6.3645 - val_value_loss: 0.8762 - val_policy_loss: 1.6768\n",
      "Saved model  connectfour_num_sim_5_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.66 - draw ratio 0.0\n",
      "Number of seen trajectories: 2300\n",
      "Number of unique trajectories: 2298\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.4105 - value_loss: 0.9668 - policy_loss: 1.6782 - val_loss: 6.3754 - val_value_loss: 0.9083 - val_policy_loss: 1.6665\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3966 - value_loss: 0.9417 - policy_loss: 1.6756 - val_loss: 6.3688 - val_value_loss: 0.8967 - val_policy_loss: 1.6651\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3824 - value_loss: 0.9158 - policy_loss: 1.6731 - val_loss: 6.3632 - val_value_loss: 0.8866 - val_policy_loss: 1.6640\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3707 - value_loss: 0.8950 - policy_loss: 1.6706 - val_loss: 6.3580 - val_value_loss: 0.8773 - val_policy_loss: 1.6629\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3603 - value_loss: 0.8754 - policy_loss: 1.6695 - val_loss: 6.3538 - val_value_loss: 0.8697 - val_policy_loss: 1.6620\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3512 - value_loss: 0.8589 - policy_loss: 1.6678 - val_loss: 6.3491 - val_value_loss: 0.8614 - val_policy_loss: 1.6611\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3388 - value_loss: 0.8366 - policy_loss: 1.6653 - val_loss: 6.3448 - val_value_loss: 0.8538 - val_policy_loss: 1.6602\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3306 - value_loss: 0.8215 - policy_loss: 1.6640 - val_loss: 6.3411 - val_value_loss: 0.8471 - val_policy_loss: 1.6595\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3210 - value_loss: 0.8040 - policy_loss: 1.6623 - val_loss: 6.3372 - val_value_loss: 0.8402 - val_policy_loss: 1.6587\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3120 - value_loss: 0.7886 - policy_loss: 1.6599 - val_loss: 6.3338 - val_value_loss: 0.8341 - val_policy_loss: 1.6580\n",
      "Saved model  connectfour_num_sim_5_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.71 - draw ratio 0.0\n",
      "Number of seen trajectories: 2400\n",
      "Number of unique trajectories: 2398\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.3959 - value_loss: 0.9610 - policy_loss: 1.6553 - val_loss: 6.3817 - val_value_loss: 0.9322 - val_policy_loss: 1.6557\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3783 - value_loss: 0.9280 - policy_loss: 1.6531 - val_loss: 6.3736 - val_value_loss: 0.9168 - val_policy_loss: 1.6550\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3646 - value_loss: 0.9024 - policy_loss: 1.6515 - val_loss: 6.3669 - val_value_loss: 0.9041 - val_policy_loss: 1.6543\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3528 - value_loss: 0.8799 - policy_loss: 1.6503 - val_loss: 6.3612 - val_value_loss: 0.8934 - val_policy_loss: 1.6537\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3386 - value_loss: 0.8544 - policy_loss: 1.6474 - val_loss: 6.3558 - val_value_loss: 0.8832 - val_policy_loss: 1.6530\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3304 - value_loss: 0.8381 - policy_loss: 1.6473 - val_loss: 6.3509 - val_value_loss: 0.8740 - val_policy_loss: 1.6525\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3199 - value_loss: 0.8191 - policy_loss: 1.6454 - val_loss: 6.3464 - val_value_loss: 0.8655 - val_policy_loss: 1.6520\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3089 - value_loss: 0.7990 - policy_loss: 1.6435 - val_loss: 6.3430 - val_value_loss: 0.8593 - val_policy_loss: 1.6514\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3004 - value_loss: 0.7847 - policy_loss: 1.6409 - val_loss: 6.3390 - val_value_loss: 0.8520 - val_policy_loss: 1.6508\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2930 - value_loss: 0.7708 - policy_loss: 1.6400 - val_loss: 6.3358 - val_value_loss: 0.8463 - val_policy_loss: 1.6502\n",
      "Saved model  connectfour_num_sim_5_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.58 - draw ratio 0.0\n",
      "Number of seen trajectories: 2500\n",
      "Number of unique trajectories: 2496\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.3902 - value_loss: 0.9424 - policy_loss: 1.6627 - val_loss: 6.3764 - val_value_loss: 0.9517 - val_policy_loss: 1.6260\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3831 - value_loss: 0.9291 - policy_loss: 1.6619 - val_loss: 6.3723 - val_value_loss: 0.9442 - val_policy_loss: 1.6252\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3770 - value_loss: 0.9188 - policy_loss: 1.6602 - val_loss: 6.3685 - val_value_loss: 0.9374 - val_policy_loss: 1.6246\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3699 - value_loss: 0.9053 - policy_loss: 1.6594 - val_loss: 6.3651 - val_value_loss: 0.9312 - val_policy_loss: 1.6240\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3619 - value_loss: 0.8911 - policy_loss: 1.6577 - val_loss: 6.3621 - val_value_loss: 0.9257 - val_policy_loss: 1.6234\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3570 - value_loss: 0.8820 - policy_loss: 1.6570 - val_loss: 6.3591 - val_value_loss: 0.9204 - val_policy_loss: 1.6228\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3507 - value_loss: 0.8704 - policy_loss: 1.6560 - val_loss: 6.3564 - val_value_loss: 0.9155 - val_policy_loss: 1.6223\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3446 - value_loss: 0.8597 - policy_loss: 1.6546 - val_loss: 6.3539 - val_value_loss: 0.9110 - val_policy_loss: 1.6219\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3378 - value_loss: 0.8476 - policy_loss: 1.6531 - val_loss: 6.3515 - val_value_loss: 0.9066 - val_policy_loss: 1.6214\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3352 - value_loss: 0.8425 - policy_loss: 1.6529 - val_loss: 6.3491 - val_value_loss: 0.9025 - val_policy_loss: 1.6209\n",
      "Saved model  connectfour_num_sim_5_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.67 - draw ratio 0.0\n",
      "Number of seen trajectories: 2600\n",
      "Number of unique trajectories: 2596\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3962 - value_loss: 0.9770 - policy_loss: 1.6405 - val_loss: 6.4136 - val_value_loss: 1.0155 - val_policy_loss: 1.6367\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3895 - value_loss: 0.9648 - policy_loss: 1.6392 - val_loss: 6.4096 - val_value_loss: 1.0086 - val_policy_loss: 1.6357\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3816 - value_loss: 0.9504 - policy_loss: 1.6379 - val_loss: 6.4060 - val_value_loss: 1.0023 - val_policy_loss: 1.6348\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3764 - value_loss: 0.9414 - policy_loss: 1.6365 - val_loss: 6.4026 - val_value_loss: 0.9963 - val_policy_loss: 1.6341\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3708 - value_loss: 0.9296 - policy_loss: 1.6371 - val_loss: 6.3993 - val_value_loss: 0.9905 - val_policy_loss: 1.6334\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3623 - value_loss: 0.9149 - policy_loss: 1.6348 - val_loss: 6.3962 - val_value_loss: 0.9849 - val_policy_loss: 1.6327\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3592 - value_loss: 0.9108 - policy_loss: 1.6329 - val_loss: 6.3931 - val_value_loss: 0.9793 - val_policy_loss: 1.6321\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3516 - value_loss: 0.8970 - policy_loss: 1.6315 - val_loss: 6.3901 - val_value_loss: 0.9739 - val_policy_loss: 1.6315\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3457 - value_loss: 0.8862 - policy_loss: 1.6304 - val_loss: 6.3871 - val_value_loss: 0.9686 - val_policy_loss: 1.6310\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3402 - value_loss: 0.8762 - policy_loss: 1.6294 - val_loss: 6.3843 - val_value_loss: 0.9634 - val_policy_loss: 1.6304\n",
      "Saved model  connectfour_num_sim_5_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.68 - draw ratio 0.0\n",
      "Number of seen trajectories: 2700\n",
      "Number of unique trajectories: 2695\n",
      "iteration 27 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.3951 - value_loss: 0.9965 - policy_loss: 1.6191 - val_loss: 6.3825 - val_value_loss: 0.9669 - val_policy_loss: 1.6233\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3884 - value_loss: 0.9834 - policy_loss: 1.6187 - val_loss: 6.3784 - val_value_loss: 0.9598 - val_policy_loss: 1.6223\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3797 - value_loss: 0.9685 - policy_loss: 1.6163 - val_loss: 6.3746 - val_value_loss: 0.9530 - val_policy_loss: 1.6214\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3723 - value_loss: 0.9550 - policy_loss: 1.6150 - val_loss: 6.3708 - val_value_loss: 0.9463 - val_policy_loss: 1.6206\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3655 - value_loss: 0.9425 - policy_loss: 1.6140 - val_loss: 6.3673 - val_value_loss: 0.9402 - val_policy_loss: 1.6198\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3603 - value_loss: 0.9330 - policy_loss: 1.6131 - val_loss: 6.3641 - val_value_loss: 0.9344 - val_policy_loss: 1.6191\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3515 - value_loss: 0.9166 - policy_loss: 1.6118 - val_loss: 6.3609 - val_value_loss: 0.9288 - val_policy_loss: 1.6184\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3449 - value_loss: 0.9052 - policy_loss: 1.6101 - val_loss: 6.3577 - val_value_loss: 0.9231 - val_policy_loss: 1.6177\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3417 - value_loss: 0.8990 - policy_loss: 1.6099 - val_loss: 6.3547 - val_value_loss: 0.9178 - val_policy_loss: 1.6171\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3327 - value_loss: 0.8833 - policy_loss: 1.6075 - val_loss: 6.3517 - val_value_loss: 0.9124 - val_policy_loss: 1.6165\n",
      "Saved model  connectfour_num_sim_5_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.66 - draw ratio 0.0\n",
      "Number of seen trajectories: 2800\n",
      "Number of unique trajectories: 2793\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.3756 - value_loss: 0.9897 - policy_loss: 1.5869 - val_loss: 6.3748 - val_value_loss: 0.9778 - val_policy_loss: 1.5972\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3684 - value_loss: 0.9770 - policy_loss: 1.5854 - val_loss: 6.3727 - val_value_loss: 0.9743 - val_policy_loss: 1.5966\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3615 - value_loss: 0.9641 - policy_loss: 1.5844 - val_loss: 6.3699 - val_value_loss: 0.9692 - val_policy_loss: 1.5961\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3556 - value_loss: 0.9530 - policy_loss: 1.5838 - val_loss: 6.3670 - val_value_loss: 0.9640 - val_policy_loss: 1.5956\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3497 - value_loss: 0.9425 - policy_loss: 1.5824 - val_loss: 6.3642 - val_value_loss: 0.9588 - val_policy_loss: 1.5951\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3429 - value_loss: 0.9306 - policy_loss: 1.5807 - val_loss: 6.3611 - val_value_loss: 0.9531 - val_policy_loss: 1.5946\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3376 - value_loss: 0.9211 - policy_loss: 1.5798 - val_loss: 6.3583 - val_value_loss: 0.9481 - val_policy_loss: 1.5942\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3342 - value_loss: 0.9142 - policy_loss: 1.5799 - val_loss: 6.3556 - val_value_loss: 0.9430 - val_policy_loss: 1.5937\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3261 - value_loss: 0.9007 - policy_loss: 1.5772 - val_loss: 6.3534 - val_value_loss: 0.9391 - val_policy_loss: 1.5933\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3213 - value_loss: 0.8916 - policy_loss: 1.5767 - val_loss: 6.3514 - val_value_loss: 0.9356 - val_policy_loss: 1.5929\n",
      "Saved model  connectfour_num_sim_5_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.59 - draw ratio 0.0\n",
      "Number of seen trajectories: 2900\n",
      "Number of unique trajectories: 2893\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_5_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.3738 - value_loss: 0.9879 - policy_loss: 1.5854 - val_loss: 6.3766 - val_value_loss: 0.9860 - val_policy_loss: 1.5928\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3666 - value_loss: 0.9750 - policy_loss: 1.5839 - val_loss: 6.3736 - val_value_loss: 0.9807 - val_policy_loss: 1.5922\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3581 - value_loss: 0.9585 - policy_loss: 1.5834 - val_loss: 6.3705 - val_value_loss: 0.9753 - val_policy_loss: 1.5914\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3509 - value_loss: 0.9461 - policy_loss: 1.5815 - val_loss: 6.3674 - val_value_loss: 0.9697 - val_policy_loss: 1.5908\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3445 - value_loss: 0.9343 - policy_loss: 1.5804 - val_loss: 6.3646 - val_value_loss: 0.9649 - val_policy_loss: 1.5902\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3391 - value_loss: 0.9242 - policy_loss: 1.5798 - val_loss: 6.3620 - val_value_loss: 0.9603 - val_policy_loss: 1.5896\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3336 - value_loss: 0.9141 - policy_loss: 1.5790 - val_loss: 6.3592 - val_value_loss: 0.9552 - val_policy_loss: 1.5891\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3261 - value_loss: 0.9004 - policy_loss: 1.5778 - val_loss: 6.3563 - val_value_loss: 0.9499 - val_policy_loss: 1.5885\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3204 - value_loss: 0.8908 - policy_loss: 1.5759 - val_loss: 6.3538 - val_value_loss: 0.9456 - val_policy_loss: 1.5879\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3178 - value_loss: 0.8838 - policy_loss: 1.5777 - val_loss: 6.3515 - val_value_loss: 0.9414 - val_policy_loss: 1.5874\n",
      "Saved model  connectfour_num_sim_5_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.71 - draw ratio 0.0\n",
      "Number of seen trajectories: 3000\n",
      "Number of unique trajectories: 2992\n"
     ]
    }
   ],
   "source": [
    "wins_2, draws_2, seen_trajectories_2, unique_trajectories_2 = test_pipeline.run(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - 5 simulations\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "losses_2 = np.ones(30) - wins_2 - draws_2\n",
    "\n",
    "plt.plot(x, wins_2, label=\"win ratio\")\n",
    "plt.plot(x, draws_2, label=\"draw ratio\")\n",
    "plt.plot(x, losses_2, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "exploration_rate_2 = unique_trajectories_2/seen_trajectories_2\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - 5 simulations\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "plt.plot(x, exploration_rate_2, label=\"unique/seen\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins_2 = [0.72, 0.55, 0.68, 0.59, 0.57, 0.59, 0.64, 0.69, 0.62, 0.75, 0.68, 0.64, 0.74, 0.65, 0.64, 0.68, 0.74, 0.65, 0.69, 0.61, 0.57, 0.62, 0.66, 0.71, 0.58, 0.67, 0.68, 0.66, 0.59, 0.71]\n",
      "draws_2 = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "seen_trajectories_2 = [ 100.  200.  300.  400.  500.  600.  700.  800.  900. 1000. 1100. 1200.\n",
      " 1300. 1400. 1500. 1600. 1700. 1800. 1900. 2000. 2100. 2200. 2300. 2400.\n",
      " 2500. 2600. 2700. 2800. 2900. 3000.]\n",
      "unique_trajectories_2 = [ 100.  200.  300.  400.  500.  600.  700.  800.  900. 1000. 1100. 1200.\n",
      " 1300. 1399. 1499. 1599. 1699. 1798. 1898. 1998. 2098. 2198. 2298. 2398.\n",
      " 2496. 2596. 2695. 2793. 2893. 2992.]\n"
     ]
    }
   ],
   "source": [
    "print(\"wins_2 =\",wins_2)\n",
    "print(\"draws_2 =\",draws_2)\n",
    "print(\"seen_trajectories_2 =\", seen_trajectories_2)\n",
    "print(\"unique_trajectories_2 =\", unique_trajectories_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCTS = {\n",
    "    'c_puct': 1,\n",
    "    'dir_alpha': 0.6,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 10,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 10\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 10,\n",
    "    'temperature': 0,\n",
    "    'show_games': False\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 10,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.002,\n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 512,\n",
    "    'num_filters_value': 512,\n",
    "    'num_filters_tower': 512,\n",
    "    'num_residual_blocks': 3,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 512\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"connectfour_num_sim_10\", \"Connect4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (2652, 6, 7, 3)\n",
      "model_y_outcomes: (2652,)\n",
      "model_y_probabilities: (2652, 7)\n",
      "Train on 2121 samples, validate on 531 samples\n",
      "Epoch 1/10\n",
      "2121/2121 [==============================] - 5s 2ms/step - loss: 6.9228 - value_loss: 1.4350 - policy_loss: 2.1726 - val_loss: 6.9425 - val_value_loss: 1.5385 - val_policy_loss: 2.1090\n",
      "Epoch 2/10\n",
      "2121/2121 [==============================] - 1s 467us/step - loss: 6.7893 - value_loss: 1.2592 - policy_loss: 2.0820 - val_loss: 7.0979 - val_value_loss: 1.8592 - val_policy_loss: 2.0994\n",
      "Epoch 3/10\n",
      "2121/2121 [==============================] - 1s 467us/step - loss: 6.7141 - value_loss: 1.1358 - policy_loss: 2.0555 - val_loss: 6.9906 - val_value_loss: 1.6403 - val_policy_loss: 2.1042\n",
      "Epoch 4/10\n",
      "2121/2121 [==============================] - 1s 466us/step - loss: 6.7275 - value_loss: 1.1818 - policy_loss: 2.0366 - val_loss: 7.0281 - val_value_loss: 1.7252 - val_policy_loss: 2.0946\n",
      "Epoch 5/10\n",
      "2121/2121 [==============================] - 1s 468us/step - loss: 6.6270 - value_loss: 0.9982 - policy_loss: 2.0196 - val_loss: 6.9771 - val_value_loss: 1.6240 - val_policy_loss: 2.0944\n",
      "Epoch 6/10\n",
      "2121/2121 [==============================] - 1s 467us/step - loss: 6.6135 - value_loss: 0.9852 - policy_loss: 2.0059 - val_loss: 6.8693 - val_value_loss: 1.4147 - val_policy_loss: 2.0884\n",
      "Epoch 7/10\n",
      "2121/2121 [==============================] - 1s 468us/step - loss: 6.4802 - value_loss: 0.7287 - policy_loss: 1.9962 - val_loss: 6.9639 - val_value_loss: 1.5991 - val_policy_loss: 2.0935\n",
      "Epoch 8/10\n",
      "2121/2121 [==============================] - 1s 468us/step - loss: 6.5579 - value_loss: 0.8961 - policy_loss: 1.9847 - val_loss: 6.8531 - val_value_loss: 1.3843 - val_policy_loss: 2.0872\n",
      "Epoch 9/10\n",
      "2121/2121 [==============================] - 1s 469us/step - loss: 6.4553 - value_loss: 0.6990 - policy_loss: 1.9771 - val_loss: 7.0322 - val_value_loss: 1.7476 - val_policy_loss: 2.0824\n",
      "Epoch 10/10\n",
      "2121/2121 [==============================] - 1s 469us/step - loss: 6.5093 - value_loss: 0.8138 - policy_loss: 1.9707 - val_loss: 6.9193 - val_value_loss: 1.5163 - val_policy_loss: 2.0885\n",
      "Saved model  connectfour_num_sim_10_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.77 - draw ratio 0.0\n",
      "Number of seen trajectories: 100\n",
      "Number of unique trajectories: 100\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.6470 - value_loss: 1.0351 - policy_loss: 2.0254 - val_loss: 6.8369 - val_value_loss: 1.4112 - val_policy_loss: 2.0294\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5885 - value_loss: 0.9456 - policy_loss: 1.9985 - val_loss: 6.5673 - val_value_loss: 0.8850 - val_policy_loss: 2.0171\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5571 - value_loss: 0.9049 - policy_loss: 1.9771 - val_loss: 6.5881 - val_value_loss: 0.9367 - val_policy_loss: 2.0076\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5209 - value_loss: 0.8481 - policy_loss: 1.9621 - val_loss: 6.5524 - val_value_loss: 0.8758 - val_policy_loss: 1.9978\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4257 - value_loss: 0.6717 - policy_loss: 1.9488 - val_loss: 6.5172 - val_value_loss: 0.8154 - val_policy_loss: 1.9884\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4505 - value_loss: 0.7320 - policy_loss: 1.9388 - val_loss: 6.5041 - val_value_loss: 0.7948 - val_policy_loss: 1.9836\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3679 - value_loss: 0.5772 - policy_loss: 1.9289 - val_loss: 6.4578 - val_value_loss: 0.7056 - val_policy_loss: 1.9807\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3272 - value_loss: 0.5041 - policy_loss: 1.9213 - val_loss: 6.4000 - val_value_loss: 0.5978 - val_policy_loss: 1.9736\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2658 - value_loss: 0.3911 - policy_loss: 1.9123 - val_loss: 6.3907 - val_value_loss: 0.5865 - val_policy_loss: 1.9669\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2530 - value_loss: 0.3742 - policy_loss: 1.9041 - val_loss: 6.3954 - val_value_loss: 0.5994 - val_policy_loss: 1.9641\n",
      "Saved model  connectfour_num_sim_10_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.71 - draw ratio 0.0\n",
      "Number of seen trajectories: 200\n",
      "Number of unique trajectories: 200\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.5249 - value_loss: 0.8391 - policy_loss: 1.9836 - val_loss: 6.4881 - val_value_loss: 0.7778 - val_policy_loss: 1.9718\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4633 - value_loss: 0.7332 - policy_loss: 1.9669 - val_loss: 6.4493 - val_value_loss: 0.7049 - val_policy_loss: 1.9677\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4210 - value_loss: 0.6613 - policy_loss: 1.9549 - val_loss: 6.4471 - val_value_loss: 0.7057 - val_policy_loss: 1.9631\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3760 - value_loss: 0.5832 - policy_loss: 1.9436 - val_loss: 6.4187 - val_value_loss: 0.6542 - val_policy_loss: 1.9585\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3192 - value_loss: 0.4800 - policy_loss: 1.9339 - val_loss: 6.3999 - val_value_loss: 0.6219 - val_policy_loss: 1.9539\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3078 - value_loss: 0.4659 - policy_loss: 1.9259 - val_loss: 6.4424 - val_value_loss: 0.7121 - val_policy_loss: 1.9492\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3303 - value_loss: 0.5195 - policy_loss: 1.9179 - val_loss: 6.4356 - val_value_loss: 0.7008 - val_policy_loss: 1.9476\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2929 - value_loss: 0.4522 - policy_loss: 1.9110 - val_loss: 6.3923 - val_value_loss: 0.6179 - val_policy_loss: 1.9445\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2530 - value_loss: 0.3806 - policy_loss: 1.9036 - val_loss: 6.3779 - val_value_loss: 0.5937 - val_policy_loss: 1.9406\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2436 - value_loss: 0.3677 - policy_loss: 1.8982 - val_loss: 6.3625 - val_value_loss: 0.5643 - val_policy_loss: 1.9399\n",
      "Saved model  connectfour_num_sim_10_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.71 - draw ratio 0.0\n",
      "Number of seen trajectories: 300\n",
      "Number of unique trajectories: 300\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4787 - value_loss: 0.7652 - policy_loss: 1.9716 - val_loss: 6.5234 - val_value_loss: 0.8619 - val_policy_loss: 1.9647\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5067 - value_loss: 0.8327 - policy_loss: 1.9607 - val_loss: 6.4742 - val_value_loss: 0.7683 - val_policy_loss: 1.9606\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3937 - value_loss: 0.6167 - policy_loss: 1.9514 - val_loss: 6.4730 - val_value_loss: 0.7700 - val_policy_loss: 1.9570\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3612 - value_loss: 0.5608 - policy_loss: 1.9431 - val_loss: 6.4402 - val_value_loss: 0.7070 - val_policy_loss: 1.9550\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3428 - value_loss: 0.5319 - policy_loss: 1.9356 - val_loss: 6.4477 - val_value_loss: 0.7252 - val_policy_loss: 1.9527\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3110 - value_loss: 0.4765 - policy_loss: 1.9282 - val_loss: 6.4295 - val_value_loss: 0.6933 - val_policy_loss: 1.9487\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3621 - value_loss: 0.5846 - policy_loss: 1.9230 - val_loss: 6.4403 - val_value_loss: 0.7156 - val_policy_loss: 1.9487\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2797 - value_loss: 0.4262 - policy_loss: 1.9171 - val_loss: 6.4074 - val_value_loss: 0.6551 - val_policy_loss: 1.9442\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2641 - value_loss: 0.4013 - policy_loss: 1.9114 - val_loss: 6.3986 - val_value_loss: 0.6396 - val_policy_loss: 1.9426\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2491 - value_loss: 0.3782 - policy_loss: 1.9054 - val_loss: 6.3983 - val_value_loss: 0.6408 - val_policy_loss: 1.9414\n",
      "Saved model  connectfour_num_sim_10_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.75 - draw ratio 0.0\n",
      "Number of seen trajectories: 400\n",
      "Number of unique trajectories: 400\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 456us/step - loss: 6.4701 - value_loss: 0.7546 - policy_loss: 1.9715 - val_loss: 6.4879 - val_value_loss: 0.8008 - val_policy_loss: 1.9612\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4465 - value_loss: 0.7203 - policy_loss: 1.9593 - val_loss: 6.4921 - val_value_loss: 0.8133 - val_policy_loss: 1.9579\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3963 - value_loss: 0.6311 - policy_loss: 1.9487 - val_loss: 6.4997 - val_value_loss: 0.8306 - val_policy_loss: 1.9564\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3785 - value_loss: 0.6039 - policy_loss: 1.9408 - val_loss: 6.4522 - val_value_loss: 0.7414 - val_policy_loss: 1.9512\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3364 - value_loss: 0.5283 - policy_loss: 1.9329 - val_loss: 6.4471 - val_value_loss: 0.7340 - val_policy_loss: 1.9489\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3480 - value_loss: 0.5583 - policy_loss: 1.9268 - val_loss: 6.4250 - val_value_loss: 0.6939 - val_policy_loss: 1.9456\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2826 - value_loss: 0.4363 - policy_loss: 1.9187 - val_loss: 6.4028 - val_value_loss: 0.6520 - val_policy_loss: 1.9437\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2700 - value_loss: 0.4165 - policy_loss: 1.9139 - val_loss: 6.3998 - val_value_loss: 0.6487 - val_policy_loss: 1.9417\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2670 - value_loss: 0.4158 - policy_loss: 1.9092 - val_loss: 6.3927 - val_value_loss: 0.6373 - val_policy_loss: 1.9395\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2670 - value_loss: 0.4218 - policy_loss: 1.9039 - val_loss: 6.3953 - val_value_loss: 0.6432 - val_policy_loss: 1.9396\n",
      "Saved model  connectfour_num_sim_10_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.0\n",
      "Number of seen trajectories: 500\n",
      "Number of unique trajectories: 500\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.4546 - value_loss: 0.7261 - policy_loss: 1.9753 - val_loss: 6.4752 - val_value_loss: 0.7702 - val_policy_loss: 1.9727\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4113 - value_loss: 0.6477 - policy_loss: 1.9675 - val_loss: 6.4588 - val_value_loss: 0.7390 - val_policy_loss: 1.9712\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3830 - value_loss: 0.5968 - policy_loss: 1.9621 - val_loss: 6.4539 - val_value_loss: 0.7312 - val_policy_loss: 1.9697\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3602 - value_loss: 0.5567 - policy_loss: 1.9568 - val_loss: 6.4433 - val_value_loss: 0.7117 - val_policy_loss: 1.9682\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3408 - value_loss: 0.5234 - policy_loss: 1.9517 - val_loss: 6.4499 - val_value_loss: 0.7269 - val_policy_loss: 1.9665\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3260 - value_loss: 0.4982 - policy_loss: 1.9477 - val_loss: 6.4308 - val_value_loss: 0.6898 - val_policy_loss: 1.9658\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3119 - value_loss: 0.4751 - policy_loss: 1.9428 - val_loss: 6.4286 - val_value_loss: 0.6875 - val_policy_loss: 1.9641\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3015 - value_loss: 0.4580 - policy_loss: 1.9395 - val_loss: 6.4232 - val_value_loss: 0.6779 - val_policy_loss: 1.9633\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2921 - value_loss: 0.4427 - policy_loss: 1.9363 - val_loss: 6.4169 - val_value_loss: 0.6669 - val_policy_loss: 1.9619\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2805 - value_loss: 0.4239 - policy_loss: 1.9321 - val_loss: 6.4151 - val_value_loss: 0.6645 - val_policy_loss: 1.9611\n",
      "Saved model  connectfour_num_sim_10_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.56 - draw ratio 0.0\n",
      "Number of seen trajectories: 600\n",
      "Number of unique trajectories: 600\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4842 - value_loss: 0.7848 - policy_loss: 1.9791 - val_loss: 6.4564 - val_value_loss: 0.7323 - val_policy_loss: 1.9761\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4389 - value_loss: 0.7023 - policy_loss: 1.9713 - val_loss: 6.4401 - val_value_loss: 0.7022 - val_policy_loss: 1.9740\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4097 - value_loss: 0.6499 - policy_loss: 1.9656 - val_loss: 6.4342 - val_value_loss: 0.6923 - val_policy_loss: 1.9724\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3837 - value_loss: 0.6042 - policy_loss: 1.9597 - val_loss: 6.4254 - val_value_loss: 0.6766 - val_policy_loss: 1.9708\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3632 - value_loss: 0.5676 - policy_loss: 1.9556 - val_loss: 6.4129 - val_value_loss: 0.6544 - val_policy_loss: 1.9684\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3461 - value_loss: 0.5380 - policy_loss: 1.9514 - val_loss: 6.4114 - val_value_loss: 0.6536 - val_policy_loss: 1.9664\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3319 - value_loss: 0.5147 - policy_loss: 1.9465 - val_loss: 6.4097 - val_value_loss: 0.6514 - val_policy_loss: 1.9655\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3207 - value_loss: 0.4963 - policy_loss: 1.9429 - val_loss: 6.3963 - val_value_loss: 0.6265 - val_policy_loss: 1.9640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3077 - value_loss: 0.4748 - policy_loss: 1.9387 - val_loss: 6.4046 - val_value_loss: 0.6451 - val_policy_loss: 1.9623\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2995 - value_loss: 0.4627 - policy_loss: 1.9347 - val_loss: 6.3883 - val_value_loss: 0.6150 - val_policy_loss: 1.9602\n",
      "Saved model  connectfour_num_sim_10_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.0\n",
      "Number of seen trajectories: 700\n",
      "Number of unique trajectories: 700\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4783 - value_loss: 0.7723 - policy_loss: 1.9830 - val_loss: 6.4488 - val_value_loss: 0.7237 - val_policy_loss: 1.9729\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4355 - value_loss: 0.6953 - policy_loss: 1.9748 - val_loss: 6.4356 - val_value_loss: 0.7005 - val_policy_loss: 1.9699\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4098 - value_loss: 0.6505 - policy_loss: 1.9684 - val_loss: 6.4306 - val_value_loss: 0.6925 - val_policy_loss: 1.9684\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3765 - value_loss: 0.5906 - policy_loss: 1.9620 - val_loss: 6.4167 - val_value_loss: 0.6674 - val_policy_loss: 1.9659\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3542 - value_loss: 0.5515 - policy_loss: 1.9570 - val_loss: 6.4230 - val_value_loss: 0.6824 - val_policy_loss: 1.9639\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3390 - value_loss: 0.5270 - policy_loss: 1.9513 - val_loss: 6.4048 - val_value_loss: 0.6471 - val_policy_loss: 1.9630\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3195 - value_loss: 0.4935 - policy_loss: 1.9461 - val_loss: 6.3979 - val_value_loss: 0.6365 - val_policy_loss: 1.9601\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3084 - value_loss: 0.4756 - policy_loss: 1.9423 - val_loss: 6.4018 - val_value_loss: 0.6460 - val_policy_loss: 1.9587\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2941 - value_loss: 0.4523 - policy_loss: 1.9372 - val_loss: 6.3934 - val_value_loss: 0.6295 - val_policy_loss: 1.9587\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2857 - value_loss: 0.4394 - policy_loss: 1.9335 - val_loss: 6.3921 - val_value_loss: 0.6300 - val_policy_loss: 1.9560\n",
      "Saved model  connectfour_num_sim_10_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.71 - draw ratio 0.0\n",
      "Number of seen trajectories: 800\n",
      "Number of unique trajectories: 800\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.4833 - value_loss: 0.7957 - policy_loss: 1.9729 - val_loss: 6.4570 - val_value_loss: 0.7476 - val_policy_loss: 1.9685\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4383 - value_loss: 0.7138 - policy_loss: 1.9651 - val_loss: 6.4414 - val_value_loss: 0.7198 - val_policy_loss: 1.9655\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4023 - value_loss: 0.6492 - policy_loss: 1.9580 - val_loss: 6.4328 - val_value_loss: 0.7051 - val_policy_loss: 1.9633\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3768 - value_loss: 0.6045 - policy_loss: 1.9521 - val_loss: 6.4200 - val_value_loss: 0.6821 - val_policy_loss: 1.9609\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3500 - value_loss: 0.5561 - policy_loss: 1.9472 - val_loss: 6.4156 - val_value_loss: 0.6759 - val_policy_loss: 1.9588\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3310 - value_loss: 0.5242 - policy_loss: 1.9415 - val_loss: 6.4086 - val_value_loss: 0.6637 - val_policy_loss: 1.9572\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3141 - value_loss: 0.4950 - policy_loss: 1.9370 - val_loss: 6.3995 - val_value_loss: 0.6485 - val_policy_loss: 1.9546\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.3082 - value_loss: 0.4877 - policy_loss: 1.9329 - val_loss: 6.3976 - val_value_loss: 0.6456 - val_policy_loss: 1.9541\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2941 - value_loss: 0.4632 - policy_loss: 1.9296 - val_loss: 6.4095 - val_value_loss: 0.6716 - val_policy_loss: 1.9521\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2806 - value_loss: 0.4417 - policy_loss: 1.9244 - val_loss: 6.3876 - val_value_loss: 0.6297 - val_policy_loss: 1.9505\n",
      "Saved model  connectfour_num_sim_10_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.75 - draw ratio 0.0\n",
      "Number of seen trajectories: 900\n",
      "Number of unique trajectories: 900\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4448 - value_loss: 0.7287 - policy_loss: 1.9661 - val_loss: 6.4368 - val_value_loss: 0.7155 - val_policy_loss: 1.9635\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4025 - value_loss: 0.6514 - policy_loss: 1.9592 - val_loss: 6.4318 - val_value_loss: 0.7084 - val_policy_loss: 1.9609\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3767 - value_loss: 0.6063 - policy_loss: 1.9530 - val_loss: 6.4211 - val_value_loss: 0.6883 - val_policy_loss: 1.9599\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3674 - value_loss: 0.5942 - policy_loss: 1.9468 - val_loss: 6.4482 - val_value_loss: 0.7449 - val_policy_loss: 1.9578\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3306 - value_loss: 0.5259 - policy_loss: 1.9417 - val_loss: 6.4080 - val_value_loss: 0.6660 - val_policy_loss: 1.9567\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3112 - value_loss: 0.4921 - policy_loss: 1.9370 - val_loss: 6.4072 - val_value_loss: 0.6652 - val_policy_loss: 1.9563\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3042 - value_loss: 0.4820 - policy_loss: 1.9335 - val_loss: 6.3996 - val_value_loss: 0.6517 - val_policy_loss: 1.9548\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2847 - value_loss: 0.4484 - policy_loss: 1.9284 - val_loss: 6.3959 - val_value_loss: 0.6460 - val_policy_loss: 1.9534\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2753 - value_loss: 0.4335 - policy_loss: 1.9249 - val_loss: 6.3923 - val_value_loss: 0.6401 - val_policy_loss: 1.9525\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2630 - value_loss: 0.4139 - policy_loss: 1.9202 - val_loss: 6.3884 - val_value_loss: 0.6347 - val_policy_loss: 1.9505\n",
      "Saved model  connectfour_num_sim_10_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.0\n",
      "Number of seen trajectories: 1000\n",
      "Number of unique trajectories: 1000\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.4816 - value_loss: 0.8049 - policy_loss: 1.9667 - val_loss: 6.4585 - val_value_loss: 0.7627 - val_policy_loss: 1.9627\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4509 - value_loss: 0.7474 - policy_loss: 1.9629 - val_loss: 6.4506 - val_value_loss: 0.7485 - val_policy_loss: 1.9613\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4257 - value_loss: 0.6998 - policy_loss: 1.9602 - val_loss: 6.4455 - val_value_loss: 0.7394 - val_policy_loss: 1.9603\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4047 - value_loss: 0.6616 - policy_loss: 1.9567 - val_loss: 6.4425 - val_value_loss: 0.7351 - val_policy_loss: 1.9589\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3887 - value_loss: 0.6324 - policy_loss: 1.9540 - val_loss: 6.4313 - val_value_loss: 0.7135 - val_policy_loss: 1.9582\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3723 - value_loss: 0.6027 - policy_loss: 1.9510 - val_loss: 6.4284 - val_value_loss: 0.7087 - val_policy_loss: 1.9573\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3592 - value_loss: 0.5795 - policy_loss: 1.9484 - val_loss: 6.4228 - val_value_loss: 0.6985 - val_policy_loss: 1.9564\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3487 - value_loss: 0.5607 - policy_loss: 1.9462 - val_loss: 6.4141 - val_value_loss: 0.6822 - val_policy_loss: 1.9555\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3374 - value_loss: 0.5406 - policy_loss: 1.9438 - val_loss: 6.4149 - val_value_loss: 0.6847 - val_policy_loss: 1.9548\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3279 - value_loss: 0.5241 - policy_loss: 1.9415 - val_loss: 6.4113 - val_value_loss: 0.6790 - val_policy_loss: 1.9536\n",
      "Saved model  connectfour_num_sim_10_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.67 - draw ratio 0.0\n",
      "Number of seen trajectories: 1100\n",
      "Number of unique trajectories: 1100\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 456us/step - loss: 6.4716 - value_loss: 0.7856 - policy_loss: 1.9676 - val_loss: 6.4350 - val_value_loss: 0.7145 - val_policy_loss: 1.9656\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4397 - value_loss: 0.7262 - policy_loss: 1.9634 - val_loss: 6.4254 - val_value_loss: 0.6963 - val_policy_loss: 1.9646\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4165 - value_loss: 0.6828 - policy_loss: 1.9605 - val_loss: 6.4174 - val_value_loss: 0.6819 - val_policy_loss: 1.9633\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3983 - value_loss: 0.6503 - policy_loss: 1.9568 - val_loss: 6.4116 - val_value_loss: 0.6709 - val_policy_loss: 1.9629\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3841 - value_loss: 0.6239 - policy_loss: 1.9549 - val_loss: 6.4061 - val_value_loss: 0.6613 - val_policy_loss: 1.9616\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3681 - value_loss: 0.5958 - policy_loss: 1.9511 - val_loss: 6.4030 - val_value_loss: 0.6562 - val_policy_loss: 1.9608\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3575 - value_loss: 0.5775 - policy_loss: 1.9485 - val_loss: 6.3963 - val_value_loss: 0.6439 - val_policy_loss: 1.9597\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3438 - value_loss: 0.5532 - policy_loss: 1.9455 - val_loss: 6.3917 - val_value_loss: 0.6358 - val_policy_loss: 1.9589\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3342 - value_loss: 0.5363 - policy_loss: 1.9434 - val_loss: 6.3893 - val_value_loss: 0.6323 - val_policy_loss: 1.9578\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3248 - value_loss: 0.5200 - policy_loss: 1.9410 - val_loss: 6.3860 - val_value_loss: 0.6264 - val_policy_loss: 1.9572\n",
      "Saved model  connectfour_num_sim_10_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.67 - draw ratio 0.0\n",
      "Number of seen trajectories: 1200\n",
      "Number of unique trajectories: 1200\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4701 - value_loss: 0.7741 - policy_loss: 1.9777 - val_loss: 6.4791 - val_value_loss: 0.7980 - val_policy_loss: 1.9719\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4398 - value_loss: 0.7182 - policy_loss: 1.9732 - val_loss: 6.4598 - val_value_loss: 0.7613 - val_policy_loss: 1.9702\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4156 - value_loss: 0.6739 - policy_loss: 1.9693 - val_loss: 6.4519 - val_value_loss: 0.7467 - val_policy_loss: 1.9692\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3997 - value_loss: 0.6443 - policy_loss: 1.9672 - val_loss: 6.4436 - val_value_loss: 0.7312 - val_policy_loss: 1.9681\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3837 - value_loss: 0.6161 - policy_loss: 1.9636 - val_loss: 6.4372 - val_value_loss: 0.7193 - val_policy_loss: 1.9674\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3646 - value_loss: 0.5814 - policy_loss: 1.9602 - val_loss: 6.4315 - val_value_loss: 0.7092 - val_policy_loss: 1.9664\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3525 - value_loss: 0.5598 - policy_loss: 1.9579 - val_loss: 6.4293 - val_value_loss: 0.7056 - val_policy_loss: 1.9657\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3390 - value_loss: 0.5364 - policy_loss: 1.9543 - val_loss: 6.4216 - val_value_loss: 0.6910 - val_policy_loss: 1.9649\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3292 - value_loss: 0.5193 - policy_loss: 1.9520 - val_loss: 6.4178 - val_value_loss: 0.6844 - val_policy_loss: 1.9642\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3185 - value_loss: 0.5005 - policy_loss: 1.9496 - val_loss: 6.4154 - val_value_loss: 0.6806 - val_policy_loss: 1.9634\n",
      "Saved model  connectfour_num_sim_10_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.72 - draw ratio 0.0\n",
      "Number of seen trajectories: 1300\n",
      "Number of unique trajectories: 1300\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.4644 - value_loss: 0.7667 - policy_loss: 1.9752 - val_loss: 6.4782 - val_value_loss: 0.7951 - val_policy_loss: 1.9747\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4388 - value_loss: 0.7207 - policy_loss: 1.9702 - val_loss: 6.4659 - val_value_loss: 0.7720 - val_policy_loss: 1.9732\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4171 - value_loss: 0.6812 - policy_loss: 1.9665 - val_loss: 6.4572 - val_value_loss: 0.7564 - val_policy_loss: 1.9717\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3971 - value_loss: 0.6451 - policy_loss: 1.9628 - val_loss: 6.4516 - val_value_loss: 0.7465 - val_policy_loss: 1.9705\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3827 - value_loss: 0.6197 - policy_loss: 1.9596 - val_loss: 6.4450 - val_value_loss: 0.7346 - val_policy_loss: 1.9693\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3678 - value_loss: 0.5935 - policy_loss: 1.9562 - val_loss: 6.4412 - val_value_loss: 0.7284 - val_policy_loss: 1.9681\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3561 - value_loss: 0.5731 - policy_loss: 1.9532 - val_loss: 6.4368 - val_value_loss: 0.7208 - val_policy_loss: 1.9672\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3427 - value_loss: 0.5493 - policy_loss: 1.9504 - val_loss: 6.4301 - val_value_loss: 0.7085 - val_policy_loss: 1.9663\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3374 - value_loss: 0.5411 - policy_loss: 1.9482 - val_loss: 6.4253 - val_value_loss: 0.6996 - val_policy_loss: 1.9656\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3269 - value_loss: 0.5231 - policy_loss: 1.9454 - val_loss: 6.4240 - val_value_loss: 0.6984 - val_policy_loss: 1.9644\n",
      "Saved model  connectfour_num_sim_10_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.68 - draw ratio 0.0\n",
      "Number of seen trajectories: 1400\n",
      "Number of unique trajectories: 1399\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4970 - value_loss: 0.8337 - policy_loss: 1.9752 - val_loss: 6.4862 - val_value_loss: 0.8040 - val_policy_loss: 1.9834\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4641 - value_loss: 0.7711 - policy_loss: 1.9721 - val_loss: 6.4735 - val_value_loss: 0.7799 - val_policy_loss: 1.9821\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4358 - value_loss: 0.7188 - policy_loss: 1.9680 - val_loss: 6.4648 - val_value_loss: 0.7642 - val_policy_loss: 1.9808\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4171 - value_loss: 0.6845 - policy_loss: 1.9651 - val_loss: 6.4562 - val_value_loss: 0.7480 - val_policy_loss: 1.9797\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3964 - value_loss: 0.6464 - policy_loss: 1.9619 - val_loss: 6.4485 - val_value_loss: 0.7341 - val_policy_loss: 1.9785\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3808 - value_loss: 0.6180 - policy_loss: 1.9594 - val_loss: 6.4458 - val_value_loss: 0.7298 - val_policy_loss: 1.9775\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3666 - value_loss: 0.5928 - policy_loss: 1.9563 - val_loss: 6.4362 - val_value_loss: 0.7121 - val_policy_loss: 1.9761\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3538 - value_loss: 0.5693 - policy_loss: 1.9543 - val_loss: 6.4345 - val_value_loss: 0.7101 - val_policy_loss: 1.9751\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3410 - value_loss: 0.5468 - policy_loss: 1.9514 - val_loss: 6.4274 - val_value_loss: 0.6973 - val_policy_loss: 1.9738\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3319 - value_loss: 0.5310 - policy_loss: 1.9491 - val_loss: 6.4235 - val_value_loss: 0.6905 - val_policy_loss: 1.9729\n",
      "Saved model  connectfour_num_sim_10_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.0\n",
      "Number of seen trajectories: 1500\n",
      "Number of unique trajectories: 1499\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.5158 - value_loss: 0.8757 - policy_loss: 1.9725 - val_loss: 6.5271 - val_value_loss: 0.8984 - val_policy_loss: 1.9723\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4987 - value_loss: 0.8424 - policy_loss: 1.9715 - val_loss: 6.5170 - val_value_loss: 0.8789 - val_policy_loss: 1.9717\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4818 - value_loss: 0.8108 - policy_loss: 1.9695 - val_loss: 6.5122 - val_value_loss: 0.8699 - val_policy_loss: 1.9710\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4669 - value_loss: 0.7827 - policy_loss: 1.9677 - val_loss: 6.5048 - val_value_loss: 0.8561 - val_policy_loss: 1.9703\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4549 - value_loss: 0.7601 - policy_loss: 1.9666 - val_loss: 6.4988 - val_value_loss: 0.8447 - val_policy_loss: 1.9698\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4411 - value_loss: 0.7342 - policy_loss: 1.9649 - val_loss: 6.4943 - val_value_loss: 0.8366 - val_policy_loss: 1.9690\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4302 - value_loss: 0.7139 - policy_loss: 1.9635 - val_loss: 6.4898 - val_value_loss: 0.8282 - val_policy_loss: 1.9684\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4202 - value_loss: 0.6950 - policy_loss: 1.9625 - val_loss: 6.4853 - val_value_loss: 0.8200 - val_policy_loss: 1.9677\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4109 - value_loss: 0.6778 - policy_loss: 1.9610 - val_loss: 6.4811 - val_value_loss: 0.8122 - val_policy_loss: 1.9671\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4024 - value_loss: 0.6620 - policy_loss: 1.9600 - val_loss: 6.4768 - val_value_loss: 0.8044 - val_policy_loss: 1.9664\n",
      "Saved model  connectfour_num_sim_10_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.75 - draw ratio 0.0\n",
      "Number of seen trajectories: 1600\n",
      "Number of unique trajectories: 1599\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5267 - value_loss: 0.8968 - policy_loss: 1.9737 - val_loss: 6.5450 - val_value_loss: 0.9153 - val_policy_loss: 1.9919\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5080 - value_loss: 0.8620 - policy_loss: 1.9714 - val_loss: 6.5389 - val_value_loss: 0.9043 - val_policy_loss: 1.9909\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4912 - value_loss: 0.8301 - policy_loss: 1.9697 - val_loss: 6.5290 - val_value_loss: 0.8854 - val_policy_loss: 1.9900\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4752 - value_loss: 0.8010 - policy_loss: 1.9669 - val_loss: 6.5221 - val_value_loss: 0.8726 - val_policy_loss: 1.9891\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4602 - value_loss: 0.7728 - policy_loss: 1.9653 - val_loss: 6.5181 - val_value_loss: 0.8652 - val_policy_loss: 1.9886\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4511 - value_loss: 0.7551 - policy_loss: 1.9648 - val_loss: 6.5108 - val_value_loss: 0.8513 - val_policy_loss: 1.9881\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4376 - value_loss: 0.7310 - policy_loss: 1.9620 - val_loss: 6.5047 - val_value_loss: 0.8397 - val_policy_loss: 1.9875\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4247 - value_loss: 0.7070 - policy_loss: 1.9603 - val_loss: 6.5014 - val_value_loss: 0.8337 - val_policy_loss: 1.9870\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4160 - value_loss: 0.6907 - policy_loss: 1.9592 - val_loss: 6.4994 - val_value_loss: 0.8305 - val_policy_loss: 1.9864\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4123 - value_loss: 0.6837 - policy_loss: 1.9588 - val_loss: 6.4932 - val_value_loss: 0.8185 - val_policy_loss: 1.9859\n",
      "Saved model  connectfour_num_sim_10_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.82 - draw ratio 0.0\n",
      "Number of seen trajectories: 1700\n",
      "Number of unique trajectories: 1699\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 456us/step - loss: 6.5462 - value_loss: 0.9301 - policy_loss: 1.9803 - val_loss: 6.5497 - val_value_loss: 0.9401 - val_policy_loss: 1.9773\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5250 - value_loss: 0.8908 - policy_loss: 1.9774 - val_loss: 6.5413 - val_value_loss: 0.9239 - val_policy_loss: 1.9768\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5072 - value_loss: 0.8577 - policy_loss: 1.9750 - val_loss: 6.5339 - val_value_loss: 0.9100 - val_policy_loss: 1.9762\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4912 - value_loss: 0.8278 - policy_loss: 1.9731 - val_loss: 6.5282 - val_value_loss: 0.8990 - val_policy_loss: 1.9757\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4786 - value_loss: 0.8045 - policy_loss: 1.9711 - val_loss: 6.5230 - val_value_loss: 0.8894 - val_policy_loss: 1.9750\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4673 - value_loss: 0.7838 - policy_loss: 1.9693 - val_loss: 6.5183 - val_value_loss: 0.8806 - val_policy_loss: 1.9746\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4555 - value_loss: 0.7611 - policy_loss: 1.9684 - val_loss: 6.5137 - val_value_loss: 0.8721 - val_policy_loss: 1.9740\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4417 - value_loss: 0.7360 - policy_loss: 1.9659 - val_loss: 6.5089 - val_value_loss: 0.8630 - val_policy_loss: 1.9734\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4312 - value_loss: 0.7171 - policy_loss: 1.9641 - val_loss: 6.5047 - val_value_loss: 0.8553 - val_policy_loss: 1.9729\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4242 - value_loss: 0.7045 - policy_loss: 1.9626 - val_loss: 6.5008 - val_value_loss: 0.8481 - val_policy_loss: 1.9725\n",
      "Saved model  connectfour_num_sim_10_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.81 - draw ratio 0.0\n",
      "Number of seen trajectories: 1800\n",
      "Number of unique trajectories: 1799\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5408 - value_loss: 0.9203 - policy_loss: 1.9802 - val_loss: 6.5335 - val_value_loss: 0.9023 - val_policy_loss: 1.9838\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5184 - value_loss: 0.8776 - policy_loss: 1.9782 - val_loss: 6.5275 - val_value_loss: 0.8912 - val_policy_loss: 1.9827\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4994 - value_loss: 0.8422 - policy_loss: 1.9757 - val_loss: 6.5200 - val_value_loss: 0.8773 - val_policy_loss: 1.9819\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4831 - value_loss: 0.8121 - policy_loss: 1.9733 - val_loss: 6.5143 - val_value_loss: 0.8668 - val_policy_loss: 1.9810\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4667 - value_loss: 0.7814 - policy_loss: 1.9711 - val_loss: 6.5088 - val_value_loss: 0.8567 - val_policy_loss: 1.9801\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4534 - value_loss: 0.7568 - policy_loss: 1.9693 - val_loss: 6.5060 - val_value_loss: 0.8523 - val_policy_loss: 1.9791\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4438 - value_loss: 0.7385 - policy_loss: 1.9685 - val_loss: 6.5008 - val_value_loss: 0.8428 - val_policy_loss: 1.9783\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4316 - value_loss: 0.7158 - policy_loss: 1.9668 - val_loss: 6.4966 - val_value_loss: 0.8353 - val_policy_loss: 1.9775\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4196 - value_loss: 0.6944 - policy_loss: 1.9644 - val_loss: 6.4925 - val_value_loss: 0.8278 - val_policy_loss: 1.9768\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4090 - value_loss: 0.6748 - policy_loss: 1.9628 - val_loss: 6.4912 - val_value_loss: 0.8260 - val_policy_loss: 1.9760\n",
      "Saved model  connectfour_num_sim_10_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.73 - draw ratio 0.0\n",
      "Number of seen trajectories: 1900\n",
      "Number of unique trajectories: 1899\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.5153 - value_loss: 0.8785 - policy_loss: 1.9718 - val_loss: 6.4958 - val_value_loss: 0.8403 - val_policy_loss: 1.9711\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4955 - value_loss: 0.8404 - policy_loss: 1.9704 - val_loss: 6.4898 - val_value_loss: 0.8288 - val_policy_loss: 1.9707\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4765 - value_loss: 0.8050 - policy_loss: 1.9679 - val_loss: 6.4830 - val_value_loss: 0.8155 - val_policy_loss: 1.9704\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4597 - value_loss: 0.7733 - policy_loss: 1.9661 - val_loss: 6.4760 - val_value_loss: 0.8018 - val_policy_loss: 1.9701\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4459 - value_loss: 0.7475 - policy_loss: 1.9644 - val_loss: 6.4697 - val_value_loss: 0.7899 - val_policy_loss: 1.9696\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4321 - value_loss: 0.7222 - policy_loss: 1.9621 - val_loss: 6.4667 - val_value_loss: 0.7845 - val_policy_loss: 1.9692\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4204 - value_loss: 0.7006 - policy_loss: 1.9604 - val_loss: 6.4628 - val_value_loss: 0.7771 - val_policy_loss: 1.9688\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4085 - value_loss: 0.6790 - policy_loss: 1.9583 - val_loss: 6.4589 - val_value_loss: 0.7697 - val_policy_loss: 1.9684\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3997 - value_loss: 0.6629 - policy_loss: 1.9568 - val_loss: 6.4538 - val_value_loss: 0.7600 - val_policy_loss: 1.9680\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3913 - value_loss: 0.6476 - policy_loss: 1.9554 - val_loss: 6.4510 - val_value_loss: 0.7549 - val_policy_loss: 1.9675\n",
      "Saved model  connectfour_num_sim_10_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.0\n",
      "Number of seen trajectories: 2000\n",
      "Number of unique trajectories: 1999\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.5122 - value_loss: 0.8702 - policy_loss: 1.9748 - val_loss: 6.5006 - val_value_loss: 0.8410 - val_policy_loss: 1.9809\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5028 - value_loss: 0.8518 - policy_loss: 1.9743 - val_loss: 6.4971 - val_value_loss: 0.8344 - val_policy_loss: 1.9803\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4926 - value_loss: 0.8327 - policy_loss: 1.9731 - val_loss: 6.4939 - val_value_loss: 0.8284 - val_policy_loss: 1.9799\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4842 - value_loss: 0.8170 - policy_loss: 1.9721 - val_loss: 6.4907 - val_value_loss: 0.8224 - val_policy_loss: 1.9796\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4763 - value_loss: 0.8024 - policy_loss: 1.9708 - val_loss: 6.4878 - val_value_loss: 0.8172 - val_policy_loss: 1.9791\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4676 - value_loss: 0.7860 - policy_loss: 1.9700 - val_loss: 6.4855 - val_value_loss: 0.8130 - val_policy_loss: 1.9788\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4611 - value_loss: 0.7737 - policy_loss: 1.9693 - val_loss: 6.4824 - val_value_loss: 0.8072 - val_policy_loss: 1.9784\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4530 - value_loss: 0.7587 - policy_loss: 1.9682 - val_loss: 6.4804 - val_value_loss: 0.8034 - val_policy_loss: 1.9781\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4476 - value_loss: 0.7483 - policy_loss: 1.9678 - val_loss: 6.4775 - val_value_loss: 0.7980 - val_policy_loss: 1.9779\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4423 - value_loss: 0.7387 - policy_loss: 1.9668 - val_loss: 6.4751 - val_value_loss: 0.7935 - val_policy_loss: 1.9776\n",
      "Saved model  connectfour_num_sim_10_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.0\n",
      "Number of seen trajectories: 2100\n",
      "Number of unique trajectories: 2099\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.5263 - value_loss: 0.8975 - policy_loss: 1.9760 - val_loss: 6.5045 - val_value_loss: 0.8539 - val_policy_loss: 1.9760\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5153 - value_loss: 0.8769 - policy_loss: 1.9747 - val_loss: 6.4991 - val_value_loss: 0.8437 - val_policy_loss: 1.9755\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5061 - value_loss: 0.8587 - policy_loss: 1.9745 - val_loss: 6.4944 - val_value_loss: 0.8348 - val_policy_loss: 1.9751\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4968 - value_loss: 0.8418 - policy_loss: 1.9729 - val_loss: 6.4900 - val_value_loss: 0.8264 - val_policy_loss: 1.9747\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4866 - value_loss: 0.8224 - policy_loss: 1.9719 - val_loss: 6.4857 - val_value_loss: 0.8181 - val_policy_loss: 1.9743\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4801 - value_loss: 0.8100 - policy_loss: 1.9712 - val_loss: 6.4817 - val_value_loss: 0.8105 - val_policy_loss: 1.9739\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4706 - value_loss: 0.7925 - policy_loss: 1.9698 - val_loss: 6.4781 - val_value_loss: 0.8039 - val_policy_loss: 1.9735\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4628 - value_loss: 0.7776 - policy_loss: 1.9692 - val_loss: 6.4743 - val_value_loss: 0.7967 - val_policy_loss: 1.9732\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4557 - value_loss: 0.7648 - policy_loss: 1.9679 - val_loss: 6.4710 - val_value_loss: 0.7904 - val_policy_loss: 1.9729\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4478 - value_loss: 0.7496 - policy_loss: 1.9673 - val_loss: 6.4679 - val_value_loss: 0.7846 - val_policy_loss: 1.9725\n",
      "Saved model  connectfour_num_sim_10_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.75 - draw ratio 0.0\n",
      "Number of seen trajectories: 2200\n",
      "Number of unique trajectories: 2198\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5534 - value_loss: 0.9561 - policy_loss: 1.9719 - val_loss: 6.5519 - val_value_loss: 0.9527 - val_policy_loss: 1.9724\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5407 - value_loss: 0.9327 - policy_loss: 1.9701 - val_loss: 6.5470 - val_value_loss: 0.9433 - val_policy_loss: 1.9721\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5309 - value_loss: 0.9140 - policy_loss: 1.9693 - val_loss: 6.5431 - val_value_loss: 0.9359 - val_policy_loss: 1.9717\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5198 - value_loss: 0.8926 - policy_loss: 1.9685 - val_loss: 6.5390 - val_value_loss: 0.9280 - val_policy_loss: 1.9715\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5096 - value_loss: 0.8732 - policy_loss: 1.9675 - val_loss: 6.5355 - val_value_loss: 0.9213 - val_policy_loss: 1.9713\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5016 - value_loss: 0.8577 - policy_loss: 1.9669 - val_loss: 6.5320 - val_value_loss: 0.9146 - val_policy_loss: 1.9710\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4913 - value_loss: 0.8387 - policy_loss: 1.9655 - val_loss: 6.5287 - val_value_loss: 0.9083 - val_policy_loss: 1.9707\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4858 - value_loss: 0.8283 - policy_loss: 1.9648 - val_loss: 6.5265 - val_value_loss: 0.9041 - val_policy_loss: 1.9705\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4787 - value_loss: 0.8152 - policy_loss: 1.9638 - val_loss: 6.5231 - val_value_loss: 0.8976 - val_policy_loss: 1.9703\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4693 - value_loss: 0.7971 - policy_loss: 1.9632 - val_loss: 6.5201 - val_value_loss: 0.8918 - val_policy_loss: 1.9701\n",
      "Saved model  connectfour_num_sim_10_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.67 - draw ratio 0.0\n",
      "Number of seen trajectories: 2300\n",
      "Number of unique trajectories: 2298\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.5360 - value_loss: 0.9221 - policy_loss: 1.9716 - val_loss: 6.5264 - val_value_loss: 0.8997 - val_policy_loss: 1.9748\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5254 - value_loss: 0.9018 - policy_loss: 1.9707 - val_loss: 6.5220 - val_value_loss: 0.8916 - val_policy_loss: 1.9742\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5141 - value_loss: 0.8807 - policy_loss: 1.9693 - val_loss: 6.5178 - val_value_loss: 0.8839 - val_policy_loss: 1.9737\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5038 - value_loss: 0.8606 - policy_loss: 1.9689 - val_loss: 6.5131 - val_value_loss: 0.8749 - val_policy_loss: 1.9732\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4964 - value_loss: 0.8469 - policy_loss: 1.9677 - val_loss: 6.5090 - val_value_loss: 0.8670 - val_policy_loss: 1.9728\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4871 - value_loss: 0.8293 - policy_loss: 1.9668 - val_loss: 6.5054 - val_value_loss: 0.8603 - val_policy_loss: 1.9725\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4796 - value_loss: 0.8147 - policy_loss: 1.9664 - val_loss: 6.5022 - val_value_loss: 0.8543 - val_policy_loss: 1.9721\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4697 - value_loss: 0.7967 - policy_loss: 1.9648 - val_loss: 6.4994 - val_value_loss: 0.8490 - val_policy_loss: 1.9718\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4634 - value_loss: 0.7847 - policy_loss: 1.9641 - val_loss: 6.4958 - val_value_loss: 0.8423 - val_policy_loss: 1.9714\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4574 - value_loss: 0.7738 - policy_loss: 1.9631 - val_loss: 6.4937 - val_value_loss: 0.8385 - val_policy_loss: 1.9711\n",
      "Saved model  connectfour_num_sim_10_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.75 - draw ratio 0.0\n",
      "Number of seen trajectories: 2400\n",
      "Number of unique trajectories: 2398\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.5453 - value_loss: 0.9421 - policy_loss: 1.9707 - val_loss: 6.5313 - val_value_loss: 0.9100 - val_policy_loss: 1.9747\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5331 - value_loss: 0.9188 - policy_loss: 1.9696 - val_loss: 6.5256 - val_value_loss: 0.8990 - val_policy_loss: 1.9744\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5240 - value_loss: 0.9015 - policy_loss: 1.9687 - val_loss: 6.5200 - val_value_loss: 0.8882 - val_policy_loss: 1.9740\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5137 - value_loss: 0.8818 - policy_loss: 1.9679 - val_loss: 6.5165 - val_value_loss: 0.8816 - val_policy_loss: 1.9738\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5038 - value_loss: 0.8632 - policy_loss: 1.9666 - val_loss: 6.5116 - val_value_loss: 0.8721 - val_policy_loss: 1.9734\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4953 - value_loss: 0.8466 - policy_loss: 1.9662 - val_loss: 6.5088 - val_value_loss: 0.8668 - val_policy_loss: 1.9732\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4873 - value_loss: 0.8320 - policy_loss: 1.9650 - val_loss: 6.5056 - val_value_loss: 0.8609 - val_policy_loss: 1.9728\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4808 - value_loss: 0.8199 - policy_loss: 1.9642 - val_loss: 6.5026 - val_value_loss: 0.8552 - val_policy_loss: 1.9724\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4713 - value_loss: 0.8018 - policy_loss: 1.9633 - val_loss: 6.4994 - val_value_loss: 0.8492 - val_policy_loss: 1.9721\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4681 - value_loss: 0.7954 - policy_loss: 1.9633 - val_loss: 6.4973 - val_value_loss: 0.8454 - val_policy_loss: 1.9718\n",
      "Saved model  connectfour_num_sim_10_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.73 - draw ratio 0.0\n",
      "Number of seen trajectories: 2500\n",
      "Number of unique trajectories: 2498\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5452 - value_loss: 0.9376 - policy_loss: 1.9752 - val_loss: 6.5506 - val_value_loss: 0.9485 - val_policy_loss: 1.9753\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5391 - value_loss: 0.9261 - policy_loss: 1.9747 - val_loss: 6.5485 - val_value_loss: 0.9445 - val_policy_loss: 1.9750\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5325 - value_loss: 0.9135 - policy_loss: 1.9740 - val_loss: 6.5466 - val_value_loss: 0.9409 - val_policy_loss: 1.9748\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5268 - value_loss: 0.9030 - policy_loss: 1.9732 - val_loss: 6.5445 - val_value_loss: 0.9371 - val_policy_loss: 1.9746\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5229 - value_loss: 0.8955 - policy_loss: 1.9730 - val_loss: 6.5426 - val_value_loss: 0.9334 - val_policy_loss: 1.9744\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5178 - value_loss: 0.8861 - policy_loss: 1.9722 - val_loss: 6.5407 - val_value_loss: 0.9299 - val_policy_loss: 1.9742\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5107 - value_loss: 0.8721 - policy_loss: 1.9719 - val_loss: 6.5390 - val_value_loss: 0.9266 - val_policy_loss: 1.9740\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5096 - value_loss: 0.8694 - policy_loss: 1.9724 - val_loss: 6.5375 - val_value_loss: 0.9238 - val_policy_loss: 1.9739\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5026 - value_loss: 0.8573 - policy_loss: 1.9706 - val_loss: 6.5358 - val_value_loss: 0.9206 - val_policy_loss: 1.9738\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5007 - value_loss: 0.8533 - policy_loss: 1.9708 - val_loss: 6.5342 - val_value_loss: 0.9174 - val_policy_loss: 1.9736\n",
      "Saved model  connectfour_num_sim_10_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.73 - draw ratio 0.0\n",
      "Number of seen trajectories: 2600\n",
      "Number of unique trajectories: 2598\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.5693 - value_loss: 0.9842 - policy_loss: 1.9773 - val_loss: 6.5522 - val_value_loss: 0.9554 - val_policy_loss: 1.9719\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5635 - value_loss: 0.9725 - policy_loss: 1.9773 - val_loss: 6.5494 - val_value_loss: 0.9502 - val_policy_loss: 1.9714\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5563 - value_loss: 0.9591 - policy_loss: 1.9763 - val_loss: 6.5466 - val_value_loss: 0.9449 - val_policy_loss: 1.9710\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5510 - value_loss: 0.9492 - policy_loss: 1.9756 - val_loss: 6.5440 - val_value_loss: 0.9402 - val_policy_loss: 1.9706\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5454 - value_loss: 0.9383 - policy_loss: 1.9753 - val_loss: 6.5416 - val_value_loss: 0.9358 - val_policy_loss: 1.9702\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5411 - value_loss: 0.9294 - policy_loss: 1.9756 - val_loss: 6.5392 - val_value_loss: 0.9315 - val_policy_loss: 1.9698\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5330 - value_loss: 0.9148 - policy_loss: 1.9740 - val_loss: 6.5368 - val_value_loss: 0.9270 - val_policy_loss: 1.9695\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5279 - value_loss: 0.9049 - policy_loss: 1.9738 - val_loss: 6.5346 - val_value_loss: 0.9229 - val_policy_loss: 1.9692\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5243 - value_loss: 0.8980 - policy_loss: 1.9736 - val_loss: 6.5324 - val_value_loss: 0.9188 - val_policy_loss: 1.9689\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5180 - value_loss: 0.8857 - policy_loss: 1.9733 - val_loss: 6.5305 - val_value_loss: 0.9153 - val_policy_loss: 1.9686\n",
      "Saved model  connectfour_num_sim_10_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.0\n",
      "Number of seen trajectories: 2700\n",
      "Number of unique trajectories: 2697\n",
      "iteration 27 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.5730 - value_loss: 0.9972 - policy_loss: 1.9718 - val_loss: 6.6004 - val_value_loss: 1.0512 - val_policy_loss: 1.9725\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5673 - value_loss: 0.9867 - policy_loss: 1.9710 - val_loss: 6.5973 - val_value_loss: 1.0455 - val_policy_loss: 1.9722\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5610 - value_loss: 0.9742 - policy_loss: 1.9707 - val_loss: 6.5945 - val_value_loss: 1.0401 - val_policy_loss: 1.9718\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5547 - value_loss: 0.9626 - policy_loss: 1.9699 - val_loss: 6.5921 - val_value_loss: 1.0357 - val_policy_loss: 1.9716\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5497 - value_loss: 0.9524 - policy_loss: 1.9701 - val_loss: 6.5897 - val_value_loss: 1.0312 - val_policy_loss: 1.9713\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5436 - value_loss: 0.9412 - policy_loss: 1.9692 - val_loss: 6.5874 - val_value_loss: 1.0268 - val_policy_loss: 1.9711\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5382 - value_loss: 0.9311 - policy_loss: 1.9684 - val_loss: 6.5852 - val_value_loss: 1.0227 - val_policy_loss: 1.9709\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5329 - value_loss: 0.9211 - policy_loss: 1.9678 - val_loss: 6.5830 - val_value_loss: 1.0185 - val_policy_loss: 1.9707\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5265 - value_loss: 0.9087 - policy_loss: 1.9673 - val_loss: 6.5808 - val_value_loss: 1.0142 - val_policy_loss: 1.9704\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5235 - value_loss: 0.9036 - policy_loss: 1.9665 - val_loss: 6.5788 - val_value_loss: 1.0106 - val_policy_loss: 1.9702\n",
      "Saved model  connectfour_num_sim_10_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.59 - draw ratio 0.0\n",
      "Number of seen trajectories: 2800\n",
      "Number of unique trajectories: 2797\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.5566 - value_loss: 0.9629 - policy_loss: 1.9735 - val_loss: 6.5524 - val_value_loss: 0.9500 - val_policy_loss: 1.9779\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5490 - value_loss: 0.9487 - policy_loss: 1.9724 - val_loss: 6.5484 - val_value_loss: 0.9424 - val_policy_loss: 1.9776\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5425 - value_loss: 0.9367 - policy_loss: 1.9716 - val_loss: 6.5448 - val_value_loss: 0.9355 - val_policy_loss: 1.9774\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5360 - value_loss: 0.9238 - policy_loss: 1.9714 - val_loss: 6.5418 - val_value_loss: 0.9296 - val_policy_loss: 1.9772\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5295 - value_loss: 0.9114 - policy_loss: 1.9709 - val_loss: 6.5388 - val_value_loss: 0.9239 - val_policy_loss: 1.9770\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5251 - value_loss: 0.9027 - policy_loss: 1.9707 - val_loss: 6.5361 - val_value_loss: 0.9187 - val_policy_loss: 1.9768\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5188 - value_loss: 0.8910 - policy_loss: 1.9699 - val_loss: 6.5335 - val_value_loss: 0.9137 - val_policy_loss: 1.9766\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5156 - value_loss: 0.8841 - policy_loss: 1.9704 - val_loss: 6.5311 - val_value_loss: 0.9090 - val_policy_loss: 1.9764\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5109 - value_loss: 0.8754 - policy_loss: 1.9698 - val_loss: 6.5288 - val_value_loss: 0.9048 - val_policy_loss: 1.9762\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5047 - value_loss: 0.8637 - policy_loss: 1.9690 - val_loss: 6.5263 - val_value_loss: 0.8999 - val_policy_loss: 1.9760\n",
      "Saved model  connectfour_num_sim_10_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.64 - draw ratio 0.0\n",
      "Number of seen trajectories: 2900\n",
      "Number of unique trajectories: 2897\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_10_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5578 - value_loss: 0.9627 - policy_loss: 1.9762 - val_loss: 6.5304 - val_value_loss: 0.9100 - val_policy_loss: 1.9741\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 446us/step - loss: 6.5489 - value_loss: 0.9458 - policy_loss: 1.9754 - val_loss: 6.5264 - val_value_loss: 0.9023 - val_policy_loss: 1.9739\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 444us/step - loss: 6.5428 - value_loss: 0.9335 - policy_loss: 1.9755 - val_loss: 6.5234 - val_value_loss: 0.8965 - val_policy_loss: 1.9737\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 447us/step - loss: 6.5364 - value_loss: 0.9211 - policy_loss: 1.9752 - val_loss: 6.5210 - val_value_loss: 0.8920 - val_policy_loss: 1.9736\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 446us/step - loss: 6.5291 - value_loss: 0.9077 - policy_loss: 1.9740 - val_loss: 6.5188 - val_value_loss: 0.8877 - val_policy_loss: 1.9734\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 446us/step - loss: 6.5241 - value_loss: 0.8980 - policy_loss: 1.9736 - val_loss: 6.5166 - val_value_loss: 0.8835 - val_policy_loss: 1.9732\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 447us/step - loss: 6.5189 - value_loss: 0.8876 - policy_loss: 1.9736 - val_loss: 6.5149 - val_value_loss: 0.8802 - val_policy_loss: 1.9731\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 446us/step - loss: 6.5150 - value_loss: 0.8800 - policy_loss: 1.9735 - val_loss: 6.5133 - val_value_loss: 0.8773 - val_policy_loss: 1.9729\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 448us/step - loss: 6.5084 - value_loss: 0.8679 - policy_loss: 1.9725 - val_loss: 6.5116 - val_value_loss: 0.8740 - val_policy_loss: 1.9727\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 446us/step - loss: 6.5052 - value_loss: 0.8617 - policy_loss: 1.9722 - val_loss: 6.5098 - val_value_loss: 0.8706 - val_policy_loss: 1.9725\n",
      "Saved model  connectfour_num_sim_10_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.77 - draw ratio 0.0\n",
      "Number of seen trajectories: 3000\n",
      "Number of unique trajectories: 2997\n"
     ]
    }
   ],
   "source": [
    "wins_3, draws_3, seen_trajectories_3, unique_trajectories_3 = test_pipeline.run(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - 10 simulations\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "losses_3 = np.ones(30) - wins_3 - draws_3\n",
    "\n",
    "plt.plot(x, wins_3, label=\"win ratio\")\n",
    "plt.plot(x, draws_3, label=\"draw ratio\")\n",
    "plt.plot(x, losses_3, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "exploration_rate_3 = unique_trajectories_3/seen_trajectories_3\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - 10 simulations\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "plt.plot(x, exploration_rate_3, label=\"unique/seen\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins_3 = [0.77, 0.71, 0.71, 0.75, 0.7, 0.56, 0.7, 0.71, 0.75, 0.79, 0.67, 0.67, 0.72, 0.68, 0.76, 0.75, 0.82, 0.81, 0.73, 0.8, 0.74, 0.75, 0.67, 0.75, 0.73, 0.73, 0.78, 0.59, 0.64, 0.77]\n",
      "draws_3 = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "seen_trajectories_3 = [ 100.  200.  300.  400.  500.  600.  700.  800.  900. 1000. 1100. 1200.\n",
      " 1300. 1400. 1500. 1600. 1700. 1800. 1900. 2000. 2100. 2200. 2300. 2400.\n",
      " 2500. 2600. 2700. 2800. 2900. 3000.]\n",
      "unique_trajectories_3 = [ 100.  200.  300.  400.  500.  600.  700.  800.  900. 1000. 1100. 1200.\n",
      " 1300. 1399. 1499. 1599. 1699. 1799. 1899. 1999. 2099. 2198. 2298. 2398.\n",
      " 2498. 2598. 2697. 2797. 2897. 2997.]\n"
     ]
    }
   ],
   "source": [
    "print(\"wins_3 =\",wins_3)\n",
    "print(\"draws_3 =\",draws_3)\n",
    "print(\"seen_trajectories_3 =\", seen_trajectories_3)\n",
    "print(\"unique_trajectories_3 =\", unique_trajectories_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25 simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCTS = {\n",
    "    'c_puct': 1,\n",
    "    'dir_alpha': 0.6,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 10,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 10\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 0,\n",
    "    'show_games': False\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 25,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.002,\n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 512,\n",
    "    'num_filters_value': 512,\n",
    "    'num_filters_tower': 512,\n",
    "    'num_residual_blocks': 3,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 512\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"connectfour_num_sim_25\", \"Connect4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (2628, 6, 7, 3)\n",
      "model_y_outcomes: (2628,)\n",
      "model_y_probabilities: (2628, 7)\n",
      "Train on 2102 samples, validate on 526 samples\n",
      "Epoch 1/10\n",
      "2102/2102 [==============================] - 5s 2ms/step - loss: 6.8518 - value_loss: 1.3109 - policy_loss: 2.1623 - val_loss: 7.0475 - val_value_loss: 1.7500 - val_policy_loss: 2.1148\n",
      "Epoch 2/10\n",
      "2102/2102 [==============================] - 1s 467us/step - loss: 6.8238 - value_loss: 1.3341 - policy_loss: 2.0835 - val_loss: 6.9352 - val_value_loss: 1.5389 - val_policy_loss: 2.1017\n",
      "Epoch 3/10\n",
      "2102/2102 [==============================] - 1s 470us/step - loss: 6.7079 - value_loss: 1.1358 - policy_loss: 2.0503 - val_loss: 7.0310 - val_value_loss: 1.7435 - val_policy_loss: 2.0891\n",
      "Epoch 4/10\n",
      "2102/2102 [==============================] - 1s 475us/step - loss: 6.7687 - value_loss: 1.2786 - policy_loss: 2.0296 - val_loss: 6.9014 - val_value_loss: 1.4851 - val_policy_loss: 2.0888\n",
      "Epoch 5/10\n",
      "2102/2102 [==============================] - 1s 471us/step - loss: 6.6777 - value_loss: 1.1132 - policy_loss: 2.0135 - val_loss: 6.9338 - val_value_loss: 1.5626 - val_policy_loss: 2.0765\n",
      "Epoch 6/10\n",
      "2102/2102 [==============================] - 1s 469us/step - loss: 6.6592 - value_loss: 1.0926 - policy_loss: 1.9974 - val_loss: 6.9264 - val_value_loss: 1.5333 - val_policy_loss: 2.0913\n",
      "Epoch 7/10\n",
      "2102/2102 [==============================] - 1s 469us/step - loss: 6.5351 - value_loss: 0.8493 - policy_loss: 1.9928 - val_loss: 6.9085 - val_value_loss: 1.4912 - val_policy_loss: 2.0980\n",
      "Epoch 8/10\n",
      "2102/2102 [==============================] - 1s 469us/step - loss: 6.5209 - value_loss: 0.8346 - policy_loss: 1.9796 - val_loss: 7.0160 - val_value_loss: 1.7349 - val_policy_loss: 2.0697\n",
      "Epoch 9/10\n",
      "2102/2102 [==============================] - 1s 469us/step - loss: 6.5366 - value_loss: 0.8778 - policy_loss: 1.9681 - val_loss: 6.9062 - val_value_loss: 1.5112 - val_policy_loss: 2.0743\n",
      "Epoch 10/10\n",
      "2102/2102 [==============================] - 1s 471us/step - loss: 6.4488 - value_loss: 0.7078 - policy_loss: 1.9630 - val_loss: 6.7833 - val_value_loss: 1.2723 - val_policy_loss: 2.0678\n",
      "Saved model  connectfour_num_sim_25_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.61 - draw ratio 0.0\n",
      "Number of seen trajectories: 100\n",
      "Number of unique trajectories: 100\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.5422 - value_loss: 0.8477 - policy_loss: 2.0105 - val_loss: 6.4906 - val_value_loss: 0.7551 - val_policy_loss: 2.0002\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4831 - value_loss: 0.7515 - policy_loss: 1.9891 - val_loss: 6.4241 - val_value_loss: 0.6328 - val_policy_loss: 1.9901\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4159 - value_loss: 0.6312 - policy_loss: 1.9757 - val_loss: 6.4432 - val_value_loss: 0.6779 - val_policy_loss: 1.9840\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4527 - value_loss: 0.7171 - policy_loss: 1.9640 - val_loss: 6.4768 - val_value_loss: 0.7539 - val_policy_loss: 1.9758\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3714 - value_loss: 0.5655 - policy_loss: 1.9537 - val_loss: 6.4379 - val_value_loss: 0.6816 - val_policy_loss: 1.9709\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3302 - value_loss: 0.4933 - policy_loss: 1.9441 - val_loss: 6.4128 - val_value_loss: 0.6389 - val_policy_loss: 1.9642\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3298 - value_loss: 0.4999 - policy_loss: 1.9373 - val_loss: 6.4613 - val_value_loss: 0.7388 - val_policy_loss: 1.9618\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.2944 - value_loss: 0.4360 - policy_loss: 1.9310 - val_loss: 6.3486 - val_value_loss: 0.5202 - val_policy_loss: 1.9556\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2665 - value_loss: 0.3886 - policy_loss: 1.9234 - val_loss: 6.3661 - val_value_loss: 0.5595 - val_policy_loss: 1.9520\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2620 - value_loss: 0.3854 - policy_loss: 1.9183 - val_loss: 6.3587 - val_value_loss: 0.5480 - val_policy_loss: 1.9493\n",
      "Saved model  connectfour_num_sim_25_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.71 - draw ratio 0.0\n",
      "Number of seen trajectories: 200\n",
      "Number of unique trajectories: 200\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 465us/step - loss: 6.5223 - value_loss: 0.8467 - policy_loss: 1.9781 - val_loss: 6.5094 - val_value_loss: 0.8234 - val_policy_loss: 1.9760\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4723 - value_loss: 0.7584 - policy_loss: 1.9672 - val_loss: 6.4732 - val_value_loss: 0.7487 - val_policy_loss: 1.9789\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4528 - value_loss: 0.7315 - policy_loss: 1.9557 - val_loss: 6.5266 - val_value_loss: 0.8619 - val_policy_loss: 1.9732\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4438 - value_loss: 0.7222 - policy_loss: 1.9477 - val_loss: 6.5136 - val_value_loss: 0.8403 - val_policy_loss: 1.9695\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4057 - value_loss: 0.6530 - policy_loss: 1.9413 - val_loss: 6.4384 - val_value_loss: 0.6923 - val_policy_loss: 1.9678\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 457us/step - loss: 6.3638 - value_loss: 0.5759 - policy_loss: 1.9352 - val_loss: 6.4388 - val_value_loss: 0.6944 - val_policy_loss: 1.9672\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 458us/step - loss: 6.3197 - value_loss: 0.4952 - policy_loss: 1.9284 - val_loss: 6.4463 - val_value_loss: 0.7137 - val_policy_loss: 1.9634\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 463us/step - loss: 6.2990 - value_loss: 0.4601 - policy_loss: 1.9226 - val_loss: 6.4219 - val_value_loss: 0.6692 - val_policy_loss: 1.9597\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2901 - value_loss: 0.4479 - policy_loss: 1.9178 - val_loss: 6.3685 - val_value_loss: 0.5659 - val_policy_loss: 1.9569\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 459us/step - loss: 6.2565 - value_loss: 0.3849 - policy_loss: 1.9142 - val_loss: 6.3636 - val_value_loss: 0.5552 - val_policy_loss: 1.9585\n",
      "Saved model  connectfour_num_sim_25_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.73 - draw ratio 0.0\n",
      "Number of seen trajectories: 300\n",
      "Number of unique trajectories: 300\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4694 - value_loss: 0.7540 - policy_loss: 1.9717 - val_loss: 6.5540 - val_value_loss: 0.9182 - val_policy_loss: 1.9769\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4865 - value_loss: 0.7994 - policy_loss: 1.9610 - val_loss: 6.5197 - val_value_loss: 0.8542 - val_policy_loss: 1.9730\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4285 - value_loss: 0.6923 - policy_loss: 1.9528 - val_loss: 6.5236 - val_value_loss: 0.8674 - val_policy_loss: 1.9682\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3991 - value_loss: 0.6412 - policy_loss: 1.9457 - val_loss: 6.4625 - val_value_loss: 0.7487 - val_policy_loss: 1.9654\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3697 - value_loss: 0.5890 - policy_loss: 1.9397 - val_loss: 6.4356 - val_value_loss: 0.6963 - val_policy_loss: 1.9645\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3105 - value_loss: 0.4783 - policy_loss: 1.9326 - val_loss: 6.4266 - val_value_loss: 0.6810 - val_policy_loss: 1.9625\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2997 - value_loss: 0.4621 - policy_loss: 1.9280 - val_loss: 6.4446 - val_value_loss: 0.7188 - val_policy_loss: 1.9614\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2849 - value_loss: 0.4385 - policy_loss: 1.9225 - val_loss: 6.4154 - val_value_loss: 0.6628 - val_policy_loss: 1.9596\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.2744 - value_loss: 0.4228 - policy_loss: 1.9178 - val_loss: 6.4259 - val_value_loss: 0.6846 - val_policy_loss: 1.9595\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3613 - value_loss: 0.6004 - policy_loss: 1.9147 - val_loss: 6.4899 - val_value_loss: 0.8136 - val_policy_loss: 1.9592\n",
      "Saved model  connectfour_num_sim_25_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.0\n",
      "Number of seen trajectories: 400\n",
      "Number of unique trajectories: 400\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.4896 - value_loss: 0.8028 - policy_loss: 1.9695 - val_loss: 6.4318 - val_value_loss: 0.6966 - val_policy_loss: 1.9606\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4042 - value_loss: 0.6430 - policy_loss: 1.9593 - val_loss: 6.4560 - val_value_loss: 0.7476 - val_policy_loss: 1.9586\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4604 - value_loss: 0.7636 - policy_loss: 1.9517 - val_loss: 6.4945 - val_value_loss: 0.8278 - val_policy_loss: 1.9560\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4044 - value_loss: 0.6590 - policy_loss: 1.9450 - val_loss: 6.4630 - val_value_loss: 0.7656 - val_policy_loss: 1.9559\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3692 - value_loss: 0.5965 - policy_loss: 1.9376 - val_loss: 6.4400 - val_value_loss: 0.7205 - val_policy_loss: 1.9557\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3237 - value_loss: 0.5109 - policy_loss: 1.9329 - val_loss: 6.3940 - val_value_loss: 0.6338 - val_policy_loss: 1.9509\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2910 - value_loss: 0.4521 - policy_loss: 1.9271 - val_loss: 6.4034 - val_value_loss: 0.6549 - val_policy_loss: 1.9494\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3125 - value_loss: 0.4994 - policy_loss: 1.9235 - val_loss: 6.4124 - val_value_loss: 0.6743 - val_policy_loss: 1.9486\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2786 - value_loss: 0.4378 - policy_loss: 1.9178 - val_loss: 6.3862 - val_value_loss: 0.6242 - val_policy_loss: 1.9469\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2626 - value_loss: 0.4101 - policy_loss: 1.9140 - val_loss: 6.3860 - val_value_loss: 0.6261 - val_policy_loss: 1.9454\n",
      "Saved model  connectfour_num_sim_25_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.0\n",
      "Number of seen trajectories: 500\n",
      "Number of unique trajectories: 500\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4698 - value_loss: 0.7716 - policy_loss: 1.9677 - val_loss: 6.4657 - val_value_loss: 0.7659 - val_policy_loss: 1.9652\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4241 - value_loss: 0.6882 - policy_loss: 1.9600 - val_loss: 6.4546 - val_value_loss: 0.7457 - val_policy_loss: 1.9635\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3945 - value_loss: 0.6337 - policy_loss: 1.9555 - val_loss: 6.4455 - val_value_loss: 0.7300 - val_policy_loss: 1.9614\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3710 - value_loss: 0.5918 - policy_loss: 1.9508 - val_loss: 6.4392 - val_value_loss: 0.7188 - val_policy_loss: 1.9603\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3502 - value_loss: 0.5557 - policy_loss: 1.9456 - val_loss: 6.4336 - val_value_loss: 0.7090 - val_policy_loss: 1.9592\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3335 - value_loss: 0.5269 - policy_loss: 1.9412 - val_loss: 6.4257 - val_value_loss: 0.6953 - val_policy_loss: 1.9575\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3215 - value_loss: 0.5064 - policy_loss: 1.9381 - val_loss: 6.4216 - val_value_loss: 0.6887 - val_policy_loss: 1.9561\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3101 - value_loss: 0.4878 - policy_loss: 1.9343 - val_loss: 6.4199 - val_value_loss: 0.6866 - val_policy_loss: 1.9551\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2980 - value_loss: 0.4674 - policy_loss: 1.9308 - val_loss: 6.4147 - val_value_loss: 0.6780 - val_policy_loss: 1.9536\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2886 - value_loss: 0.4523 - policy_loss: 1.9274 - val_loss: 6.4141 - val_value_loss: 0.6780 - val_policy_loss: 1.9528\n",
      "Saved model  connectfour_num_sim_25_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.66 - draw ratio 0.0\n",
      "Number of seen trajectories: 600\n",
      "Number of unique trajectories: 600\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4712 - value_loss: 0.7686 - policy_loss: 1.9766 - val_loss: 6.4671 - val_value_loss: 0.7647 - val_policy_loss: 1.9725\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4275 - value_loss: 0.6888 - policy_loss: 1.9693 - val_loss: 6.4511 - val_value_loss: 0.7341 - val_policy_loss: 1.9715\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3968 - value_loss: 0.6340 - policy_loss: 1.9630 - val_loss: 6.4436 - val_value_loss: 0.7213 - val_policy_loss: 1.9695\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3745 - value_loss: 0.5958 - policy_loss: 1.9570 - val_loss: 6.4376 - val_value_loss: 0.7102 - val_policy_loss: 1.9688\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3559 - value_loss: 0.5633 - policy_loss: 1.9527 - val_loss: 6.4287 - val_value_loss: 0.6945 - val_policy_loss: 1.9672\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3393 - value_loss: 0.5358 - policy_loss: 1.9471 - val_loss: 6.4227 - val_value_loss: 0.6828 - val_policy_loss: 1.9672\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3246 - value_loss: 0.5117 - policy_loss: 1.9423 - val_loss: 6.4208 - val_value_loss: 0.6815 - val_policy_loss: 1.9650\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3131 - value_loss: 0.4926 - policy_loss: 1.9387 - val_loss: 6.4205 - val_value_loss: 0.6823 - val_policy_loss: 1.9640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3036 - value_loss: 0.4776 - policy_loss: 1.9350 - val_loss: 6.4079 - val_value_loss: 0.6587 - val_policy_loss: 1.9627\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2897 - value_loss: 0.4549 - policy_loss: 1.9302 - val_loss: 6.4056 - val_value_loss: 0.6557 - val_policy_loss: 1.9614\n",
      "Saved model  connectfour_num_sim_25_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.68 - draw ratio 0.0\n",
      "Number of seen trajectories: 700\n",
      "Number of unique trajectories: 700\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4850 - value_loss: 0.7956 - policy_loss: 1.9805 - val_loss: 6.4423 - val_value_loss: 0.7146 - val_policy_loss: 1.9761\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4395 - value_loss: 0.7128 - policy_loss: 1.9726 - val_loss: 6.4348 - val_value_loss: 0.7023 - val_policy_loss: 1.9739\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4020 - value_loss: 0.6443 - policy_loss: 1.9664 - val_loss: 6.4254 - val_value_loss: 0.6855 - val_policy_loss: 1.9722\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3717 - value_loss: 0.5906 - policy_loss: 1.9598 - val_loss: 6.4166 - val_value_loss: 0.6706 - val_policy_loss: 1.9699\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3540 - value_loss: 0.5598 - policy_loss: 1.9555 - val_loss: 6.4111 - val_value_loss: 0.6624 - val_policy_loss: 1.9673\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3347 - value_loss: 0.5266 - policy_loss: 1.9505 - val_loss: 6.4120 - val_value_loss: 0.6659 - val_policy_loss: 1.9659\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3228 - value_loss: 0.5077 - policy_loss: 1.9459 - val_loss: 6.3992 - val_value_loss: 0.6424 - val_policy_loss: 1.9641\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3100 - value_loss: 0.4863 - policy_loss: 1.9420 - val_loss: 6.3906 - val_value_loss: 0.6270 - val_policy_loss: 1.9628\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2934 - value_loss: 0.4574 - policy_loss: 1.9381 - val_loss: 6.3847 - val_value_loss: 0.6162 - val_policy_loss: 1.9621\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2831 - value_loss: 0.4405 - policy_loss: 1.9345 - val_loss: 6.3829 - val_value_loss: 0.6146 - val_policy_loss: 1.9603\n",
      "Saved model  connectfour_num_sim_25_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.66 - draw ratio 0.0\n",
      "Number of seen trajectories: 800\n",
      "Number of unique trajectories: 800\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.4612 - value_loss: 0.7623 - policy_loss: 1.9694 - val_loss: 6.4840 - val_value_loss: 0.8108 - val_policy_loss: 1.9666\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4244 - value_loss: 0.6951 - policy_loss: 1.9633 - val_loss: 6.4701 - val_value_loss: 0.7841 - val_policy_loss: 1.9658\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3976 - value_loss: 0.6479 - policy_loss: 1.9572 - val_loss: 6.4726 - val_value_loss: 0.7909 - val_policy_loss: 1.9643\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3621 - value_loss: 0.5822 - policy_loss: 1.9522 - val_loss: 6.4493 - val_value_loss: 0.7458 - val_policy_loss: 1.9632\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 456us/step - loss: 6.3432 - value_loss: 0.5485 - policy_loss: 1.9484 - val_loss: 6.4417 - val_value_loss: 0.7328 - val_policy_loss: 1.9613\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.3254 - value_loss: 0.5184 - policy_loss: 1.9433 - val_loss: 6.4354 - val_value_loss: 0.7214 - val_policy_loss: 1.9604\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3100 - value_loss: 0.4913 - policy_loss: 1.9398 - val_loss: 6.4306 - val_value_loss: 0.7132 - val_policy_loss: 1.9594\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2966 - value_loss: 0.4691 - policy_loss: 1.9357 - val_loss: 6.4317 - val_value_loss: 0.7177 - val_policy_loss: 1.9575\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 461us/step - loss: 6.2915 - value_loss: 0.4614 - policy_loss: 1.9336 - val_loss: 6.4305 - val_value_loss: 0.7163 - val_policy_loss: 1.9568\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 459us/step - loss: 6.2804 - value_loss: 0.4433 - policy_loss: 1.9296 - val_loss: 6.4220 - val_value_loss: 0.7009 - val_policy_loss: 1.9556\n",
      "Saved model  connectfour_num_sim_25_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.75 - draw ratio 0.0\n",
      "Number of seen trajectories: 900\n",
      "Number of unique trajectories: 900\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 457us/step - loss: 6.4558 - value_loss: 0.7513 - policy_loss: 1.9727 - val_loss: 6.4614 - val_value_loss: 0.7523 - val_policy_loss: 1.9832\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4161 - value_loss: 0.6778 - policy_loss: 1.9671 - val_loss: 6.4509 - val_value_loss: 0.7334 - val_policy_loss: 1.9814\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3813 - value_loss: 0.6139 - policy_loss: 1.9618 - val_loss: 6.4422 - val_value_loss: 0.7182 - val_policy_loss: 1.9795\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3581 - value_loss: 0.5727 - policy_loss: 1.9571 - val_loss: 6.4386 - val_value_loss: 0.7136 - val_policy_loss: 1.9773\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 458us/step - loss: 6.3447 - value_loss: 0.5498 - policy_loss: 1.9534 - val_loss: 6.4282 - val_value_loss: 0.6950 - val_policy_loss: 1.9754\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 459us/step - loss: 6.3237 - value_loss: 0.5127 - policy_loss: 1.9489 - val_loss: 6.4258 - val_value_loss: 0.6926 - val_policy_loss: 1.9732\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 459us/step - loss: 6.3116 - value_loss: 0.4927 - policy_loss: 1.9450 - val_loss: 6.4164 - val_value_loss: 0.6760 - val_policy_loss: 1.9714\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 460us/step - loss: 6.2981 - value_loss: 0.4682 - policy_loss: 1.9427 - val_loss: 6.4105 - val_value_loss: 0.6668 - val_policy_loss: 1.9693\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 463us/step - loss: 6.2884 - value_loss: 0.4526 - policy_loss: 1.9392 - val_loss: 6.4067 - val_value_loss: 0.6605 - val_policy_loss: 1.9681\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 459us/step - loss: 6.2785 - value_loss: 0.4370 - policy_loss: 1.9354 - val_loss: 6.4047 - val_value_loss: 0.6593 - val_policy_loss: 1.9657\n",
      "Saved model  connectfour_num_sim_25_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.0\n",
      "Number of seen trajectories: 1000\n",
      "Number of unique trajectories: 1000\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4639 - value_loss: 0.7805 - policy_loss: 1.9631 - val_loss: 6.4560 - val_value_loss: 0.7624 - val_policy_loss: 1.9652\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4341 - value_loss: 0.7251 - policy_loss: 1.9590 - val_loss: 6.4482 - val_value_loss: 0.7480 - val_policy_loss: 1.9642\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4123 - value_loss: 0.6843 - policy_loss: 1.9563 - val_loss: 6.4397 - val_value_loss: 0.7319 - val_policy_loss: 1.9637\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3938 - value_loss: 0.6496 - policy_loss: 1.9543 - val_loss: 6.4343 - val_value_loss: 0.7222 - val_policy_loss: 1.9627\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3761 - value_loss: 0.6170 - policy_loss: 1.9515 - val_loss: 6.4325 - val_value_loss: 0.7194 - val_policy_loss: 1.9621\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3645 - value_loss: 0.5957 - policy_loss: 1.9498 - val_loss: 6.4302 - val_value_loss: 0.7159 - val_policy_loss: 1.9611\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3536 - value_loss: 0.5765 - policy_loss: 1.9474 - val_loss: 6.4254 - val_value_loss: 0.7074 - val_policy_loss: 1.9601\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3383 - value_loss: 0.5489 - policy_loss: 1.9445 - val_loss: 6.4208 - val_value_loss: 0.6991 - val_policy_loss: 1.9594\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3312 - value_loss: 0.5366 - policy_loss: 1.9428 - val_loss: 6.4157 - val_value_loss: 0.6894 - val_policy_loss: 1.9590\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3207 - value_loss: 0.5182 - policy_loss: 1.9402 - val_loss: 6.4111 - val_value_loss: 0.6815 - val_policy_loss: 1.9579\n",
      "Saved model  connectfour_num_sim_25_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.67 - draw ratio 0.0\n",
      "Number of seen trajectories: 1100\n",
      "Number of unique trajectories: 1100\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4834 - value_loss: 0.8136 - policy_loss: 1.9705 - val_loss: 6.4672 - val_value_loss: 0.7779 - val_policy_loss: 1.9739\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4550 - value_loss: 0.7609 - policy_loss: 1.9665 - val_loss: 6.4592 - val_value_loss: 0.7623 - val_policy_loss: 1.9736\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4296 - value_loss: 0.7143 - policy_loss: 1.9625 - val_loss: 6.4497 - val_value_loss: 0.7441 - val_policy_loss: 1.9729\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4114 - value_loss: 0.6811 - policy_loss: 1.9594 - val_loss: 6.4441 - val_value_loss: 0.7336 - val_policy_loss: 1.9725\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3929 - value_loss: 0.6475 - policy_loss: 1.9563 - val_loss: 6.4396 - val_value_loss: 0.7257 - val_policy_loss: 1.9717\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3801 - value_loss: 0.6243 - policy_loss: 1.9540 - val_loss: 6.4313 - val_value_loss: 0.7095 - val_policy_loss: 1.9713\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3636 - value_loss: 0.5945 - policy_loss: 1.9509 - val_loss: 6.4273 - val_value_loss: 0.7019 - val_policy_loss: 1.9709\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3580 - value_loss: 0.5850 - policy_loss: 1.9495 - val_loss: 6.4239 - val_value_loss: 0.6965 - val_policy_loss: 1.9698\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3441 - value_loss: 0.5603 - policy_loss: 1.9465 - val_loss: 6.4240 - val_value_loss: 0.6973 - val_policy_loss: 1.9694\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3351 - value_loss: 0.5445 - policy_loss: 1.9444 - val_loss: 6.4186 - val_value_loss: 0.6873 - val_policy_loss: 1.9688\n",
      "Saved model  connectfour_num_sim_25_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.0\n",
      "Number of seen trajectories: 1200\n",
      "Number of unique trajectories: 1200\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.4942 - value_loss: 0.8337 - policy_loss: 1.9736 - val_loss: 6.5036 - val_value_loss: 0.8577 - val_policy_loss: 1.9685\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4646 - value_loss: 0.7774 - policy_loss: 1.9708 - val_loss: 6.4940 - val_value_loss: 0.8396 - val_policy_loss: 1.9676\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4406 - value_loss: 0.7331 - policy_loss: 1.9674 - val_loss: 6.4859 - val_value_loss: 0.8252 - val_policy_loss: 1.9659\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4230 - value_loss: 0.7006 - policy_loss: 1.9648 - val_loss: 6.4763 - val_value_loss: 0.8071 - val_policy_loss: 1.9650\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4029 - value_loss: 0.6630 - policy_loss: 1.9624 - val_loss: 6.4715 - val_value_loss: 0.7988 - val_policy_loss: 1.9639\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3909 - value_loss: 0.6418 - policy_loss: 1.9597 - val_loss: 6.4654 - val_value_loss: 0.7871 - val_policy_loss: 1.9634\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3742 - value_loss: 0.6108 - policy_loss: 1.9574 - val_loss: 6.4596 - val_value_loss: 0.7773 - val_policy_loss: 1.9619\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3647 - value_loss: 0.5932 - policy_loss: 1.9562 - val_loss: 6.4589 - val_value_loss: 0.7764 - val_policy_loss: 1.9616\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3568 - value_loss: 0.5800 - policy_loss: 1.9539 - val_loss: 6.4499 - val_value_loss: 0.7594 - val_policy_loss: 1.9606\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3448 - value_loss: 0.5582 - policy_loss: 1.9518 - val_loss: 6.4475 - val_value_loss: 0.7553 - val_policy_loss: 1.9602\n",
      "Saved model  connectfour_num_sim_25_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.77 - draw ratio 0.0\n",
      "Number of seen trajectories: 1300\n",
      "Number of unique trajectories: 1300\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5005 - value_loss: 0.8467 - policy_loss: 1.9749 - val_loss: 6.5048 - val_value_loss: 0.8463 - val_policy_loss: 1.9840\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4730 - value_loss: 0.7947 - policy_loss: 1.9720 - val_loss: 6.4987 - val_value_loss: 0.8358 - val_policy_loss: 1.9823\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4461 - value_loss: 0.7453 - policy_loss: 1.9678 - val_loss: 6.4865 - val_value_loss: 0.8124 - val_policy_loss: 1.9816\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4252 - value_loss: 0.7061 - policy_loss: 1.9653 - val_loss: 6.4785 - val_value_loss: 0.7977 - val_policy_loss: 1.9804\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4068 - value_loss: 0.6725 - policy_loss: 1.9623 - val_loss: 6.4696 - val_value_loss: 0.7810 - val_policy_loss: 1.9794\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3912 - value_loss: 0.6439 - policy_loss: 1.9599 - val_loss: 6.4652 - val_value_loss: 0.7733 - val_policy_loss: 1.9785\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3746 - value_loss: 0.6140 - policy_loss: 1.9567 - val_loss: 6.4583 - val_value_loss: 0.7609 - val_policy_loss: 1.9774\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3615 - value_loss: 0.5907 - policy_loss: 1.9539 - val_loss: 6.4542 - val_value_loss: 0.7534 - val_policy_loss: 1.9767\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3500 - value_loss: 0.5699 - policy_loss: 1.9519 - val_loss: 6.4509 - val_value_loss: 0.7484 - val_policy_loss: 1.9753\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3411 - value_loss: 0.5548 - policy_loss: 1.9494 - val_loss: 6.4464 - val_value_loss: 0.7408 - val_policy_loss: 1.9741\n",
      "Saved model  connectfour_num_sim_25_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.71 - draw ratio 0.0\n",
      "Number of seen trajectories: 1400\n",
      "Number of unique trajectories: 1400\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5105 - value_loss: 0.8697 - policy_loss: 1.9734 - val_loss: 6.4940 - val_value_loss: 0.8372 - val_policy_loss: 1.9731\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4789 - value_loss: 0.8100 - policy_loss: 1.9701 - val_loss: 6.4835 - val_value_loss: 0.8171 - val_policy_loss: 1.9723\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4512 - value_loss: 0.7578 - policy_loss: 1.9670 - val_loss: 6.4760 - val_value_loss: 0.8036 - val_policy_loss: 1.9710\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4298 - value_loss: 0.7177 - policy_loss: 1.9645 - val_loss: 6.4685 - val_value_loss: 0.7891 - val_policy_loss: 1.9706\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4091 - value_loss: 0.6787 - policy_loss: 1.9623 - val_loss: 6.4635 - val_value_loss: 0.7798 - val_policy_loss: 1.9701\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3931 - value_loss: 0.6495 - policy_loss: 1.9598 - val_loss: 6.4603 - val_value_loss: 0.7746 - val_policy_loss: 1.9691\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3777 - value_loss: 0.6209 - policy_loss: 1.9577 - val_loss: 6.4598 - val_value_loss: 0.7742 - val_policy_loss: 1.9686\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3650 - value_loss: 0.5978 - policy_loss: 1.9555 - val_loss: 6.4456 - val_value_loss: 0.7470 - val_policy_loss: 1.9677\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3540 - value_loss: 0.5783 - policy_loss: 1.9532 - val_loss: 6.4419 - val_value_loss: 0.7406 - val_policy_loss: 1.9668\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3427 - value_loss: 0.5576 - policy_loss: 1.9515 - val_loss: 6.4365 - val_value_loss: 0.7308 - val_policy_loss: 1.9658\n",
      "Saved model  connectfour_num_sim_25_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.0\n",
      "Number of seen trajectories: 1500\n",
      "Number of unique trajectories: 1500\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.4839 - value_loss: 0.8164 - policy_loss: 1.9752 - val_loss: 6.4716 - val_value_loss: 0.7964 - val_policy_loss: 1.9706\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4644 - value_loss: 0.7787 - policy_loss: 1.9739 - val_loss: 6.4673 - val_value_loss: 0.7887 - val_policy_loss: 1.9697\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4493 - value_loss: 0.7503 - policy_loss: 1.9722 - val_loss: 6.4607 - val_value_loss: 0.7762 - val_policy_loss: 1.9691\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4370 - value_loss: 0.7276 - policy_loss: 1.9705 - val_loss: 6.4572 - val_value_loss: 0.7700 - val_policy_loss: 1.9685\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4279 - value_loss: 0.7103 - policy_loss: 1.9695 - val_loss: 6.4507 - val_value_loss: 0.7577 - val_policy_loss: 1.9678\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4133 - value_loss: 0.6831 - policy_loss: 1.9677 - val_loss: 6.4480 - val_value_loss: 0.7527 - val_policy_loss: 1.9674\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4033 - value_loss: 0.6640 - policy_loss: 1.9669 - val_loss: 6.4455 - val_value_loss: 0.7484 - val_policy_loss: 1.9668\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3928 - value_loss: 0.6449 - policy_loss: 1.9650 - val_loss: 6.4404 - val_value_loss: 0.7389 - val_policy_loss: 1.9663\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3847 - value_loss: 0.6296 - policy_loss: 1.9642 - val_loss: 6.4363 - val_value_loss: 0.7313 - val_policy_loss: 1.9658\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3799 - value_loss: 0.6209 - policy_loss: 1.9633 - val_loss: 6.4352 - val_value_loss: 0.7295 - val_policy_loss: 1.9653\n",
      "Saved model  connectfour_num_sim_25_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.73 - draw ratio 0.0\n",
      "Number of seen trajectories: 1600\n",
      "Number of unique trajectories: 1600\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5052 - value_loss: 0.8641 - policy_loss: 1.9709 - val_loss: 6.4939 - val_value_loss: 0.8289 - val_policy_loss: 1.9835\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4842 - value_loss: 0.8241 - policy_loss: 1.9690 - val_loss: 6.4858 - val_value_loss: 0.8134 - val_policy_loss: 1.9828\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4648 - value_loss: 0.7875 - policy_loss: 1.9669 - val_loss: 6.4787 - val_value_loss: 0.8000 - val_policy_loss: 1.9821\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4477 - value_loss: 0.7556 - policy_loss: 1.9647 - val_loss: 6.4713 - val_value_loss: 0.7858 - val_policy_loss: 1.9815\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4342 - value_loss: 0.7293 - policy_loss: 1.9639 - val_loss: 6.4686 - val_value_loss: 0.7812 - val_policy_loss: 1.9808\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4222 - value_loss: 0.7072 - policy_loss: 1.9621 - val_loss: 6.4622 - val_value_loss: 0.7693 - val_policy_loss: 1.9802\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4123 - value_loss: 0.6892 - policy_loss: 1.9604 - val_loss: 6.4622 - val_value_loss: 0.7700 - val_policy_loss: 1.9796\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4003 - value_loss: 0.6668 - policy_loss: 1.9588 - val_loss: 6.4571 - val_value_loss: 0.7603 - val_policy_loss: 1.9791\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3905 - value_loss: 0.6490 - policy_loss: 1.9572 - val_loss: 6.4516 - val_value_loss: 0.7498 - val_policy_loss: 1.9786\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.3805 - value_loss: 0.6306 - policy_loss: 1.9558 - val_loss: 6.4492 - val_value_loss: 0.7457 - val_policy_loss: 1.9781\n",
      "Saved model  connectfour_num_sim_25_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.79 - draw ratio 0.0\n",
      "Number of seen trajectories: 1700\n",
      "Number of unique trajectories: 1700\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.5105 - value_loss: 0.8758 - policy_loss: 1.9704 - val_loss: 6.4771 - val_value_loss: 0.8167 - val_policy_loss: 1.9629\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4907 - value_loss: 0.8377 - policy_loss: 1.9690 - val_loss: 6.4709 - val_value_loss: 0.8053 - val_policy_loss: 1.9619\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4726 - value_loss: 0.8038 - policy_loss: 1.9670 - val_loss: 6.4653 - val_value_loss: 0.7948 - val_policy_loss: 1.9614\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4569 - value_loss: 0.7739 - policy_loss: 1.9655 - val_loss: 6.4601 - val_value_loss: 0.7850 - val_policy_loss: 1.9609\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4469 - value_loss: 0.7548 - policy_loss: 1.9648 - val_loss: 6.4562 - val_value_loss: 0.7778 - val_policy_loss: 1.9603\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4311 - value_loss: 0.7255 - policy_loss: 1.9625 - val_loss: 6.4518 - val_value_loss: 0.7696 - val_policy_loss: 1.9598\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4208 - value_loss: 0.7065 - policy_loss: 1.9610 - val_loss: 6.4476 - val_value_loss: 0.7617 - val_policy_loss: 1.9595\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4103 - value_loss: 0.6862 - policy_loss: 1.9603 - val_loss: 6.4446 - val_value_loss: 0.7561 - val_policy_loss: 1.9592\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4010 - value_loss: 0.6698 - policy_loss: 1.9581 - val_loss: 6.4417 - val_value_loss: 0.7506 - val_policy_loss: 1.9588\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3941 - value_loss: 0.6566 - policy_loss: 1.9577 - val_loss: 6.4393 - val_value_loss: 0.7464 - val_policy_loss: 1.9585\n",
      "Saved model  connectfour_num_sim_25_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.0\n",
      "Number of seen trajectories: 1800\n",
      "Number of unique trajectories: 1800\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5073 - value_loss: 0.8693 - policy_loss: 1.9715 - val_loss: 6.5027 - val_value_loss: 0.8642 - val_policy_loss: 1.9674\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4867 - value_loss: 0.8302 - policy_loss: 1.9695 - val_loss: 6.4952 - val_value_loss: 0.8499 - val_policy_loss: 1.9668\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4698 - value_loss: 0.7981 - policy_loss: 1.9678 - val_loss: 6.4885 - val_value_loss: 0.8370 - val_policy_loss: 1.9664\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4552 - value_loss: 0.7706 - policy_loss: 1.9662 - val_loss: 6.4831 - val_value_loss: 0.8267 - val_policy_loss: 1.9659\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4429 - value_loss: 0.7468 - policy_loss: 1.9655 - val_loss: 6.4778 - val_value_loss: 0.8166 - val_policy_loss: 1.9656\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4327 - value_loss: 0.7275 - policy_loss: 1.9646 - val_loss: 6.4742 - val_value_loss: 0.8096 - val_policy_loss: 1.9654\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4195 - value_loss: 0.7030 - policy_loss: 1.9627 - val_loss: 6.4705 - val_value_loss: 0.8027 - val_policy_loss: 1.9650\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4072 - value_loss: 0.6805 - policy_loss: 1.9607 - val_loss: 6.4661 - val_value_loss: 0.7943 - val_policy_loss: 1.9647\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4030 - value_loss: 0.6722 - policy_loss: 1.9606 - val_loss: 6.4629 - val_value_loss: 0.7885 - val_policy_loss: 1.9643\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3901 - value_loss: 0.6489 - policy_loss: 1.9582 - val_loss: 6.4598 - val_value_loss: 0.7826 - val_policy_loss: 1.9640\n",
      "Saved model  connectfour_num_sim_25_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.72 - draw ratio 0.0\n",
      "Number of seen trajectories: 1900\n",
      "Number of unique trajectories: 1900\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4922 - value_loss: 0.8411 - policy_loss: 1.9702 - val_loss: 6.4963 - val_value_loss: 0.8418 - val_policy_loss: 1.9777\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4756 - value_loss: 0.8099 - policy_loss: 1.9683 - val_loss: 6.4895 - val_value_loss: 0.8291 - val_policy_loss: 1.9770\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4621 - value_loss: 0.7841 - policy_loss: 1.9672 - val_loss: 6.4836 - val_value_loss: 0.8180 - val_policy_loss: 1.9764\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4472 - value_loss: 0.7569 - policy_loss: 1.9646 - val_loss: 6.4786 - val_value_loss: 0.8087 - val_policy_loss: 1.9757\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4348 - value_loss: 0.7337 - policy_loss: 1.9633 - val_loss: 6.4749 - val_value_loss: 0.8020 - val_policy_loss: 1.9752\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4233 - value_loss: 0.7119 - policy_loss: 1.9620 - val_loss: 6.4712 - val_value_loss: 0.7953 - val_policy_loss: 1.9745\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4139 - value_loss: 0.6949 - policy_loss: 1.9605 - val_loss: 6.4678 - val_value_loss: 0.7889 - val_policy_loss: 1.9742\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4042 - value_loss: 0.6767 - policy_loss: 1.9593 - val_loss: 6.4639 - val_value_loss: 0.7817 - val_policy_loss: 1.9736\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3953 - value_loss: 0.6604 - policy_loss: 1.9579 - val_loss: 6.4596 - val_value_loss: 0.7740 - val_policy_loss: 1.9730\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3873 - value_loss: 0.6461 - policy_loss: 1.9561 - val_loss: 6.4576 - val_value_loss: 0.7705 - val_policy_loss: 1.9725\n",
      "Saved model  connectfour_num_sim_25_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.0\n",
      "Number of seen trajectories: 2000\n",
      "Number of unique trajectories: 2000\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4835 - value_loss: 0.8266 - policy_loss: 1.9682 - val_loss: 6.4907 - val_value_loss: 0.8391 - val_policy_loss: 1.9701\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4738 - value_loss: 0.8083 - policy_loss: 1.9672 - val_loss: 6.4877 - val_value_loss: 0.8336 - val_policy_loss: 1.9697\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4646 - value_loss: 0.7908 - policy_loss: 1.9662 - val_loss: 6.4853 - val_value_loss: 0.8292 - val_policy_loss: 1.9693\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4543 - value_loss: 0.7715 - policy_loss: 1.9651 - val_loss: 6.4824 - val_value_loss: 0.8238 - val_policy_loss: 1.9689\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4474 - value_loss: 0.7583 - policy_loss: 1.9644 - val_loss: 6.4798 - val_value_loss: 0.8189 - val_policy_loss: 1.9686\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4409 - value_loss: 0.7463 - policy_loss: 1.9635 - val_loss: 6.4778 - val_value_loss: 0.8153 - val_policy_loss: 1.9683\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4328 - value_loss: 0.7307 - policy_loss: 1.9629 - val_loss: 6.4762 - val_value_loss: 0.8125 - val_policy_loss: 1.9681\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4281 - value_loss: 0.7217 - policy_loss: 1.9626 - val_loss: 6.4741 - val_value_loss: 0.8085 - val_policy_loss: 1.9678\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4197 - value_loss: 0.7064 - policy_loss: 1.9612 - val_loss: 6.4731 - val_value_loss: 0.8068 - val_policy_loss: 1.9676\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4150 - value_loss: 0.6977 - policy_loss: 1.9604 - val_loss: 6.4712 - val_value_loss: 0.8032 - val_policy_loss: 1.9674\n",
      "Saved model  connectfour_num_sim_25_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.86 - draw ratio 0.0\n",
      "Number of seen trajectories: 2100\n",
      "Number of unique trajectories: 2100\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5330 - value_loss: 0.9137 - policy_loss: 1.9806 - val_loss: 6.5063 - val_value_loss: 0.8712 - val_policy_loss: 1.9697\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5215 - value_loss: 0.8918 - policy_loss: 1.9794 - val_loss: 6.5010 - val_value_loss: 0.8607 - val_policy_loss: 1.9695\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.5113 - value_loss: 0.8722 - policy_loss: 1.9786 - val_loss: 6.4959 - val_value_loss: 0.8509 - val_policy_loss: 1.9692\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5010 - value_loss: 0.8533 - policy_loss: 1.9771 - val_loss: 6.4913 - val_value_loss: 0.8421 - val_policy_loss: 1.9689\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4931 - value_loss: 0.8381 - policy_loss: 1.9766 - val_loss: 6.4870 - val_value_loss: 0.8337 - val_policy_loss: 1.9686\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4846 - value_loss: 0.8216 - policy_loss: 1.9760 - val_loss: 6.4828 - val_value_loss: 0.8257 - val_policy_loss: 1.9684\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4768 - value_loss: 0.8071 - policy_loss: 1.9749 - val_loss: 6.4790 - val_value_loss: 0.8184 - val_policy_loss: 1.9681\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4668 - value_loss: 0.7882 - policy_loss: 1.9740 - val_loss: 6.4752 - val_value_loss: 0.8110 - val_policy_loss: 1.9679\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4617 - value_loss: 0.7782 - policy_loss: 1.9737 - val_loss: 6.4720 - val_value_loss: 0.8049 - val_policy_loss: 1.9677\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4529 - value_loss: 0.7621 - policy_loss: 1.9723 - val_loss: 6.4693 - val_value_loss: 0.7997 - val_policy_loss: 1.9675\n",
      "Saved model  connectfour_num_sim_25_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.72 - draw ratio 0.0\n",
      "Number of seen trajectories: 2200\n",
      "Number of unique trajectories: 2199\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5424 - value_loss: 0.9385 - policy_loss: 1.9749 - val_loss: 6.5162 - val_value_loss: 0.8863 - val_policy_loss: 1.9748\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5325 - value_loss: 0.9192 - policy_loss: 1.9744 - val_loss: 6.5120 - val_value_loss: 0.8782 - val_policy_loss: 1.9744\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5220 - value_loss: 0.8995 - policy_loss: 1.9732 - val_loss: 6.5074 - val_value_loss: 0.8693 - val_policy_loss: 1.9742\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5110 - value_loss: 0.8784 - policy_loss: 1.9723 - val_loss: 6.5041 - val_value_loss: 0.8631 - val_policy_loss: 1.9739\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5052 - value_loss: 0.8676 - policy_loss: 1.9717 - val_loss: 6.4997 - val_value_loss: 0.8546 - val_policy_loss: 1.9736\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4952 - value_loss: 0.8481 - policy_loss: 1.9710 - val_loss: 6.4973 - val_value_loss: 0.8501 - val_policy_loss: 1.9734\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4881 - value_loss: 0.8346 - policy_loss: 1.9705 - val_loss: 6.4944 - val_value_loss: 0.8445 - val_policy_loss: 1.9732\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4800 - value_loss: 0.8196 - policy_loss: 1.9694 - val_loss: 6.4915 - val_value_loss: 0.8389 - val_policy_loss: 1.9730\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4724 - value_loss: 0.8051 - policy_loss: 1.9686 - val_loss: 6.4888 - val_value_loss: 0.8337 - val_policy_loss: 1.9729\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4658 - value_loss: 0.7927 - policy_loss: 1.9679 - val_loss: 6.4868 - val_value_loss: 0.8300 - val_policy_loss: 1.9727\n",
      "Saved model  connectfour_num_sim_25_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.0\n",
      "Number of seen trajectories: 2300\n",
      "Number of unique trajectories: 2299\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5213 - value_loss: 0.8950 - policy_loss: 1.9766 - val_loss: 6.5087 - val_value_loss: 0.8675 - val_policy_loss: 1.9790\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.5061 - value_loss: 0.8661 - policy_loss: 1.9753 - val_loss: 6.5042 - val_value_loss: 0.8588 - val_policy_loss: 1.9787\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4954 - value_loss: 0.8456 - policy_loss: 1.9743 - val_loss: 6.5013 - val_value_loss: 0.8534 - val_policy_loss: 1.9784\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4874 - value_loss: 0.8300 - policy_loss: 1.9739 - val_loss: 6.4944 - val_value_loss: 0.8400 - val_policy_loss: 1.9780\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4772 - value_loss: 0.8105 - policy_loss: 1.9731 - val_loss: 6.4906 - val_value_loss: 0.8328 - val_policy_loss: 1.9777\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4697 - value_loss: 0.7966 - policy_loss: 1.9721 - val_loss: 6.4861 - val_value_loss: 0.8242 - val_policy_loss: 1.9773\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4620 - value_loss: 0.7816 - policy_loss: 1.9716 - val_loss: 6.4829 - val_value_loss: 0.8183 - val_policy_loss: 1.9769\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4538 - value_loss: 0.7665 - policy_loss: 1.9704 - val_loss: 6.4805 - val_value_loss: 0.8138 - val_policy_loss: 1.9766\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4479 - value_loss: 0.7553 - policy_loss: 1.9698 - val_loss: 6.4772 - val_value_loss: 0.8074 - val_policy_loss: 1.9763\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4404 - value_loss: 0.7411 - policy_loss: 1.9691 - val_loss: 6.4750 - val_value_loss: 0.8034 - val_policy_loss: 1.9760\n",
      "Saved model  connectfour_num_sim_25_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.75 - draw ratio 0.0\n",
      "Number of seen trajectories: 2400\n",
      "Number of unique trajectories: 2398\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.5254 - value_loss: 0.9079 - policy_loss: 1.9722 - val_loss: 6.5072 - val_value_loss: 0.8649 - val_policy_loss: 1.9789\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5137 - value_loss: 0.8854 - policy_loss: 1.9715 - val_loss: 6.5038 - val_value_loss: 0.8586 - val_policy_loss: 1.9786\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5034 - value_loss: 0.8664 - policy_loss: 1.9700 - val_loss: 6.5004 - val_value_loss: 0.8521 - val_policy_loss: 1.9782\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4923 - value_loss: 0.8449 - policy_loss: 1.9692 - val_loss: 6.4976 - val_value_loss: 0.8468 - val_policy_loss: 1.9780\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4859 - value_loss: 0.8327 - policy_loss: 1.9687 - val_loss: 6.4949 - val_value_loss: 0.8418 - val_policy_loss: 1.9777\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4783 - value_loss: 0.8177 - policy_loss: 1.9685 - val_loss: 6.4918 - val_value_loss: 0.8359 - val_policy_loss: 1.9774\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4689 - value_loss: 0.8000 - policy_loss: 1.9675 - val_loss: 6.4892 - val_value_loss: 0.8309 - val_policy_loss: 1.9771\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4604 - value_loss: 0.7841 - policy_loss: 1.9664 - val_loss: 6.4873 - val_value_loss: 0.8276 - val_policy_loss: 1.9768\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4521 - value_loss: 0.7684 - policy_loss: 1.9655 - val_loss: 6.4852 - val_value_loss: 0.8237 - val_policy_loss: 1.9764\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4485 - value_loss: 0.7617 - policy_loss: 1.9650 - val_loss: 6.4820 - val_value_loss: 0.8178 - val_policy_loss: 1.9761\n",
      "Saved model  connectfour_num_sim_25_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.73 - draw ratio 0.0\n",
      "Number of seen trajectories: 2500\n",
      "Number of unique trajectories: 2497\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5245 - value_loss: 0.8981 - policy_loss: 1.9808 - val_loss: 6.5326 - val_value_loss: 0.9148 - val_policy_loss: 1.9802\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5177 - value_loss: 0.8853 - policy_loss: 1.9800 - val_loss: 6.5302 - val_value_loss: 0.9106 - val_policy_loss: 1.9798\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.5130 - value_loss: 0.8764 - policy_loss: 1.9795 - val_loss: 6.5278 - val_value_loss: 0.9062 - val_policy_loss: 1.9793\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.5071 - value_loss: 0.8650 - policy_loss: 1.9791 - val_loss: 6.5256 - val_value_loss: 0.9021 - val_policy_loss: 1.9790\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5021 - value_loss: 0.8559 - policy_loss: 1.9782 - val_loss: 6.5235 - val_value_loss: 0.8984 - val_policy_loss: 1.9786\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4997 - value_loss: 0.8507 - policy_loss: 1.9785 - val_loss: 6.5214 - val_value_loss: 0.8944 - val_policy_loss: 1.9783\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4947 - value_loss: 0.8418 - policy_loss: 1.9775 - val_loss: 6.5191 - val_value_loss: 0.8902 - val_policy_loss: 1.9780\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4903 - value_loss: 0.8335 - policy_loss: 1.9772 - val_loss: 6.5170 - val_value_loss: 0.8863 - val_policy_loss: 1.9777\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4853 - value_loss: 0.8243 - policy_loss: 1.9762 - val_loss: 6.5150 - val_value_loss: 0.8826 - val_policy_loss: 1.9775\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4805 - value_loss: 0.8153 - policy_loss: 1.9756 - val_loss: 6.5131 - val_value_loss: 0.8791 - val_policy_loss: 1.9772\n",
      "Saved model  connectfour_num_sim_25_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.72 - draw ratio 0.0\n",
      "Number of seen trajectories: 2600\n",
      "Number of unique trajectories: 2597\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.5527 - value_loss: 0.9470 - policy_loss: 1.9886 - val_loss: 6.5685 - val_value_loss: 0.9800 - val_policy_loss: 1.9870\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.5472 - value_loss: 0.9364 - policy_loss: 1.9881 - val_loss: 6.5645 - val_value_loss: 0.9722 - val_policy_loss: 1.9869\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5397 - value_loss: 0.9215 - policy_loss: 1.9880 - val_loss: 6.5619 - val_value_loss: 0.9671 - val_policy_loss: 1.9867\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5353 - value_loss: 0.9136 - policy_loss: 1.9872 - val_loss: 6.5596 - val_value_loss: 0.9628 - val_policy_loss: 1.9865\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5296 - value_loss: 0.9026 - policy_loss: 1.9867 - val_loss: 6.5574 - val_value_loss: 0.9585 - val_policy_loss: 1.9864\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5265 - value_loss: 0.8966 - policy_loss: 1.9866 - val_loss: 6.5553 - val_value_loss: 0.9545 - val_policy_loss: 1.9862\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5201 - value_loss: 0.8842 - policy_loss: 1.9862 - val_loss: 6.5532 - val_value_loss: 0.9505 - val_policy_loss: 1.9861\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5155 - value_loss: 0.8757 - policy_loss: 1.9855 - val_loss: 6.5511 - val_value_loss: 0.9466 - val_policy_loss: 1.9859\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5104 - value_loss: 0.8661 - policy_loss: 1.9850 - val_loss: 6.5494 - val_value_loss: 0.9433 - val_policy_loss: 1.9858\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5055 - value_loss: 0.8567 - policy_loss: 1.9845 - val_loss: 6.5478 - val_value_loss: 0.9401 - val_policy_loss: 1.9857\n",
      "Saved model  connectfour_num_sim_25_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.78 - draw ratio 0.0\n",
      "Number of seen trajectories: 2700\n",
      "Number of unique trajectories: 2697\n",
      "iteration 27 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5623 - value_loss: 0.9686 - policy_loss: 1.9863 - val_loss: 6.5681 - val_value_loss: 0.9876 - val_policy_loss: 1.9790\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5540 - value_loss: 0.9527 - policy_loss: 1.9855 - val_loss: 6.5647 - val_value_loss: 0.9808 - val_policy_loss: 1.9789\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5487 - value_loss: 0.9424 - policy_loss: 1.9852 - val_loss: 6.5618 - val_value_loss: 0.9749 - val_policy_loss: 1.9789\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5410 - value_loss: 0.9276 - policy_loss: 1.9847 - val_loss: 6.5587 - val_value_loss: 0.9690 - val_policy_loss: 1.9788\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5347 - value_loss: 0.9158 - policy_loss: 1.9840 - val_loss: 6.5559 - val_value_loss: 0.9635 - val_policy_loss: 1.9787\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5288 - value_loss: 0.9040 - policy_loss: 1.9838 - val_loss: 6.5535 - val_value_loss: 0.9587 - val_policy_loss: 1.9786\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5222 - value_loss: 0.8915 - policy_loss: 1.9832 - val_loss: 6.5512 - val_value_loss: 0.9543 - val_policy_loss: 1.9785\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5177 - value_loss: 0.8827 - policy_loss: 1.9830 - val_loss: 6.5486 - val_value_loss: 0.9493 - val_policy_loss: 1.9784\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5119 - value_loss: 0.8711 - policy_loss: 1.9831 - val_loss: 6.5462 - val_value_loss: 0.9446 - val_policy_loss: 1.9783\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5059 - value_loss: 0.8605 - policy_loss: 1.9818 - val_loss: 6.5440 - val_value_loss: 0.9404 - val_policy_loss: 1.9782\n",
      "Saved model  connectfour_num_sim_25_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.0\n",
      "Number of seen trajectories: 2800\n",
      "Number of unique trajectories: 2796\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5560 - value_loss: 0.9652 - policy_loss: 1.9772 - val_loss: 6.5332 - val_value_loss: 0.9257 - val_policy_loss: 1.9711\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5500 - value_loss: 0.9533 - policy_loss: 1.9771 - val_loss: 6.5308 - val_value_loss: 0.9208 - val_policy_loss: 1.9712\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5436 - value_loss: 0.9415 - policy_loss: 1.9761 - val_loss: 6.5283 - val_value_loss: 0.9159 - val_policy_loss: 1.9712\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5377 - value_loss: 0.9301 - policy_loss: 1.9757 - val_loss: 6.5260 - val_value_loss: 0.9114 - val_policy_loss: 1.9711\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5317 - value_loss: 0.9187 - policy_loss: 1.9751 - val_loss: 6.5240 - val_value_loss: 0.9075 - val_policy_loss: 1.9711\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5250 - value_loss: 0.9059 - policy_loss: 1.9747 - val_loss: 6.5217 - val_value_loss: 0.9028 - val_policy_loss: 1.9711\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5214 - value_loss: 0.8991 - policy_loss: 1.9743 - val_loss: 6.5198 - val_value_loss: 0.8991 - val_policy_loss: 1.9710\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5163 - value_loss: 0.8893 - policy_loss: 1.9739 - val_loss: 6.5175 - val_value_loss: 0.8948 - val_policy_loss: 1.9709\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5119 - value_loss: 0.8810 - policy_loss: 1.9735 - val_loss: 6.5158 - val_value_loss: 0.8915 - val_policy_loss: 1.9708\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5062 - value_loss: 0.8699 - policy_loss: 1.9732 - val_loss: 6.5137 - val_value_loss: 0.8874 - val_policy_loss: 1.9707\n",
      "Saved model  connectfour_num_sim_25_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.0\n",
      "Number of seen trajectories: 2900\n",
      "Number of unique trajectories: 2896\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_25_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5363 - value_loss: 0.9270 - policy_loss: 1.9763 - val_loss: 6.5203 - val_value_loss: 0.8931 - val_policy_loss: 1.9782\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5277 - value_loss: 0.9095 - policy_loss: 1.9767 - val_loss: 6.5171 - val_value_loss: 0.8869 - val_policy_loss: 1.9780\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5218 - value_loss: 0.8984 - policy_loss: 1.9759 - val_loss: 6.5147 - val_value_loss: 0.8822 - val_policy_loss: 1.9778\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5161 - value_loss: 0.8877 - policy_loss: 1.9752 - val_loss: 6.5127 - val_value_loss: 0.8786 - val_policy_loss: 1.9776\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5107 - value_loss: 0.8776 - policy_loss: 1.9747 - val_loss: 6.5105 - val_value_loss: 0.8743 - val_policy_loss: 1.9774\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5064 - value_loss: 0.8694 - policy_loss: 1.9742 - val_loss: 6.5083 - val_value_loss: 0.8702 - val_policy_loss: 1.9772\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5014 - value_loss: 0.8595 - policy_loss: 1.9740 - val_loss: 6.5067 - val_value_loss: 0.8671 - val_policy_loss: 1.9770\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4970 - value_loss: 0.8510 - policy_loss: 1.9737 - val_loss: 6.5046 - val_value_loss: 0.8631 - val_policy_loss: 1.9768\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4937 - value_loss: 0.8448 - policy_loss: 1.9735 - val_loss: 6.5026 - val_value_loss: 0.8593 - val_policy_loss: 1.9767\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4881 - value_loss: 0.8343 - policy_loss: 1.9728 - val_loss: 6.5009 - val_value_loss: 0.8562 - val_policy_loss: 1.9765\n",
      "Saved model  connectfour_num_sim_25_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.0\n",
      "Number of seen trajectories: 3000\n",
      "Number of unique trajectories: 2996\n"
     ]
    }
   ],
   "source": [
    "wins_4, draws_4, seen_trajectories_4, unique_trajectories_4 = test_pipeline.run(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - 25 simulations\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "losses_4 = np.ones(30) - wins_4 - draws_4\n",
    "\n",
    "plt.plot(x, wins_4, label=\"win ratio\")\n",
    "plt.plot(x, draws_4, label=\"draw ratio\")\n",
    "plt.plot(x, losses_4, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "exploration_rate_4 = unique_trajectories_4/seen_trajectories_4\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - 25 simulations\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "plt.plot(x, exploration_rate_4, label=\"unique/seen\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins_4 = [0.61, 0.71, 0.73, 0.76, 0.74, 0.66, 0.68, 0.66, 0.75, 0.76, 0.67, 0.76, 0.77, 0.71, 0.7, 0.73, 0.79, 0.7, 0.72, 0.74, 0.86, 0.72, 0.74, 0.75, 0.73, 0.72, 0.78, 0.74, 0.76, 0.76]\n",
      "draws_4 = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "seen_trajectories_4= [ 100.  200.  300.  400.  500.  600.  700.  800.  900. 1000. 1100. 1200.\n",
      " 1300. 1400. 1500. 1600. 1700. 1800. 1900. 2000. 2100. 2200. 2300. 2400.\n",
      " 2500. 2600. 2700. 2800. 2900. 3000.]\n",
      "unique_trajectories_4 = [ 100.  200.  300.  400.  500.  600.  700.  800.  900. 1000. 1100. 1200.\n",
      " 1300. 1400. 1500. 1600. 1700. 1800. 1900. 2000. 2100. 2199. 2299. 2398.\n",
      " 2497. 2597. 2697. 2796. 2896. 2996.]\n"
     ]
    }
   ],
   "source": [
    "print(\"wins_4 =\",wins_4)\n",
    "print(\"draws_4 =\",draws_4)\n",
    "print(\"seen_trajectories_4=\", seen_trajectories_4)\n",
    "print(\"unique_trajectories_4 =\", unique_trajectories_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50 simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCTS = {\n",
    "    'c_puct': 1,\n",
    "    'dir_alpha': 0.6,\n",
    "    'dir_epsilon': 0.25\n",
    "}\n",
    "\n",
    "OPTIMISATION = {\n",
    "    'num_batches': 10,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 10\n",
    "}\n",
    "\n",
    "EVALUATION = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 50,\n",
    "    'temperature': 0,\n",
    "    'show_games': False\n",
    "}\n",
    "\n",
    "SELF_PLAY = {\n",
    "    'num_games': 100,\n",
    "    'num_simulations': 50,\n",
    "    'temperature': 1\n",
    "}\n",
    "\n",
    "NEURAL_NETWORKS = {\n",
    "    'learning_rate': 0.002,\n",
    "    'regularization_strength': 0.001,\n",
    "    'num_filters_policy': 512,\n",
    "    'num_filters_value': 512,\n",
    "    'num_filters_tower': 512,\n",
    "    'num_residual_blocks': 3,\n",
    "    'kernel_size_tower': 3,\n",
    "    'hidden_dim_value': 512\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline(\"connectfour_num_sim_50\", \"Connect4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_0\n",
      "iteration 0 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (2766, 6, 7, 3)\n",
      "model_y_outcomes: (2766,)\n",
      "model_y_probabilities: (2766, 7)\n",
      "Train on 2212 samples, validate on 554 samples\n",
      "Epoch 1/10\n",
      "2212/2212 [==============================] - 5s 2ms/step - loss: 6.9487 - value_loss: 1.4873 - policy_loss: 2.1735 - val_loss: 6.9083 - val_value_loss: 1.4761 - val_policy_loss: 2.1040\n",
      "Epoch 2/10\n",
      "2212/2212 [==============================] - 1s 463us/step - loss: 6.7642 - value_loss: 1.2182 - policy_loss: 2.0739 - val_loss: 6.8588 - val_value_loss: 1.3912 - val_policy_loss: 2.0904\n",
      "Epoch 3/10\n",
      "2212/2212 [==============================] - 1s 463us/step - loss: 6.7527 - value_loss: 1.2219 - policy_loss: 2.0475 - val_loss: 6.9601 - val_value_loss: 1.6121 - val_policy_loss: 2.0725\n",
      "Epoch 4/10\n",
      "2212/2212 [==============================] - 1s 464us/step - loss: 6.6838 - value_loss: 1.1047 - policy_loss: 2.0273 - val_loss: 6.8307 - val_value_loss: 1.3597 - val_policy_loss: 2.0666\n",
      "Epoch 5/10\n",
      "2212/2212 [==============================] - 1s 463us/step - loss: 6.5622 - value_loss: 0.8782 - policy_loss: 2.0112 - val_loss: 6.9743 - val_value_loss: 1.6483 - val_policy_loss: 2.0655\n",
      "Epoch 6/10\n",
      "2212/2212 [==============================] - 1s 464us/step - loss: 6.7031 - value_loss: 1.1727 - policy_loss: 1.9989 - val_loss: 6.9158 - val_value_loss: 1.5392 - val_policy_loss: 2.0581\n",
      "Epoch 7/10\n",
      "2212/2212 [==============================] - 1s 463us/step - loss: 6.4624 - value_loss: 0.7047 - policy_loss: 1.9859 - val_loss: 7.0332 - val_value_loss: 1.7681 - val_policy_loss: 2.0644\n",
      "Epoch 8/10\n",
      "2212/2212 [==============================] - 1s 463us/step - loss: 6.5607 - value_loss: 0.9090 - policy_loss: 1.9785 - val_loss: 6.9620 - val_value_loss: 1.6362 - val_policy_loss: 2.0542\n",
      "Epoch 9/10\n",
      "2212/2212 [==============================] - 1s 464us/step - loss: 6.5034 - value_loss: 0.8041 - policy_loss: 1.9692 - val_loss: 6.8917 - val_value_loss: 1.4999 - val_policy_loss: 2.0503\n",
      "Epoch 10/10\n",
      "2212/2212 [==============================] - 1s 464us/step - loss: 6.4511 - value_loss: 0.7059 - policy_loss: 1.9633 - val_loss: 6.8856 - val_value_loss: 1.4912 - val_policy_loss: 2.0472\n",
      "Saved model  connectfour_num_sim_50_0\n",
      "iteration 0 | evaluation\n",
      "agent vs random - win ratio 0.76 - draw ratio 0.0\n",
      "Number of seen trajectories: 100\n",
      "Number of unique trajectories: 100\n",
      "iteration 1 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_1\n",
      "iteration 1 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.6226 - value_loss: 1.0006 - policy_loss: 2.0121 - val_loss: 6.6211 - val_value_loss: 1.0153 - val_policy_loss: 1.9948\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.6009 - value_loss: 0.9769 - policy_loss: 1.9930 - val_loss: 6.5003 - val_value_loss: 0.7795 - val_policy_loss: 1.9897\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.5318 - value_loss: 0.8538 - policy_loss: 1.9788 - val_loss: 6.4969 - val_value_loss: 0.7809 - val_policy_loss: 1.9821\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4107 - value_loss: 0.6246 - policy_loss: 1.9662 - val_loss: 6.6434 - val_value_loss: 1.0792 - val_policy_loss: 1.9775\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4384 - value_loss: 0.6907 - policy_loss: 1.9563 - val_loss: 6.6916 - val_value_loss: 1.1824 - val_policy_loss: 1.9713\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3951 - value_loss: 0.6147 - policy_loss: 1.9463 - val_loss: 6.4630 - val_value_loss: 0.7318 - val_policy_loss: 1.9653\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4000 - value_loss: 0.6317 - policy_loss: 1.9399 - val_loss: 6.5026 - val_value_loss: 0.8167 - val_policy_loss: 1.9604\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.3881 - value_loss: 0.6140 - policy_loss: 1.9343 - val_loss: 6.4028 - val_value_loss: 0.6207 - val_policy_loss: 1.9574\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3270 - value_loss: 0.5002 - policy_loss: 1.9266 - val_loss: 6.4283 - val_value_loss: 0.6767 - val_policy_loss: 1.9530\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2924 - value_loss: 0.4373 - policy_loss: 1.9210 - val_loss: 6.4078 - val_value_loss: 0.6402 - val_policy_loss: 1.9492\n",
      "Saved model  connectfour_num_sim_50_1\n",
      "iteration 1 | evaluation\n",
      "agent vs random - win ratio 0.6 - draw ratio 0.0\n",
      "Number of seen trajectories: 200\n",
      "Number of unique trajectories: 200\n",
      "iteration 2 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_2\n",
      "iteration 2 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4850 - value_loss: 0.7685 - policy_loss: 1.9756 - val_loss: 6.5247 - val_value_loss: 0.8407 - val_policy_loss: 1.9830\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 448us/step - loss: 6.4479 - value_loss: 0.7081 - policy_loss: 1.9625 - val_loss: 6.5389 - val_value_loss: 0.8726 - val_policy_loss: 1.9803\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3890 - value_loss: 0.6017 - policy_loss: 1.9517 - val_loss: 6.4623 - val_value_loss: 0.7238 - val_policy_loss: 1.9765\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3990 - value_loss: 0.6309 - policy_loss: 1.9432 - val_loss: 6.4796 - val_value_loss: 0.7604 - val_policy_loss: 1.9751\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3785 - value_loss: 0.5981 - policy_loss: 1.9357 - val_loss: 6.5677 - val_value_loss: 0.9397 - val_policy_loss: 1.9729\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3130 - value_loss: 0.4745 - policy_loss: 1.9289 - val_loss: 6.4407 - val_value_loss: 0.6886 - val_policy_loss: 1.9705\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3239 - value_loss: 0.5037 - policy_loss: 1.9220 - val_loss: 6.4171 - val_value_loss: 0.6443 - val_policy_loss: 1.9683\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2759 - value_loss: 0.4136 - policy_loss: 1.9169 - val_loss: 6.4505 - val_value_loss: 0.7138 - val_policy_loss: 1.9661\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3171 - value_loss: 0.5014 - policy_loss: 1.9121 - val_loss: 6.4072 - val_value_loss: 0.6284 - val_policy_loss: 1.9656\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.2675 - value_loss: 0.4078 - policy_loss: 1.9070 - val_loss: 6.4124 - val_value_loss: 0.6416 - val_policy_loss: 1.9634\n",
      "Saved model  connectfour_num_sim_50_2\n",
      "iteration 2 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.0\n",
      "Number of seen trajectories: 300\n",
      "Number of unique trajectories: 300\n",
      "iteration 3 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_3\n",
      "iteration 3 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4734 - value_loss: 0.7568 - policy_loss: 1.9705 - val_loss: 6.5619 - val_value_loss: 0.9365 - val_policy_loss: 1.9682\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4601 - value_loss: 0.7417 - policy_loss: 1.9597 - val_loss: 6.5051 - val_value_loss: 0.8245 - val_policy_loss: 1.9673\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4452 - value_loss: 0.7212 - policy_loss: 1.9511 - val_loss: 6.5136 - val_value_loss: 0.8462 - val_policy_loss: 1.9632\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3745 - value_loss: 0.5888 - policy_loss: 1.9428 - val_loss: 6.4576 - val_value_loss: 0.7361 - val_policy_loss: 1.9619\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3212 - value_loss: 0.4898 - policy_loss: 1.9358 - val_loss: 6.4617 - val_value_loss: 0.7486 - val_policy_loss: 1.9584\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.2948 - value_loss: 0.4434 - policy_loss: 1.9300 - val_loss: 6.4169 - val_value_loss: 0.6614 - val_policy_loss: 1.9566\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2800 - value_loss: 0.4204 - policy_loss: 1.9240 - val_loss: 6.4203 - val_value_loss: 0.6702 - val_policy_loss: 1.9552\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3267 - value_loss: 0.5181 - policy_loss: 1.9203 - val_loss: 6.4587 - val_value_loss: 0.7501 - val_policy_loss: 1.9528\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2814 - value_loss: 0.4320 - policy_loss: 1.9166 - val_loss: 6.4316 - val_value_loss: 0.6973 - val_policy_loss: 1.9520\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2586 - value_loss: 0.3917 - policy_loss: 1.9119 - val_loss: 6.4268 - val_value_loss: 0.6912 - val_policy_loss: 1.9491\n",
      "Saved model  connectfour_num_sim_50_3\n",
      "iteration 3 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.0\n",
      "Number of seen trajectories: 400\n",
      "Number of unique trajectories: 400\n",
      "iteration 4 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_4\n",
      "iteration 4 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5242 - value_loss: 0.8606 - policy_loss: 1.9749 - val_loss: 6.4533 - val_value_loss: 0.7271 - val_policy_loss: 1.9670\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.5022 - value_loss: 0.8277 - policy_loss: 1.9644 - val_loss: 6.5110 - val_value_loss: 0.8445 - val_policy_loss: 1.9655\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4586 - value_loss: 0.7529 - policy_loss: 1.9526 - val_loss: 6.5062 - val_value_loss: 0.8385 - val_policy_loss: 1.9626\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3981 - value_loss: 0.6399 - policy_loss: 1.9453 - val_loss: 6.4266 - val_value_loss: 0.6829 - val_policy_loss: 1.9596\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3564 - value_loss: 0.5659 - policy_loss: 1.9367 - val_loss: 6.4383 - val_value_loss: 0.7042 - val_policy_loss: 1.9624\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3692 - value_loss: 0.5968 - policy_loss: 1.9320 - val_loss: 6.3979 - val_value_loss: 0.6300 - val_policy_loss: 1.9565\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3004 - value_loss: 0.4663 - policy_loss: 1.9254 - val_loss: 6.3940 - val_value_loss: 0.6223 - val_policy_loss: 1.9570\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.2765 - value_loss: 0.4252 - policy_loss: 1.9193 - val_loss: 6.3901 - val_value_loss: 0.6188 - val_policy_loss: 1.9534\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.2771 - value_loss: 0.4324 - policy_loss: 1.9141 - val_loss: 6.4059 - val_value_loss: 0.6527 - val_policy_loss: 1.9518\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.2771 - value_loss: 0.4360 - policy_loss: 1.9110 - val_loss: 6.4026 - val_value_loss: 0.6486 - val_policy_loss: 1.9500\n",
      "Saved model  connectfour_num_sim_50_4\n",
      "iteration 4 | evaluation\n",
      "agent vs random - win ratio 0.65 - draw ratio 0.0\n",
      "Number of seen trajectories: 500\n",
      "Number of unique trajectories: 500\n",
      "iteration 5 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_5\n",
      "iteration 5 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4656 - value_loss: 0.7498 - policy_loss: 1.9748 - val_loss: 6.4474 - val_value_loss: 0.7149 - val_policy_loss: 1.9735\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4190 - value_loss: 0.6627 - policy_loss: 1.9690 - val_loss: 6.4352 - val_value_loss: 0.6931 - val_policy_loss: 1.9713\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3864 - value_loss: 0.6042 - policy_loss: 1.9627 - val_loss: 6.4256 - val_value_loss: 0.6760 - val_policy_loss: 1.9694\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3666 - value_loss: 0.5690 - policy_loss: 1.9585 - val_loss: 6.4177 - val_value_loss: 0.6623 - val_policy_loss: 1.9676\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3466 - value_loss: 0.5337 - policy_loss: 1.9542 - val_loss: 6.4123 - val_value_loss: 0.6534 - val_policy_loss: 1.9661\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3342 - value_loss: 0.5131 - policy_loss: 1.9503 - val_loss: 6.4060 - val_value_loss: 0.6422 - val_policy_loss: 1.9649\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3178 - value_loss: 0.4847 - policy_loss: 1.9463 - val_loss: 6.4004 - val_value_loss: 0.6332 - val_policy_loss: 1.9632\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3077 - value_loss: 0.4687 - policy_loss: 1.9423 - val_loss: 6.3961 - val_value_loss: 0.6261 - val_policy_loss: 1.9619\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.2984 - value_loss: 0.4530 - policy_loss: 1.9397 - val_loss: 6.3926 - val_value_loss: 0.6206 - val_policy_loss: 1.9608\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.2885 - value_loss: 0.4374 - policy_loss: 1.9359 - val_loss: 6.3893 - val_value_loss: 0.6152 - val_policy_loss: 1.9598\n",
      "Saved model  connectfour_num_sim_50_5\n",
      "iteration 5 | evaluation\n",
      "agent vs random - win ratio 0.73 - draw ratio 0.0\n",
      "Number of seen trajectories: 600\n",
      "Number of unique trajectories: 600\n",
      "iteration 6 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_6\n",
      "iteration 6 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4795 - value_loss: 0.7816 - policy_loss: 1.9740 - val_loss: 6.4648 - val_value_loss: 0.7512 - val_policy_loss: 1.9752\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4324 - value_loss: 0.6933 - policy_loss: 1.9684 - val_loss: 6.4478 - val_value_loss: 0.7195 - val_policy_loss: 1.9733\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4033 - value_loss: 0.6410 - policy_loss: 1.9628 - val_loss: 6.4363 - val_value_loss: 0.6982 - val_policy_loss: 1.9717\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3760 - value_loss: 0.5915 - policy_loss: 1.9581 - val_loss: 6.4271 - val_value_loss: 0.6815 - val_policy_loss: 1.9706\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3561 - value_loss: 0.5560 - policy_loss: 1.9540 - val_loss: 6.4419 - val_value_loss: 0.7129 - val_policy_loss: 1.9690\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3364 - value_loss: 0.5214 - policy_loss: 1.9496 - val_loss: 6.4187 - val_value_loss: 0.6683 - val_policy_loss: 1.9675\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3235 - value_loss: 0.4988 - policy_loss: 1.9468 - val_loss: 6.4202 - val_value_loss: 0.6722 - val_policy_loss: 1.9670\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3105 - value_loss: 0.4775 - policy_loss: 1.9424 - val_loss: 6.4139 - val_value_loss: 0.6617 - val_policy_loss: 1.9651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3031 - value_loss: 0.4656 - policy_loss: 1.9398 - val_loss: 6.4064 - val_value_loss: 0.6483 - val_policy_loss: 1.9639\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.2885 - value_loss: 0.4404 - policy_loss: 1.9361 - val_loss: 6.4040 - val_value_loss: 0.6446 - val_policy_loss: 1.9631\n",
      "Saved model  connectfour_num_sim_50_6\n",
      "iteration 6 | evaluation\n",
      "agent vs random - win ratio 0.65 - draw ratio 0.0\n",
      "Number of seen trajectories: 700\n",
      "Number of unique trajectories: 700\n",
      "iteration 7 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_7\n",
      "iteration 7 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4867 - value_loss: 0.7937 - policy_loss: 1.9795 - val_loss: 6.4785 - val_value_loss: 0.7826 - val_policy_loss: 1.9745\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4383 - value_loss: 0.7047 - policy_loss: 1.9720 - val_loss: 6.4623 - val_value_loss: 0.7517 - val_policy_loss: 1.9732\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4047 - value_loss: 0.6444 - policy_loss: 1.9656 - val_loss: 6.4632 - val_value_loss: 0.7562 - val_policy_loss: 1.9710\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3780 - value_loss: 0.5971 - policy_loss: 1.9597 - val_loss: 6.4503 - val_value_loss: 0.7322 - val_policy_loss: 1.9693\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3536 - value_loss: 0.5536 - policy_loss: 1.9548 - val_loss: 6.4348 - val_value_loss: 0.7033 - val_policy_loss: 1.9676\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3341 - value_loss: 0.5197 - policy_loss: 1.9501 - val_loss: 6.4336 - val_value_loss: 0.7032 - val_policy_loss: 1.9656\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3274 - value_loss: 0.5102 - policy_loss: 1.9464 - val_loss: 6.4266 - val_value_loss: 0.6902 - val_policy_loss: 1.9650\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3090 - value_loss: 0.4785 - policy_loss: 1.9415 - val_loss: 6.4200 - val_value_loss: 0.6790 - val_policy_loss: 1.9633\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2955 - value_loss: 0.4554 - policy_loss: 1.9380 - val_loss: 6.4175 - val_value_loss: 0.6756 - val_policy_loss: 1.9620\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2864 - value_loss: 0.4408 - policy_loss: 1.9348 - val_loss: 6.4094 - val_value_loss: 0.6612 - val_policy_loss: 1.9606\n",
      "Saved model  connectfour_num_sim_50_7\n",
      "iteration 7 | evaluation\n",
      "agent vs random - win ratio 0.66 - draw ratio 0.0\n",
      "Number of seen trajectories: 800\n",
      "Number of unique trajectories: 800\n",
      "iteration 8 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_8\n",
      "iteration 8 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4824 - value_loss: 0.8000 - policy_loss: 1.9680 - val_loss: 6.4866 - val_value_loss: 0.8019 - val_policy_loss: 1.9746\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4243 - value_loss: 0.6917 - policy_loss: 1.9604 - val_loss: 6.4635 - val_value_loss: 0.7577 - val_policy_loss: 1.9729\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3951 - value_loss: 0.6391 - policy_loss: 1.9548 - val_loss: 6.4516 - val_value_loss: 0.7347 - val_policy_loss: 1.9725\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3656 - value_loss: 0.5855 - policy_loss: 1.9497 - val_loss: 6.4494 - val_value_loss: 0.7325 - val_policy_loss: 1.9705\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3475 - value_loss: 0.5543 - policy_loss: 1.9450 - val_loss: 6.4373 - val_value_loss: 0.7098 - val_policy_loss: 1.9694\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3384 - value_loss: 0.5406 - policy_loss: 1.9408 - val_loss: 6.4447 - val_value_loss: 0.7256 - val_policy_loss: 1.9686\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3206 - value_loss: 0.5099 - policy_loss: 1.9364 - val_loss: 6.4305 - val_value_loss: 0.6990 - val_policy_loss: 1.9672\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3147 - value_loss: 0.5011 - policy_loss: 1.9336 - val_loss: 6.4302 - val_value_loss: 0.6998 - val_policy_loss: 1.9662\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2975 - value_loss: 0.4716 - policy_loss: 1.9290 - val_loss: 6.4202 - val_value_loss: 0.6811 - val_policy_loss: 1.9652\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2805 - value_loss: 0.4416 - policy_loss: 1.9254 - val_loss: 6.4101 - val_value_loss: 0.6624 - val_policy_loss: 1.9640\n",
      "Saved model  connectfour_num_sim_50_8\n",
      "iteration 8 | evaluation\n",
      "agent vs random - win ratio 0.71 - draw ratio 0.0\n",
      "Number of seen trajectories: 900\n",
      "Number of unique trajectories: 900\n",
      "iteration 9 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_9\n",
      "iteration 9 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4740 - value_loss: 0.7848 - policy_loss: 1.9694 - val_loss: 6.4578 - val_value_loss: 0.7545 - val_policy_loss: 1.9676\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 448us/step - loss: 6.4212 - value_loss: 0.6861 - policy_loss: 1.9629 - val_loss: 6.4349 - val_value_loss: 0.7099 - val_policy_loss: 1.9668\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3867 - value_loss: 0.6225 - policy_loss: 1.9578 - val_loss: 6.4281 - val_value_loss: 0.6967 - val_policy_loss: 1.9665\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3571 - value_loss: 0.5690 - policy_loss: 1.9524 - val_loss: 6.4205 - val_value_loss: 0.6831 - val_policy_loss: 1.9654\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3442 - value_loss: 0.5476 - policy_loss: 1.9485 - val_loss: 6.4140 - val_value_loss: 0.6710 - val_policy_loss: 1.9649\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3313 - value_loss: 0.5255 - policy_loss: 1.9450 - val_loss: 6.4081 - val_value_loss: 0.6604 - val_policy_loss: 1.9639\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3094 - value_loss: 0.4862 - policy_loss: 1.9410 - val_loss: 6.4007 - val_value_loss: 0.6472 - val_policy_loss: 1.9626\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2981 - value_loss: 0.4676 - policy_loss: 1.9373 - val_loss: 6.3959 - val_value_loss: 0.6389 - val_policy_loss: 1.9616\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2968 - value_loss: 0.4687 - policy_loss: 1.9338 - val_loss: 6.4035 - val_value_loss: 0.6554 - val_policy_loss: 1.9608\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.2816 - value_loss: 0.4419 - policy_loss: 1.9306 - val_loss: 6.3873 - val_value_loss: 0.6244 - val_policy_loss: 1.9596\n",
      "Saved model  connectfour_num_sim_50_9\n",
      "iteration 9 | evaluation\n",
      "agent vs random - win ratio 0.77 - draw ratio 0.0\n",
      "Number of seen trajectories: 1000\n",
      "Number of unique trajectories: 1000\n",
      "iteration 10 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_10\n",
      "iteration 10 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4677 - value_loss: 0.7751 - policy_loss: 1.9697 - val_loss: 6.4458 - val_value_loss: 0.7255 - val_policy_loss: 1.9757\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4368 - value_loss: 0.7172 - policy_loss: 1.9661 - val_loss: 6.4370 - val_value_loss: 0.7092 - val_policy_loss: 1.9745\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4151 - value_loss: 0.6764 - policy_loss: 1.9636 - val_loss: 6.4294 - val_value_loss: 0.6953 - val_policy_loss: 1.9735\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3938 - value_loss: 0.6378 - policy_loss: 1.9599 - val_loss: 6.4232 - val_value_loss: 0.6842 - val_policy_loss: 1.9722\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3770 - value_loss: 0.6066 - policy_loss: 1.9574 - val_loss: 6.4187 - val_value_loss: 0.6761 - val_policy_loss: 1.9714\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3651 - value_loss: 0.5850 - policy_loss: 1.9554 - val_loss: 6.4191 - val_value_loss: 0.6781 - val_policy_loss: 1.9705\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3503 - value_loss: 0.5584 - policy_loss: 1.9526 - val_loss: 6.4109 - val_value_loss: 0.6626 - val_policy_loss: 1.9699\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3400 - value_loss: 0.5393 - policy_loss: 1.9513 - val_loss: 6.4068 - val_value_loss: 0.6556 - val_policy_loss: 1.9687\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3313 - value_loss: 0.5244 - policy_loss: 1.9490 - val_loss: 6.4032 - val_value_loss: 0.6494 - val_policy_loss: 1.9679\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3225 - value_loss: 0.5091 - policy_loss: 1.9468 - val_loss: 6.4042 - val_value_loss: 0.6523 - val_policy_loss: 1.9672\n",
      "Saved model  connectfour_num_sim_50_10\n",
      "iteration 10 | evaluation\n",
      "agent vs random - win ratio 0.75 - draw ratio 0.0\n",
      "Number of seen trajectories: 1100\n",
      "Number of unique trajectories: 1100\n",
      "iteration 11 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_11\n",
      "iteration 11 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4905 - value_loss: 0.8208 - policy_loss: 1.9713 - val_loss: 6.4849 - val_value_loss: 0.8098 - val_policy_loss: 1.9711\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4562 - value_loss: 0.7559 - policy_loss: 1.9678 - val_loss: 6.4761 - val_value_loss: 0.7935 - val_policy_loss: 1.9700\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4306 - value_loss: 0.7079 - policy_loss: 1.9647 - val_loss: 6.4673 - val_value_loss: 0.7773 - val_policy_loss: 1.9689\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4127 - value_loss: 0.6750 - policy_loss: 1.9621 - val_loss: 6.4570 - val_value_loss: 0.7577 - val_policy_loss: 1.9681\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3973 - value_loss: 0.6460 - policy_loss: 1.9603 - val_loss: 6.4518 - val_value_loss: 0.7487 - val_policy_loss: 1.9668\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3807 - value_loss: 0.6163 - policy_loss: 1.9571 - val_loss: 6.4449 - val_value_loss: 0.7360 - val_policy_loss: 1.9659\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3681 - value_loss: 0.5935 - policy_loss: 1.9549 - val_loss: 6.4446 - val_value_loss: 0.7355 - val_policy_loss: 1.9660\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3540 - value_loss: 0.5681 - policy_loss: 1.9521 - val_loss: 6.4360 - val_value_loss: 0.7194 - val_policy_loss: 1.9651\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3459 - value_loss: 0.5539 - policy_loss: 1.9504 - val_loss: 6.4343 - val_value_loss: 0.7165 - val_policy_loss: 1.9647\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3332 - value_loss: 0.5309 - policy_loss: 1.9481 - val_loss: 6.4290 - val_value_loss: 0.7066 - val_policy_loss: 1.9641\n",
      "Saved model  connectfour_num_sim_50_11\n",
      "iteration 11 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.0\n",
      "Number of seen trajectories: 1200\n",
      "Number of unique trajectories: 1200\n",
      "iteration 12 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_12\n",
      "iteration 12 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5030 - value_loss: 0.8371 - policy_loss: 1.9816 - val_loss: 6.4698 - val_value_loss: 0.7812 - val_policy_loss: 1.9712\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4682 - value_loss: 0.7713 - policy_loss: 1.9780 - val_loss: 6.4631 - val_value_loss: 0.7683 - val_policy_loss: 1.9709\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4405 - value_loss: 0.7194 - policy_loss: 1.9746 - val_loss: 6.4525 - val_value_loss: 0.7482 - val_policy_loss: 1.9699\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4172 - value_loss: 0.6757 - policy_loss: 1.9718 - val_loss: 6.4478 - val_value_loss: 0.7398 - val_policy_loss: 1.9690\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3999 - value_loss: 0.6438 - policy_loss: 1.9694 - val_loss: 6.4405 - val_value_loss: 0.7257 - val_policy_loss: 1.9688\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3810 - value_loss: 0.6090 - policy_loss: 1.9666 - val_loss: 6.4404 - val_value_loss: 0.7266 - val_policy_loss: 1.9679\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3684 - value_loss: 0.5867 - policy_loss: 1.9638 - val_loss: 6.4352 - val_value_loss: 0.7169 - val_policy_loss: 1.9673\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3568 - value_loss: 0.5655 - policy_loss: 1.9620 - val_loss: 6.4328 - val_value_loss: 0.7130 - val_policy_loss: 1.9666\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3475 - value_loss: 0.5493 - policy_loss: 1.9597 - val_loss: 6.4252 - val_value_loss: 0.6984 - val_policy_loss: 1.9661\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3347 - value_loss: 0.5259 - policy_loss: 1.9577 - val_loss: 6.4233 - val_value_loss: 0.6954 - val_policy_loss: 1.9655\n",
      "Saved model  connectfour_num_sim_50_12\n",
      "iteration 12 | evaluation\n",
      "agent vs random - win ratio 0.63 - draw ratio 0.0\n",
      "Number of seen trajectories: 1300\n",
      "Number of unique trajectories: 1300\n",
      "iteration 13 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_13\n",
      "iteration 13 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4697 - value_loss: 0.7813 - policy_loss: 1.9724 - val_loss: 6.4490 - val_value_loss: 0.7335 - val_policy_loss: 1.9790\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4384 - value_loss: 0.7218 - policy_loss: 1.9695 - val_loss: 6.4382 - val_value_loss: 0.7130 - val_policy_loss: 1.9780\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4139 - value_loss: 0.6761 - policy_loss: 1.9663 - val_loss: 6.4282 - val_value_loss: 0.6942 - val_policy_loss: 1.9769\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3958 - value_loss: 0.6421 - policy_loss: 1.9643 - val_loss: 6.4231 - val_value_loss: 0.6847 - val_policy_loss: 1.9764\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3772 - value_loss: 0.6088 - policy_loss: 1.9606 - val_loss: 6.4178 - val_value_loss: 0.6752 - val_policy_loss: 1.9755\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3624 - value_loss: 0.5811 - policy_loss: 1.9588 - val_loss: 6.4163 - val_value_loss: 0.6734 - val_policy_loss: 1.9745\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3493 - value_loss: 0.5576 - policy_loss: 1.9564 - val_loss: 6.4068 - val_value_loss: 0.6558 - val_policy_loss: 1.9733\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3385 - value_loss: 0.5384 - policy_loss: 1.9540 - val_loss: 6.4008 - val_value_loss: 0.6448 - val_policy_loss: 1.9725\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3291 - value_loss: 0.5219 - policy_loss: 1.9520 - val_loss: 6.4001 - val_value_loss: 0.6442 - val_policy_loss: 1.9717\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3194 - value_loss: 0.5051 - policy_loss: 1.9496 - val_loss: 6.4016 - val_value_loss: 0.6482 - val_policy_loss: 1.9710\n",
      "Saved model  connectfour_num_sim_50_13\n",
      "iteration 13 | evaluation\n",
      "agent vs random - win ratio 0.75 - draw ratio 0.0\n",
      "Number of seen trajectories: 1400\n",
      "Number of unique trajectories: 1400\n",
      "iteration 14 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_14\n",
      "iteration 14 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.4763 - value_loss: 0.7928 - policy_loss: 1.9759 - val_loss: 6.4776 - val_value_loss: 0.7948 - val_policy_loss: 1.9764\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4464 - value_loss: 0.7369 - policy_loss: 1.9720 - val_loss: 6.4724 - val_value_loss: 0.7859 - val_policy_loss: 1.9752\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4235 - value_loss: 0.6945 - policy_loss: 1.9689 - val_loss: 6.4675 - val_value_loss: 0.7778 - val_policy_loss: 1.9737\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4049 - value_loss: 0.6604 - policy_loss: 1.9658 - val_loss: 6.4539 - val_value_loss: 0.7522 - val_policy_loss: 1.9721\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3870 - value_loss: 0.6273 - policy_loss: 1.9633 - val_loss: 6.4475 - val_value_loss: 0.7404 - val_policy_loss: 1.9712\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.3710 - value_loss: 0.5983 - policy_loss: 1.9605 - val_loss: 6.4443 - val_value_loss: 0.7354 - val_policy_loss: 1.9701\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3579 - value_loss: 0.5740 - policy_loss: 1.9587 - val_loss: 6.4386 - val_value_loss: 0.7251 - val_policy_loss: 1.9691\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3515 - value_loss: 0.5632 - policy_loss: 1.9569 - val_loss: 6.4362 - val_value_loss: 0.7217 - val_policy_loss: 1.9680\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3385 - value_loss: 0.5397 - policy_loss: 1.9545 - val_loss: 6.4288 - val_value_loss: 0.7076 - val_policy_loss: 1.9673\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3325 - value_loss: 0.5294 - policy_loss: 1.9530 - val_loss: 6.4320 - val_value_loss: 0.7149 - val_policy_loss: 1.9667\n",
      "Saved model  connectfour_num_sim_50_14\n",
      "iteration 14 | evaluation\n",
      "agent vs random - win ratio 0.73 - draw ratio 0.0\n",
      "Number of seen trajectories: 1500\n",
      "Number of unique trajectories: 1500\n",
      "iteration 15 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_15\n",
      "iteration 15 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.4530 - value_loss: 0.7541 - policy_loss: 1.9694 - val_loss: 6.4564 - val_value_loss: 0.7710 - val_policy_loss: 1.9596\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4348 - value_loss: 0.7203 - policy_loss: 1.9671 - val_loss: 6.4512 - val_value_loss: 0.7613 - val_policy_loss: 1.9588\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4219 - value_loss: 0.6959 - policy_loss: 1.9657 - val_loss: 6.4467 - val_value_loss: 0.7531 - val_policy_loss: 1.9581\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4090 - value_loss: 0.6725 - policy_loss: 1.9633 - val_loss: 6.4420 - val_value_loss: 0.7441 - val_policy_loss: 1.9577\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3982 - value_loss: 0.6525 - policy_loss: 1.9617 - val_loss: 6.4379 - val_value_loss: 0.7366 - val_policy_loss: 1.9572\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3880 - value_loss: 0.6336 - policy_loss: 1.9603 - val_loss: 6.4354 - val_value_loss: 0.7319 - val_policy_loss: 1.9568\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.3798 - value_loss: 0.6192 - policy_loss: 1.9584 - val_loss: 6.4315 - val_value_loss: 0.7247 - val_policy_loss: 1.9563\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3721 - value_loss: 0.6047 - policy_loss: 1.9577 - val_loss: 6.4300 - val_value_loss: 0.7224 - val_policy_loss: 1.9558\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3633 - value_loss: 0.5889 - policy_loss: 1.9558 - val_loss: 6.4263 - val_value_loss: 0.7155 - val_policy_loss: 1.9553\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3556 - value_loss: 0.5753 - policy_loss: 1.9541 - val_loss: 6.4241 - val_value_loss: 0.7116 - val_policy_loss: 1.9549\n",
      "Saved model  connectfour_num_sim_50_15\n",
      "iteration 15 | evaluation\n",
      "agent vs random - win ratio 0.69 - draw ratio 0.0\n",
      "Number of seen trajectories: 1600\n",
      "Number of unique trajectories: 1600\n",
      "iteration 16 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_16\n",
      "iteration 16 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.4776 - value_loss: 0.8039 - policy_loss: 1.9698 - val_loss: 6.4590 - val_value_loss: 0.7636 - val_policy_loss: 1.9728\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4616 - value_loss: 0.7729 - policy_loss: 1.9687 - val_loss: 6.4533 - val_value_loss: 0.7526 - val_policy_loss: 1.9726\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4453 - value_loss: 0.7427 - policy_loss: 1.9665 - val_loss: 6.4483 - val_value_loss: 0.7428 - val_policy_loss: 1.9724\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4316 - value_loss: 0.7170 - policy_loss: 1.9649 - val_loss: 6.4416 - val_value_loss: 0.7298 - val_policy_loss: 1.9720\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4224 - value_loss: 0.6995 - policy_loss: 1.9640 - val_loss: 6.4376 - val_value_loss: 0.7226 - val_policy_loss: 1.9714\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4089 - value_loss: 0.6749 - policy_loss: 1.9617 - val_loss: 6.4341 - val_value_loss: 0.7161 - val_policy_loss: 1.9710\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4003 - value_loss: 0.6586 - policy_loss: 1.9609 - val_loss: 6.4291 - val_value_loss: 0.7067 - val_policy_loss: 1.9705\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3903 - value_loss: 0.6400 - policy_loss: 1.9595 - val_loss: 6.4252 - val_value_loss: 0.6995 - val_policy_loss: 1.9700\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3808 - value_loss: 0.6225 - policy_loss: 1.9581 - val_loss: 6.4221 - val_value_loss: 0.6939 - val_policy_loss: 1.9695\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3776 - value_loss: 0.6168 - policy_loss: 1.9576 - val_loss: 6.4188 - val_value_loss: 0.6876 - val_policy_loss: 1.9691\n",
      "Saved model  connectfour_num_sim_50_16\n",
      "iteration 16 | evaluation\n",
      "agent vs random - win ratio 0.61 - draw ratio 0.0\n",
      "Number of seen trajectories: 1700\n",
      "Number of unique trajectories: 1700\n",
      "iteration 17 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_17\n",
      "iteration 17 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.4878 - value_loss: 0.8176 - policy_loss: 1.9773 - val_loss: 6.4853 - val_value_loss: 0.8097 - val_policy_loss: 1.9800\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4690 - value_loss: 0.7818 - policy_loss: 1.9755 - val_loss: 6.4786 - val_value_loss: 0.7972 - val_policy_loss: 1.9793\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4516 - value_loss: 0.7493 - policy_loss: 1.9733 - val_loss: 6.4709 - val_value_loss: 0.7827 - val_policy_loss: 1.9786\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4383 - value_loss: 0.7245 - policy_loss: 1.9716 - val_loss: 6.4643 - val_value_loss: 0.7699 - val_policy_loss: 1.9782\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4264 - value_loss: 0.7019 - policy_loss: 1.9705 - val_loss: 6.4590 - val_value_loss: 0.7601 - val_policy_loss: 1.9774\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4134 - value_loss: 0.6780 - policy_loss: 1.9683 - val_loss: 6.4539 - val_value_loss: 0.7506 - val_policy_loss: 1.9769\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4064 - value_loss: 0.6646 - policy_loss: 1.9679 - val_loss: 6.4500 - val_value_loss: 0.7436 - val_policy_loss: 1.9762\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.3925 - value_loss: 0.6397 - policy_loss: 1.9650 - val_loss: 6.4469 - val_value_loss: 0.7379 - val_policy_loss: 1.9757\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.3865 - value_loss: 0.6289 - policy_loss: 1.9639 - val_loss: 6.4435 - val_value_loss: 0.7318 - val_policy_loss: 1.9750\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.3778 - value_loss: 0.6131 - policy_loss: 1.9625 - val_loss: 6.4408 - val_value_loss: 0.7272 - val_policy_loss: 1.9745\n",
      "Saved model  connectfour_num_sim_50_17\n",
      "iteration 17 | evaluation\n",
      "agent vs random - win ratio 0.69 - draw ratio 0.0\n",
      "Number of seen trajectories: 1800\n",
      "Number of unique trajectories: 1800\n",
      "iteration 18 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_18\n",
      "iteration 18 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5011 - value_loss: 0.8475 - policy_loss: 1.9747 - val_loss: 6.4893 - val_value_loss: 0.8260 - val_policy_loss: 1.9726\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4827 - value_loss: 0.8129 - policy_loss: 1.9726 - val_loss: 6.4816 - val_value_loss: 0.8110 - val_policy_loss: 1.9723\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4674 - value_loss: 0.7834 - policy_loss: 1.9716 - val_loss: 6.4762 - val_value_loss: 0.8004 - val_policy_loss: 1.9722\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4533 - value_loss: 0.7570 - policy_loss: 1.9698 - val_loss: 6.4694 - val_value_loss: 0.7871 - val_policy_loss: 1.9719\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4387 - value_loss: 0.7296 - policy_loss: 1.9682 - val_loss: 6.4663 - val_value_loss: 0.7813 - val_policy_loss: 1.9717\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4260 - value_loss: 0.7062 - policy_loss: 1.9662 - val_loss: 6.4603 - val_value_loss: 0.7697 - val_policy_loss: 1.9715\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4175 - value_loss: 0.6900 - policy_loss: 1.9654 - val_loss: 6.4562 - val_value_loss: 0.7616 - val_policy_loss: 1.9713\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4053 - value_loss: 0.6677 - policy_loss: 1.9635 - val_loss: 6.4514 - val_value_loss: 0.7524 - val_policy_loss: 1.9710\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3975 - value_loss: 0.6528 - policy_loss: 1.9629 - val_loss: 6.4498 - val_value_loss: 0.7498 - val_policy_loss: 1.9706\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.3858 - value_loss: 0.6313 - policy_loss: 1.9611 - val_loss: 6.4467 - val_value_loss: 0.7439 - val_policy_loss: 1.9703\n",
      "Saved model  connectfour_num_sim_50_18\n",
      "iteration 18 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.0\n",
      "Number of seen trajectories: 1900\n",
      "Number of unique trajectories: 1900\n",
      "iteration 19 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_19\n",
      "iteration 19 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.5278 - value_loss: 0.8978 - policy_loss: 1.9786 - val_loss: 6.5473 - val_value_loss: 0.9296 - val_policy_loss: 1.9858\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.5082 - value_loss: 0.8606 - policy_loss: 1.9768 - val_loss: 6.5385 - val_value_loss: 0.9128 - val_policy_loss: 1.9851\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4911 - value_loss: 0.8284 - policy_loss: 1.9748 - val_loss: 6.5326 - val_value_loss: 0.9018 - val_policy_loss: 1.9844\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4755 - value_loss: 0.7988 - policy_loss: 1.9732 - val_loss: 6.5275 - val_value_loss: 0.8923 - val_policy_loss: 1.9838\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4601 - value_loss: 0.7697 - policy_loss: 1.9716 - val_loss: 6.5208 - val_value_loss: 0.8798 - val_policy_loss: 1.9831\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4497 - value_loss: 0.7500 - policy_loss: 1.9707 - val_loss: 6.5170 - val_value_loss: 0.8729 - val_policy_loss: 1.9825\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4345 - value_loss: 0.7217 - policy_loss: 1.9686 - val_loss: 6.5115 - val_value_loss: 0.8625 - val_policy_loss: 1.9819\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4262 - value_loss: 0.7058 - policy_loss: 1.9679 - val_loss: 6.5062 - val_value_loss: 0.8528 - val_policy_loss: 1.9810\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4173 - value_loss: 0.6897 - policy_loss: 1.9664 - val_loss: 6.5017 - val_value_loss: 0.8446 - val_policy_loss: 1.9804\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4068 - value_loss: 0.6698 - policy_loss: 1.9653 - val_loss: 6.4970 - val_value_loss: 0.8358 - val_policy_loss: 1.9797\n",
      "Saved model  connectfour_num_sim_50_19\n",
      "iteration 19 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.0\n",
      "Number of seen trajectories: 2000\n",
      "Number of unique trajectories: 2000\n",
      "iteration 20 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_20\n",
      "iteration 20 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 2s 458us/step - loss: 6.5223 - value_loss: 0.8813 - policy_loss: 1.9849 - val_loss: 6.5179 - val_value_loss: 0.8713 - val_policy_loss: 1.9860\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 458us/step - loss: 6.5133 - value_loss: 0.8639 - policy_loss: 1.9843 - val_loss: 6.5147 - val_value_loss: 0.8656 - val_policy_loss: 1.9856\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 456us/step - loss: 6.5015 - value_loss: 0.8418 - policy_loss: 1.9829 - val_loss: 6.5114 - val_value_loss: 0.8594 - val_policy_loss: 1.9852\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 460us/step - loss: 6.4930 - value_loss: 0.8253 - policy_loss: 1.9823 - val_loss: 6.5081 - val_value_loss: 0.8532 - val_policy_loss: 1.9848\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 458us/step - loss: 6.4862 - value_loss: 0.8129 - policy_loss: 1.9812 - val_loss: 6.5053 - val_value_loss: 0.8480 - val_policy_loss: 1.9845\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 462us/step - loss: 6.4771 - value_loss: 0.7954 - policy_loss: 1.9806 - val_loss: 6.5029 - val_value_loss: 0.8435 - val_policy_loss: 1.9842\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 460us/step - loss: 6.4722 - value_loss: 0.7859 - policy_loss: 1.9803 - val_loss: 6.5004 - val_value_loss: 0.8389 - val_policy_loss: 1.9839\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 460us/step - loss: 6.4640 - value_loss: 0.7709 - policy_loss: 1.9789 - val_loss: 6.4984 - val_value_loss: 0.8351 - val_policy_loss: 1.9836\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 463us/step - loss: 6.4565 - value_loss: 0.7567 - policy_loss: 1.9782 - val_loss: 6.4959 - val_value_loss: 0.8305 - val_policy_loss: 1.9833\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 458us/step - loss: 6.4494 - value_loss: 0.7435 - policy_loss: 1.9772 - val_loss: 6.4938 - val_value_loss: 0.8267 - val_policy_loss: 1.9830\n",
      "Saved model  connectfour_num_sim_50_20\n",
      "iteration 20 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.0\n",
      "Number of seen trajectories: 2100\n",
      "Number of unique trajectories: 2099\n",
      "iteration 21 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_21\n",
      "iteration 21 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5235 - value_loss: 0.8877 - policy_loss: 1.9813 - val_loss: 6.5187 - val_value_loss: 0.8858 - val_policy_loss: 1.9736\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5118 - value_loss: 0.8652 - policy_loss: 1.9804 - val_loss: 6.5137 - val_value_loss: 0.8764 - val_policy_loss: 1.9731\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4997 - value_loss: 0.8425 - policy_loss: 1.9790 - val_loss: 6.5090 - val_value_loss: 0.8675 - val_policy_loss: 1.9727\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4913 - value_loss: 0.8265 - policy_loss: 1.9781 - val_loss: 6.5060 - val_value_loss: 0.8619 - val_policy_loss: 1.9722\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4829 - value_loss: 0.8102 - policy_loss: 1.9778 - val_loss: 6.5018 - val_value_loss: 0.8540 - val_policy_loss: 1.9718\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4753 - value_loss: 0.7960 - policy_loss: 1.9768 - val_loss: 6.4987 - val_value_loss: 0.8482 - val_policy_loss: 1.9715\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4684 - value_loss: 0.7832 - policy_loss: 1.9759 - val_loss: 6.4957 - val_value_loss: 0.8425 - val_policy_loss: 1.9712\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4590 - value_loss: 0.7654 - policy_loss: 1.9750 - val_loss: 6.4938 - val_value_loss: 0.8390 - val_policy_loss: 1.9709\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4532 - value_loss: 0.7545 - policy_loss: 1.9742 - val_loss: 6.4906 - val_value_loss: 0.8330 - val_policy_loss: 1.9706\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4454 - value_loss: 0.7401 - policy_loss: 1.9732 - val_loss: 6.4873 - val_value_loss: 0.8268 - val_policy_loss: 1.9702\n",
      "Saved model  connectfour_num_sim_50_21\n",
      "iteration 21 | evaluation\n",
      "agent vs random - win ratio 0.72 - draw ratio 0.0\n",
      "Number of seen trajectories: 2200\n",
      "Number of unique trajectories: 2199\n",
      "iteration 22 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_22\n",
      "iteration 22 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.5303 - value_loss: 0.9055 - policy_loss: 1.9776 - val_loss: 6.5148 - val_value_loss: 0.8884 - val_policy_loss: 1.9637\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.5175 - value_loss: 0.8815 - policy_loss: 1.9759 - val_loss: 6.5094 - val_value_loss: 0.8779 - val_policy_loss: 1.9634\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5065 - value_loss: 0.8600 - policy_loss: 1.9756 - val_loss: 6.5055 - val_value_loss: 0.8704 - val_policy_loss: 1.9632\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4969 - value_loss: 0.8419 - policy_loss: 1.9745 - val_loss: 6.5006 - val_value_loss: 0.8609 - val_policy_loss: 1.9630\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4878 - value_loss: 0.8242 - policy_loss: 1.9739 - val_loss: 6.4975 - val_value_loss: 0.8548 - val_policy_loss: 1.9628\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4798 - value_loss: 0.8095 - policy_loss: 1.9728 - val_loss: 6.4945 - val_value_loss: 0.8490 - val_policy_loss: 1.9626\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4707 - value_loss: 0.7921 - policy_loss: 1.9719 - val_loss: 6.4912 - val_value_loss: 0.8426 - val_policy_loss: 1.9625\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4635 - value_loss: 0.7787 - policy_loss: 1.9710 - val_loss: 6.4884 - val_value_loss: 0.8372 - val_policy_loss: 1.9624\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4577 - value_loss: 0.7674 - policy_loss: 1.9707 - val_loss: 6.4860 - val_value_loss: 0.8326 - val_policy_loss: 1.9623\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4509 - value_loss: 0.7549 - policy_loss: 1.9697 - val_loss: 6.4831 - val_value_loss: 0.8269 - val_policy_loss: 1.9621\n",
      "Saved model  connectfour_num_sim_50_22\n",
      "iteration 22 | evaluation\n",
      "agent vs random - win ratio 0.8 - draw ratio 0.0\n",
      "Number of seen trajectories: 2300\n",
      "Number of unique trajectories: 2299\n",
      "iteration 23 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_23\n",
      "iteration 23 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 455us/step - loss: 6.5119 - value_loss: 0.8682 - policy_loss: 1.9785 - val_loss: 6.4937 - val_value_loss: 0.8395 - val_policy_loss: 1.9707\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.5026 - value_loss: 0.8504 - policy_loss: 1.9777 - val_loss: 6.4879 - val_value_loss: 0.8285 - val_policy_loss: 1.9702\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4911 - value_loss: 0.8283 - policy_loss: 1.9769 - val_loss: 6.4843 - val_value_loss: 0.8218 - val_policy_loss: 1.9698\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4804 - value_loss: 0.8087 - policy_loss: 1.9750 - val_loss: 6.4812 - val_value_loss: 0.8160 - val_policy_loss: 1.9694\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4728 - value_loss: 0.7938 - policy_loss: 1.9749 - val_loss: 6.4782 - val_value_loss: 0.8104 - val_policy_loss: 1.9691\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4638 - value_loss: 0.7771 - policy_loss: 1.9736 - val_loss: 6.4753 - val_value_loss: 0.8048 - val_policy_loss: 1.9688\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4554 - value_loss: 0.7612 - policy_loss: 1.9726 - val_loss: 6.4726 - val_value_loss: 0.7998 - val_policy_loss: 1.9685\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4491 - value_loss: 0.7491 - policy_loss: 1.9722 - val_loss: 6.4692 - val_value_loss: 0.7934 - val_policy_loss: 1.9682\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4421 - value_loss: 0.7361 - policy_loss: 1.9712 - val_loss: 6.4667 - val_value_loss: 0.7887 - val_policy_loss: 1.9679\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4349 - value_loss: 0.7223 - policy_loss: 1.9707 - val_loss: 6.4647 - val_value_loss: 0.7851 - val_policy_loss: 1.9675\n",
      "Saved model  connectfour_num_sim_50_23\n",
      "iteration 23 | evaluation\n",
      "agent vs random - win ratio 0.7 - draw ratio 0.0\n",
      "Number of seen trajectories: 2400\n",
      "Number of unique trajectories: 2399\n",
      "iteration 24 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_24\n",
      "iteration 24 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5150 - value_loss: 0.8741 - policy_loss: 1.9791 - val_loss: 6.4842 - val_value_loss: 0.8073 - val_policy_loss: 1.9844\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.5023 - value_loss: 0.8498 - policy_loss: 1.9780 - val_loss: 6.4805 - val_value_loss: 0.8003 - val_policy_loss: 1.9841\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.4930 - value_loss: 0.8324 - policy_loss: 1.9769 - val_loss: 6.4781 - val_value_loss: 0.7958 - val_policy_loss: 1.9838\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4828 - value_loss: 0.8128 - policy_loss: 1.9762 - val_loss: 6.4743 - val_value_loss: 0.7883 - val_policy_loss: 1.9836\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4731 - value_loss: 0.7944 - policy_loss: 1.9752 - val_loss: 6.4691 - val_value_loss: 0.7782 - val_policy_loss: 1.9834\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4658 - value_loss: 0.7805 - policy_loss: 1.9746 - val_loss: 6.4665 - val_value_loss: 0.7732 - val_policy_loss: 1.9833\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4570 - value_loss: 0.7637 - policy_loss: 1.9738 - val_loss: 6.4631 - val_value_loss: 0.7667 - val_policy_loss: 1.9830\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.4522 - value_loss: 0.7542 - policy_loss: 1.9737 - val_loss: 6.4613 - val_value_loss: 0.7633 - val_policy_loss: 1.9829\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4430 - value_loss: 0.7371 - policy_loss: 1.9725 - val_loss: 6.4590 - val_value_loss: 0.7588 - val_policy_loss: 1.9827\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4358 - value_loss: 0.7233 - policy_loss: 1.9719 - val_loss: 6.4576 - val_value_loss: 0.7563 - val_policy_loss: 1.9825\n",
      "Saved model  connectfour_num_sim_50_24\n",
      "iteration 24 | evaluation\n",
      "agent vs random - win ratio 0.81 - draw ratio 0.0\n",
      "Number of seen trajectories: 2500\n",
      "Number of unique trajectories: 2499\n",
      "iteration 25 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_25\n",
      "iteration 25 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 453us/step - loss: 6.5267 - value_loss: 0.8923 - policy_loss: 1.9847 - val_loss: 6.5224 - val_value_loss: 0.8963 - val_policy_loss: 1.9722\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5214 - value_loss: 0.8824 - policy_loss: 1.9840 - val_loss: 6.5199 - val_value_loss: 0.8916 - val_policy_loss: 1.9719\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5141 - value_loss: 0.8689 - policy_loss: 1.9831 - val_loss: 6.5176 - val_value_loss: 0.8872 - val_policy_loss: 1.9716\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5086 - value_loss: 0.8583 - policy_loss: 1.9826 - val_loss: 6.5153 - val_value_loss: 0.8828 - val_policy_loss: 1.9714\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5054 - value_loss: 0.8523 - policy_loss: 1.9822 - val_loss: 6.5131 - val_value_loss: 0.8788 - val_policy_loss: 1.9712\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5014 - value_loss: 0.8447 - policy_loss: 1.9818 - val_loss: 6.5110 - val_value_loss: 0.8747 - val_policy_loss: 1.9710\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4951 - value_loss: 0.8326 - policy_loss: 1.9814 - val_loss: 6.5092 - val_value_loss: 0.8712 - val_policy_loss: 1.9709\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4902 - value_loss: 0.8234 - policy_loss: 1.9808 - val_loss: 6.5074 - val_value_loss: 0.8680 - val_policy_loss: 1.9707\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.4871 - value_loss: 0.8177 - policy_loss: 1.9802 - val_loss: 6.5056 - val_value_loss: 0.8644 - val_policy_loss: 1.9706\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4824 - value_loss: 0.8089 - policy_loss: 1.9797 - val_loss: 6.5038 - val_value_loss: 0.8611 - val_policy_loss: 1.9704\n",
      "Saved model  connectfour_num_sim_50_25\n",
      "iteration 25 | evaluation\n",
      "agent vs random - win ratio 0.73 - draw ratio 0.0\n",
      "Number of seen trajectories: 2600\n",
      "Number of unique trajectories: 2599\n",
      "iteration 26 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_26\n",
      "iteration 26 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5425 - value_loss: 0.9330 - policy_loss: 1.9760 - val_loss: 6.5376 - val_value_loss: 0.9159 - val_policy_loss: 1.9831\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.5357 - value_loss: 0.9197 - policy_loss: 1.9756 - val_loss: 6.5351 - val_value_loss: 0.9110 - val_policy_loss: 1.9830\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5303 - value_loss: 0.9087 - policy_loss: 1.9759 - val_loss: 6.5329 - val_value_loss: 0.9068 - val_policy_loss: 1.9829\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5251 - value_loss: 0.8990 - policy_loss: 1.9751 - val_loss: 6.5305 - val_value_loss: 0.9022 - val_policy_loss: 1.9828\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5189 - value_loss: 0.8875 - policy_loss: 1.9742 - val_loss: 6.5283 - val_value_loss: 0.8979 - val_policy_loss: 1.9827\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5156 - value_loss: 0.8806 - policy_loss: 1.9745 - val_loss: 6.5266 - val_value_loss: 0.8946 - val_policy_loss: 1.9826\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5100 - value_loss: 0.8699 - policy_loss: 1.9740 - val_loss: 6.5242 - val_value_loss: 0.8899 - val_policy_loss: 1.9825\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5045 - value_loss: 0.8598 - policy_loss: 1.9733 - val_loss: 6.5223 - val_value_loss: 0.8862 - val_policy_loss: 1.9824\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5011 - value_loss: 0.8531 - policy_loss: 1.9731 - val_loss: 6.5202 - val_value_loss: 0.8822 - val_policy_loss: 1.9823\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4957 - value_loss: 0.8430 - policy_loss: 1.9726 - val_loss: 6.5184 - val_value_loss: 0.8787 - val_policy_loss: 1.9822\n",
      "Saved model  connectfour_num_sim_50_26\n",
      "iteration 26 | evaluation\n",
      "agent vs random - win ratio 0.66 - draw ratio 0.0\n",
      "Number of seen trajectories: 2700\n",
      "Number of unique trajectories: 2699\n",
      "iteration 27 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_27\n",
      "iteration 27 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5632 - value_loss: 0.9745 - policy_loss: 1.9760 - val_loss: 6.5734 - val_value_loss: 0.9905 - val_policy_loss: 1.9803\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.5567 - value_loss: 0.9615 - policy_loss: 1.9761 - val_loss: 6.5703 - val_value_loss: 0.9846 - val_policy_loss: 1.9801\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5496 - value_loss: 0.9476 - policy_loss: 1.9757 - val_loss: 6.5676 - val_value_loss: 0.9795 - val_policy_loss: 1.9799\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5461 - value_loss: 0.9411 - policy_loss: 1.9752 - val_loss: 6.5651 - val_value_loss: 0.9746 - val_policy_loss: 1.9797\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5387 - value_loss: 0.9276 - policy_loss: 1.9740 - val_loss: 6.5626 - val_value_loss: 0.9698 - val_policy_loss: 1.9795\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5331 - value_loss: 0.9170 - policy_loss: 1.9734 - val_loss: 6.5601 - val_value_loss: 0.9652 - val_policy_loss: 1.9793\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5290 - value_loss: 0.9087 - policy_loss: 1.9735 - val_loss: 6.5579 - val_value_loss: 0.9610 - val_policy_loss: 1.9791\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5228 - value_loss: 0.8970 - policy_loss: 1.9729 - val_loss: 6.5558 - val_value_loss: 0.9568 - val_policy_loss: 1.9790\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5191 - value_loss: 0.8898 - policy_loss: 1.9725 - val_loss: 6.5535 - val_value_loss: 0.9525 - val_policy_loss: 1.9788\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5144 - value_loss: 0.8809 - policy_loss: 1.9722 - val_loss: 6.5515 - val_value_loss: 0.9488 - val_policy_loss: 1.9786\n",
      "Saved model  connectfour_num_sim_50_27\n",
      "iteration 27 | evaluation\n",
      "agent vs random - win ratio 0.74 - draw ratio 0.0\n",
      "Number of seen trajectories: 2800\n",
      "Number of unique trajectories: 2799\n",
      "iteration 28 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_28\n",
      "iteration 28 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5587 - value_loss: 0.9612 - policy_loss: 1.9805 - val_loss: 6.5571 - val_value_loss: 0.9668 - val_policy_loss: 1.9716\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5531 - value_loss: 0.9503 - policy_loss: 1.9802 - val_loss: 6.5536 - val_value_loss: 0.9602 - val_policy_loss: 1.9714\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.5464 - value_loss: 0.9380 - policy_loss: 1.9792 - val_loss: 6.5504 - val_value_loss: 0.9539 - val_policy_loss: 1.9712\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5408 - value_loss: 0.9269 - policy_loss: 1.9789 - val_loss: 6.5473 - val_value_loss: 0.9480 - val_policy_loss: 1.9710\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.5365 - value_loss: 0.9186 - policy_loss: 1.9788 - val_loss: 6.5442 - val_value_loss: 0.9420 - val_policy_loss: 1.9708\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.5308 - value_loss: 0.9077 - policy_loss: 1.9783 - val_loss: 6.5414 - val_value_loss: 0.9366 - val_policy_loss: 1.9706\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5267 - value_loss: 0.8997 - policy_loss: 1.9782 - val_loss: 6.5387 - val_value_loss: 0.9313 - val_policy_loss: 1.9705\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5196 - value_loss: 0.8861 - policy_loss: 1.9774 - val_loss: 6.5362 - val_value_loss: 0.9264 - val_policy_loss: 1.9703\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.5150 - value_loss: 0.8774 - policy_loss: 1.9770 - val_loss: 6.5337 - val_value_loss: 0.9216 - val_policy_loss: 1.9702\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5099 - value_loss: 0.8677 - policy_loss: 1.9765 - val_loss: 6.5313 - val_value_loss: 0.9171 - val_policy_loss: 1.9700\n",
      "Saved model  connectfour_num_sim_50_28\n",
      "iteration 28 | evaluation\n",
      "agent vs random - win ratio 0.67 - draw ratio 0.0\n",
      "Number of seen trajectories: 2900\n",
      "Number of unique trajectories: 2899\n",
      "iteration 29 | self-play\n",
      "saving memory position_memory_connectfour_num_sim_50_ep_29\n",
      "iteration 29 | optimization\n",
      "num_positions: 5120\n",
      "model_X shape: (5120, 6, 7, 3)\n",
      "model_y_outcomes: (5120,)\n",
      "model_y_probabilities: (5120, 7)\n",
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 2s 454us/step - loss: 6.5389 - value_loss: 0.9324 - policy_loss: 1.9699 - val_loss: 6.5462 - val_value_loss: 0.9346 - val_policy_loss: 1.9823\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 2s 449us/step - loss: 6.5323 - value_loss: 0.9193 - policy_loss: 1.9698 - val_loss: 6.5442 - val_value_loss: 0.9309 - val_policy_loss: 1.9821\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5272 - value_loss: 0.9095 - policy_loss: 1.9695 - val_loss: 6.5419 - val_value_loss: 0.9263 - val_policy_loss: 1.9820\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5220 - value_loss: 0.8998 - policy_loss: 1.9686 - val_loss: 6.5391 - val_value_loss: 0.9211 - val_policy_loss: 1.9817\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5164 - value_loss: 0.8893 - policy_loss: 1.9681 - val_loss: 6.5368 - val_value_loss: 0.9166 - val_policy_loss: 1.9816\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 2s 450us/step - loss: 6.5107 - value_loss: 0.8780 - policy_loss: 1.9679 - val_loss: 6.5348 - val_value_loss: 0.9128 - val_policy_loss: 1.9814\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5064 - value_loss: 0.8700 - policy_loss: 1.9675 - val_loss: 6.5329 - val_value_loss: 0.9092 - val_policy_loss: 1.9812\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 2s 451us/step - loss: 6.5031 - value_loss: 0.8629 - policy_loss: 1.9678 - val_loss: 6.5308 - val_value_loss: 0.9052 - val_policy_loss: 1.9811\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4985 - value_loss: 0.8550 - policy_loss: 1.9667 - val_loss: 6.5289 - val_value_loss: 0.9015 - val_policy_loss: 1.9809\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 2s 452us/step - loss: 6.4930 - value_loss: 0.8444 - policy_loss: 1.9663 - val_loss: 6.5267 - val_value_loss: 0.8974 - val_policy_loss: 1.9807\n",
      "Saved model  connectfour_num_sim_50_29\n",
      "iteration 29 | evaluation\n",
      "agent vs random - win ratio 0.77 - draw ratio 0.0\n",
      "Number of seen trajectories: 3000\n",
      "Number of unique trajectories: 2999\n"
     ]
    }
   ],
   "source": [
    "wins_5, draws_5, seen_trajectories_5, unique_trajectories_5 = test_pipeline.run(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - 50 simulations\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "losses_5 = np.ones(30) - wins_5 - draws_5\n",
    "\n",
    "plt.plot(x, wins_5, label=\"win ratio\")\n",
    "plt.plot(x, draws_5, label=\"draw ratio\")\n",
    "plt.plot(x, losses_5, label=\"loss ratio\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "exploration_rate_5 = unique_trajectories_5/seen_trajectories_5\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Evaluation - 50 simulations\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ratio\")\n",
    "\n",
    "x = np.arange(30)\n",
    "plt.plot(x, exploration_rate_5, label=\"unique/seen\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins_5 = [0.76, 0.6, 0.7, 0.7, 0.65, 0.73, 0.65, 0.66, 0.71, 0.77, 0.75, 0.74, 0.63, 0.75, 0.73, 0.69, 0.61, 0.69, 0.74, 0.7, 0.8, 0.72, 0.8, 0.7, 0.81, 0.73, 0.66, 0.74, 0.67, 0.77]\n",
      "draws_5 = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "seen_trajectories_5 = [ 100.  200.  300.  400.  500.  600.  700.  800.  900. 1000. 1100. 1200.\n",
      " 1300. 1400. 1500. 1600. 1700. 1800. 1900. 2000. 2100. 2200. 2300. 2400.\n",
      " 2500. 2600. 2700. 2800. 2900. 3000.]\n",
      "unique_trajectories_5 = [ 100.  200.  300.  400.  500.  600.  700.  800.  900. 1000. 1100. 1200.\n",
      " 1300. 1400. 1500. 1600. 1700. 1800. 1900. 2000. 2099. 2199. 2299. 2399.\n",
      " 2499. 2599. 2699. 2799. 2899. 2999.]\n"
     ]
    }
   ],
   "source": [
    "print(\"wins_5 =\",wins_5)\n",
    "print(\"draws_5 =\",draws_5)\n",
    "print(\"seen_trajectories_5 =\", seen_trajectories_5)\n",
    "print(\"unique_trajectories_5 =\", unique_trajectories_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(data, window_size):\n",
    "    return np.convolve(data, np.ones((window_size,))/window_size, mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 simulation\n",
    "wins_1 = [0.67, 0.51, 0.62, 0.54, 0.5, 0.63, 0.58, 0.56, 0.61, 0.53, 0.63, 0.52, 0.43, 0.55, 0.57, 0.6, 0.65, 0.62, 0.56, 0.6, 0.53, 0.54, 0.47, 0.62, 0.56, 0.56, 0.42, 0.48, 0.53, 0.65]\n",
    "draws_1 = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "seen_trajectories_1 = [ 100,  200,  300,  400,  500,  600,  700,  800,  900, 1000, 1100, 1200,\n",
    " 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400,\n",
    " 2500, 2600, 2700, 2800, 2900, 3000]\n",
    "unique_trajectories_1 = [ 100,  200,  300,  400,  500,  600,  700,  800,  900, 1000, 1100, 1200,\n",
    " 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400,\n",
    " 2500, 2600, 2700, 2800, 2900, 3000]\n",
    "\n",
    "# 5 simulations\n",
    "wins_2 = [0.72, 0.55, 0.68, 0.59, 0.57, 0.59, 0.64, 0.69, 0.62, 0.75, 0.68, 0.64, 0.74, 0.65, 0.64, 0.68, 0.74, 0.65, 0.69, 0.61, 0.57, 0.62, 0.66, 0.71, 0.58, 0.67, 0.68, 0.66, 0.59, 0.71]\n",
    "draws_2 = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "seen_trajectories_2 = [ 100,  200,  300,  400,  500,  600,  700,  800,  900, 1000, 1100, 1200,\n",
    " 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400,\n",
    " 2500, 2600, 2700, 2800, 2900, 3000]\n",
    "unique_trajectories_2 = [ 100,  200,  300,  400,  500,  600,  700,  800,  900, 1000, 1100, 1200,\n",
    " 1300, 1399, 1499, 1599, 1699, 1798, 1898, 1998, 2098, 2198, 2298, 2398,\n",
    " 2496, 2596, 2695, 2793, 2893, 2992]\n",
    "\n",
    "# 10 simulations\n",
    "wins_3 = [0.77, 0.71, 0.71, 0.75, 0.7, 0.56, 0.7, 0.71, 0.75, 0.79, 0.67, 0.67, 0.72, 0.68, 0.76, 0.75, 0.82, 0.81, 0.73, 0.8, 0.74, 0.75, 0.67, 0.75, 0.73, 0.73, 0.78, 0.59, 0.64, 0.77]\n",
    "draws_3 = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "seen_trajectories_3 = [ 100,  200,  300,  400,  500,  600,  700,  800,  900, 1000, 1100, 1200,\n",
    " 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400,\n",
    " 2500, 2600, 2700, 2800, 2900, 3000]\n",
    "unique_trajectories_3 = [ 100,  200,  300,  400,  500,  600,  700,  800,  900, 1000, 1100, 1200,\n",
    " 1300, 1399, 1499, 1599, 1699, 1799, 1899, 1999, 2099, 2198, 2298, 2398,\n",
    " 2498, 2598, 2697, 2797, 2897, 2997]\n",
    "\n",
    "# 25 simulations\n",
    "wins_4 = [0.61, 0.71, 0.73, 0.76, 0.74, 0.66, 0.68, 0.66, 0.75, 0.76, 0.67, 0.76, 0.77, 0.71, 0.7, 0.73, 0.79, 0.7, 0.72, 0.74, 0.86, 0.72, 0.74, 0.75, 0.73, 0.72, 0.78, 0.74, 0.76, 0.76]\n",
    "draws_4 = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "seen_trajectories_4= [ 100,  200,  300,  400,  500,  600,  700,  800,  900, 1000, 1100, 1200,\n",
    " 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400,\n",
    " 2500, 2600, 2700, 2800, 2900, 3000]\n",
    "unique_trajectories_4 = [ 100,  200,  300,  400,  500,  600,  700,  800,  900, 1000, 1100, 1200,\n",
    " 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2199, 2299, 2398,\n",
    " 2497, 2597, 2697, 2796, 2896, 2996]\n",
    "\n",
    "# 50 simulations\n",
    "wins_5 = [0.76, 0.6, 0.7, 0.7, 0.65, 0.73, 0.65, 0.66, 0.71, 0.77, 0.75, 0.74, 0.63, 0.75, 0.73, 0.69, 0.61, 0.69, 0.74, 0.7, 0.8, 0.72, 0.8, 0.7, 0.81, 0.73, 0.66, 0.74, 0.67, 0.77]\n",
    "draws_5 = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "seen_trajectories_5 = [ 100,  200,  300,  400,  500,  600,  700,  800,  900, 1000, 1100, 1200,\n",
    " 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400,\n",
    " 2500, 2600, 2700, 2800, 2900, 3000]\n",
    "unique_trajectories_5 = [ 100,  200,  300,  400,  500,  600,  700,  800,  900, 1000, 1100, 1200,\n",
    " 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2099, 2199, 2299, 2399,\n",
    " 2499, 2599, 2699, 2799, 2899, 2999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_size = 3\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "\n",
    "plt.title(\"Evaluation - Win ratio\")\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Win ratio\")\n",
    "\n",
    "x = np.arange(30 - window_size + 1)\n",
    "\n",
    "plt.plot(x, smooth(wins_1, window_size), label=\"1 simulation\")\n",
    "plt.plot(x, smooth(wins_2, window_size), label=\"5 simulations\")\n",
    "plt.plot(x, smooth(wins_3, window_size), label=\"10 simulations\")\n",
    "plt.plot(x, smooth(wins_4, window_size), label=\"25 simulations\")\n",
    "plt.plot(x, smooth(wins_5, window_size), label=\"50 simulations\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_rate_1 = np.array(unique_trajectories_1)/np.array(seen_trajectories_1)\n",
    "exp_rate_2 = np.array(unique_trajectories_2)/np.array(seen_trajectories_2)\n",
    "exp_rate_3 = np.array(unique_trajectories_3)/np.array(seen_trajectories_3)\n",
    "exp_rate_4 = np.array(unique_trajectories_4)/np.array(seen_trajectories_4)\n",
    "exp_rate_5 = np.array(unique_trajectories_5)/np.array(seen_trajectories_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_size = 1\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "\n",
    "plt.title(\"Evaluation - Exploration rate\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"exploration rate (unique/seen)\")\n",
    "\n",
    "x = np.arange(30 - window_size + 1)\n",
    "\n",
    "plt.plot(x, smooth(exp_rate_1, window_size), label=\"1 simulation\")\n",
    "plt.plot(x, smooth(exp_rate_2, window_size), label=\"5 simulations\")\n",
    "plt.plot(x, smooth(exp_rate_3, window_size), label=\"10 simulations\")\n",
    "plt.plot(x, smooth(exp_rate_4, window_size), label=\"25 simulations\")\n",
    "plt.plot(x, smooth(exp_rate_5, window_size), label=\"50 simulations\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
